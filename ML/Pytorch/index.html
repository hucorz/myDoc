
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://hucorz.github.io/myDoc/ML/Pytorch/">
      
      <link rel="icon" href="../../img/favicon.ico">
      <meta name="generator" content="mkdocs-1.3.0, mkdocs-material-8.3.4">
    
    
      
        <title>Pytorch - hucorz's Docs</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.4a0965b7.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.cbb835fc.min.css">
        
          
          
          <meta name="theme-color" content="#ffffff">
        
      
      
    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="white" data-md-color-accent="indigo">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#pytorch" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="hucorz&#39;s Docs" class="md-header__button md-logo" aria-label="hucorz's Docs" data-md-component="logo">
      
  <img src="../../img/cat-solid.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            hucorz's Docs
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Pytorch
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/hucorz/myDoc" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg>
  </div>
  <div class="md-source__repository">
    hucorz/myDoc
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  <li class="md-tabs__item">
    <a href="../.." class="md-tabs__link">
      Home
    </a>
  </li>

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../OI/%E5%8F%82%E8%80%83/" class="md-tabs__link">
        OI
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/" class="md-tabs__link">
        笔记
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../%E5%89%8D%E7%AB%AF/HTML/" class="md-tabs__link">
        前端
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../Python/%E8%AF%B4%E6%98%8E/" class="md-tabs__link">
        Python
      </a>
    </li>
  

      
        
  
  
    
  


  
  
  
    <li class="md-tabs__item">
      <a href="../%E8%AF%B4%E6%98%8E/" class="md-tabs__link md-tabs__link--active">
        ML
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../%E5%85%B6%E4%BB%96/Mkdocs/" class="md-tabs__link">
        其他
      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="hucorz&#39;s Docs" class="md-nav__button md-logo" aria-label="hucorz's Docs" data-md-component="logo">
      
  <img src="../../img/cat-solid.svg" alt="logo">

    </a>
    hucorz's Docs
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/hucorz/myDoc" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg>
  </div>
  <div class="md-source__repository">
    hucorz/myDoc
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2">
          OI
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="OI" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          OI
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../OI/%E5%8F%82%E8%80%83/" class="md-nav__link">
        参考
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../OI/%E6%95%B0%E8%AE%BA/" class="md-nav__link">
        数论
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../OI/%E8%AE%A1%E7%AE%97%E5%87%A0%E4%BD%95/" class="md-nav__link">
        计算几何
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../OI/%E5%9B%BE%E8%AE%BA/" class="md-nav__link">
        图论
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../OI/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" class="md-nav__link">
        数据结构
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../OI/%E5%AD%97%E7%AC%A6%E4%B8%B2/" class="md-nav__link">
        字符串
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../OI/%E5%85%B6%E4%BB%96/" class="md-nav__link">
        其他
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../OI/STL/" class="md-nav__link">
        STL
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          笔记
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="笔记" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          笔记
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/" class="md-nav__link">
        数据库系统
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_2" type="checkbox" id="__nav_3_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3_2">
          线性代数
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="线性代数" data-md-level="2">
        <label class="md-nav__title" for="__nav_3_2">
          <span class="md-nav__icon md-icon"></span>
          线性代数
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../笔记/线性代数/说明.md" class="md-nav__link">
        说明
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../笔记/线性代数/Chapter1.md" class="md-nav__link">
        Chapter1
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4">
          前端
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="前端" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          前端
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E5%89%8D%E7%AB%AF/HTML/" class="md-nav__link">
        HTML
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" type="checkbox" id="__nav_5" >
      
      
      
      
        <label class="md-nav__link" for="__nav_5">
          Python
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Python" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          Python
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Python/%E8%AF%B4%E6%98%8E/" class="md-nav__link">
        说明
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Python/Numpy/" class="md-nav__link">
        Numpy
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Python/Pandas/" class="md-nav__link">
        Pandas
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Python/Matplotlib/" class="md-nav__link">
        Matplotlib
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Python/Pymssql/" class="md-nav__link">
        Pymssql
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../Python/Streamlit.md" class="md-nav__link">
        Streamlit
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6" type="checkbox" id="__nav_6" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_6">
          ML
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="ML" data-md-level="1">
        <label class="md-nav__title" for="__nav_6">
          <span class="md-nav__icon md-icon"></span>
          ML
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../%E8%AF%B4%E6%98%8E/" class="md-nav__link">
        说明
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../1_Regression/" class="md-nav__link">
        Regression
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../2_Classification/" class="md-nav__link">
        Classification
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../3_Logistic%20Regression/" class="md-nav__link">
        Logistic Regression
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../4_Deep%20learning/" class="md-nav__link">
        Deep Learning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../5_Convolutional%20Neural%20Network/" class="md-nav__link">
        CNN
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../6_Recurrent%20Neural%20Network/" class="md-nav__link">
        RNN
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../7_Semi-supervised%20Learning/" class="md-nav__link">
        Semi Supervised Learning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../8_Unsupervised%20Learning%20Word%20Embedding/" class="md-nav__link">
        Unsupervised Learning:Word Embedding
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Pytorch
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Pytorch
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#pytorch-introduction" class="md-nav__link">
    Pytorch Introduction
  </a>
  
    <nav class="md-nav" aria-label="Pytorch Introduction">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensors-numpy" class="md-nav__link">
    Tensors &amp;&amp; numpy
  </a>
  
    <nav class="md-nav" aria-label="Tensors &amp;&amp; numpy">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchview" class="md-nav__link">
    torch.view
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#broadcasting-semantics" class="md-nav__link">
    broadcasting semantics
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#computation-graphs" class="md-nav__link">
    Computation graphs
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda-semantics" class="md-nav__link">
    CUDA semantics
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pytorch-as-an-auto-grad-framework" class="md-nav__link">
    PyTorch as an auto grad framework
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#using-the-gradients" class="md-nav__link">
    Using the gradients
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#linear-regression" class="md-nav__link">
    Linear Regression
  </a>
  
    <nav class="md-nav" aria-label="Linear Regression">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#example" class="md-nav__link">
    Example
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchnnmodule" class="md-nav__link">
    torch.nn.Module
  </a>
  
    <nav class="md-nav" aria-label="torch.nn.Module">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#linear-module" class="md-nav__link">
    Linear Module
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#activation-functions" class="md-nav__link">
    Activation functions
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sequential" class="md-nav__link">
    Sequential
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#loss-functions" class="md-nav__link">
    Loss functions
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchoptim" class="md-nav__link">
    torch.optim
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#linear-regression-using-gd" class="md-nav__link">
    Linear regression using GD
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#linear-regression-using-sgd" class="md-nav__link">
    Linear regression using SGD
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#neural-network-basics-in-pytorch" class="md-nav__link">
    Neural Network Basics in PyTorch
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#things-that-may-help" class="md-nav__link">
    Things that may help
  </a>
  
    <nav class="md-nav" aria-label="Things that may help">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#momentum" class="md-nav__link">
    Momentum
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#crossentropyloss" class="md-nav__link">
    CrossEntropyLoss
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#learning-rate-schedulers" class="md-nav__link">
    Learning rate schedulers
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#convolutions" class="md-nav__link">
    Convolutions
  </a>
  
    <nav class="md-nav" aria-label="Convolutions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#nnconv2d" class="md-nav__link">
    nn.Conv2d
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nnbatchnorm2d" class="md-nav__link">
    nn.BatchNorm2d
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nnmaxpool2d" class="md-nav__link">
    nn.MaxPool2d
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#custom-datasets-dataloaders" class="md-nav__link">
    Custom Datasets, DataLoaders
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transforms" class="md-nav__link">
    Transforms
  </a>
  
    <nav class="md-nav" aria-label="Transforms">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#crop" class="md-nav__link">
    裁剪 Crop
  </a>
  
    <nav class="md-nav" aria-label="裁剪 Crop">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    随机裁剪
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    中心裁剪
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    随机长宽比裁剪
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    上下左右中心裁剪
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    上下左右中心裁剪后翻转
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flip-and-rotation" class="md-nav__link">
    翻转和旋转 Flip and Rotation
  </a>
  
    <nav class="md-nav" aria-label="翻转和旋转 Flip and Rotation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#p" class="md-nav__link">
    依概率 p 水平翻转
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#p_1" class="md-nav__link">
    依概率 p 垂直翻转
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    随机旋转
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#resize" class="md-nav__link">
    图像变换 Resize
  </a>
  
    <nav class="md-nav" aria-label="图像变换 Resize">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#resize_1" class="md-nav__link">
    Resize
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    标准化
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensor" class="md-nav__link">
    转为 Tensor
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_8" class="md-nav__link">
    填充
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_9" class="md-nav__link">
    修改亮度、对比度和饱和度
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_10" class="md-nav__link">
    转灰度图
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_11" class="md-nav__link">
    线性变换
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_12" class="md-nav__link">
    仿射变换
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#p_2" class="md-nav__link">
    依概率 p 转为灰度图
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pilimage" class="md-nav__link">
    转换为 PILImage
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lambda" class="md-nav__link">
    Lambda
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transforms_1" class="md-nav__link">
    对 transforms 操作
  </a>
  
    <nav class="md-nav" aria-label="对 transforms 操作">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#randomchoice" class="md-nav__link">
    RandomChoice
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#randomapply" class="md-nav__link">
    RandomApply
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#randomorder" class="md-nav__link">
    RandomOrder
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_13" class="md-nav__link">
    其他
  </a>
  
    <nav class="md-nav" aria-label="其他">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#modeltrain-modeleval-torchno_grad" class="md-nav__link">
    model.train() &amp;&amp; model.eval() &amp;&amp; torch.no_grad()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stack-cat" class="md-nav__link">
    stack() &amp;&amp; cat()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Keras/" class="md-nav__link">
        Keras
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7" type="checkbox" id="__nav_7" >
      
      
      
      
        <label class="md-nav__link" for="__nav_7">
          其他
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="其他" data-md-level="1">
        <label class="md-nav__title" for="__nav_7">
          <span class="md-nav__icon md-icon"></span>
          其他
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E5%85%B6%E4%BB%96/Mkdocs/" class="md-nav__link">
        Mkdocs
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E5%85%B6%E4%BB%96/Markdown/" class="md-nav__link">
        Markdown
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#pytorch-introduction" class="md-nav__link">
    Pytorch Introduction
  </a>
  
    <nav class="md-nav" aria-label="Pytorch Introduction">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensors-numpy" class="md-nav__link">
    Tensors &amp;&amp; numpy
  </a>
  
    <nav class="md-nav" aria-label="Tensors &amp;&amp; numpy">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchview" class="md-nav__link">
    torch.view
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#broadcasting-semantics" class="md-nav__link">
    broadcasting semantics
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#computation-graphs" class="md-nav__link">
    Computation graphs
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cuda-semantics" class="md-nav__link">
    CUDA semantics
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pytorch-as-an-auto-grad-framework" class="md-nav__link">
    PyTorch as an auto grad framework
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#using-the-gradients" class="md-nav__link">
    Using the gradients
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#linear-regression" class="md-nav__link">
    Linear Regression
  </a>
  
    <nav class="md-nav" aria-label="Linear Regression">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#example" class="md-nav__link">
    Example
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchnnmodule" class="md-nav__link">
    torch.nn.Module
  </a>
  
    <nav class="md-nav" aria-label="torch.nn.Module">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#linear-module" class="md-nav__link">
    Linear Module
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#activation-functions" class="md-nav__link">
    Activation functions
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sequential" class="md-nav__link">
    Sequential
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#loss-functions" class="md-nav__link">
    Loss functions
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#torchoptim" class="md-nav__link">
    torch.optim
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#linear-regression-using-gd" class="md-nav__link">
    Linear regression using GD
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#linear-regression-using-sgd" class="md-nav__link">
    Linear regression using SGD
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#neural-network-basics-in-pytorch" class="md-nav__link">
    Neural Network Basics in PyTorch
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#things-that-may-help" class="md-nav__link">
    Things that may help
  </a>
  
    <nav class="md-nav" aria-label="Things that may help">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#momentum" class="md-nav__link">
    Momentum
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#crossentropyloss" class="md-nav__link">
    CrossEntropyLoss
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#learning-rate-schedulers" class="md-nav__link">
    Learning rate schedulers
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#convolutions" class="md-nav__link">
    Convolutions
  </a>
  
    <nav class="md-nav" aria-label="Convolutions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#nnconv2d" class="md-nav__link">
    nn.Conv2d
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nnbatchnorm2d" class="md-nav__link">
    nn.BatchNorm2d
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nnmaxpool2d" class="md-nav__link">
    nn.MaxPool2d
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#custom-datasets-dataloaders" class="md-nav__link">
    Custom Datasets, DataLoaders
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transforms" class="md-nav__link">
    Transforms
  </a>
  
    <nav class="md-nav" aria-label="Transforms">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#crop" class="md-nav__link">
    裁剪 Crop
  </a>
  
    <nav class="md-nav" aria-label="裁剪 Crop">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    随机裁剪
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    中心裁剪
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    随机长宽比裁剪
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    上下左右中心裁剪
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    上下左右中心裁剪后翻转
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flip-and-rotation" class="md-nav__link">
    翻转和旋转 Flip and Rotation
  </a>
  
    <nav class="md-nav" aria-label="翻转和旋转 Flip and Rotation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#p" class="md-nav__link">
    依概率 p 水平翻转
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#p_1" class="md-nav__link">
    依概率 p 垂直翻转
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    随机旋转
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#resize" class="md-nav__link">
    图像变换 Resize
  </a>
  
    <nav class="md-nav" aria-label="图像变换 Resize">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#resize_1" class="md-nav__link">
    Resize
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    标准化
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensor" class="md-nav__link">
    转为 Tensor
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_8" class="md-nav__link">
    填充
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_9" class="md-nav__link">
    修改亮度、对比度和饱和度
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_10" class="md-nav__link">
    转灰度图
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_11" class="md-nav__link">
    线性变换
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_12" class="md-nav__link">
    仿射变换
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#p_2" class="md-nav__link">
    依概率 p 转为灰度图
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pilimage" class="md-nav__link">
    转换为 PILImage
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lambda" class="md-nav__link">
    Lambda
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transforms_1" class="md-nav__link">
    对 transforms 操作
  </a>
  
    <nav class="md-nav" aria-label="对 transforms 操作">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#randomchoice" class="md-nav__link">
    RandomChoice
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#randomapply" class="md-nav__link">
    RandomApply
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#randomorder" class="md-nav__link">
    RandomOrder
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_13" class="md-nav__link">
    其他
  </a>
  
    <nav class="md-nav" aria-label="其他">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#modeltrain-modeleval-torchno_grad" class="md-nav__link">
    model.train() &amp;&amp; model.eval() &amp;&amp; torch.no_grad()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stack-cat" class="md-nav__link">
    stack() &amp;&amp; cat()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
  <a href="https://github.com/hucorz/myDoc/edit/master/docs/ML/Pytorch.md" title="Edit this page" class="md-content__button md-icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
  </a>



<h1 id="pytorch">Pytorch<a class="headerlink" href="#pytorch" title="Permanent link">&para;</a></h1>
<h2 id="pytorch-introduction">Pytorch Introduction<a class="headerlink" href="#pytorch-introduction" title="Permanent link">&para;</a></h2>
<p>李宏毅老师20年ML的PyTorch Tutorial：<a href="https://colab.research.google.com/drive/1Xed5YSpLsLfkn66OhhyNzr05VE89enng#scrollTo=Xi_QP1bmMThC">PyTorch_Introduction.ipynb - Colaboratory (google.com)</a></p>
<p>参考：<a href="https://mp.weixin.qq.com/s/42LLqscyrTaqFqgMk1VDrg">PyTorch简易入门 </a> </p>
<p>doc：<a href="https://pytorch.org/docs/1.2.0/">PyTorch documentation — PyTorch master documentation</a> </p>
<p>其中加了一些自己学习中的补充内容</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>

<span class="kn">from</span> <span class="nn">mpl_toolkits.mplot3d</span> <span class="kn">import</span> <span class="n">Axes3D</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">446</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">446</span><span class="p">)</span>
</code></pre></div>
<h3 id="tensors-numpy">Tensors &amp;&amp; numpy<a class="headerlink" href="#tensors-numpy" title="Permanent link">&para;</a></h3>
<p>the <code>tensor</code> is similar to numpy's <code>ndarray</code></p>
<div class="highlight"><pre><span></span><code><span class="c1"># 初始化</span>
<span class="n">x_numpy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">])</span>
<span class="n">x_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">])</span>
<span class="n">y_numpy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mf">5.</span><span class="p">])</span>
<span class="n">y_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mf">5.</span><span class="p">])</span>

<span class="c1"># tensor 和 array 的转换</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x_numpy</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">0.1000</span><span class="p">,</span> <span class="mf">0.2000</span><span class="p">,</span> <span class="mf">0.3000</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x_torch</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="p">[</span><span class="mf">0.1</span> <span class="mf">0.2</span> <span class="mf">0.3</span><span class="p">]</span>

<span class="c1"># 加减操作</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x_torch</span> <span class="o">+</span> <span class="n">y_torch</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">3.1000</span><span class="p">,</span> <span class="mf">4.2000</span><span class="p">,</span> <span class="mf">5.3000</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x_torch</span> <span class="o">-</span> <span class="n">y_torch</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">2.9000</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.8000</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.7000</span><span class="p">])</span>

<span class="c1"># 求norm</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x_numpy</span><span class="p">)</span>
<span class="mf">0.37416573867739417</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x_torch</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">(</span><span class="mf">0.3742</span><span class="p">)</span>

<span class="c1"># 求均值mean</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x_numpy</span><span class="p">)</span>
<span class="mf">0.20000000000000004</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x_torch</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">(</span><span class="mf">0.2000</span><span class="p">)</span>
</code></pre></div>
<h4 id="torchview">torch.view<a class="headerlink" href="#torchview" title="Permanent link">&para;</a></h4>
<p>similarly to <code>numpy.reshape()</code></p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">H</span> <span class="o">=</span> <span class="mi">10000</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">H</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">])</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">784</span><span class="p">])</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">X</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span> <span class="c1"># -1的可以自动计算X.shape中对应维的值</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">784</span><span class="p">])</span>
</code></pre></div>
<h4 id="broadcasting-semantics">broadcasting semantics<a class="headerlink" href="#broadcasting-semantics" title="Permanent link">&para;</a></h4>
<p>处理维数不同的 tensors 时会进行广播，类似 <code>np.matmul()</code></p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>  <span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</code></pre></div>
<p>按照尾部维度对齐，且对应维度要么相同，要么有一个为 1</p>
<h3 id="computation-graphs">Computation graphs<a class="headerlink" href="#computation-graphs" title="Permanent link">&para;</a></h3>
<p>做加减乘除运算时，只要其中一项需要做<code>gradient</code>，<code>pytorch</code>就会自动建立一张计算图</p>
<div class="highlight"><pre><span></span><code><span class="c1"># 我们需要设置requires_grad=True使pytorch知道要保存计算图的存在</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">b</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">c</span><span class="o">=</span><span class="n">a</span><span class="o">+</span><span class="n">b</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">d</span><span class="o">=</span><span class="n">b</span><span class="o">+</span><span class="mi">1</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">e</span><span class="o">=</span><span class="n">c</span><span class="o">*</span><span class="n">d</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">c</span>
<span class="n">tensor</span><span class="p">(</span><span class="mf">3.</span><span class="p">,</span> <span class="n">grad_fn</span><span class="o">=&lt;</span><span class="n">AddBackward0</span><span class="o">&gt;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">d</span>
<span class="n">tensor</span><span class="p">(</span><span class="mf">2.</span><span class="p">,</span> <span class="n">grad_fn</span><span class="o">=&lt;</span><span class="n">AddBackward0</span><span class="o">&gt;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">e</span>
<span class="n">tensor</span><span class="p">(</span><span class="mf">6.</span><span class="p">,</span> <span class="n">grad_fn</span><span class="o">=&lt;</span><span class="n">MulBackward0</span><span class="o">&gt;</span><span class="p">)</span>
</code></pre></div>
<p><img src="https://cdn.jsdelivr.net/gh/hucorz/imgbed/ML/Note/Pytorch/pytorch_1.png" /></p>
<h3 id="cuda-semantics">CUDA semantics<a class="headerlink" href="#cuda-semantics" title="Permanent link">&para;</a></h3>
<p>使用<code>torch.device("cpu")</code>和<code>torch.device("cuda")</code>，并使用<code>data.to()</code>将数据在<code>cpu</code>和<code>gpu</code>上切换</p>
<div class="highlight"><pre><span></span><code><span class="n">cpu</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="n">gpu</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>

<span class="n">x</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">gpu</span><span class="p">)</span> <span class="c1"># x切换到gpu上</span>
<span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">cpu</span><span class="p">)</span> <span class="c1"># x切换到cpu上</span>
</code></pre></div>
<h3 id="pytorch-as-an-auto-grad-framework">PyTorch as an auto grad framework<a class="headerlink" href="#pytorch-as-an-auto-grad-framework" title="Permanent link">&para;</a></h3>
<p><code>y.backward()</code>计算出计算图中 <span class="arithmatex">\(y\)</span> 对以 <span class="arithmatex">\(y\)</span> 为终点的路径上所有变量 <span class="arithmatex">\(x^i\)</span> 的<code>gradient</code> <span class="arithmatex">\(\frac{\partial y}{\partial x^i}\)</span></p>
<p>例1：<span class="arithmatex">\(f(x)=(x-2)^2,f'(x)=2(x-2)\)</span></p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="o">...</span>  <span class="k">return</span> <span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># 需要先建立计算图后续才能微分</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span><span class="o">=</span><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span> <span class="c1"># 计算图上以y为终点的路径上的所有变量都自动微分</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">grad</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">2.</span><span class="p">])</span>
</code></pre></div>
<p>例2：<span class="arithmatex">\(w=[w_1,w_2]^T,g(w)=2w_1w_2+w_2cos(w_1)\)</span> </p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="k">def</span> <span class="nf">g</span><span class="p">(</span><span class="n">w</span><span class="p">):</span>
<span class="o">...</span>     <span class="k">return</span> <span class="mi">2</span><span class="o">*</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">w</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="n">w</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">w</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">z</span><span class="o">=</span><span class="n">g</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">z</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">w</span><span class="o">.</span><span class="n">grad</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">2.0000</span><span class="p">,</span> <span class="mf">5.2832</span><span class="p">])</span> <span class="c1"># z对w[0]和w[1]的微分</span>
</code></pre></div>
<h3 id="using-the-gradients">Using the gradients<a class="headerlink" href="#using-the-gradients" title="Permanent link">&para;</a></h3>
<p>以<span class="arithmatex">\(f(x)=(x-2)^2,f'(x)=2(x-2)\)</span>为例做 gradient descent</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="o">...</span>  <span class="k">return</span> <span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">5.0</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># 随机定义x的初值值</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.25</span> <span class="c1"># learning rate</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">15</span><span class="p">):</span> <span class="c1"># 做gd</span>
<span class="o">...</span>     <span class="n">y</span><span class="o">=</span><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="o">...</span>     <span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="o">...</span>     <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x=</span><span class="si">%f</span><span class="se">\t</span><span class="s2"> f(x)=</span><span class="si">%f</span><span class="se">\t</span><span class="s2"> f&#39;(x)=</span><span class="si">%f</span><span class="s2">&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">y</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>
<span class="o">...</span>     <span class="n">x</span><span class="o">.</span><span class="n">data</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">data</span><span class="o">-</span><span class="n">lr</span><span class="o">*</span><span class="n">x</span><span class="o">.</span><span class="n">grad</span> <span class="c1"># 不用x.data会出问题</span>
<span class="o">...</span>     <span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">detach_</span><span class="p">()</span> <span class="c1"># The detach_() is for efficiency. You do not need to worry too much about it.</span>
<span class="o">...</span>     <span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
<span class="o">...</span> 
<span class="n">x</span><span class="o">=</span><span class="mf">5.000000</span>  <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">=</span><span class="mf">9.000000</span>  <span class="sa">f</span><span class="s1">&#39;(x)=6.000000</span>
<span class="n">x</span><span class="o">=</span><span class="mf">3.500000</span>  <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">=</span><span class="mf">2.250000</span>  <span class="sa">f</span><span class="s1">&#39;(x)=3.000000</span>
<span class="n">x</span><span class="o">=</span><span class="mf">2.750000</span>  <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">=</span><span class="mf">0.562500</span>  <span class="sa">f</span><span class="s1">&#39;(x)=1.500000</span>
<span class="n">x</span><span class="o">=</span><span class="mf">2.375000</span>  <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">=</span><span class="mf">0.140625</span>  <span class="sa">f</span><span class="s1">&#39;(x)=0.750000</span>
<span class="n">x</span><span class="o">=</span><span class="mf">2.187500</span>  <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">=</span><span class="mf">0.035156</span>  <span class="sa">f</span><span class="s1">&#39;(x)=0.375000</span>
<span class="n">x</span><span class="o">=</span><span class="mf">2.093750</span>  <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">=</span><span class="mf">0.008789</span>  <span class="sa">f</span><span class="s1">&#39;(x)=0.187500</span>
<span class="n">x</span><span class="o">=</span><span class="mf">2.046875</span>  <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">=</span><span class="mf">0.002197</span>  <span class="sa">f</span><span class="s1">&#39;(x)=0.093750</span>
<span class="n">x</span><span class="o">=</span><span class="mf">2.023438</span>  <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">=</span><span class="mf">0.000549</span>  <span class="sa">f</span><span class="s1">&#39;(x)=0.046875</span>
<span class="n">x</span><span class="o">=</span><span class="mf">2.011719</span>  <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">=</span><span class="mf">0.000137</span>  <span class="sa">f</span><span class="s1">&#39;(x)=0.023438</span>
<span class="n">x</span><span class="o">=</span><span class="mf">2.005859</span>  <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">=</span><span class="mf">0.000034</span>  <span class="sa">f</span><span class="s1">&#39;(x)=0.011719</span>
<span class="n">x</span><span class="o">=</span><span class="mf">2.002930</span>  <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">=</span><span class="mf">0.000009</span>  <span class="sa">f</span><span class="s1">&#39;(x)=0.005859</span>
<span class="n">x</span><span class="o">=</span><span class="mf">2.001465</span>  <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">=</span><span class="mf">0.000002</span>  <span class="sa">f</span><span class="s1">&#39;(x)=0.002930</span>
<span class="n">x</span><span class="o">=</span><span class="mf">2.000732</span>  <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">=</span><span class="mf">0.000001</span>  <span class="sa">f</span><span class="s1">&#39;(x)=0.001465</span>
<span class="n">x</span><span class="o">=</span><span class="mf">2.000366</span>  <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">=</span><span class="mf">0.000000</span>  <span class="sa">f</span><span class="s1">&#39;(x)=0.000732</span>
<span class="n">x</span><span class="o">=</span><span class="mf">2.000183</span>  <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">=</span><span class="mf">0.000000</span>  <span class="sa">f</span><span class="s1">&#39;(x)=0.000366</span>
</code></pre></div>
<p><code>tensor.grad.zero_()</code>：gradient 清零，否则会累加</p>
<p><code>tensor.item()</code>：用于取出 tensor 中的纯数值，一般适用于 tensor 只包含一个元素的情况，多个元素可采用 <code>tensor.tolist()</code> 转化为列表</p>
<p><code>tensor.detach_()</code>：切断计算图，比如我们对 y 进行 detach_()，就把 x-&gt;y-&gt;z 切成两部分：x 和 y-&gt;z，x 就无法接受到后面传过来的梯度，对 z 进行 backward() 时也不会对求 y 的梯度</p>
<p><code>tensor.detach() &amp;&amp; tensor.data</code>：获取 x 这个 tensor 的值（创建 x 的副本），且内存都是与 x 共享，即修改后也会影响 x 的值，但不会自动微分，<code>require s_grad = False</code> ；两者区别在于在后续的反向传播中，tensor.data 不会报错，所以 detach() 会更加安全</p>
<p><a href="https://www.cnblogs.com/wanghui-garcia/p/10677071.html">pytorch .detach() .detach_() 和 .data用于切断反向传播 - 慢行厚积</a></p>
<h2 id="linear-regression">Linear Regression<a class="headerlink" href="#linear-regression" title="Permanent link">&para;</a></h2>
<h3 id="example">Example<a class="headerlink" href="#example" title="Permanent link">&para;</a></h3>
<p>损失函数：RSS，残差平方和</p>
<ol>
<li>数据准备</li>
</ol>
<p>true_w 是真实参数，y 通过 <span class="arithmatex">\(x@w\)</span>​​ 加上一个偏差获得</p>
<div class="highlight"><pre><span></span><code><span class="n">d</span><span class="o">=</span><span class="mi">2</span>
<span class="n">n</span><span class="o">=</span><span class="mi">50</span>
<span class="n">x</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">d</span><span class="p">)</span>
<span class="n">true_w</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">1.0</span><span class="p">],[</span><span class="mf">2.0</span><span class="p">]])</span>
<span class="n">y</span><span class="o">=</span><span class="n">x</span><span class="nd">@true_w</span><span class="o">+</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="mf">0.1</span>
</code></pre></div>
<ol>
<li>创建线性回归模型和损失函数</li>
</ol>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span> 
    <span class="k">return</span> <span class="n">x</span><span class="nd">@w</span>                                                         
<span class="k">def</span> <span class="nf">rss</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">h_hat</span><span class="p">):</span> 
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">y</span><span class="o">-</span><span class="n">h_hat</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">n</span> 
</code></pre></div>
<ol>
<li>使用梯度进行梯度下降法线性回归</li>
</ol>
<div class="highlight"><pre><span></span><code><span class="n">w</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">],[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span> 
    <span class="n">y_hat</span><span class="o">=</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span> 
    <span class="n">loss</span><span class="o">=</span><span class="n">rss</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">)</span> 
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span> 
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;loss = </span><span class="si">%f</span><span class="s1">&#39;</span><span class="o">%</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> \\
          <span class="s2">&quot;</span><span class="se">\t</span><span class="s2">w =&quot;</span><span class="p">,</span><span class="n">w</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span> 
    <span class="n">w</span><span class="o">.</span><span class="n">data</span><span class="o">=</span><span class="n">w</span><span class="o">.</span><span class="n">data</span><span class="o">-</span><span class="n">lr</span><span class="o">*</span><span class="n">w</span><span class="o">.</span><span class="n">grad</span> 
    <span class="n">w</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">detach_</span><span class="p">()</span> 
    <span class="n">w</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span> 

<span class="n">loss</span> <span class="o">=</span> <span class="mf">6.877078</span>  <span class="n">w</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">]]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="mf">4.700166</span>  <span class="n">w</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.6123040914535522</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.29769018292427063</span><span class="p">]]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="mf">3.225300</span>  <span class="n">w</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.3017166256904602</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5531282424926758</span><span class="p">]]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="mf">2.221793</span>  <span class="n">w</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.052597105503082275</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.7719148397445679</span><span class="p">]]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="mf">1.536276</span>  <span class="n">w</span> <span class="o">=</span> <span class="p">[[</span><span class="o">-</span><span class="mf">0.1474691480398178</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.9590051174163818</span><span class="p">]]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="mf">1.066256</span>  <span class="n">w</span> <span class="o">=</span> <span class="p">[[</span><span class="o">-</span><span class="mf">0.3083454966545105</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.1187583208084106</span><span class="p">]]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="mf">0.742897</span>  <span class="n">w</span> <span class="o">=</span> <span class="p">[[</span><span class="o">-</span><span class="mf">0.4378759264945984</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.2549899816513062</span><span class="p">]]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="mf">0.519751</span>  <span class="n">w</span> <span class="o">=</span> <span class="p">[[</span><span class="o">-</span><span class="mf">0.5423045754432678</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.371025800704956</span><span class="p">]]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="mf">0.365329</span>  <span class="n">w</span> <span class="o">=</span> <span class="p">[[</span><span class="o">-</span><span class="mf">0.6266074180603027</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.4697538614273071</span><span class="p">]]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="mf">0.258197</span>  <span class="n">w</span> <span class="o">=</span> <span class="p">[[</span><span class="o">-</span><span class="mf">0.694753885269165</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.5536739826202393</span><span class="p">]]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="mf">0.183704</span>  <span class="n">w</span> <span class="o">=</span> <span class="p">[[</span><span class="o">-</span><span class="mf">0.7499141693115234</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.6249440908432007</span><span class="p">]]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="mf">0.131802</span>  <span class="n">w</span> <span class="o">=</span> <span class="p">[[</span><span class="o">-</span><span class="mf">0.7946230173110962</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.6854223012924194</span><span class="p">]]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="mf">0.095576</span>  <span class="n">w</span> <span class="o">=</span> <span class="p">[[</span><span class="o">-</span><span class="mf">0.8309094309806824</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.7367050647735596</span><span class="p">]]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="mf">0.070251</span>  <span class="n">w</span> <span class="o">=</span> <span class="p">[[</span><span class="o">-</span><span class="mf">0.8603994846343994</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.7801612615585327</span><span class="p">]]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="mf">0.052521</span>  <span class="n">w</span> <span class="o">=</span> <span class="p">[[</span><span class="o">-</span><span class="mf">0.8843981027603149</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.8169628381729126</span><span class="p">]]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="mf">0.040094</span>  <span class="n">w</span> <span class="o">=</span> <span class="p">[[</span><span class="o">-</span><span class="mf">0.9039536118507385</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.8481112718582153</span><span class="p">]]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="mf">0.031374</span>  <span class="n">w</span> <span class="o">=</span> <span class="p">[[</span><span class="o">-</span><span class="mf">0.9199094772338867</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.8744614124298096</span><span class="p">]]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="mf">0.025249</span>  <span class="n">w</span> <span class="o">=</span> <span class="p">[[</span><span class="o">-</span><span class="mf">0.9329451322555542</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.8967417478561401</span><span class="p">]]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="mf">0.020944</span>  <span class="n">w</span> <span class="o">=</span> <span class="p">[[</span><span class="o">-</span><span class="mf">0.9436085224151611</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.9155727624893188</span><span class="p">]]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="mf">0.017916</span>  <span class="n">w</span> <span class="o">=</span> <span class="p">[[</span><span class="o">-</span><span class="mf">0.9523422122001648</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.931482195854187</span><span class="p">]]</span>
</code></pre></div>
<h3 id="torchnnmodule">torch.nn.Module<a class="headerlink" href="#torchnnmodule" title="Permanent link">&para;</a></h3>
<h4 id="linear-module">Linear Module<a class="headerlink" href="#linear-module" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="n">d_in</span><span class="o">=</span><span class="mi">3</span>              
<span class="n">d_out</span><span class="o">=</span><span class="mi">4</span>             
<span class="n">linear_module</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span><span class="n">d_out</span><span class="p">)</span>
<span class="n">example_tensor</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">transformed</span><span class="o">=</span><span class="n">linear_module</span><span class="p">(</span><span class="n">example_tensor</span><span class="p">)</span>                                   <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;example_tensor&#39;</span><span class="p">,</span> <span class="n">example_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;transormed&#39;</span><span class="p">,</span> <span class="n">transformed</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;We can see that the weights exist in the background</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;W:&#39;</span><span class="p">,</span> <span class="n">linear_module</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;b:&#39;</span><span class="p">,</span> <span class="n">linear_module</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">example_tensor torch.Size([2, 3])</span>
<span class="sd">transormed torch.Size([2, 4])</span>

<span class="sd">We can see that the weights exist in the background</span>

<span class="sd">W: Parameter containing:</span>
<span class="sd">tensor([[ 0.5260,  0.4925, -0.0887],</span>
<span class="sd">        [ 0.3944,  0.4080,  0.2182],</span>
<span class="sd">        [-0.1409,  0.0518,  0.3034],</span>
<span class="sd">        [ 0.0913,  0.2452, -0.2616]], requires_grad=True)</span>
<span class="sd">b: Parameter containing:</span>
<span class="sd">tensor([0.5021, 0.0118, 0.1383, 0.4757], requires_grad=True)</span>
<span class="sd">&#39;&#39;&#39;</span>
</code></pre></div>
<h4 id="activation-functions">Activation functions<a class="headerlink" href="#activation-functions" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="n">activation_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span> <span class="c1"># we instantiate an instance of the ReLU module</span>
<span class="n">example_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">])</span>
<span class="n">activated</span> <span class="o">=</span> <span class="n">activation_fn</span><span class="p">(</span><span class="n">example_tensor</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;example_tensor&#39;</span><span class="p">,</span> <span class="n">example_tensor</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;activated&#39;</span><span class="p">,</span> <span class="n">activated</span><span class="p">)</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">example_tensor tensor([-1.,  1.,  0.])</span>
<span class="sd">activated tensor([0., 1., 0.])</span>
<span class="sd">&#39;&#39;&#39;</span>
</code></pre></div>
<h4 id="sequential">Sequential<a class="headerlink" href="#sequential" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="n">d_in</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">d_hidden</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">d_out</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_hidden</span><span class="p">),</span>
                            <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span>
                            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_hidden</span><span class="p">,</span> <span class="n">d_out</span><span class="p">),</span>
                            <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
                           <span class="p">)</span>
<span class="n">example_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">transformed</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">example_tensor</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;transformed&#39;</span><span class="p">,</span> <span class="n">transformed</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">transformed torch.Size([2, 1])</span>
<span class="sd">&#39;&#39;&#39;</span>
</code></pre></div>
<p>上面的式子等价于</p>
<div class="highlight"><pre><span></span><code><span class="n">d_in</span><span class="o">=</span><span class="mi">3</span>
<span class="n">d_hidden</span><span class="o">=</span><span class="mi">4</span>
<span class="n">d_out</span><span class="o">=</span><span class="mi">1</span>

<span class="n">linear</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_hidden</span><span class="p">)</span>
<span class="n">tanh</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>
<span class="n">linear2</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_hidden</span><span class="p">,</span> <span class="n">d_out</span><span class="p">)</span>
<span class="n">sigmoid</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>

<span class="n">tensor_input</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">tensor_input</span><span class="o">=</span><span class="n">linear</span><span class="p">(</span><span class="n">tensor_input</span><span class="p">)</span>
<span class="n">tensor_input</span><span class="o">=</span><span class="n">tanh</span><span class="p">(</span><span class="n">tensor_input</span><span class="p">)</span>
<span class="n">tensor_input</span><span class="o">=</span><span class="n">linear2</span><span class="p">(</span><span class="n">tensor_input</span><span class="p">)</span>
<span class="n">transformed</span><span class="o">=</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">tensor_input</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">transformed</span><span class="p">)</span>
</code></pre></div>
<p>获取参数</p>
<div class="highlight"><pre><span></span><code><span class="n">params</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span>

<span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">Parameter containing:</span>
<span class="sd">tensor([[-0.5607,  0.4221, -0.0254],</span>
<span class="sd">        [-0.3630,  0.4541,  0.0275],</span>
<span class="sd">        [-0.0703, -0.1463,  0.3065],</span>
<span class="sd">        [ 0.0065, -0.2664,  0.0267]], requires_grad=True)</span>
<span class="sd">Parameter containing:</span>
<span class="sd">tensor([-0.3196,  0.2911,  0.1999, -0.3758], requires_grad=True)</span>
<span class="sd">Parameter containing:</span>
<span class="sd">tensor([[-0.0289,  0.1544,  0.3992, -0.3301]], requires_grad=True)</span>
<span class="sd">Parameter containing:</span>
<span class="sd">tensor([-0.1438], requires_grad=True)</span>
<span class="sd">&#39;&#39;&#39;</span>
</code></pre></div>
<h4 id="loss-functions">Loss functions<a class="headerlink" href="#loss-functions" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="n">mse_loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>

<span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]])</span>

<span class="n">loss</span> <span class="o">=</span> <span class="n">mse_loss_fn</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">tensor(0.6667)</span>
<span class="sd">&#39;&#39;&#39;</span>
</code></pre></div>
<h3 id="torchoptim">torch.optim<a class="headerlink" href="#torchoptim" title="Permanent link">&para;</a></h3>
<p>使用优化器 <code>Optimizer</code> 搭建一个完整的神经网络</p>
<p>下面的例子 GD 了一次</p>
<div class="highlight"><pre><span></span><code><span class="c1"># create a simple model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># create a simple dataset</span>
<span class="n">X_simple</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">]])</span>
<span class="n">y_simple</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">2.</span><span class="p">]])</span>

<span class="c1"># create our optimizer</span>
<span class="c1"># 必须要把model的参数喂给optim，lr可以不写，会有默认参数值</span>
<span class="n">optim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">)</span>
<span class="n">mse_loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>

<span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_simple</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;model params before:&#39;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">mse_loss_fn</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y_simple</span><span class="p">)</span>


<span class="c1"># 梯度清零-&gt;计算梯度-&gt;梯度下降</span>
<span class="c1"># 做Backpropagation之前先将梯度清零，防止与旧值叠加</span>
<span class="n">optim</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="n">optim</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;model params after:&#39;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">model params before: Parameter containing:</span>
<span class="sd">tensor([[-0.9604]], requires_grad=True)</span>
<span class="sd">model params after: Parameter containing:</span>
<span class="sd">tensor([[-0.9060]], requires_grad=True)</span>
<span class="sd">&#39;&#39;&#39;</span>
</code></pre></div>
<h3 id="linear-regression-using-gd">Linear regression using GD<a class="headerlink" href="#linear-regression-using-gd" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="n">step_size</span> <span class="o">=</span> <span class="mf">0.1</span>

<span class="n">linear_module</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">loss_func</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>

<span class="n">optim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">linear_module</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">step_size</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;iter,</span><span class="se">\t</span><span class="s1">loss,</span><span class="se">\t</span><span class="s1">w&#39;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">linear_module</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_func</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">optim</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optim</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1">,</span><span class="se">\t</span><span class="si">{:.2f}</span><span class="s1">,</span><span class="se">\t</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">linear_module</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">true w</span><span class="se">\t\t</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">true_w</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;estimated w</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">linear_module</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

<span class="sd">&#39;&#39;&#39;</span>

<span class="sd">iter,   loss,   w</span>
<span class="sd">0,  6.14,   [-0.4951109  -0.20055914]</span>
<span class="sd">1,  4.19,   [-0.64017504  0.1509075 ]</span>
<span class="sd">2,  2.87,   [-0.7496651  0.4441856]</span>
<span class="sd">3,  1.98,   [-0.8317375  0.689143 ]</span>
<span class="sd">4,  1.37,   [-0.8927491   0.89393103]</span>
<span class="sd">5,  0.95,   [-0.93764454  1.0652909 ]</span>
<span class="sd">6,  0.67,   [-0.9702622  1.208804 ]</span>
<span class="sd">7,  0.47,   [-0.99357456  1.3290964 ]</span>
<span class="sd">8,  0.33,   [-1.0098771  1.4300069]</span>
<span class="sd">9,  0.23,   [-1.0209374  1.5147243]</span>
<span class="sd">10, 0.17,   [-1.028112   1.5859002]</span>
<span class="sd">11, 0.12,   [-1.0324373  1.6457422]</span>
<span class="sd">12, 0.09,   [-1.0347017  1.6960896]</span>
<span class="sd">13, 0.06,   [-1.035502   1.7384766]</span>
<span class="sd">14, 0.05,   [-1.0352864  1.7741843]</span>
<span class="sd">15, 0.04,   [-1.0343897  1.8042834]</span>
<span class="sd">16, 0.03,   [-1.033059  1.829669]</span>
<span class="sd">17, 0.02,   [-1.031475   1.8510911]</span>
<span class="sd">18, 0.02,   [-1.0297676  1.8691778]</span>
<span class="sd">19, 0.01,   [-1.0280287  1.8844559]</span>

<span class="sd">true w       [-1.  2.]</span>
<span class="sd">estimated w  [-1.0280287  1.8844559]</span>
<span class="sd">&#39;&#39;&#39;</span>
</code></pre></div>
<h3 id="linear-regression-using-sgd">Linear regression using SGD<a class="headerlink" href="#linear-regression-using-sgd" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="n">step_size</span> <span class="o">=</span> <span class="mf">0.01</span>

<span class="n">linear_module</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">loss_func</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
<span class="n">optim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">linear_module</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">step_size</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;iter,</span><span class="se">\t</span><span class="s1">loss,</span><span class="se">\t</span><span class="s1">w&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">200</span><span class="p">):</span>
    <span class="n">rand_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="c1"># take a random point from the dataset</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">rand_idx</span><span class="p">]</span> 
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">linear_module</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_func</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">[</span><span class="n">rand_idx</span><span class="p">])</span> <span class="c1"># only compute the loss on the single point</span>
    <span class="n">optim</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optim</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">20</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1">,</span><span class="se">\t</span><span class="si">{:.2f}</span><span class="s1">,</span><span class="se">\t</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">linear_module</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">true w</span><span class="se">\t\t</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">true_w</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;estimated w</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">linear_module</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

<span class="sd">&#39;&#39;&#39;</span>

<span class="sd">iter,   loss,   w</span>
<span class="sd">0,  5.33,   [-0.52818084  0.2690754 ]</span>
<span class="sd">20, 1.33,   [-0.5849738   0.54701847]</span>
<span class="sd">40, 0.21,   [-0.68336743  0.93094164]</span>
<span class="sd">60, 0.41,   [-0.76554966  1.3865377 ]</span>
<span class="sd">80, 0.22,   [-0.8548197  1.528812 ]</span>
<span class="sd">100,    0.45,   [-0.9011376  1.679943 ]</span>
<span class="sd">120,    0.04,   [-0.9418524  1.7858417]</span>
<span class="sd">140,    0.00,   [-0.97288156  1.857902  ]</span>
<span class="sd">160,    0.00,   [-0.98335326  1.893024  ]</span>
<span class="sd">180,    0.01,   [-0.9927237  1.904962 ]</span>

<span class="sd">true w       [-1.  2.]</span>
<span class="sd">estimated w  [-0.99158174  1.9331173 ]</span>
<span class="sd">&#39;&#39;&#39;</span>
</code></pre></div>
<h2 id="neural-network-basics-in-pytorch">Neural Network Basics in PyTorch<a class="headerlink" href="#neural-network-basics-in-pytorch" title="Permanent link">&para;</a></h2>
<p>We will try and fit a simple neural network to the data.</p>
<div class="highlight"><pre><span></span><code><span class="n">d</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">d</span><span class="p">)</span> <span class="c1"># rand 生成的随机数在 [0,1]</span>
<span class="c1"># 一个由 sin 和 cos 的合成函数</span>
<span class="n">y</span> <span class="o">=</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="mi">6</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">X</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">y</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;plot of $f(x)$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;$x$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;$y$&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<p><img src="https://cdn.jsdelivr.net/gh/hucorz/imgbed/ML/Note/Pytorch/pytorch_2.png" /></p>
<p>用<code>pytorch</code>搭建神经网络拟合数据集的曲线，activation function 用 Tanh</p>
<div class="highlight"><pre><span></span><code><span class="n">step_size</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">6000</span>
<span class="n">n_hidden_1</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">n_hidden_2</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">d_out</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">neural_network</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">n_hidden_1</span><span class="p">),</span> 
                            <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span>
                            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_hidden_1</span><span class="p">,</span> <span class="n">n_hidden_2</span><span class="p">),</span>
                            <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span>
                            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_hidden_2</span><span class="p">,</span> <span class="n">d_out</span><span class="p">)</span>
                            <span class="p">)</span>

<span class="n">loss_func</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>

<span class="n">optim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">neural_network</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">step_size</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;iter,</span><span class="se">\t</span><span class="s1">loss&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">neural_network</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_func</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">optim</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optim</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="p">(</span><span class="n">n_epochs</span> <span class="o">//</span> <span class="mi">10</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1">,</span><span class="se">\t</span><span class="si">{:.2f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">iter,   loss</span>
<span class="sd">0,  4.33</span>
<span class="sd">600,    4.27</span>
<span class="sd">1200,   3.87</span>
<span class="sd">1800,   1.54</span>
<span class="sd">2400,   0.71</span>
<span class="sd">3000,   0.78</span>
<span class="sd">3600,   0.24</span>
<span class="sd">4200,   0.10</span>
<span class="sd">4800,   0.08</span>
<span class="sd">5400,   0.08</span>
<span class="sd">&#39;&#39;&#39;</span>
</code></pre></div>
<p>画出拟合后的曲线</p>
<div class="highlight"><pre><span></span><code><span class="n">X_grid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">50</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>
<span class="n">y_hat</span> <span class="o">=</span> <span class="n">neural_network</span><span class="p">(</span><span class="n">X_grid</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">y</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_grid</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">y_hat</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;plot of $f(x)$ and $\hat</span><span class="si">{f}</span><span class="s1">(x)$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;$x$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;$y$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<p><img src="https://cdn.jsdelivr.net/gh/hucorz/imgbed/ML/Note/Pytorch/pytorch_3.png" /></p>
<h2 id="things-that-may-help">Things that may help<a class="headerlink" href="#things-that-may-help" title="Permanent link">&para;</a></h2>
<h3 id="momentum">Momentum<a class="headerlink" href="#momentum" title="Permanent link">&para;</a></h3>
<p>doc：<a href="https://distill.pub/2017/momentum/">Why Momentum Really Works (distill.pub)</a></p>
<div class="highlight"><pre><span></span><code><span class="n">optim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">neural_network</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">step_size</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="n">momentum</span><span class="p">)</span>
</code></pre></div>
<h3 id="crossentropyloss">CrossEntropyLoss<a class="headerlink" href="#crossentropyloss" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
</code></pre></div>
<h3 id="learning-rate-schedulers">Learning rate schedulers<a class="headerlink" href="#learning-rate-schedulers" title="Permanent link">&para;</a></h3>
<p>doc：<a href="https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate">torch.optim — PyTorch 1.9.0 documentation</a></p>
<h3 id="convolutions">Convolutions<a class="headerlink" href="#convolutions" title="Permanent link">&para;</a></h3>
<h4 id="nnconv2d">nn.Conv2d<a class="headerlink" href="#nnconv2d" title="Permanent link">&para;</a></h4>
<p>用 CNN 处理图像 <code>torch.nn.Conv2d</code> </p>
<p>doc：<a href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d">Conv2d — PyTorch 1.9.0 documentation</a> </p>
<p><a href="https://blog.csdn.net/qq_38863413/article/details/104108808">torch.nn.Conv2d() 用法讲解_假装很坏的谦谦君</a> </p>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">padding_mode</span><span class="o">=</span><span class="err">‘</span><span class="n">zeros</span><span class="err">’</span><span class="p">)</span>
</code></pre></div>
<ul>
<li><code>in_channels</code>：输入的通道数目，比如 RGB 就是 3 通道</li>
<li><code>out_channels</code>：输出的通道数目，卷积核的数量</li>
<li><code>kernel_size</code>：卷积核 (filter) 大小，int 或者 元组，int 表示正方形的宽度</li>
<li><code>stride</code>：步长，默认 1</li>
<li><code>padding</code>：在边界增加<strong>值为0</strong>的边距的长度，或者说加几圈 0，默认为 0</li>
<li><code>dilation</code>：控制卷积核之间的间距</li>
</ul>
<h4 id="nnbatchnorm2d">nn.BatchNorm2d<a class="headerlink" href="#nnbatchnorm2d" title="Permanent link">&para;</a></h4>
<p>在深度神经网络训练时通常一次训练一个 batch，但是每个 batch 的分布不同，所以会对下一层网络的学习带来困难，BatchNorm 就是把数据标准化（均值为 0， 方差为 1），避免梯度消失和梯度爆炸</p>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">num_features</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>
<p><code>num_features</code>：channel 数</p>
<p><code>eps</code>：为保证数值稳定性（分母不能趋近或取0）,给分母加上的值。默认为 1e-5</p>
<p><code>momentum</code>：动态均值和动态方差所使用的动量</p>
<p><code>affine</code>： 一个布尔值，当设为true，给该层添加可学习的仿射变换参数</p>
<h4 id="nnmaxpool2d">nn.MaxPool2d<a class="headerlink" href="#nnmaxpool2d" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">return_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div>
<p><code>kernel_size</code>：max pooling 窗口大小</p>
<p><code>stride</code>：窗口移动步长，默认为 kernel_size</p>
<p><code>padding</code>：在边界增加<strong>值为0</strong>的边距的长度，或者说加几圈 0，默认为 0</p>
<h2 id="custom-datasets-dataloaders">Custom Datasets, DataLoaders<a class="headerlink" href="#custom-datasets-dataloaders" title="Permanent link">&para;</a></h2>
<p><code>torch.utils.data.Dataset</code> 是表示数据集的抽象类，你的自定义数据集应继承 Dataset 并覆盖以下方法：</p>
<ul>
<li><code>__len__</code> so that <code>len(dataset)</code> returns the size of the dataset.</li>
<li><code>__getitem__</code> to support the indexing such that <code>dataset[i]</code> can be used to get i-th sample</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>


<span class="k">class</span> <span class="nc">MyDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># 可以在这里读取数据</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="o">...</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

<span class="n">myDataset</span> <span class="o">=</span> <span class="n">MyDataset</span><span class="p">()</span>
</code></pre></div>
<p><code>torch.utils.data.DataLoader</code></p>
<div class="highlight"><pre><span></span><code><span class="n">train_loader</span><span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">myDataset</span><span class="p">,</span>  <span class="c1"># 传递数据集</span>
                          <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>    <span class="c1"># 小批量的数据大小，每次加载一batch数据</span>
                          <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>     <span class="c1"># 打乱数据之间的顺序</span>
                          <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>    <span class="c1"># 使用多少个子进程来加载数据，默认为0, 代表使用主线程加载batch数据</span>
</code></pre></div>
<h2 id="transforms">Transforms<a class="headerlink" href="#transforms" title="Permanent link">&para;</a></h2>
<p>参考：<a href="https://blog.csdn.net/qq_38410428/article/details/94719553">PyTorch 学习笔记:transforms的二十二个方法 初识-CV的博客</a> </p>
<p>图像变换，可以利用 <code>Compose</code> 把变换连接起来</p>
<p>eg：</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="n">train_transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
     <span class="n">transforms</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
     <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="p">])</span>
</code></pre></div>
<h3 id="crop">裁剪 Crop<a class="headerlink" href="#crop" title="Permanent link">&para;</a></h3>
<h4 id="_1">随机裁剪<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">RandomCrop</span><span class="err">（</span><span class="n">size</span><span class="err">，</span><span class="n">padding</span> <span class="o">=</span> <span class="kc">None</span><span class="err">，</span><span class="n">pad_if_needed</span> <span class="o">=</span> <span class="kc">False</span><span class="err">，</span><span class="n">fill</span> <span class="o">=</span> <span class="mi">0</span><span class="err">，</span><span class="n">padding_mode</span> <span class="o">=</span><span class="s1">&#39;constant&#39;</span> <span class="err">）</span>
</code></pre></div>
<h4 id="_2">中心裁剪<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="n">size</span><span class="p">)</span> 
</code></pre></div>
<h4 id="_3">随机长宽比裁剪<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">RandomResizedCrop</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="p">(</span><span class="mf">0.08</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span> <span class="n">ratio</span><span class="o">=</span><span class="p">(</span><span class="mf">0.75</span><span class="p">,</span> <span class="mf">1.3333333333333333</span><span class="p">),</span> <span class="n">interpolation</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div>
<h4 id="_4">上下左右中心裁剪<a class="headerlink" href="#_4" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">FiveCrop</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>
</code></pre></div>
<h4 id="_5">上下左右中心裁剪后翻转<a class="headerlink" href="#_5" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">TenCrop</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">vertical_flip</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div>
<h3 id="flip-and-rotation">翻转和旋转 Flip and Rotation<a class="headerlink" href="#flip-and-rotation" title="Permanent link">&para;</a></h3>
<h4 id="p">依概率 p 水平翻转<a class="headerlink" href="#p" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span> <span class="c1"># p 默认为 0.5</span>
</code></pre></div>
<h4 id="p_1">依概率 p 垂直翻转<a class="headerlink" href="#p_1" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">RandomVerticalFlip</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</code></pre></div>
<h4 id="_6">随机旋转<a class="headerlink" href="#_6" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">RandomRotation</span><span class="p">(</span><span class="n">degrees</span><span class="p">,</span> <span class="n">resample</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">expand</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div>
<ul>
<li><code>degree</code>：如果不是一个范围而是一个数字，那范围是<span class="arithmatex">\((-degree,degree)\)</span> </li>
</ul>
<h3 id="resize">图像变换 Resize<a class="headerlink" href="#resize" title="Permanent link">&para;</a></h3>
<h4 id="resize_1">Resize<a class="headerlink" href="#resize_1" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div>
<h4 id="_7">标准化<a class="headerlink" href="#_7" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">)</span>
</code></pre></div>
<h4 id="tensor">转为 Tensor<a class="headerlink" href="#tensor" title="Permanent link">&para;</a></h4>
<p>将 PIL Image 或者 ndarray 转换为 tensor，并且归一化至 [0-1] </p>
<p>注意事项：归一化至 [0, 1] 是直接除以255，若自己的 ndarray 数据尺度有变化，则需要自行修改</p>
<div class="highlight"><pre><span></span><code><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span>
</code></pre></div>
<h4 id="_8">填充<a class="headerlink" href="#_8" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Pad</span><span class="p">(</span><span class="n">padding</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">padding_mode</span><span class="o">=</span><span class="s1">&#39;constant&#39;</span><span class="p">)</span>
</code></pre></div>
<h4 id="_9">修改亮度、对比度和饱和度<a class="headerlink" href="#_9" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ColorJitter</span><span class="p">(</span><span class="n">brightness</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">contrast</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">saturation</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div>
<h4 id="_10">转灰度图<a class="headerlink" href="#_10" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Grayscale</span><span class="p">(</span><span class="n">num_output_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div>
<h4 id="_11">线性变换<a class="headerlink" href="#_11" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">LinearTransformation</span><span class="p">(</span><span class="n">transformation_matrix</span><span class="p">)</span> 
</code></pre></div>
<h4 id="_12">仿射变换<a class="headerlink" href="#_12" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">RandomAffine</span><span class="p">(</span><span class="n">degrees</span><span class="p">,</span> <span class="n">translate</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">shear</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">resample</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fillcolor</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> 
</code></pre></div>
<h4 id="p_2">依概率 p 转为灰度图<a class="headerlink" href="#p_2" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">RandomGrayscale</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</code></pre></div>
<h4 id="pilimage">转换为 PILImage<a class="headerlink" href="#pilimage" title="Permanent link">&para;</a></h4>
<p>将 tensor 或者 ndarray 的数据转换为 PIL Image 类型数据 </p>
<p>参数： mode 为 None 时，为1通道， mode=3 通道默认转换为 RGB，4 通道默认转换为RGBA</p>
<div class="highlight"><pre><span></span><code><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToPILImage</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div>
<h4 id="lambda">Lambda<a class="headerlink" href="#lambda" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Lambda</span><span class="err">（</span><span class="n">lambd</span><span class="err">）</span>
</code></pre></div>
<h3 id="transforms_1">对 transforms 操作<a class="headerlink" href="#transforms_1" title="Permanent link">&para;</a></h3>
<h4 id="randomchoice">RandomChoice<a class="headerlink" href="#randomchoice" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">RandomChoice</span><span class="p">(</span><span class="n">transforms</span><span class="p">)</span>
</code></pre></div>
<h4 id="randomapply">RandomApply<a class="headerlink" href="#randomapply" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">RandomApply</span><span class="p">(</span><span class="n">transforms</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</code></pre></div>
<h4 id="randomorder">RandomOrder<a class="headerlink" href="#randomorder" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">RandomOrder</span><span class="p">(</span><span class="n">transforms</span><span class="p">)</span>
</code></pre></div>
<h2 id="_13">其他<a class="headerlink" href="#_13" title="Permanent link">&para;</a></h2>
<h3 id="modeltrain-modeleval-torchno_grad">model.train() &amp;&amp; model.eval() &amp;&amp; torch.no_grad()<a class="headerlink" href="#modeltrain-modeleval-torchno_grad" title="Permanent link">&para;</a></h3>
<p><a href="https://blog.csdn.net/qq_38410428/article/details/101102075">Pytorch：model.train()和model.eval()用法和区别，以及model.eval()和torch.no_grad()的区别</a> </p>
<ul>
<li><code>model.train()</code> </li>
</ul>
<p>在训练前需要写 <code>model.train()</code>，使 <code>Batch Normalization</code> 层用的是每一批数据的均值和方差，使 <code>Dropout</code> 随机取一部分网络来训练更新参数</p>
<div class="highlight"><pre><span></span><code><span class="n">model</span><span class="o">.</span><span class="n">train</span>
</code></pre></div>
<ul>
<li><code>model.eval()</code> </li>
</ul>
<p>在测试前需要写 <code>model.eval()</code>，使 <code>Batch Normalization</code> 层用的是全部训练数据的均值和方差，使 <code>Dropout</code> 不进行随机舍弃神经元</p>
<div class="highlight"><pre><span></span><code><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</code></pre></div>
<ul>
<li><code>torch.no_grad()</code> </li>
</ul>
<p>在 eval() 模式下仍然会进行 gradient 的计算行为，只是不进行反向传播，<code>with torch.no_grad()</code> 用以停止 autograd 模块的工作，以起到加速和节省显存的作用</p>
<div class="highlight"><pre><span></span><code><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="o">...</span>
</code></pre></div>
<h3 id="stack-cat">stack() &amp;&amp; cat()<a class="headerlink" href="#stack-cat" title="Permanent link">&para;</a></h3>
<p><a href="https://blog.csdn.net/xinjieyuan/article/details/105205326">torch.stack()的官方解释，详解以及例子_xinjieyuan的博客-CSDN博客</a> </p>

              
            </article>
            
          </div>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    
    <nav class="md-footer__inner md-grid" aria-label="Footer" >
      
        
        <a href="../8_Unsupervised%20Learning%20Word%20Embedding/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Unsupervised Learning:Word Embedding" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Unsupervised Learning:Word Embedding
            </div>
          </div>
        </a>
      
      
        
        <a href="../Keras/" class="md-footer__link md-footer__link--next" aria-label="Next: Keras" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Keras
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tabs", "navigation.tabs.sticky"], "search": "../../assets/javascripts/workers/search.85cb4492.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.f758a944.min.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.css"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
      
    
  </body>
</html>