{"config":{"indexing":"full","lang":["ja"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"\u4e00\u540d\u849f\u84bb\u7684\u5b66\u4e60\u7b14\u8bb0 \u00b6 \u6b64\u6587\u6863\u4ec5\u4f5c\u4e3a\u4e2a\u4eba\u7684\u5b66\u4e60\u7b14\u8bb0 \u535a\u5ba2\uff1a hucorz's blog \u5982\u6709\u9519\u8bef\u5341\u5206\u62b1\u6b49\uff0c\u6b22\u8fce\u6307\u6b63\uff1aQQ3044464174","title":"Home"},{"location":"#_1","text":"\u6b64\u6587\u6863\u4ec5\u4f5c\u4e3a\u4e2a\u4eba\u7684\u5b66\u4e60\u7b14\u8bb0 \u535a\u5ba2\uff1a hucorz's blog \u5982\u6709\u9519\u8bef\u5341\u5206\u62b1\u6b49\uff0c\u6b22\u8fce\u6307\u6b63\uff1aQQ3044464174","title":"\u4e00\u540d\u849f\u84bb\u7684\u5b66\u4e60\u7b14\u8bb0"},{"location":"ISL/","text":"\u7edf\u8ba1\u5b66\u5bfc\u8bba \u57fa\u4e8eR\u5e94\u7528 \u00b6 An Introduction to Statistical Learning with Applications in R \u5e38\u7528\u672f\u8bed \u00b6 MSE \uff1aMean Squared Error \u5747\u65b9\u8bef\u5dee \\(MSE=\\frac{1}{n}\\sum(\\hat{y_i}-y_i)^2=\\frac{1}{n}RSS\\) RSS \uff1aResidual Sum of Squares \u6b8b\u5dee\u5e73\u65b9\u548c \\(RSS=\\sum(y_i-\\hat{y_i})^2\\) ESS \uff1aExplained Sum of Squares \u89e3\u91ca\u5e73\u65b9\u548c \\(ESS=\\sum(\\hat{y_i}-\\bar{y})^2\\) TSS \uff1aTotal Sum of Square \u603b\u5e73\u65b9\u548c \\(TSS=\\sum(y_i-\\bar{y})^2=RSS+ESS\\) RSE \uff1aResidual Standard Error \u6b8b\u5dee\u6807\u51c6\u8bef \u6b8b\u5dee\u7684\u6807\u51c6\u5dee \\(RSE=\\sqrt{\\frac{1}{n-p-1}RSS}\\) \uff0cp \u662f \u53d8\u91cf\u6570 \\(R^2\\) \u7edf\u8ba1\u91cf \uff1a \\(R^2=\\frac{TSS-RSS}{TSS}=1-\\frac{RSS}{TSS}\\) SD / SE \uff1a \u7edf\u8ba1\u5b66\u4e0a\u6807\u51c6\u5dee\u4e0e\u6807\u51c6\u8bef\u7684\u533a\u522b\u4e0e\u8054\u7cfb\u662f\u4ec0\u4e48\uff1f \u4e2a\u4eba\u7406\u89e3\u5982\u4e0b\uff1a SD\u662f\u6807\u51c6\u5dee\uff0cSE\u662f\u6807\u51c6\u8bef\uff1bSD\u662f\u7edf\u8ba1\u91cf\uff0cSE\u662f\u7edf\u8ba1\u91cf\u7684\u6807\u51c6\u5dee\uff0c\u6bd4\u5982\u5bf9\u4e8e\u4e00\u4e2a\u6837\u672c\u7684\u5e73\u5747\u503c\uff0c\u5728\u603b\u4f53\u4e2d\u591a\u6b21\u53d6\u6709\u653e\u56de\u7684\u53d6\u540c\u89c4\u6a21\u7684\u6837\u672c\uff0c\u5f97\u5230\u7684\u5e73\u5747\u503c\u662f\u4e0d\u540c\u7684\uff0c\u6240\u4ee5\u8fd9\u4e2a\u5e73\u5747\u503c\u4e5f\u662f\u6709\u6807\u51c6\u5dee\u7684\uff0c\u53eb\u505a\u6807\u51c6\u8bef\uff1b\u800c\u4e14\u663e\u7136\u7684\u662f\u6837\u672c\u89c4\u6a21\u8d8a\u5927\uff0c\u6807\u51c6\u8bef\u8d8a\u5c0f\uff08\u6240\u4ee5\u6807\u51c6\u8bef\u7684\u5f0f\u5b50\u7684\u5206\u6bcd\u662f n\uff09\uff1bSE \u8d8a\u5c0f\u8868\u793a\u6240\u5f97\u7684\u7edf\u8ba1\u503c\u8d8a\u63a5\u8fd1\u771f\u5b9e\u503c \\(C_p=\\frac{1}{n}(RSS+2d\\hat{\\sigma}^2)\\) \\(AIC=\\frac{1}{n\\hat{\\sigma}^2}(RSS+2d\\hat{\\sigma}^2)\\) \\(BIC=\\frac{1}{n}(RSS+log(n)d\\hat{\\sigma}^2)\\) \\(\u8c03\u6574R^2=1-\\frac{RSS/(n-d-1)}{TSS/(n-1)}\\) \u7ebf\u6027\u56de\u5f52 \u00b6 \u7b80\u5355\u7ebf\u6027\u56de\u5f52 \u00b6 \\[ Y=\\beta_0+\\beta_1X+\\epsilon \\] \u4f30\u8ba1\u7cfb\u6570 \u00b6 \\[ RSS=\\sum_n(y_i-\\beta_0-\\beta_0x_i)^2 \\] \\[ \\beta_1=\\frac{\\sum_n(x_i-\\bar{x})(y_i-\\bar{y})}{\\sum_n(x_i-\\bar{x})^2} \\\\ \\beta_0=\\bar{y}-\\beta_1\\bar{x} \\] \u4f30\u8ba1\u503c\u7684\u51c6\u786e\u6027 \u00b6 \u5047\u8bbe \\(Y=\\beta_0+\\beta_1X+\\epsilon\\) \u4e2d\u7684\u8bef\u5dee\u9879 \\(\\epsilon_i\\) \u72ec\u7acb\u5e76\u5177\u6709\u76f8\u7b49\u7684\u65b9\u5dee\uff0c\u6709 \\(\\hat{u}\\) \u7684\u6807\u51c6\u8bef\uff1a \u8bb0 \\(\\hat{u}\\) \u4e3a \\(Y\\) \u7684\u6837\u672c\u5747\u503c\uff0c\u6709 \u6807\u51c6\u8bef (standard error\uff0c\u5199\u4f5c \\(SE(\\hat{u})\\) )\uff0c \\(Var(\\hat{u})=SE(\\hat{u})^2=\\frac{\\sigma^2}{n}\\) \uff0c\u5176\u4e2d \\(\\sigma\\) \u662f \\(Y\\) \u7684\u6bcf\u4e2a\u5b9e\u73b0\u503c \\(y_i\\) \u7684\u6807\u51c6\u5dee\uff0c\u6807\u51c6\u8bef\u544a\u8bc9\u6211\u4eec \\(\\hat{u}\\) \u504f\u79bb\u771f\u5b9e\u503c \\(u\\) \u7684\u5e73\u5747\u91cf\uff0c\u800c\u4e14\u8fd9\u79cd\u504f\u5dee\u968f\u7740 \\(n\\) \u7684\u589e\u52a0\u800c\u51cf\u5c0f \\(\\hat{\\beta_0} \\ \\hat{\\beta_1}\\) \u7684\u6807\u51c6\u8bef\uff1a \\(SE(\\hat{\\beta_0})^2=\\sigma^2[\\frac{1}{n}+\\frac{\\bar{x}^2}{\\sum(x_i-\\bar{x})^2}] \\ \\ \\ \\ SE(\\hat{\\beta_1})^2=\\frac{\\sigma^2}{\\sum(x_i-\\bar{x})^2}\\) \uff0c \u5176\u4e2d \\(\\sigma^2=Var(\\epsilon)\\) \\(x_i\\) \u503c\u5206\u6563\u65f6\uff0c \\(SE(\\hat{\\beta_1})\\) \u66f4\u5c0f\uff1b \\(\\bar{x}=0\\) \u65f6\uff0c \\(SE(\\hat{\\beta_0})=SE(\\hat{u})\\) \\(\\sigma^2\\) \u662f\u672a\u77e5\u7684\uff0c\u5bf9\u5176\u4e2d \\(\\sigma^2\\) \u7684\u4f30\u8ba1\u7528 RSE\uff08\u6b8b\u5dee\u6807\u51c6\u8bef\uff09\uff1a \\(RES=\\sqrt{\\frac{1}{n-2}RSS}\\) \u6709\u4e86\u6807\u51c6\u8bef\u540e\u5c31\u53ef\u4ee5\u8ba1\u7b97\u7f6e\u4fe1\u533a\u95f4\uff0c\u5bf9\u4e8e\u7ebf\u6027\u56de\u5f52\u6a21\u578b \\(\\beta_1\\) \u7684 95% \u7684\u7f6e\u4fe1\u533a\u95f4\u4e3a \\(\\beta_1\\pm 2SE(\\hat{\\beta_1})\\) \uff1b\u4e5f\u53ef\u4ee5\u8fdb\u884c\u5047\u8bbe\u68c0\u9a8c $$ H_0:X\u548cY\u6ca1\u6709\u5173\u7cfb\\ \\ H_{\\alpha}:X\u548cY\u4e4b\u95f4\u6709\u4e00\u5b9a\u5173\u7cfb \\ \u5373 H_0:\\beta_1=0 \\ \\ H_{\\alpha}:\\beta_1\\not=0 $$ \u5f53 \\(t=|\\frac{\\hat{\\beta_1}-0}{SE(\\hat{\\beta_1})}|>Z_{\\alpha/2}\\) \u662f\u62d2\u7edd\u539f\u5047\u8bbe \u8bc4\u4ef7\u6a21\u578b\u7684\u6b63\u786e\u6027 \u00b6 \u91cf\u5316 \u6a21\u578b\u62df\u5408\u6570\u636e\u7684\u7a0b\u5ea6 \u7528 RSE\uff08\u6b8b\u5dee\u6807\u51c6\u8bef\uff09\u548c \\(R^2\\) \u7edf\u8ba1\u91cf RSE\uff1a\u5bf9\u6a21\u578b \u5931\u62df \u7684\u5ea6\u91cf\uff0c\u8d8a\u5c0f\u8868\u793a\u6a21\u578b\u8d8a\u63a5\u8fd1\u771f\u5b9e\u503c \\(R^2\\) \u7edf\u8ba1\u91cf\uff1a \\(R^2=\\frac{TSS-RSS}{TSS}=1-\\frac{RSS}{TSS}\\) \u8d8a\u63a5\u8fd1 1 \u8d8a\u597d\uff0c\u8d8a\u63a5\u8fd1 1 \u8bf4\u660e\u56de\u5f52\u7684\u6a21\u578b\u53ef\u4ee5\u89e3\u91ca\u54cd\u5e94\u53d8\u91cf \\(y_i\\) \u7684\u7edd\u5927\u90e8\u5206\u53d8\u5f02\uff1b\u63a5\u8fd1 0 \u8bf4\u660e \u7ebf\u6027\u6a21\u578b\u662f\u9519\u8bef\u7684\uff0c\u6216\u8005\u662f \u56fa\u6709\u8bef\u5dee \\(\\sigma^2\\) \u8f83\u5927\uff0c\u6216\u8005\u4e24\u8005\u517c\u6709 \\(R^2\\) \u4e00\u5b9a\u5728 0~1 \u4e4b\u95f4\uff0c\u6240\u4ee5\u6bd4 RSE \u66f4\u6613\u4e8e\u89e3\u91ca\uff0c\u4f46\u662f\u8fd8\u662f\u8981\u5177\u4f53\u53d6\u51b3\u4e8e\u5e94\u7528 \\(R^2\\) \u8861\u91cf\u4e86 \\(X\\ Y\\) \u4e4b\u95f4\u7684\u7ebf\u6027\u5173\u7cfb\uff0c\u800c \u76f8\u5173\u7cfb\u6570 \\(r=cor(X,Y)\\) \u4e5f\u8861\u91cf\u4e86 \\(X\\ Y\\) \u4e4b\u95f4\u7684\u7ebf\u6027\u5173\u7cfb\uff1b\u4e8b\u5b9e\u4e0a\u5728\u7b80\u5355\u7684\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u4e2d\uff0c \\(R^2=r^2\\) \uff1b\u4f46\u5728\u591a\u5143\u7ebf\u6027\u56de\u5f52\u4e2d \\(r^2\\) \u65e0\u6cd5\u8bc4\u4ef7\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u7684\u62df\u5408\u5ea6\uff0c \\(R^2\\) \u5c06\u627f\u62c5\u8fd9\u9879\u4efb\u52a1 \u591a\u5143\u7ebf\u6027\u56de\u5f52 \u00b6 \\[ Y=\\beta_0+\\sum_p(\\beta_iX_i)+\\epsilon \\] \u4f30\u8ba1\u7cfb\u6570 \u00b6 \\[ RSS=\\sum(\\hat{y_i}-y_i)^2 \\] \u4e00\u4e9b\u91cd\u8981\u95ee\u9898 \u00b6 \u76f8\u5e94\u53d8\u91cf\u548c\u9884\u6d4b\u53d8\u91cf\u4e4b\u95f4\u662f\u5426\u6709\u5173\u7cfb\uff1f \u00b6 \u5047\u8bbe\u68c0\u9a8c $$ H_0:\\beta_1=..\\beta_p=0 \\ \\ \\ H_{\\alpha}:\u81f3\u5c11\u6709\u4e00\u4e2a\\beta_j \\not=0\u200b $$ \u8ba1\u7b97 F\u7edf\u8ba1\u91cf \uff1a \\(F=\\frac{ESS/p}{RSS/(n-p-1)}\\) \uff0cF \u63a5\u8fd1 1 \u63a5\u53d7\u539f\u5047\u8bbe .... \u9009\u5b9a\u91cd\u8981\u53d8\u91cf \u00b6 \u5c1d\u8bd5\u6240\u6709\u7684\u6a21\u578b( \\(2^p\\) \u79cd)\uff1a \u7edf\u8ba1\u6307\u6807\uff1aMallow's\u7edf\u8ba1\u91cf \\(C_p\\) \uff0c\u8d64\u6c60\u4fe1\u606f\u91cf\u51c6\u5219AIC\uff0c\u8d1d\u53f6\u65af\u4fe1\u606f\u51c6\u5219BIC\uff0c\u8c03\u6574 \\(R^2\\) (Adjusted \\(R^2\\) ) \u53ea\u9002\u7528\u4e8e p \u8f83\u5c0f\u7684\u60c5\u51b5 \u5411\u524d\u9009\u62e9\uff0c\u5411\u540e\u9009\u62e9\uff0c\u6df7\u5408\u9009\u62e9 p > n \u65f6\u4e0d\u80fd\u5411\u540e\u9009\u62e9 \u6a21\u578b\u62df\u5408 \u00b6 RSE \u548c \\(R^2\\) \u9884\u6d4b \u00b6 \u56de\u5f52\u6a21\u578b\u5176\u4ed6\u6ce8\u610f\u4e8b\u9879 \u00b6 \u8425\u9500\u8ba1\u5212 \u00b6 \u7ebf\u6027\u56de\u5f52\u4e0eK\u6700\u8fd1\u90bb\u6cd5\u7684\u6bd4\u8f83 \u00b6 \u5b9e\u9a8c\uff1a\u7ebf\u6027\u56de\u5f52 \u00b6 \u91cd\u62bd\u6837\u65b9\u6cd5 \u00b6 \u4ea4\u53c9\u9a8c\u8bc1\u6cd5 \u00b6 \u9a8c\u8bc1\u96c6\u65b9\u6cd5 \u00b6 \u5c06\u6570\u636e\u96c6\u5206\u4e3a\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\uff0c\u5c06\u4e0d\u540c\u7684\u6a21\u578b\u8bad\u7ec3\u597d\u540e\u53bb\u6d4b\u8bd5\u96c6\u8ba1\u7b97\u5747\u65b9\u8bef\u5dee \u7f3a\u9677\uff1a\u6d4b\u8bd5\u96c6\u7684\u6ce2\u52a8\u5927\uff0c\u8bad\u7ec3\u6570\u636e\u5c11 \u7559\u4e00\u4ea4\u53c9\u9a8c\u8bc1\u6cd5 \u00b6 LOOCV\uff1aleave-one-out cross-validation \u5728\u89c4\u6a21\u4e3a n \u7684\u6570\u636e\u96c6\u4e2d\u7559\u4e0b \\((x_i,y_i)\\) \u4f5c\u4e3a\u6d4b\u8bd5\u96c6\uff0c\u5176\u4f59 \\(n-1\\) \u4e2a\u6570\u636e\u4f5c\u4e3a\u8bad\u7ec3\u96c6\uff0c\u8bad\u7ec3\u540e\u5728 \\((x_i,y_i)\\) \u4e0a\u8ba1\u7b97\u51fa \\(MSE_i=(y_i-\\hat{y_i})^2\\) \u91cd\u590d\u4e0a\u8ff0\u64cd\u4f5c n \u6b21\uff0c\u8ba1\u7b97 \\(CV_{n}=\\frac{1}{n}\\sum_{i=1}^nMSE_i\\) \u7f3a\u9677\uff1a n \u5f88\u5927 \u6216\u8005 \u62df\u5408\u4e00\u6b21\u5f88\u6162 \u5341\u5206\u8017\u65f6 \u5982\u679c\u7528\u6700\u5c0f\u4e8c\u4e58\u6cd5\u6765\u62df\u5408\u7ebf\u6027\u6216\u8005\u591a\u9879\u5f0f\u56de\u5f52\u6a21\u578b\uff0c\u53ef\u4ee5\u628a\u65f6\u95f4\u538b\u7f29\u81f3\u4e0e\u62df\u5408\u4e00\u4e2a\u6a21\u578b\u65f6\u95f4\u76f8\u540c\uff0c\u516c\u5f0f\u5982\u4e0b\uff1a $$ CV_{n}=\\frac{i}{n}\\sum_{i=1}^n(\\frac{y_i-\\hat{y_i}}{1-h_i})^2 $$ \u5176\u4e2d \\(h_i\\) \u4e3a\u6760\u6746\u503c k \u6298\u4ea4\u53c9\u9a8c\u8bc1\u6cd5 \u00b6 \u4e0e LOOCV \u7c7b\u4f3c\uff0c\u628a\u6570\u636e\u96c6\u5206\u6210 k \u7ec4\uff0c\u6bcf\u6b21\u7559\u4e00\u7ec4\u4f5c\u4e3a\u9a8c\u8bc1\u96c6\uff0c\u8ba1\u7b97 \\(CV_k=\\frac{1}{k}\\sum_{i=1}^kMSE_i\\) \u4e3a\u4e86\u6743\u8861\u65b9\u5dee\u4e0e\u504f\u5dee\uff0ck \u4e00\u822c\u53d6 5 \u6216 10 \u4f18\u70b9\u663e\u800c\u6613\u89c1\uff0c\u8fd0\u7b97\u5feb\uff0c\u4f46\u662f\u5b58\u5728\u4e00\u5b9a\u7684\u6ce2\u52a8\u6027 LOOCV \u548c k\u6298\u4ea4\u53c9\u9a8c\u8bc1\u8fd8\u53ef\u4ee5\u7528\u4e8e\u9009\u62e9\u6a21\u578b\u7684\u5149\u6ed1\u7a0b\u5ea6 k \u6298\u4ea4\u53c9\u9a8c\u8bc1\u7684\u504f\u5dee-\u65b9\u5dee\u6743\u8861 \u00b6 \u4ece\u51cf\u5c0f\u504f\u5dee\u7684\u89d2\u5ea6\u6765\u770b\uff0c\u663e\u7136 LOOCV \u6bd4 k \u6298 CV\u597d\uff0c\u4f46\u504f\u5dee\u4e0d\u662f\u552f\u4e00\u8003\u8651\u7684\u8981\u7d20 \\(k<n\\) \u65f6\uff0cLOOCV \u65b9\u6cd5\u7684\u65b9\u5dee\u6bd4 k \u6298 CV \u65b9\u6cd5\u7684\u65b9\u5dee\u5927\uff1b\u56e0\u4e3a LOOCV \u7684\u6bcf\u4e2a\u8bad\u7ec3\u96c6\u90fd\u662f\u51e0\u4e4e\u4e00\u6837\u7684\uff0c\u800c k \u6298 CV \u6bcf\u4e2a\u8bad\u7ec3\u96c6\u7684\u91cd\u53e0\u7a0b\u5ea6\u76f8\u5bf9\u8f83\u5c0f \u6240\u4ee5\u4e3a\u4e86\u6743\u8861\u65b9\u5dee\u4e0e\u504f\u5dee\uff0ck \u4e00\u822c\u53d6 5 \u6216 10 \u81ea\u52a9\u6cd5 \u00b6 \u7ebf\u6027\u6a21\u578b\u9009\u62e9\u4e0e\u6b63\u5219\u5316 \u00b6 \u5b50\u96c6\u9009\u62e9 \u00b6 \u4ece \\(p\\) \u4e2a\u9884\u6d4b\u53d8\u91cf\u4e2d\u6311\u9009\u4e0e\u54cd\u5e94\u53d8\u91cf\u76f8\u5173\u7684\u53d8\u91cf\u5f62\u6210\u5b50\u96c6\uff0c\u518d\u5bf9\u8fd9\u4e2a\u5b50\u96c6\u8fd0\u7528\u6700\u5c0f\u4e8c\u4e58 \u6700\u4f18\u5b50\u96c6\u9009\u62e9 \u00b6 \u5bf9 \\(p\\) \u4e2a\u9884\u6d4b\u53d8\u91cf\u7684\u6240\u6709\u7ec4\u5408\u5206\u522b\u4f7f\u7528\u6700\u5c0f\u4e8c\u4e58\uff0c\u5373\u4e00\u5171 \\(2^p\\) \u4e2a\u6a21\u578b \\(O(2^p)\\) \u5177\u4f53\u8fc7\u7a0b\uff1a \u4e0d\u542b\u9884\u6d4b\u53d8\u91cf\u7684\u96f6\u6a21\u578b \\(M_0\\) \u53ea\u7528\u4e8e\u4f30\u8ba1\u89c2\u6d4b\u6837\u672c\u7684\u6837\u672c\u5747\u503c \u5bf9\u4e8e \\(k=1,2,...,p\\) \uff1a (a) \u62df\u5408 \\(\\begin{pmatrix}p\\\\k\\end{pmatrix}\\) \u4e2a\u5305\u542b \\(k\\) \u4e2a\u9884\u6d4b\u53d8\u91cf\u7684\u6a21\u578b (b) \u4ece \\(\\begin{pmatrix}p\\\\k\\end{pmatrix}\\) \u4e2d\u9009\u62e9 \\(RSS\\) \u6700\u5c0f \u6216 \\(R^2\\) \u6700\u5927\u7684\u4f5c\u4e3a\u6700\u4f18\u6a21\u578b\uff0c\u8bb0\u4e3a \\(M_k\\) \u6839\u636e\u4ea4\u53c9\u9a8c\u8bc1\u9884\u6d4b\u8bef\u5dee\uff0c \\(c_p(AIC)\\) \uff0c \\(BIC\\) \uff0c\u6216\u8005 \u8c03\u6574 \\(R^2\\) \u4ece \\(M_0,...,M_p\\) \u4e2d\u9009\u62e9\u6700\u4f18\u7684\u6a21\u578b \u9010\u6b65\u9009\u62e9 \u00b6 \u5411\u524d\u9010\u6b65\u9009\u62e9 \u00b6 \u6bcf\u6b21\u6dfb\u52a0\u4e00\u4e2a\u80fd\u6700\u5927\u9650\u5ea6\u63d0\u5347\u6a21\u578b\u6548\u679c\u7684\u53d8\u91cf\u52a0\u5165\u6a21\u578b \\(O(n^2)\\) \u4e0d\u542b\u9884\u6d4b\u53d8\u91cf\u7684\u96f6\u6a21\u578b\u8bb0\u4e3a \\(M_0\\) \u5bf9\u4e8e \\(k=0,2,...,p-1\\) \uff1a (a) \u4ece \\(p-k\\) \u4e2a\u6a21\u578b\u4e2d\u8fdb\u884c\u9009\u62e9\uff0c\u6bcf\u4e2a\u90fd\u5728 \\(M_k\\) \u7684\u57fa\u7840\u4e0a\u589e\u52a0\u4e00\u4e2a\u53d8\u91cf (b) \u5728 \\(p-k\\) \u4e2a\u6a21\u578b\u4e2d\u9009\u62e9 \\(RSS\\) \u6700\u5c0f \u6216 \\(R^2\\) \u6700\u5927\u7684\u6a21\u578b\u8bb0\u4e3a \\(M_{k+1}\\) \u6839\u636e\u4ea4\u53c9\u9a8c\u8bc1\u9884\u6d4b\u8bef\u5dee\uff0c \\(c_p(AIC)\\) \uff0c \\(BIC\\) \uff0c\u6216\u8005 \u8c03\u6574 \\(R^2\\) \u4ece \\(M_0,...,M_p\\) \u4e2d\u9009\u62e9\u6700\u4f18\u7684\u6a21\u578b \u65e0\u6cd5\u4fdd\u8bc1\u662f\u5168\u5c40\u6700\u4f18\u7684\uff0c\u5728 \\(n<p\\) \u65f6\u90fd\u53ef\u4ee5\u4f7f\u7528\u5411\u524d\u9009\u62e9\uff0c\u8fd9\u65f6\u53ef\u4ee5\u5efa\u7acb\u5b50\u6a21\u578b \\(M_0,...,M_{n-1}\\) \u82e5 \\(n\\leq p\\) \uff0c\u7ed3\u679c\u662f\u4e0d\u552f\u4e00\u7684 \u5411\u540e\u9010\u6b65\u9009\u62e9 \u00b6 \u4e0e\u5411\u524d\u9009\u62e9\u7c7b\u4f3c \\(O(n^2)\\) \u5305\u542b\u5168\u90e8 \\(p\\) \u4e2a\u9884\u6d4b\u53d8\u91cf\u7684\u96f6\u6a21\u578b\u8bb0\u4e3a \\(M_p\\) \u5bf9\u4e8e \\(k=p,...1\\) \uff1a (a) \u4ece \\(k\\) \u4e2a\u6a21\u578b\u4e2d\u8fdb\u884c\u9009\u62e9\uff0c\u6bcf\u4e2a\u90fd\u5728 \\(M_k\\) \u7684\u57fa\u7840\u4e0a\u51cf\u5c11\u4e00\u4e2a\u53d8\u91cf (b) \u5728 \\(k\\) \u4e2a\u6a21\u578b\u4e2d\u9009\u62e9 \\(RSS\\) \u6700\u5c0f \u6216 \\(R^2\\) \u6700\u5927\u7684\u6a21\u578b\u8bb0\u4e3a \\(M_{k-1}\\) \u6839\u636e\u4ea4\u53c9\u9a8c\u8bc1\u9884\u6d4b\u8bef\u5dee\uff0c \\(c_p(AIC)\\) \uff0c \\(BIC\\) \uff0c\u6216\u8005 \u8c03\u6574 \\(R^2\\) \u4ece \\(M_0,...,M_p\\) \u4e2d\u9009\u62e9\u6700\u4f18\u7684\u6a21\u578b \u65e0\u6cd5\u4fdd\u8bc1\u662f\u5168\u5c40\u6700\u4f18\u7684\uff0c\u4e14\u9700\u8981\u6ee1\u8db3 \\(n > p\\) \u9009\u62e9\u6700\u4f18\u6a21\u578b \u00b6 \\(C_p\\) \uff0cAIC\uff0cBIC\uff0c\u8c03\u6574 \\(R^2\\) \u00b6 \u8bad\u7ec3\u8bef\u5dee\u53ef\u80fd\u662f\u6d4b\u8bd5\u8bef\u5dee\u4e2d\u8f83\u5dee\u7684\u4e00\u4e2a\u4f30\u8ba1\uff0c \\(RSS,R^2\\) \u503c\u5e76\u4e0d\u9002\u7528\u4e8e\u5bf9\u5305\u542b\u4e0d\u540c\u53d8\u91cf\u4e2a\u6570\u7684\u6a21\u578b\u8fdb\u884c\u9009\u62e9 \u672c\u8282\u5305\u542b\u4e09\u4e2a\u65b9\u6cd5\uff1a \\(C_p\\) \uff0c\u8d64\u6c60\u4fe1\u606f\u91cf\u51c6\u5219AIC\uff0c\u8d1d\u53f6\u65af\u4fe1\u606f\u51c6\u5219BIC\uff0c\u8c03\u6574 \\(R^2\\) (Adjusted \\(R^2\\) ) \\(C_p=\\frac{1}{n}(RSS+2d\\hat{\\sigma}^2)\\) \u5176\u4e2d \\(\\hat{\\sigma}^2\\) \u662f \\(\\epsilon\\) \u7684\u4f30\u8ba1\u503c\uff0c \\(d\\) \u662f\u9884\u6d4b\u53d8\u91cf\u6570 \\(AIC=\\frac{1}{n\\hat{\\sigma}^2}(RSS+2d\\hat{\\sigma}^2)\\) \u9002\u7528\u4e8e\u4f7f\u7528\u6781\u5927\u4f3c\u7136\u4f30\u8ba1\u62df\u5408\u7684\u6a21\u578b\uff0c\u82e5 \\(\\epsilon\\) \u670d\u4ece\u9ad8\u65af\u5206\u5e03\uff0c\u6781\u5927\u4f3c\u7136\u4f30\u8ba1\u548c\u6700\u5c0f\u4e8c\u4e58\u662f\u7b49\u4ef7\u7684\uff1b\u5bf9\u4e8e\u6700\u5c0f\u4e8c\u4e58\u6a21\u578b \\(c_p\\ \\ AIC\\) \u6210\u6bd4\u4f8b \\(BIC=\\frac{1}{n}(RSS+log(n)d\\hat{\\sigma}^2)\\) \uff0c\u5bf9\u4e8e\u4efb\u610f \\(n>7,\\ log(n)>2\\) \u6240\u4ee5 \\(BIC\\) \u7684\u60e9\u7f5a\u66f4\u91cd\uff0c\u76f8\u6bd4\u4e8e \\(C_p\\) \u5f97\u5230\u7684\u6a21\u578b\u7684\u53d8\u91cf\u66f4\u5c11 \\(\u8c03\u6574R^2=1-\\frac{RSS/(n-d-1)}{TSS/(n-1)}\\) \u76f8\u6bd4\u4e8e \\(R^2\\) \u5f15\u5165\u4e86\u60e9\u7f5a \u9664\u4e86 \\(\u8c03\u6574R^2\\) \u90fd\u662f\u8d8a\u5c0f\u8d8a\u597d \u9a8c\u8bc1\u4e0e\u4ea4\u53c9\u9a8c\u8bc1 \u00b6 \u538b\u7f29\u4f30\u8ba1\u65b9\u6cd5 \u00b6 \u5bf9\u5168\u90e8 \\(p\\) \u4e2a\u53d8\u91cf\u62df\u5408\uff0c\u52a0\u5165\u4e00\u4e9b\u7ea6\u675f\uff0c\u4e0e\u6700\u5c0f\u4e8c\u4e58\u76f8\u6bd4\u53ef\u4ee5\u5c06\u67d0\u4e9b\u7cfb\u6570\u7f29\u51cf\u4e3a 0 \u5cad\u56de\u5f52 \u00b6 \\[ min \\ \\ RSS+\\lambda\\sum_{j=1}^{p}\\beta_j^2 \\] \\(\\lambda=0\\) \u65f6\uff0c\u60e9\u7f5a\u9879\u4e0d\u8d77\u4f5c\u7528\uff1b \\(\\lambda\\rightarrow inf\\) \u65f6\uff0c\u4f30\u8ba1\u503c\u4f1a\u8d8a\u6765\u8d8a\u63a5\u8fd1 0 \u60e9\u7f5a\u9879\u4e0d\u60e9\u7f5a\u5e38\u6570\u9879 \\(\\beta_0\\) \u6700\u5c0f\u4e8c\u4e58\u5982\u679c\u4e00\u4e2a\u53d8\u91cf\u7684\u5355\u4f4d\u53d8\u4e86\uff0c\u53ea\u4f1a\u5f71\u54cd\u6b64\u53d8\u91cf\u7684\u7cfb\u6570\uff1b\u800c\u5cad\u56de\u5f52\u5219\u4f1a\u5f71\u54cd\u5176\u4ed6\u7684\u7cfb\u6570\uff0c\u6240\u4ee5\u4f7f\u7528\u524d\u9700\u8981\u5c06\u53d8\u91cf\u8fdb\u884c\u6807\u51c6\u5316 (\u8fd9\u91cc\u7684\u6807\u51c6\u5316\u53ea\u662f\u9664\u4ee5\u4e86\u6807\u51c6\u5dee) $$ \\widetilde{x} {i,j}=\\frac{x {i,j}}{\\sqrt{\\frac{1}{n}\\sum(x_{ij}-\\bar{x}_j)^2}} $$ \u52a3\u52bf\uff1a\u4e0d\u4f1a\u628a\u7cfb\u6570\u786e\u5207\u7684\u538b\u7f29\u81f3 0\uff0c\u5f53 p \u5f88\u5927\u65f6\uff0c\u4e0d\u5229\u4e8e\u6a21\u578b\u89e3\u91ca Lasso \u00b6 \\[ min \\ \\ RSS+\\lambda\\sum_{j=1}^p|\\beta_j| \\] \u60e9\u7f5a\u9879\u4e0d\u60e9\u7f5a\u5e38\u6570\u9879 \\(\\beta_0\\) Lasso \u80fd\u591f\u5c06\u53d8\u91cf\u538b\u7f29\u81f3 0 \u5176\u4ed6 \u00b6 \u6700\u5c0f\u4e8c\u4e58\u63a8\u5bfc \u00b6 \u7b80\u5355\u7ebf\u6027\u56de\u5f52\uff1a $$ RSS=\\sum_n(y_i-\\beta_0-\\beta_1x_i)^2 $$ \\[ \\frac{\\alpha RSS}{\\alpha \\beta_1}=\\sum_n-2x_i(y_i-\\beta_0-\\beta_1x_i)=0 \\\\ \\frac{\\alpha RSS}{\\alpha \\beta_0}=\\sum_n-2(y_i-\\beta_0-\\beta_1x_i)=0 \\] \u6574\u7406\u5f97 $$ \\beta_1=\\frac{\\sum_n(x_i-\\bar{x})(y_i-\\bar{y})}{\\sum_n(x_i-\\bar{x})^2} \\ \\beta_0=\\bar{y}-\\beta_1\\bar{x} $$ \u591a\u5143\u7ebf\u6027\u56de\u5f52\uff1a\u7528\u77e9\u9635\u7684\u5f62\u5f0f $$ min(RSS)=min||XA-Y||_2^2 $$ \\[ \\begin{equation} \\begin{split} \\frac{\\alpha RSS}{\\alpha X} &=\\frac{\\alpha (AX-Y)^T(AX-Y)}{\\alpha X} \\\\ &=\\frac{\\alpha (X^TA^TAX-X^TA^TY-Y^TAX+Y^TY)}{\\alpha X} \\end{split} \\end{equation} \\] \u7531 \\(\\frac{\\alpha X^TA}{\\alpha X} =\\frac{\\alpha A^TX}{\\alpha X}=A, \\ \\ \\ \\frac{\\alpha X^TAX}{\\alpha X} =AX+A^TX\\) \u5f97 $$ \\frac{\\alpha RSS}{\\alpha X} =2A^TAX-2A^TY=0 \\ X=(A^TA)^{-1}A^TY $$","title":"\u7edf\u8ba1\u5b66\u5bfc\u8bba \u57fa\u4e8eR\u5e94\u7528"},{"location":"ISL/#r","text":"An Introduction to Statistical Learning with Applications in R","title":"\u7edf\u8ba1\u5b66\u5bfc\u8bba \u57fa\u4e8eR\u5e94\u7528"},{"location":"ISL/#_1","text":"MSE \uff1aMean Squared Error \u5747\u65b9\u8bef\u5dee \\(MSE=\\frac{1}{n}\\sum(\\hat{y_i}-y_i)^2=\\frac{1}{n}RSS\\) RSS \uff1aResidual Sum of Squares \u6b8b\u5dee\u5e73\u65b9\u548c \\(RSS=\\sum(y_i-\\hat{y_i})^2\\) ESS \uff1aExplained Sum of Squares \u89e3\u91ca\u5e73\u65b9\u548c \\(ESS=\\sum(\\hat{y_i}-\\bar{y})^2\\) TSS \uff1aTotal Sum of Square \u603b\u5e73\u65b9\u548c \\(TSS=\\sum(y_i-\\bar{y})^2=RSS+ESS\\) RSE \uff1aResidual Standard Error \u6b8b\u5dee\u6807\u51c6\u8bef \u6b8b\u5dee\u7684\u6807\u51c6\u5dee \\(RSE=\\sqrt{\\frac{1}{n-p-1}RSS}\\) \uff0cp \u662f \u53d8\u91cf\u6570 \\(R^2\\) \u7edf\u8ba1\u91cf \uff1a \\(R^2=\\frac{TSS-RSS}{TSS}=1-\\frac{RSS}{TSS}\\) SD / SE \uff1a \u7edf\u8ba1\u5b66\u4e0a\u6807\u51c6\u5dee\u4e0e\u6807\u51c6\u8bef\u7684\u533a\u522b\u4e0e\u8054\u7cfb\u662f\u4ec0\u4e48\uff1f \u4e2a\u4eba\u7406\u89e3\u5982\u4e0b\uff1a SD\u662f\u6807\u51c6\u5dee\uff0cSE\u662f\u6807\u51c6\u8bef\uff1bSD\u662f\u7edf\u8ba1\u91cf\uff0cSE\u662f\u7edf\u8ba1\u91cf\u7684\u6807\u51c6\u5dee\uff0c\u6bd4\u5982\u5bf9\u4e8e\u4e00\u4e2a\u6837\u672c\u7684\u5e73\u5747\u503c\uff0c\u5728\u603b\u4f53\u4e2d\u591a\u6b21\u53d6\u6709\u653e\u56de\u7684\u53d6\u540c\u89c4\u6a21\u7684\u6837\u672c\uff0c\u5f97\u5230\u7684\u5e73\u5747\u503c\u662f\u4e0d\u540c\u7684\uff0c\u6240\u4ee5\u8fd9\u4e2a\u5e73\u5747\u503c\u4e5f\u662f\u6709\u6807\u51c6\u5dee\u7684\uff0c\u53eb\u505a\u6807\u51c6\u8bef\uff1b\u800c\u4e14\u663e\u7136\u7684\u662f\u6837\u672c\u89c4\u6a21\u8d8a\u5927\uff0c\u6807\u51c6\u8bef\u8d8a\u5c0f\uff08\u6240\u4ee5\u6807\u51c6\u8bef\u7684\u5f0f\u5b50\u7684\u5206\u6bcd\u662f n\uff09\uff1bSE \u8d8a\u5c0f\u8868\u793a\u6240\u5f97\u7684\u7edf\u8ba1\u503c\u8d8a\u63a5\u8fd1\u771f\u5b9e\u503c \\(C_p=\\frac{1}{n}(RSS+2d\\hat{\\sigma}^2)\\) \\(AIC=\\frac{1}{n\\hat{\\sigma}^2}(RSS+2d\\hat{\\sigma}^2)\\) \\(BIC=\\frac{1}{n}(RSS+log(n)d\\hat{\\sigma}^2)\\) \\(\u8c03\u6574R^2=1-\\frac{RSS/(n-d-1)}{TSS/(n-1)}\\)","title":"\u5e38\u7528\u672f\u8bed"},{"location":"ISL/#_2","text":"","title":"\u7ebf\u6027\u56de\u5f52"},{"location":"ISL/#_3","text":"\\[ Y=\\beta_0+\\beta_1X+\\epsilon \\]","title":"\u7b80\u5355\u7ebf\u6027\u56de\u5f52"},{"location":"ISL/#_4","text":"\\[ RSS=\\sum_n(y_i-\\beta_0-\\beta_0x_i)^2 \\] \\[ \\beta_1=\\frac{\\sum_n(x_i-\\bar{x})(y_i-\\bar{y})}{\\sum_n(x_i-\\bar{x})^2} \\\\ \\beta_0=\\bar{y}-\\beta_1\\bar{x} \\]","title":"\u4f30\u8ba1\u7cfb\u6570"},{"location":"ISL/#_5","text":"\u5047\u8bbe \\(Y=\\beta_0+\\beta_1X+\\epsilon\\) \u4e2d\u7684\u8bef\u5dee\u9879 \\(\\epsilon_i\\) \u72ec\u7acb\u5e76\u5177\u6709\u76f8\u7b49\u7684\u65b9\u5dee\uff0c\u6709 \\(\\hat{u}\\) \u7684\u6807\u51c6\u8bef\uff1a \u8bb0 \\(\\hat{u}\\) \u4e3a \\(Y\\) \u7684\u6837\u672c\u5747\u503c\uff0c\u6709 \u6807\u51c6\u8bef (standard error\uff0c\u5199\u4f5c \\(SE(\\hat{u})\\) )\uff0c \\(Var(\\hat{u})=SE(\\hat{u})^2=\\frac{\\sigma^2}{n}\\) \uff0c\u5176\u4e2d \\(\\sigma\\) \u662f \\(Y\\) \u7684\u6bcf\u4e2a\u5b9e\u73b0\u503c \\(y_i\\) \u7684\u6807\u51c6\u5dee\uff0c\u6807\u51c6\u8bef\u544a\u8bc9\u6211\u4eec \\(\\hat{u}\\) \u504f\u79bb\u771f\u5b9e\u503c \\(u\\) \u7684\u5e73\u5747\u91cf\uff0c\u800c\u4e14\u8fd9\u79cd\u504f\u5dee\u968f\u7740 \\(n\\) \u7684\u589e\u52a0\u800c\u51cf\u5c0f \\(\\hat{\\beta_0} \\ \\hat{\\beta_1}\\) \u7684\u6807\u51c6\u8bef\uff1a \\(SE(\\hat{\\beta_0})^2=\\sigma^2[\\frac{1}{n}+\\frac{\\bar{x}^2}{\\sum(x_i-\\bar{x})^2}] \\ \\ \\ \\ SE(\\hat{\\beta_1})^2=\\frac{\\sigma^2}{\\sum(x_i-\\bar{x})^2}\\) \uff0c \u5176\u4e2d \\(\\sigma^2=Var(\\epsilon)\\) \\(x_i\\) \u503c\u5206\u6563\u65f6\uff0c \\(SE(\\hat{\\beta_1})\\) \u66f4\u5c0f\uff1b \\(\\bar{x}=0\\) \u65f6\uff0c \\(SE(\\hat{\\beta_0})=SE(\\hat{u})\\) \\(\\sigma^2\\) \u662f\u672a\u77e5\u7684\uff0c\u5bf9\u5176\u4e2d \\(\\sigma^2\\) \u7684\u4f30\u8ba1\u7528 RSE\uff08\u6b8b\u5dee\u6807\u51c6\u8bef\uff09\uff1a \\(RES=\\sqrt{\\frac{1}{n-2}RSS}\\) \u6709\u4e86\u6807\u51c6\u8bef\u540e\u5c31\u53ef\u4ee5\u8ba1\u7b97\u7f6e\u4fe1\u533a\u95f4\uff0c\u5bf9\u4e8e\u7ebf\u6027\u56de\u5f52\u6a21\u578b \\(\\beta_1\\) \u7684 95% \u7684\u7f6e\u4fe1\u533a\u95f4\u4e3a \\(\\beta_1\\pm 2SE(\\hat{\\beta_1})\\) \uff1b\u4e5f\u53ef\u4ee5\u8fdb\u884c\u5047\u8bbe\u68c0\u9a8c $$ H_0:X\u548cY\u6ca1\u6709\u5173\u7cfb\\ \\ H_{\\alpha}:X\u548cY\u4e4b\u95f4\u6709\u4e00\u5b9a\u5173\u7cfb \\ \u5373 H_0:\\beta_1=0 \\ \\ H_{\\alpha}:\\beta_1\\not=0 $$ \u5f53 \\(t=|\\frac{\\hat{\\beta_1}-0}{SE(\\hat{\\beta_1})}|>Z_{\\alpha/2}\\) \u662f\u62d2\u7edd\u539f\u5047\u8bbe","title":"\u4f30\u8ba1\u503c\u7684\u51c6\u786e\u6027"},{"location":"ISL/#_6","text":"\u91cf\u5316 \u6a21\u578b\u62df\u5408\u6570\u636e\u7684\u7a0b\u5ea6 \u7528 RSE\uff08\u6b8b\u5dee\u6807\u51c6\u8bef\uff09\u548c \\(R^2\\) \u7edf\u8ba1\u91cf RSE\uff1a\u5bf9\u6a21\u578b \u5931\u62df \u7684\u5ea6\u91cf\uff0c\u8d8a\u5c0f\u8868\u793a\u6a21\u578b\u8d8a\u63a5\u8fd1\u771f\u5b9e\u503c \\(R^2\\) \u7edf\u8ba1\u91cf\uff1a \\(R^2=\\frac{TSS-RSS}{TSS}=1-\\frac{RSS}{TSS}\\) \u8d8a\u63a5\u8fd1 1 \u8d8a\u597d\uff0c\u8d8a\u63a5\u8fd1 1 \u8bf4\u660e\u56de\u5f52\u7684\u6a21\u578b\u53ef\u4ee5\u89e3\u91ca\u54cd\u5e94\u53d8\u91cf \\(y_i\\) \u7684\u7edd\u5927\u90e8\u5206\u53d8\u5f02\uff1b\u63a5\u8fd1 0 \u8bf4\u660e \u7ebf\u6027\u6a21\u578b\u662f\u9519\u8bef\u7684\uff0c\u6216\u8005\u662f \u56fa\u6709\u8bef\u5dee \\(\\sigma^2\\) \u8f83\u5927\uff0c\u6216\u8005\u4e24\u8005\u517c\u6709 \\(R^2\\) \u4e00\u5b9a\u5728 0~1 \u4e4b\u95f4\uff0c\u6240\u4ee5\u6bd4 RSE \u66f4\u6613\u4e8e\u89e3\u91ca\uff0c\u4f46\u662f\u8fd8\u662f\u8981\u5177\u4f53\u53d6\u51b3\u4e8e\u5e94\u7528 \\(R^2\\) \u8861\u91cf\u4e86 \\(X\\ Y\\) \u4e4b\u95f4\u7684\u7ebf\u6027\u5173\u7cfb\uff0c\u800c \u76f8\u5173\u7cfb\u6570 \\(r=cor(X,Y)\\) \u4e5f\u8861\u91cf\u4e86 \\(X\\ Y\\) \u4e4b\u95f4\u7684\u7ebf\u6027\u5173\u7cfb\uff1b\u4e8b\u5b9e\u4e0a\u5728\u7b80\u5355\u7684\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u4e2d\uff0c \\(R^2=r^2\\) \uff1b\u4f46\u5728\u591a\u5143\u7ebf\u6027\u56de\u5f52\u4e2d \\(r^2\\) \u65e0\u6cd5\u8bc4\u4ef7\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u7684\u62df\u5408\u5ea6\uff0c \\(R^2\\) \u5c06\u627f\u62c5\u8fd9\u9879\u4efb\u52a1","title":"\u8bc4\u4ef7\u6a21\u578b\u7684\u6b63\u786e\u6027"},{"location":"ISL/#_7","text":"\\[ Y=\\beta_0+\\sum_p(\\beta_iX_i)+\\epsilon \\]","title":"\u591a\u5143\u7ebf\u6027\u56de\u5f52"},{"location":"ISL/#_8","text":"\\[ RSS=\\sum(\\hat{y_i}-y_i)^2 \\]","title":"\u4f30\u8ba1\u7cfb\u6570"},{"location":"ISL/#_9","text":"","title":"\u4e00\u4e9b\u91cd\u8981\u95ee\u9898"},{"location":"ISL/#_10","text":"\u5047\u8bbe\u68c0\u9a8c $$ H_0:\\beta_1=..\\beta_p=0 \\ \\ \\ H_{\\alpha}:\u81f3\u5c11\u6709\u4e00\u4e2a\\beta_j \\not=0\u200b $$ \u8ba1\u7b97 F\u7edf\u8ba1\u91cf \uff1a \\(F=\\frac{ESS/p}{RSS/(n-p-1)}\\) \uff0cF \u63a5\u8fd1 1 \u63a5\u53d7\u539f\u5047\u8bbe ....","title":"\u76f8\u5e94\u53d8\u91cf\u548c\u9884\u6d4b\u53d8\u91cf\u4e4b\u95f4\u662f\u5426\u6709\u5173\u7cfb\uff1f"},{"location":"ISL/#_11","text":"\u5c1d\u8bd5\u6240\u6709\u7684\u6a21\u578b( \\(2^p\\) \u79cd)\uff1a \u7edf\u8ba1\u6307\u6807\uff1aMallow's\u7edf\u8ba1\u91cf \\(C_p\\) \uff0c\u8d64\u6c60\u4fe1\u606f\u91cf\u51c6\u5219AIC\uff0c\u8d1d\u53f6\u65af\u4fe1\u606f\u51c6\u5219BIC\uff0c\u8c03\u6574 \\(R^2\\) (Adjusted \\(R^2\\) ) \u53ea\u9002\u7528\u4e8e p \u8f83\u5c0f\u7684\u60c5\u51b5 \u5411\u524d\u9009\u62e9\uff0c\u5411\u540e\u9009\u62e9\uff0c\u6df7\u5408\u9009\u62e9 p > n \u65f6\u4e0d\u80fd\u5411\u540e\u9009\u62e9","title":"\u9009\u5b9a\u91cd\u8981\u53d8\u91cf"},{"location":"ISL/#_12","text":"RSE \u548c \\(R^2\\)","title":"\u6a21\u578b\u62df\u5408"},{"location":"ISL/#_13","text":"","title":"\u9884\u6d4b"},{"location":"ISL/#_14","text":"","title":"\u56de\u5f52\u6a21\u578b\u5176\u4ed6\u6ce8\u610f\u4e8b\u9879"},{"location":"ISL/#_15","text":"","title":"\u8425\u9500\u8ba1\u5212"},{"location":"ISL/#k","text":"","title":"\u7ebf\u6027\u56de\u5f52\u4e0eK\u6700\u8fd1\u90bb\u6cd5\u7684\u6bd4\u8f83"},{"location":"ISL/#_16","text":"","title":"\u5b9e\u9a8c\uff1a\u7ebf\u6027\u56de\u5f52"},{"location":"ISL/#_17","text":"","title":"\u91cd\u62bd\u6837\u65b9\u6cd5"},{"location":"ISL/#_18","text":"","title":"\u4ea4\u53c9\u9a8c\u8bc1\u6cd5"},{"location":"ISL/#_19","text":"\u5c06\u6570\u636e\u96c6\u5206\u4e3a\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\uff0c\u5c06\u4e0d\u540c\u7684\u6a21\u578b\u8bad\u7ec3\u597d\u540e\u53bb\u6d4b\u8bd5\u96c6\u8ba1\u7b97\u5747\u65b9\u8bef\u5dee \u7f3a\u9677\uff1a\u6d4b\u8bd5\u96c6\u7684\u6ce2\u52a8\u5927\uff0c\u8bad\u7ec3\u6570\u636e\u5c11","title":"\u9a8c\u8bc1\u96c6\u65b9\u6cd5"},{"location":"ISL/#_20","text":"LOOCV\uff1aleave-one-out cross-validation \u5728\u89c4\u6a21\u4e3a n \u7684\u6570\u636e\u96c6\u4e2d\u7559\u4e0b \\((x_i,y_i)\\) \u4f5c\u4e3a\u6d4b\u8bd5\u96c6\uff0c\u5176\u4f59 \\(n-1\\) \u4e2a\u6570\u636e\u4f5c\u4e3a\u8bad\u7ec3\u96c6\uff0c\u8bad\u7ec3\u540e\u5728 \\((x_i,y_i)\\) \u4e0a\u8ba1\u7b97\u51fa \\(MSE_i=(y_i-\\hat{y_i})^2\\) \u91cd\u590d\u4e0a\u8ff0\u64cd\u4f5c n \u6b21\uff0c\u8ba1\u7b97 \\(CV_{n}=\\frac{1}{n}\\sum_{i=1}^nMSE_i\\) \u7f3a\u9677\uff1a n \u5f88\u5927 \u6216\u8005 \u62df\u5408\u4e00\u6b21\u5f88\u6162 \u5341\u5206\u8017\u65f6 \u5982\u679c\u7528\u6700\u5c0f\u4e8c\u4e58\u6cd5\u6765\u62df\u5408\u7ebf\u6027\u6216\u8005\u591a\u9879\u5f0f\u56de\u5f52\u6a21\u578b\uff0c\u53ef\u4ee5\u628a\u65f6\u95f4\u538b\u7f29\u81f3\u4e0e\u62df\u5408\u4e00\u4e2a\u6a21\u578b\u65f6\u95f4\u76f8\u540c\uff0c\u516c\u5f0f\u5982\u4e0b\uff1a $$ CV_{n}=\\frac{i}{n}\\sum_{i=1}^n(\\frac{y_i-\\hat{y_i}}{1-h_i})^2 $$ \u5176\u4e2d \\(h_i\\) \u4e3a\u6760\u6746\u503c","title":"\u7559\u4e00\u4ea4\u53c9\u9a8c\u8bc1\u6cd5"},{"location":"ISL/#k_1","text":"\u4e0e LOOCV \u7c7b\u4f3c\uff0c\u628a\u6570\u636e\u96c6\u5206\u6210 k \u7ec4\uff0c\u6bcf\u6b21\u7559\u4e00\u7ec4\u4f5c\u4e3a\u9a8c\u8bc1\u96c6\uff0c\u8ba1\u7b97 \\(CV_k=\\frac{1}{k}\\sum_{i=1}^kMSE_i\\) \u4e3a\u4e86\u6743\u8861\u65b9\u5dee\u4e0e\u504f\u5dee\uff0ck \u4e00\u822c\u53d6 5 \u6216 10 \u4f18\u70b9\u663e\u800c\u6613\u89c1\uff0c\u8fd0\u7b97\u5feb\uff0c\u4f46\u662f\u5b58\u5728\u4e00\u5b9a\u7684\u6ce2\u52a8\u6027 LOOCV \u548c k\u6298\u4ea4\u53c9\u9a8c\u8bc1\u8fd8\u53ef\u4ee5\u7528\u4e8e\u9009\u62e9\u6a21\u578b\u7684\u5149\u6ed1\u7a0b\u5ea6","title":"k \u6298\u4ea4\u53c9\u9a8c\u8bc1\u6cd5"},{"location":"ISL/#k-","text":"\u4ece\u51cf\u5c0f\u504f\u5dee\u7684\u89d2\u5ea6\u6765\u770b\uff0c\u663e\u7136 LOOCV \u6bd4 k \u6298 CV\u597d\uff0c\u4f46\u504f\u5dee\u4e0d\u662f\u552f\u4e00\u8003\u8651\u7684\u8981\u7d20 \\(k<n\\) \u65f6\uff0cLOOCV \u65b9\u6cd5\u7684\u65b9\u5dee\u6bd4 k \u6298 CV \u65b9\u6cd5\u7684\u65b9\u5dee\u5927\uff1b\u56e0\u4e3a LOOCV \u7684\u6bcf\u4e2a\u8bad\u7ec3\u96c6\u90fd\u662f\u51e0\u4e4e\u4e00\u6837\u7684\uff0c\u800c k \u6298 CV \u6bcf\u4e2a\u8bad\u7ec3\u96c6\u7684\u91cd\u53e0\u7a0b\u5ea6\u76f8\u5bf9\u8f83\u5c0f \u6240\u4ee5\u4e3a\u4e86\u6743\u8861\u65b9\u5dee\u4e0e\u504f\u5dee\uff0ck \u4e00\u822c\u53d6 5 \u6216 10","title":"k \u6298\u4ea4\u53c9\u9a8c\u8bc1\u7684\u504f\u5dee-\u65b9\u5dee\u6743\u8861"},{"location":"ISL/#_21","text":"","title":"\u81ea\u52a9\u6cd5"},{"location":"ISL/#_22","text":"","title":"\u7ebf\u6027\u6a21\u578b\u9009\u62e9\u4e0e\u6b63\u5219\u5316"},{"location":"ISL/#_23","text":"\u4ece \\(p\\) \u4e2a\u9884\u6d4b\u53d8\u91cf\u4e2d\u6311\u9009\u4e0e\u54cd\u5e94\u53d8\u91cf\u76f8\u5173\u7684\u53d8\u91cf\u5f62\u6210\u5b50\u96c6\uff0c\u518d\u5bf9\u8fd9\u4e2a\u5b50\u96c6\u8fd0\u7528\u6700\u5c0f\u4e8c\u4e58","title":"\u5b50\u96c6\u9009\u62e9"},{"location":"ISL/#_24","text":"\u5bf9 \\(p\\) \u4e2a\u9884\u6d4b\u53d8\u91cf\u7684\u6240\u6709\u7ec4\u5408\u5206\u522b\u4f7f\u7528\u6700\u5c0f\u4e8c\u4e58\uff0c\u5373\u4e00\u5171 \\(2^p\\) \u4e2a\u6a21\u578b \\(O(2^p)\\) \u5177\u4f53\u8fc7\u7a0b\uff1a \u4e0d\u542b\u9884\u6d4b\u53d8\u91cf\u7684\u96f6\u6a21\u578b \\(M_0\\) \u53ea\u7528\u4e8e\u4f30\u8ba1\u89c2\u6d4b\u6837\u672c\u7684\u6837\u672c\u5747\u503c \u5bf9\u4e8e \\(k=1,2,...,p\\) \uff1a (a) \u62df\u5408 \\(\\begin{pmatrix}p\\\\k\\end{pmatrix}\\) \u4e2a\u5305\u542b \\(k\\) \u4e2a\u9884\u6d4b\u53d8\u91cf\u7684\u6a21\u578b (b) \u4ece \\(\\begin{pmatrix}p\\\\k\\end{pmatrix}\\) \u4e2d\u9009\u62e9 \\(RSS\\) \u6700\u5c0f \u6216 \\(R^2\\) \u6700\u5927\u7684\u4f5c\u4e3a\u6700\u4f18\u6a21\u578b\uff0c\u8bb0\u4e3a \\(M_k\\) \u6839\u636e\u4ea4\u53c9\u9a8c\u8bc1\u9884\u6d4b\u8bef\u5dee\uff0c \\(c_p(AIC)\\) \uff0c \\(BIC\\) \uff0c\u6216\u8005 \u8c03\u6574 \\(R^2\\) \u4ece \\(M_0,...,M_p\\) \u4e2d\u9009\u62e9\u6700\u4f18\u7684\u6a21\u578b","title":"\u6700\u4f18\u5b50\u96c6\u9009\u62e9"},{"location":"ISL/#_25","text":"","title":"\u9010\u6b65\u9009\u62e9"},{"location":"ISL/#_26","text":"\u6bcf\u6b21\u6dfb\u52a0\u4e00\u4e2a\u80fd\u6700\u5927\u9650\u5ea6\u63d0\u5347\u6a21\u578b\u6548\u679c\u7684\u53d8\u91cf\u52a0\u5165\u6a21\u578b \\(O(n^2)\\) \u4e0d\u542b\u9884\u6d4b\u53d8\u91cf\u7684\u96f6\u6a21\u578b\u8bb0\u4e3a \\(M_0\\) \u5bf9\u4e8e \\(k=0,2,...,p-1\\) \uff1a (a) \u4ece \\(p-k\\) \u4e2a\u6a21\u578b\u4e2d\u8fdb\u884c\u9009\u62e9\uff0c\u6bcf\u4e2a\u90fd\u5728 \\(M_k\\) \u7684\u57fa\u7840\u4e0a\u589e\u52a0\u4e00\u4e2a\u53d8\u91cf (b) \u5728 \\(p-k\\) \u4e2a\u6a21\u578b\u4e2d\u9009\u62e9 \\(RSS\\) \u6700\u5c0f \u6216 \\(R^2\\) \u6700\u5927\u7684\u6a21\u578b\u8bb0\u4e3a \\(M_{k+1}\\) \u6839\u636e\u4ea4\u53c9\u9a8c\u8bc1\u9884\u6d4b\u8bef\u5dee\uff0c \\(c_p(AIC)\\) \uff0c \\(BIC\\) \uff0c\u6216\u8005 \u8c03\u6574 \\(R^2\\) \u4ece \\(M_0,...,M_p\\) \u4e2d\u9009\u62e9\u6700\u4f18\u7684\u6a21\u578b \u65e0\u6cd5\u4fdd\u8bc1\u662f\u5168\u5c40\u6700\u4f18\u7684\uff0c\u5728 \\(n<p\\) \u65f6\u90fd\u53ef\u4ee5\u4f7f\u7528\u5411\u524d\u9009\u62e9\uff0c\u8fd9\u65f6\u53ef\u4ee5\u5efa\u7acb\u5b50\u6a21\u578b \\(M_0,...,M_{n-1}\\) \u82e5 \\(n\\leq p\\) \uff0c\u7ed3\u679c\u662f\u4e0d\u552f\u4e00\u7684","title":"\u5411\u524d\u9010\u6b65\u9009\u62e9"},{"location":"ISL/#_27","text":"\u4e0e\u5411\u524d\u9009\u62e9\u7c7b\u4f3c \\(O(n^2)\\) \u5305\u542b\u5168\u90e8 \\(p\\) \u4e2a\u9884\u6d4b\u53d8\u91cf\u7684\u96f6\u6a21\u578b\u8bb0\u4e3a \\(M_p\\) \u5bf9\u4e8e \\(k=p,...1\\) \uff1a (a) \u4ece \\(k\\) \u4e2a\u6a21\u578b\u4e2d\u8fdb\u884c\u9009\u62e9\uff0c\u6bcf\u4e2a\u90fd\u5728 \\(M_k\\) \u7684\u57fa\u7840\u4e0a\u51cf\u5c11\u4e00\u4e2a\u53d8\u91cf (b) \u5728 \\(k\\) \u4e2a\u6a21\u578b\u4e2d\u9009\u62e9 \\(RSS\\) \u6700\u5c0f \u6216 \\(R^2\\) \u6700\u5927\u7684\u6a21\u578b\u8bb0\u4e3a \\(M_{k-1}\\) \u6839\u636e\u4ea4\u53c9\u9a8c\u8bc1\u9884\u6d4b\u8bef\u5dee\uff0c \\(c_p(AIC)\\) \uff0c \\(BIC\\) \uff0c\u6216\u8005 \u8c03\u6574 \\(R^2\\) \u4ece \\(M_0,...,M_p\\) \u4e2d\u9009\u62e9\u6700\u4f18\u7684\u6a21\u578b \u65e0\u6cd5\u4fdd\u8bc1\u662f\u5168\u5c40\u6700\u4f18\u7684\uff0c\u4e14\u9700\u8981\u6ee1\u8db3 \\(n > p\\)","title":"\u5411\u540e\u9010\u6b65\u9009\u62e9"},{"location":"ISL/#_28","text":"","title":"\u9009\u62e9\u6700\u4f18\u6a21\u578b"},{"location":"ISL/#c_paicbicr2","text":"\u8bad\u7ec3\u8bef\u5dee\u53ef\u80fd\u662f\u6d4b\u8bd5\u8bef\u5dee\u4e2d\u8f83\u5dee\u7684\u4e00\u4e2a\u4f30\u8ba1\uff0c \\(RSS,R^2\\) \u503c\u5e76\u4e0d\u9002\u7528\u4e8e\u5bf9\u5305\u542b\u4e0d\u540c\u53d8\u91cf\u4e2a\u6570\u7684\u6a21\u578b\u8fdb\u884c\u9009\u62e9 \u672c\u8282\u5305\u542b\u4e09\u4e2a\u65b9\u6cd5\uff1a \\(C_p\\) \uff0c\u8d64\u6c60\u4fe1\u606f\u91cf\u51c6\u5219AIC\uff0c\u8d1d\u53f6\u65af\u4fe1\u606f\u51c6\u5219BIC\uff0c\u8c03\u6574 \\(R^2\\) (Adjusted \\(R^2\\) ) \\(C_p=\\frac{1}{n}(RSS+2d\\hat{\\sigma}^2)\\) \u5176\u4e2d \\(\\hat{\\sigma}^2\\) \u662f \\(\\epsilon\\) \u7684\u4f30\u8ba1\u503c\uff0c \\(d\\) \u662f\u9884\u6d4b\u53d8\u91cf\u6570 \\(AIC=\\frac{1}{n\\hat{\\sigma}^2}(RSS+2d\\hat{\\sigma}^2)\\) \u9002\u7528\u4e8e\u4f7f\u7528\u6781\u5927\u4f3c\u7136\u4f30\u8ba1\u62df\u5408\u7684\u6a21\u578b\uff0c\u82e5 \\(\\epsilon\\) \u670d\u4ece\u9ad8\u65af\u5206\u5e03\uff0c\u6781\u5927\u4f3c\u7136\u4f30\u8ba1\u548c\u6700\u5c0f\u4e8c\u4e58\u662f\u7b49\u4ef7\u7684\uff1b\u5bf9\u4e8e\u6700\u5c0f\u4e8c\u4e58\u6a21\u578b \\(c_p\\ \\ AIC\\) \u6210\u6bd4\u4f8b \\(BIC=\\frac{1}{n}(RSS+log(n)d\\hat{\\sigma}^2)\\) \uff0c\u5bf9\u4e8e\u4efb\u610f \\(n>7,\\ log(n)>2\\) \u6240\u4ee5 \\(BIC\\) \u7684\u60e9\u7f5a\u66f4\u91cd\uff0c\u76f8\u6bd4\u4e8e \\(C_p\\) \u5f97\u5230\u7684\u6a21\u578b\u7684\u53d8\u91cf\u66f4\u5c11 \\(\u8c03\u6574R^2=1-\\frac{RSS/(n-d-1)}{TSS/(n-1)}\\) \u76f8\u6bd4\u4e8e \\(R^2\\) \u5f15\u5165\u4e86\u60e9\u7f5a \u9664\u4e86 \\(\u8c03\u6574R^2\\) \u90fd\u662f\u8d8a\u5c0f\u8d8a\u597d","title":"\\(C_p\\)\uff0cAIC\uff0cBIC\uff0c\u8c03\u6574\\(R^2\\)"},{"location":"ISL/#_29","text":"","title":"\u9a8c\u8bc1\u4e0e\u4ea4\u53c9\u9a8c\u8bc1"},{"location":"ISL/#_30","text":"\u5bf9\u5168\u90e8 \\(p\\) \u4e2a\u53d8\u91cf\u62df\u5408\uff0c\u52a0\u5165\u4e00\u4e9b\u7ea6\u675f\uff0c\u4e0e\u6700\u5c0f\u4e8c\u4e58\u76f8\u6bd4\u53ef\u4ee5\u5c06\u67d0\u4e9b\u7cfb\u6570\u7f29\u51cf\u4e3a 0","title":"\u538b\u7f29\u4f30\u8ba1\u65b9\u6cd5"},{"location":"ISL/#_31","text":"\\[ min \\ \\ RSS+\\lambda\\sum_{j=1}^{p}\\beta_j^2 \\] \\(\\lambda=0\\) \u65f6\uff0c\u60e9\u7f5a\u9879\u4e0d\u8d77\u4f5c\u7528\uff1b \\(\\lambda\\rightarrow inf\\) \u65f6\uff0c\u4f30\u8ba1\u503c\u4f1a\u8d8a\u6765\u8d8a\u63a5\u8fd1 0 \u60e9\u7f5a\u9879\u4e0d\u60e9\u7f5a\u5e38\u6570\u9879 \\(\\beta_0\\) \u6700\u5c0f\u4e8c\u4e58\u5982\u679c\u4e00\u4e2a\u53d8\u91cf\u7684\u5355\u4f4d\u53d8\u4e86\uff0c\u53ea\u4f1a\u5f71\u54cd\u6b64\u53d8\u91cf\u7684\u7cfb\u6570\uff1b\u800c\u5cad\u56de\u5f52\u5219\u4f1a\u5f71\u54cd\u5176\u4ed6\u7684\u7cfb\u6570\uff0c\u6240\u4ee5\u4f7f\u7528\u524d\u9700\u8981\u5c06\u53d8\u91cf\u8fdb\u884c\u6807\u51c6\u5316 (\u8fd9\u91cc\u7684\u6807\u51c6\u5316\u53ea\u662f\u9664\u4ee5\u4e86\u6807\u51c6\u5dee) $$ \\widetilde{x} {i,j}=\\frac{x {i,j}}{\\sqrt{\\frac{1}{n}\\sum(x_{ij}-\\bar{x}_j)^2}} $$ \u52a3\u52bf\uff1a\u4e0d\u4f1a\u628a\u7cfb\u6570\u786e\u5207\u7684\u538b\u7f29\u81f3 0\uff0c\u5f53 p \u5f88\u5927\u65f6\uff0c\u4e0d\u5229\u4e8e\u6a21\u578b\u89e3\u91ca","title":"\u5cad\u56de\u5f52"},{"location":"ISL/#lasso","text":"\\[ min \\ \\ RSS+\\lambda\\sum_{j=1}^p|\\beta_j| \\] \u60e9\u7f5a\u9879\u4e0d\u60e9\u7f5a\u5e38\u6570\u9879 \\(\\beta_0\\) Lasso \u80fd\u591f\u5c06\u53d8\u91cf\u538b\u7f29\u81f3 0","title":"Lasso"},{"location":"ISL/#_32","text":"","title":"\u5176\u4ed6"},{"location":"ISL/#_33","text":"\u7b80\u5355\u7ebf\u6027\u56de\u5f52\uff1a $$ RSS=\\sum_n(y_i-\\beta_0-\\beta_1x_i)^2 $$ \\[ \\frac{\\alpha RSS}{\\alpha \\beta_1}=\\sum_n-2x_i(y_i-\\beta_0-\\beta_1x_i)=0 \\\\ \\frac{\\alpha RSS}{\\alpha \\beta_0}=\\sum_n-2(y_i-\\beta_0-\\beta_1x_i)=0 \\] \u6574\u7406\u5f97 $$ \\beta_1=\\frac{\\sum_n(x_i-\\bar{x})(y_i-\\bar{y})}{\\sum_n(x_i-\\bar{x})^2} \\ \\beta_0=\\bar{y}-\\beta_1\\bar{x} $$ \u591a\u5143\u7ebf\u6027\u56de\u5f52\uff1a\u7528\u77e9\u9635\u7684\u5f62\u5f0f $$ min(RSS)=min||XA-Y||_2^2 $$ \\[ \\begin{equation} \\begin{split} \\frac{\\alpha RSS}{\\alpha X} &=\\frac{\\alpha (AX-Y)^T(AX-Y)}{\\alpha X} \\\\ &=\\frac{\\alpha (X^TA^TAX-X^TA^TY-Y^TAX+Y^TY)}{\\alpha X} \\end{split} \\end{equation} \\] \u7531 \\(\\frac{\\alpha X^TA}{\\alpha X} =\\frac{\\alpha A^TX}{\\alpha X}=A, \\ \\ \\ \\frac{\\alpha X^TAX}{\\alpha X} =AX+A^TX\\) \u5f97 $$ \\frac{\\alpha RSS}{\\alpha X} =2A^TAX-2A^TY=0 \\ X=(A^TA)^{-1}A^TY $$","title":"\u6700\u5c0f\u4e8c\u4e58\u63a8\u5bfc"},{"location":"R/","text":"R \u00b6 \u57fa\u672c\u64cd\u4f5c \u00b6 ? funcname # \u6253\u5f00\u51fd\u6570\u5e2e\u52a9\u6587\u4ef6 ls () # \u67e5\u770b\u6240\u6709\u5bf9\u8c61 rm ( x , y ) # \u5220\u9664\u5bf9\u8c61 rm ( list = ls ()) # \u5220\u9664\u6240\u6709\u5bf9\u8c61 set.seed ( n ) # \u6307\u5b9a\u968f\u673a\u6570\u79cd\u5b50 q () # \u9000\u51fa Matrix \u00b6 \u5411\u91cf \u00b6 x = c ( 1 , 2 , 3 , 4 ) # connect \u5efa\u7acb\u6570\u503c\u5411\u91cf seq ( a , b , length = n ) # [a,b]\u4e4b\u95f4\u7b49\u8ddd\u7684n\u4e2a\u5143\u7d20\u7684\u5411\u91cf\uff0c\u4e5f\u53ef\u4ee5\u76f4\u63a5 a:b rnorm ( n ) # \u4ea7\u751f\u957f\u5ea6\u4e3an\u7684\u968f\u673a\u6b63\u6001\u5206\u5e03\u5411\u91cf\uff0c\u5982\u679c\u6307\u5b9a\u4e86\u968f\u673a\u6570\u79cd\u5b50\u90a3\u6bcf\u6b21\u7684\u6570\u4f1a\u4e00\u6837 length ( x ) # \u8fd4\u56de\u5411\u91cf\u957f\u5ea6 mean ( x ) # \u5411\u91cf\u5747\u503c sd ( x ) # \u6807\u51c6\u5dee var ( x ) # \u5411\u91cf\u65b9\u5dee cor ( x , y ) # \u8ba1\u7b972\u5411\u91cf\u7684\u76f8\u5173\u7cfb\u6570 Matrix \u00b6 matrix ( data = NA , nrow = 1 , ncol = 1 , byrow = FALSE ) # eg: x = (data=c(1,2,3,4),2,2) \u53ea\u5199\u524d\u4e09\u4e2a\u53c2\u6570\u540d\u53ef\u4ee5\u7701\u7565 # \u9ed8\u8ba4\u6309\u5217\u586b\u5199matrix, byrow=TRUE\u4f1a\u6309\u884c\u586b\u5199 dim ( A ) # \u8f93\u51fa\u7ef4\u6570 sqrt ( x ) # \u6bcf\u4e2a\u5143\u7d20\u5f00\u6839 x ^ 2 # \u6bcf\u4e2a\u5143\u7d20\u5f00\u65b9 \u7d22\u5f15\u6570\u636e \u00b6 A [ 1 , 2 ] # \u6307\u5b9a\u5355\u5143\u683c A [ c ( x1 , x2 ), c ( y1 , y2 )] # \u6307\u5b9a\u67d0\u4e9b\u5217\u548c\u67d0\u4e9b\u884c A [ x1 : x2 , y1 : y2 ] # \u6307\u5b9a\u884c\u4e0e\u5217\u7684\u8303\u56f4 A [ x1 : x2 ,] # \u6307\u5b9a\u884c\uff0c\u4e0d\u6307\u5b9a\u5217 A [ - c ( x1 , x2 )] # \u6307\u5b9a\u4e0d\u5305\u542b\u7684\u6570\u636e \u6570\u636e\u5904\u7406 \u00b6 a = as.factor ( a ) # \u5982\u679ca\u7684\u6570\u636e\u662f\u79bb\u6563\u7684\u8f6c\u6362\u6210\u4e00\u4e2a\u5b9a\u6027\u7684\u53d8\u91cf # eg: # > a=[1,2,2,3,1,2,3,2,1,3] # > a=as.factor(a) # > print(a) # [1] 1 2 3 1 2 1 3 2 1 # Levels: 1 2 3 summary ( a ) # \u5bf9\u6307\u5b9a\u6570\u636e\u96c6\u4e2d\u7684\u6bcf\u4e2a\u53d8\u91cf\u8ba1\u7b97\u7edf\u8ba1\u4fe1\u606f(\u6700\u5927\u503c\uff0c\u6700\u5c0f\u503c...) summary ( name ) # \u4e5f\u53ef\u4ee5\u6307\u5b9a\u67d0\u4e2a\u5177\u4f53\u7684\u5c5e\u6027\u540d \u56fe\u50cf \u00b6 \u5efa\u7acb\u56fe\u50cf \u00b6 # \u5982\u679cx\u662f\u5b9a\u6027(\u79bb\u6563)\u53d8\u91cf\u4f1a\u81ea\u52a8\u753b\u7bb1\u7ebf\u56fe plot ( x , y , xlim = ( x1 , x2 ), xlab = \"\" , main = \"\" ) # main: title hist ( x ) # \u76f4\u65b9\u56fe,\u7eb5\u5750\u6807\u662f\u843d\u5728\u533a\u95f4\u5185\u5143\u7d20\u7684\u4e2a\u6570 # \u901a\u8fc7 IO \u6570\u636e\u4f5c\u56fe plot ( a $ name1 , a $ name2 ) # \u6570\u636e\u96c6\u548c\u53d8\u91cf\u540d\u95f4\u52a0$ attach ( a ) # \u4e5f\u53ef\u4ee5\u6307\u5b9a\u6570\u636e\u96c6 plot ( name1 , name2 ) \u7b49\u9ad8\u7ebf\u56fe \u00b6 outer ( x , y , FUN = \"*\" ) # \u5efa\u7acb\u4e00\u4e2alen(x)*len(y)\u7ef4\u7684\u77e9\u9635\uff0cfun\u9ed8\u8ba4\u662f*,\u5373 xi*yj contour ( x , y , z , nlevels = 10 ) # \u7b49\u9ad8\u7ebf nlevels:\u7b49\u9ad8\u7ebf\u6570\u91cf image ( x , y , z , xlim , xlab ) # \u70ed\u5730\u56fe persp ( x , y , z , xlim , xlab , theta , phi ) # \u4e09\u7ef4\u56fe theta/phi \u63a7\u5236\u56fe\u5f62\u67e5\u770b\u89d2\u5ea6eg:persp(x, y, z, theta = 30, phi = 20) \u4fdd\u5b58\u56fe\u50cf \u00b6 pdf ( \"test.pdf\" ) # \u7528\u8fd9\u4e2a\u6587\u4ef6\u4fdd\u5b58\u56fe\u50cf plot ( x , y ) dev.off () # \u6307\u793a\u521b\u5efa\u56fe\u50cf\u7684\u5de5\u4f5c\u7ed3\u675f I/O \u00b6 \u8bfb\u5165\u6570\u636e \u00b6 a = read.table ( \"filepath\" , header = T , na.strings = \"\" ) # \u8bfb\u5165\u6587\u672c\u6587\u4ef6,\u6307\u5b9a\u8868\u5934\u548c\u7f3a\u5931\u503c a = read.csv () # \u8bfb\u5165csv(','\u5206\u9694\u7b26\u6587\u4ef6) a = na.omit ( a ) # \u76f4\u63a5\u5220\u53bb\u6709\u7f3a\u5931\u503c\u7684\u884c fix ( a ) # \u5c55\u793a\u6570\u636e name ( a ) # \u67e5\u770b\u8868\u5934(\u53d8\u91cf\u540d)","title":"R"},{"location":"R/#r","text":"","title":"R"},{"location":"R/#_1","text":"? funcname # \u6253\u5f00\u51fd\u6570\u5e2e\u52a9\u6587\u4ef6 ls () # \u67e5\u770b\u6240\u6709\u5bf9\u8c61 rm ( x , y ) # \u5220\u9664\u5bf9\u8c61 rm ( list = ls ()) # \u5220\u9664\u6240\u6709\u5bf9\u8c61 set.seed ( n ) # \u6307\u5b9a\u968f\u673a\u6570\u79cd\u5b50 q () # \u9000\u51fa","title":"\u57fa\u672c\u64cd\u4f5c"},{"location":"R/#matrix","text":"","title":"Matrix"},{"location":"R/#_2","text":"x = c ( 1 , 2 , 3 , 4 ) # connect \u5efa\u7acb\u6570\u503c\u5411\u91cf seq ( a , b , length = n ) # [a,b]\u4e4b\u95f4\u7b49\u8ddd\u7684n\u4e2a\u5143\u7d20\u7684\u5411\u91cf\uff0c\u4e5f\u53ef\u4ee5\u76f4\u63a5 a:b rnorm ( n ) # \u4ea7\u751f\u957f\u5ea6\u4e3an\u7684\u968f\u673a\u6b63\u6001\u5206\u5e03\u5411\u91cf\uff0c\u5982\u679c\u6307\u5b9a\u4e86\u968f\u673a\u6570\u79cd\u5b50\u90a3\u6bcf\u6b21\u7684\u6570\u4f1a\u4e00\u6837 length ( x ) # \u8fd4\u56de\u5411\u91cf\u957f\u5ea6 mean ( x ) # \u5411\u91cf\u5747\u503c sd ( x ) # \u6807\u51c6\u5dee var ( x ) # \u5411\u91cf\u65b9\u5dee cor ( x , y ) # \u8ba1\u7b972\u5411\u91cf\u7684\u76f8\u5173\u7cfb\u6570","title":"\u5411\u91cf"},{"location":"R/#matrix_1","text":"matrix ( data = NA , nrow = 1 , ncol = 1 , byrow = FALSE ) # eg: x = (data=c(1,2,3,4),2,2) \u53ea\u5199\u524d\u4e09\u4e2a\u53c2\u6570\u540d\u53ef\u4ee5\u7701\u7565 # \u9ed8\u8ba4\u6309\u5217\u586b\u5199matrix, byrow=TRUE\u4f1a\u6309\u884c\u586b\u5199 dim ( A ) # \u8f93\u51fa\u7ef4\u6570 sqrt ( x ) # \u6bcf\u4e2a\u5143\u7d20\u5f00\u6839 x ^ 2 # \u6bcf\u4e2a\u5143\u7d20\u5f00\u65b9","title":"Matrix"},{"location":"R/#_3","text":"A [ 1 , 2 ] # \u6307\u5b9a\u5355\u5143\u683c A [ c ( x1 , x2 ), c ( y1 , y2 )] # \u6307\u5b9a\u67d0\u4e9b\u5217\u548c\u67d0\u4e9b\u884c A [ x1 : x2 , y1 : y2 ] # \u6307\u5b9a\u884c\u4e0e\u5217\u7684\u8303\u56f4 A [ x1 : x2 ,] # \u6307\u5b9a\u884c\uff0c\u4e0d\u6307\u5b9a\u5217 A [ - c ( x1 , x2 )] # \u6307\u5b9a\u4e0d\u5305\u542b\u7684\u6570\u636e","title":"\u7d22\u5f15\u6570\u636e"},{"location":"R/#_4","text":"a = as.factor ( a ) # \u5982\u679ca\u7684\u6570\u636e\u662f\u79bb\u6563\u7684\u8f6c\u6362\u6210\u4e00\u4e2a\u5b9a\u6027\u7684\u53d8\u91cf # eg: # > a=[1,2,2,3,1,2,3,2,1,3] # > a=as.factor(a) # > print(a) # [1] 1 2 3 1 2 1 3 2 1 # Levels: 1 2 3 summary ( a ) # \u5bf9\u6307\u5b9a\u6570\u636e\u96c6\u4e2d\u7684\u6bcf\u4e2a\u53d8\u91cf\u8ba1\u7b97\u7edf\u8ba1\u4fe1\u606f(\u6700\u5927\u503c\uff0c\u6700\u5c0f\u503c...) summary ( name ) # \u4e5f\u53ef\u4ee5\u6307\u5b9a\u67d0\u4e2a\u5177\u4f53\u7684\u5c5e\u6027\u540d","title":"\u6570\u636e\u5904\u7406"},{"location":"R/#_5","text":"","title":"\u56fe\u50cf"},{"location":"R/#_6","text":"# \u5982\u679cx\u662f\u5b9a\u6027(\u79bb\u6563)\u53d8\u91cf\u4f1a\u81ea\u52a8\u753b\u7bb1\u7ebf\u56fe plot ( x , y , xlim = ( x1 , x2 ), xlab = \"\" , main = \"\" ) # main: title hist ( x ) # \u76f4\u65b9\u56fe,\u7eb5\u5750\u6807\u662f\u843d\u5728\u533a\u95f4\u5185\u5143\u7d20\u7684\u4e2a\u6570 # \u901a\u8fc7 IO \u6570\u636e\u4f5c\u56fe plot ( a $ name1 , a $ name2 ) # \u6570\u636e\u96c6\u548c\u53d8\u91cf\u540d\u95f4\u52a0$ attach ( a ) # \u4e5f\u53ef\u4ee5\u6307\u5b9a\u6570\u636e\u96c6 plot ( name1 , name2 )","title":"\u5efa\u7acb\u56fe\u50cf"},{"location":"R/#_7","text":"outer ( x , y , FUN = \"*\" ) # \u5efa\u7acb\u4e00\u4e2alen(x)*len(y)\u7ef4\u7684\u77e9\u9635\uff0cfun\u9ed8\u8ba4\u662f*,\u5373 xi*yj contour ( x , y , z , nlevels = 10 ) # \u7b49\u9ad8\u7ebf nlevels:\u7b49\u9ad8\u7ebf\u6570\u91cf image ( x , y , z , xlim , xlab ) # \u70ed\u5730\u56fe persp ( x , y , z , xlim , xlab , theta , phi ) # \u4e09\u7ef4\u56fe theta/phi \u63a7\u5236\u56fe\u5f62\u67e5\u770b\u89d2\u5ea6eg:persp(x, y, z, theta = 30, phi = 20)","title":"\u7b49\u9ad8\u7ebf\u56fe"},{"location":"R/#_8","text":"pdf ( \"test.pdf\" ) # \u7528\u8fd9\u4e2a\u6587\u4ef6\u4fdd\u5b58\u56fe\u50cf plot ( x , y ) dev.off () # \u6307\u793a\u521b\u5efa\u56fe\u50cf\u7684\u5de5\u4f5c\u7ed3\u675f","title":"\u4fdd\u5b58\u56fe\u50cf"},{"location":"R/#io","text":"","title":"I/O"},{"location":"R/#_9","text":"a = read.table ( \"filepath\" , header = T , na.strings = \"\" ) # \u8bfb\u5165\u6587\u672c\u6587\u4ef6,\u6307\u5b9a\u8868\u5934\u548c\u7f3a\u5931\u503c a = read.csv () # \u8bfb\u5165csv(','\u5206\u9694\u7b26\u6587\u4ef6) a = na.omit ( a ) # \u76f4\u63a5\u5220\u53bb\u6709\u7f3a\u5931\u503c\u7684\u884c fix ( a ) # \u5c55\u793a\u6570\u636e name ( a ) # \u67e5\u770b\u8868\u5934(\u53d8\u91cf\u540d)","title":"\u8bfb\u5165\u6570\u636e"},{"location":"ML/1_Regression/","text":"Regression \u00b6 Regression \u5177\u4f53\u8fc7\u7a0b \u00b6 \u5b9a\u4e49\u4e00\u4e2a model \u5373 function set \u5b9a\u4e49\u4e00\u4e2a goodness of function \u635f\u5931\u51fd\u6570\u53bb\u8bc4\u4f30\u8be5 function \u7684\u597d\u574f \u627e\u4e00\u4e2a\u6700\u597d\u7684 function Linear Model \u7ebf\u6027\u6a21\u578b \u00b6 Model (function set)\uff1a \\(y=b+w \\cdot X_{cp}\\) \uff0c\u53ef\u4ee5\u6269\u5c55\u4e3a \\(y=b+ \\sum w_ix_i\\) Loss function\uff1a \\(L(f)=L(w,b)=\\sum_{n=1}^{10}(\\widehat{y}^n-(b+w \\cdot x^{n}_{cp}))^2\\) Gradient Descent \u68af\u5ea6\u4e0b\u964d \u00b6 \u5355\u4e2a\u53c2\u6570\u76f4\u63a5\u6c42\u5fae\u5206\uff0c\u591a\u4e2a\u53c2\u6570\u6c42\u504f\u5fae\u5206 \\[ \\begin{align} L(w,b)=\\sum\\limits_{n=1}^{10}(\\widehat{y}^n-(b+w\\cdot x_{cp}^n))^2 \\\\ \\frac{\\partial L}{\\partial w}=\\sum\\limits_{n=1}^{10}2(\\widehat{y}^n-(b+w\\cdot x_{cp}^n))(-x_{cp}^n) \\\\ \\frac{\\partial L}{\\partial b}=\\sum\\limits_{n=1}^{10}2(\\widehat{y}^n-(b+w\\cdot x_{cp}^n))(-1) \\end{align} \\] \\[ \\begin{align} w^1=w^0-\u03b7\\frac{\\partial L}{\\partial w}|_{w=w^0,b=b^0} \\ \\ \\ \\ \\ \\ \\ \\ \\ b^1=b^0-\u03b7\\frac{\\partial L}{\\partial b}|_{w=w^0,b=b^0} \\\\ w^2=w^1-\u03b7\\frac{\\partial L}{\\partial w}|_{w=w^1,b=b^1} \\ \\ \\ \\ \\ \\ \\ \\ \\ b^2=b^1-\u03b7\\frac{\\partial L}{\\partial b}|_{w=w^1,b=b^1} \\\\ ... \\\\ w^{i+1}=w^{i}-\u03b7\\frac{\\partial L}{\\partial w}|_{w=w^{i},b=b^{i}} \\ \\ \\ \\ \\ \\ \\ \\ \\ b^{i+1}=b^{i}-\u03b7\\frac{\\partial L}{\\partial b}|_{w=w^{i},b=b^{i}} \\\\ if(\\frac{\\partial L}{\\partial w}==0 \\&\\& \\frac{\\partial L}{\\partial b}==0) \\ \\ \\ then \\ \\ stop \\end{align} \\] \u7f3a\u70b9\uff1a\u627e\u5230\u7684\u70b9\u672a\u5fc5\u662f\u6781\u5c0f\u503c\u70b9 # eg: y = b + w * x \u8ba1\u7b97\u68af\u5ea6\u5fae\u5206\u7684\u51fd\u6570 getGrad() def getGrad ( b , w ): # initial b_grad and w_grad b_grad = 0.0 w_grad = 0.0 for i in range ( 10 ): b_grad += ( - 2.0 ) * ( y_data [ i ] - ( b + w * x_data [ i ])) w_grad += ( - 2.0 * x_data [ i ]) * ( y_data [ i ] - ( b + w * x_data [ i ])) return ( b_grad , w_grad ) \u975e\u7ebf\u6027\u7684\u6a21\u578b \u00b6 \\((x_{cp})^2\\) \u7684 model \uff1atraining data \u4e2d model \u8d8a\u590d\u6742 error \u4f1a\u8d8a\u4f4e\uff0c\u4f46 testing data \u4e2d error \u4f1a\u53d8\u5927\uff0coverfitting \u8003\u8651\u79cd\u65cf\u3001\u7c7b\u522b\u7684\u5f71\u54cd \\[ \\begin{align} if \\ \\ x_s=Pidgey: \\ \\ \\ \\ \\ \\ \\ y=b_1+w_1\\cdot x_{cp} \\\\ if \\ \\ x_s=Weedle: \\ \\ \\ \\ \\ \\ y=b_2+w_2\\cdot x_{cp} \\\\ if \\ \\ x_s=Caterpie: \\ \\ \\ \\ y=b_3+w_3\\cdot x_{cp} \\\\ if \\ \\ x_s=Eevee: \\ \\ \\ \\ \\ \\ \\ \\ \\ y=b_4+w_4\\cdot x_{cp} \\end{align} \\] regularization \u89e3\u51b3 overfitting \u00b6 \u6b63\u5219\u5316\u89e3\u51b3\u8fc7\u62df\u5408\u95ee\u9898 $$ L=\\sum\\limits_i^n(\\widehat{y}^i-(b+\\sum\\limits_{j}w_jx_j))^2+\\lambda\\sum(w_i)^2 $$ \u5e0c\u671b \\(w_i\\) \u6bd4\u8f83\u5c0f\u800c\u5f97\u5230\u4e00\u4e2a\u5e73\u6ed1\u7684\u66f2\u7ebf\uff0c\u8fd9\u91cc\u7684 \u03bb \u9700\u8981\u6211\u4eec\u624b\u52a8\u53bb\u8c03\u6574\u4ee5\u53d6\u5f97\u6700\u597d\u7684\u503c Adaptive Learning rates \u00b6 learning rate \u5927\u4e86\u5c0f\u4e86\u90fd\u4e0d\u597d \u4e00\u4e2a\u7b80\u7b54\u7684\u539f\u5219\uff1alearning rate \u901a\u5e38\u662f\u968f\u7740\u53c2\u6570\u7684 update \u8d8a\u6765\u8d8a\u5c0f\u7684 eg\uff1a \\(\\eta^t=\\eta/ \\sqrt{t+1}\\) \uff08\u7b2c t \u6b21 update\uff09 Adagrad \u00b6 Divide the learning rate of each parameter by the root mean square(\u65b9\u5747\u6839) of its previous derivatives Adagrad \u5c06\u4e0d\u540c\u53c2\u6570\u7684 learning rate \u5206\u5f00\u8003\u8651\uff0cupdate\u5230\u540e\u9762\u901f\u5ea6\u4f1a\u8d8a\u6765\u8d8a\u6162\uff0c\u8fd9\u662fadaptive\u7b97\u6cd5\u4e2d\u6700\u7b80\u5355\u7684\u4e00\u79cd $$ \\begin{equation} \\begin{split} &Adagrad\\ &w^1=w^0-\\frac{\\eta^0}{\\sigma^0}\\cdot g^0, \\ \\ \\ \\sigma^0=\\sqrt{(g^0)^2} \\ &w^2=w^1-\\frac{\\eta^1}{\\sigma^1}\\cdot g^1, \\ \\ \\ \\sigma^1=\\sqrt{\\frac{1}{2}[(g^0)^2+(g^1)^2]} \\ &w^3=w^2-\\frac{\\eta2}{\\sigma^2}\\cdot g^2, \\ \\ \\ \\sigma^2=\\sqrt{\\frac{1}{3}[(g^0)^2+(g^1)^2+(g^2)^2]} \\ &... \\ &w^{t+1}=w^t-\\frac{\\eta^t}{\\sigma^t}\\cdot g^t, \\ \\ \\ \\sigma^t=\\sqrt{\\frac{1}{1+t}\\sum\\limits_{i=0}^{t}(g^i)^2} \\end{split} \\end{equation} $$ \\(g^t\\) \u8868\u793a Loss \u5bf9 w \u7684\u504f\u5fae\u5206 \u7531\u4e8e \\(\\eta^t=\\eta/ \\sqrt{t+1}\\) \u548c \\(\\sigma^t=\\sqrt{\\frac{1}{1+t}\\sum\\limits_{i=0}^{t}(g^i)^2}\\) \u4e2d\u90fd\u6709\u4e00\u4e2a \\(\\sqrt{\\frac{1}{1+t}}\\) \u7684\u56e0\u5b50\uff0c\u4e24\u8005\u76f8\u6d88\uff0c\u5373\u53ef\u5f97\u5230 adagrad \u7684\u6700\u7ec8\u8868\u8fbe\u5f0f\uff1a $$ w^{t+1}=w^t-\\frac{\\eta}{\\sqrt{\\sum\\limits_{i=0}^t(g^i)^2}}\\cdot g^t $$ Adagrad \u7684 contradiction \u89e3\u91ca \u6211\u4eec\u5728\u505a gradient descent \u7684\u65f6\u5019\uff0c\u5e0c\u671b\u7684\u662f\u5f53\u68af\u5ea6\u503c\u5373\u5fae\u5206\u503c \\(g^t\\) \u8d8a\u5927\u7684\u65f6\u5019\u66f4\u65b0\u7684\u6b65\u4f10\u8981\u66f4\u5927\u4e00\u4e9b\uff0c\u4f46\u662f Adagrad \u7684\u8868\u8fbe\u5f0f\u4e2d\uff0c\u5206\u6bcd\u8868\u793a\u68af\u5ea6\u8d8a\u5927\u6b65\u4f10\u8d8a\u5c0f\uff0c\u5206\u5b50\u5374\u8868\u793a\u68af\u5ea6\u8d8a\u5927\u6b65\u4f10\u8d8a\u5927\uff0c\u4e24\u8005\u4f3c\u4e4e\u76f8\u4e92\u77db\u76fe \u5728\u4e00\u4e9b paper \u91cc\u662f\u8fd9\u6837\u89e3\u91ca\u7684\uff1aAdagrad \u8981\u8003\u8651\u7684\u662f\uff0c\u8fd9\u4e2a gradient \u6709\u591a surprise\uff0c\u5373\u53cd\u5dee\u6709\u591a\u5927\uff0c\u5047\u8bbe t=4 \u7684\u65f6\u5019 \\(g^4\\) \u4e0e\u524d\u9762\u7684 gradient \u53cd\u5dee\u7279\u522b\u5927\uff0c\u90a3\u4e48 \\(g^t\\) \u4e0e \\(\\sqrt{\\frac{1}{t+1}\\sum\\limits_{i=0}^t(g^i)^2}\\) \u4e4b\u95f4\u7684\u5927\u5c0f\u53cd\u5dee\u5c31\u4f1a\u6bd4\u8f83\u5927\uff0c\u5b83\u4eec\u7684\u5546\u5c31\u4f1a\u628a\u8fd9\u4e00\u53cd\u5dee\u6548\u679c\u4f53\u73b0\u51fa\u6765 gradient \u8d8a\u5927\uff0c\u79bb\u6700\u4f4e\u70b9\u8d8a\u8fdc\u8fd9\u4ef6\u4e8b\u60c5\u5728\u6709\u591a\u4e2a\u53c2\u6570\u7684\u60c5\u51b5\u4e0b\u662f\u4e0d\u4e00\u5b9a\u6210\u7acb\u7684 \u5b9e\u9645\u4e0a\uff0c\u5bf9\u4e8e\u4e00\u4e2a\u4e8c\u6b21\u51fd\u6570 \\(y=ax^2+bx+c\\) \u6765\u8bf4\uff0c\u6700\u5c0f\u503c\u70b9\u7684 \\(x=-\\frac{b}{2a}\\) \uff0c\u800c\u5bf9\u4e8e\u4efb\u610f\u4e00\u70b9 \\(x_0\\) \uff0c\u5b83\u8fc8\u51fa\u6700\u597d\u7684\u6b65\u4f10\u957f\u5ea6\u662f \\(|x_0+\\frac{b}{2a}|=|\\frac{2ax_0+b}{2a}|\\) (\u8fd9\u6837\u5c31\u4e00\u6b65\u8fc8\u5230\u6700\u5c0f\u503c\u70b9\u4e86)\uff0c\u8054\u7cfb\u8be5\u51fd\u6570\u7684\u4e00\u9636\u548c\u4e8c\u9636\u5bfc\u6570 \\(y'=2ax+b\\) \u3001 \\(y''=2a\\) \uff0c\u53ef\u4ee5\u53d1\u73b0the best step is \\(|\\frac{y'}{y''}|\\) \uff0c\u4e5f\u5c31\u662f\u8bf4\u4ed6\u4e0d\u4ec5\u8ddf\u4e00\u9636\u5bfc\u6570(gradient)\u6709\u5173\uff0c\u8fd8\u8ddf\u4e8c\u9636\u5bfc\u5e08\u6709\u5173\uff0c\u56e0\u6b64\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u8fd9\u79cd\u65b9\u6cd5\u91cd\u65b0\u6bd4\u8f83\u4e0a\u9762\u7684a\u548cc\u70b9\uff0c\u5c31\u53ef\u4ee5\u5f97\u5230\u6bd4\u8f83\u6b63\u786e\u7684\u7b54\u6848 \u518d\u6765\u56de\u987e Adagrad \u7684\u8868\u8fbe\u5f0f\uff1a \\(w^{t+1}=w^t-\\frac{\\eta}{\\sqrt{\\sum\\limits_{i=0}^t(g^i)^2}}\\cdot g^t\\) \\(g^t\\) \u5c31\u662f\u4e00\u6b21\u5fae\u5206\uff0c\u800c\u5206\u6bcd\u4e2d\u7684 \\(\\sum\\limits_{i=0}^t(g^i)^2\\) \u53cd\u6620\u4e86\u4e8c\u6b21\u5fae\u5206\u7684\u5927\u5c0f\uff0c\u6240\u4ee5 Adagrad \u60f3\u8981\u505a\u7684\u4e8b\u60c5\u5c31\u662f\uff0c\u5728\u4e0d\u589e\u52a0\u4efb\u4f55\u989d\u5916\u8fd0\u7b97\u7684\u524d\u63d0\u4e0b\uff0c\u60f3\u529e\u6cd5\u53bb\u4f30\u6d4b\u4e8c\u6b21\u5fae\u5206\u7684\u503c Stochastic Gradicent Descent \u00b6 \u968f\u673a\u68af\u5ea6\u4e0b\u964d\u7684\u65b9\u6cd5\u53ef\u4ee5\u8ba9\u8bad\u7ec3\u66f4\u5feb\u901f\uff0c\u4f20\u7edf\u7684 gradient descent \u7684\u601d\u8def\u662f\u770b\u5b8c\u6240\u6709\u7684\u6837\u672c\u70b9\u4e4b\u540e\u518d\u6784\u5efa loss function\uff0c\u7136\u540e\u53bb update \u53c2\u6570\uff1b\u800c stochastic gradient descent \u7684\u505a\u6cd5\u662f\uff0c\u770b\u5230\u4e00\u4e2a\u6837\u672c\u70b9\u5c31 update \u4e00\u6b21\uff0c\u56e0\u6b64\u5b83\u7684 loss function \u4e0d\u662f\u6240\u6709\u6837\u672c\u70b9\u7684 error \u5e73\u65b9\u548c\uff0c\u800c\u662f\u8fd9\u4e2a\u968f\u673a\u6837\u672c\u70b9\u7684 error \u5e73\u65b9 Feature Scaling \u00b6 \u7279\u5f81\u7f29\u653e\uff0c\u5f53\u591a\u4e2a\u7279\u5f81\u7684\u5206\u5e03\u8303\u56f4\u5f88\u4e0d\u4e00\u6837\u65f6\uff0c\u6700\u597d\u5c06\u8fd9\u4e9b\u4e0d\u540c feature \u7684\u8303\u56f4\u7f29\u653e\u6210\u4e00\u6837\uff0c\u5373\u5c06\u7279\u5f81\u7684\u6307\u6807\u6807\u51c6\u5316 \u5982\u4f55\u505a feature scaling \u5047\u8bbe\u6709 R \u4e2a example (\u4e0a\u6807i\u8868\u793a\u7b2ci\u4e2a\u6837\u672c\u70b9)\uff0c \\(x^1,x^2,x^3,...,x^r,...x^R\\) \uff0c\u6bcf\u4e00\u7b14 example\uff0c\u5b83\u91cc\u9762\u90fd\u6709\u4e00\u7ec4 feature (\u4e0b\u6807j\u8868\u793a\u8be5\u6837\u672c\u70b9\u7684\u7b2cj\u4e2a\u7279\u5f81) \u5bf9\u6bcf\u4e00\u4e2a \\(demension_i\\) \uff0c\u90fd\u53bb\u7b97\u51fa\u5b83\u7684\u5e73\u5747\u503c \\(mean=m_i\\) \uff0c\u4ee5\u53ca\u6807\u51c6\u5dee \\(standard\\ deviation=\\sigma_i\\) \u5bf9\u7b2c r \u4e2a example \u7684\u7b2c i \u4e2a component\uff0c\u51cf\u6389\u5747\u503c\uff0c\u9664\u4ee5\u6807\u51c6\u5dee\uff0c\u5373 \\(x_i^r=\\frac{x_i^r-m_i}{\\sigma_i}\\) \uff0c\u5373\u628a\u6bcf\u4e00\u4e2a\u53c2\u6570\u5316\u6210\u6807\u51c6\u7684\u6b63\u6001\u5206\u5e03 \u5bf9gradient decent\u7684\u5e2e\u52a9 \u5e2e\u52a9\u6211\u4eec\u66f4\u597d\u7684 update \u53c2\u6570 Bias and Variance \u00b6 \u6bd4\u8f83\u7b80\u5355\u7684model\uff0cvariance\u6bd4\u8f83\u5c0f\uff0cbias\u6bd4\u8f83\u5927\uff0c\u751a\u81f3\u5b83\u7684\u8303\u56f4\u6ca1\u6709\u5305\u542b\u771f\u6b63\u7684 target \u800c\u6bd4\u8f83\u590d\u6742\u7684model\uff0cbias\u6bd4\u8f83\u5c0f\uff0cvariance\u6bd4\u8f83\u5927 \u5fc5\u987b\u8981\u77e5\u9053\u81ea\u5df1\u7684 error \u4e3b\u8981\u6765\u81ea\u4e8e\u54ea\u91cc\uff0c\u73b0\u5728\u7684\u95ee\u9898\u662f bias \u5927\uff0c\u8fd8\u662f variance \u5927\uff1f \u5982\u679c model \u6ca1\u6709\u529e\u6cd5 fit training data \u7684 examples\uff0c\u4ee3\u8868 bias \u6bd4\u8f83\u5927\uff0c\u8fd9\u65f6\u662f underfitting \u5982\u679c model \u53ef\u4ee5 fit training data\uff0c\u5728 training data \u4e0a\u5f97\u5230\u5c0f\u7684 error\uff0c\u4f46\u662f\u5728 testing data \u4e0a\uff0c\u5374\u5f97\u5230\u4e00\u4e2a\u5927\u7684 error\uff0c\u4ee3\u8868 variance \u6bd4\u8f83\u5927\uff0c\u8fd9\u65f6\u662f overfitting \u5982\u4f55\u5904\u7406 bias \u5927 or variance \u5927\u7684\u60c5\u51b5\u5462\uff1f \u00b6 bias \u6bd4\u8f83\u5927 redesign\uff0c\u91cd\u65b0\u8bbe\u8ba1\u4f60\u7684 model \u589e\u52a0\u66f4\u591a\u7684 features \u4f5c\u4e3a model \u7684 input \u8f93\u5165\u53d8\u91cf \u6bd4\u5982 pokemon \u7684\u4f8b\u5b50\u91cc\uff0c\u53ea\u8003\u8651\u8fdb\u5316\u524d cp \u503c\u53ef\u80fd\u4e0d\u591f\uff0c\u8fd8\u8981\u8003\u8651 hp \u503c\u3001species \u79cd\u7c7b...\u4f5c\u4e3amodel \u65b0\u7684 input \u53d8\u91cf \u8ba9 model \u53d8\u5f97\u66f4\u590d\u6742\uff0c\u589e\u52a0\u9ad8\u6b21\u9879 \u6bd4\u5982\u539f\u672c\u53ea\u662f linear model\uff0c\u73b0\u5728\u8003\u8651\u589e\u52a0\u4e8c\u6b21\u9879\u3001\u4e09\u6b21\u9879... variance \u6bd4\u8f83\u5927 \u589e\u52a0data \u5982\u679c\u6ca1\u6709\u529e\u6cd5 collect \u66f4\u591a\u7684 data\uff0c\u5176\u5b9e\u6709\u4e00\u62db\uff0c\u6839\u636e\u4f60\u5bf9\u8fd9\u4e2a\u95ee\u9898\u7684\u7406\u89e3\uff0c\u81ea\u5df1\u53bbgenerate \u66f4\u591a\u201c\u5047\u7684\u201d data \u6bd4\u5982\u624b\u5199\u6570\u5b57\u8bc6\u522b\uff0c\u56e0\u4e3a\u6bcf\u4e2a\u4eba\u624b\u5199\u6570\u5b57\u7684\u89d2\u5ea6\u90fd\u4e0d\u4e00\u6837\uff0c\u90a3\u5c31\u628a\u6240\u6709 training data \u91cc\u9762\u7684\u6570\u5b57\u90fd\u5de6\u8f6c15\u00b0\uff0c\u53f3\u8f6c15\u00b0 \u6bd4\u5982\u505a\u706b\u8f66\u7684\u5f71\u50cf\u8fa8\u8bc6\uff0c\u53ea\u6709\u4ece\u5de6\u8fb9\u5f00\u8fc7\u6765\u7684\u706b\u8f66\u5f71\u50cf\u8d44\u6599\uff0c\u6ca1\u6709\u4ece\u53f3\u8fb9\u5f00\u8fc7\u6765\u7684\u706b\u8f66\u5f71\u50cf\u8d44\u6599\uff0c\u8be5\u600e\u4e48\u529e\uff1f\u5b9e\u9645\u4e0a\u53ef\u4ee5\u628a\u6bcf\u5f20\u56fe\u7247\u90fd\u5de6\u53f3\u98a0\u5012\uff0c\u5c31 generate \u51fa\u53f3\u8fb9\u7684\u706b\u8f66\u6570\u636e\u4e86\uff0c\u8fd9\u6837\u5c31\u591a\u4e86\u4e00\u500d data \u51fa\u6765 \u6bd4\u5982\u505a\u8bed\u97f3\u8fa8\u8bc6\u7684\u65f6\u5019\uff0c\u53ea\u6709\u7537\u751f\u8bf4\u7684\u201c\u4f60\u597d\u201d\uff0c\u6ca1\u6709\u5973\u751f\u8bf4\u7684\u201c\u4f60\u597d\u201d\uff0c\u90a3\u5c31\u7528\u7537\u751f\u7684\u58f0\u97f3\u7528\u4e00\u4e2a\u53d8\u58f0\u5668\u628a\u5b83\u8f6c\u5316\u4e00\u4e0b\uff0c\u8fd9\u6837\u7537\u5973\u751f\u7684\u58f0\u97f3\u5c31\u53ef\u4ee5\u4e92\u76f8\u8f6c\u5316\uff0c\u8fd9\u6837 data \u5c31\u53ef\u4ee5\u591a\u51fa\u6765 \u6bd4\u5982\u73b0\u5728\u4f60\u53ea\u6709\u5f55\u97f3\u5ba4\u91cc\u5f55\u4e0b\u7684\u58f0\u97f3\uff0c\u4f46\u662f detection \u5b9e\u9645\u8981\u5728\u771f\u5b9e\u573a\u666f\u4e0b\u4f7f\u7528\u7684\uff0c\u90a3\u4f60\u5c31\u53bb\u771f\u5b9e\u573a\u666f\u4e0b\u5f55\u4e00\u4e9b\u566a\u97f3\u52a0\u5230\u539f\u672c\u7684\u58f0\u97f3\u91cc\uff0c\u5c31\u53ef\u4ee5 generate \u51fa\u7b26\u5408\u6761\u4ef6\u7684 data \u4e86 Regularization(\u6b63\u89c4\u5316) \u5c31\u662f\u5728 loss function \u91cc\u9762\u518d\u52a0\u4e00\u4e2a\u4e0e model \u9ad8\u6b21\u9879\u7cfb\u6570\u76f8\u5173\u7684 term\uff0c\u5b83\u4f1a\u5e0c\u671b\u4f60\u7684 model \u91cc\u9ad8\u6b21\u9879\u7684\u53c2\u6570\u8d8a\u5c0f\u8d8a\u597d\uff0c\u4e5f\u5c31\u662f\u8bf4\u5e0c\u671b\u4f60\u4eca\u5929\u627e\u51fa\u6765\u7684\u66f2\u7ebf\u8d8a\u5e73\u6ed1\u8d8a\u597d\uff1b\u8fd9\u4e2a\u65b0\u52a0\u7684 term\u524d\u9762\u53ef\u4ee5\u6709\u4e00\u4e2a weight\uff0c\u4ee3\u8868\u4f60\u5e0c\u671b\u4f60\u7684\u66f2\u7ebf\u6709\u591a\u5e73\u6ed1 \u52a0\u4e86 regularization \u4ee5\u540e\uff0c\u56e0\u4e3a\u4f60\u5f3a\u8feb\u6240\u6709\u7684\u66f2\u7ebf\u90fd\u8981\u6bd4\u8f83\u5e73\u6ed1\uff0c\u6240\u4ee5\u8fd9\u4e2a\u65f6\u5019\u4e5f\u4f1a\u8ba9\u4f60\u7684variance \u53d8\u5c0f\uff1b\u4f46 regularization \u662f\u53ef\u80fd\u4f1a\u4f24\u5bb3 bias \u7684\uff0c\u56e0\u4e3a\u5b83\u5b9e\u9645\u4e0a\u8c03\u6574\u4e86 function set \u7684 space \u8303\u56f4\uff0c\u53d8\u6210\u5b83\u53ea\u5305\u542b\u90a3\u4e9b\u6bd4\u8f83\u5e73\u6ed1\u7684\u66f2\u7ebf\uff0c\u8fd9\u4e2a\u7f29\u5c0f\u7684 space \u53ef\u80fd\u6ca1\u6709\u5305\u542b\u539f\u5148\u5728\u66f4\u5927 space \u5185\u7684 \\(\\widehat{f}\\) \uff0c\u56e0\u6b64\u4f24\u5bb3\u4e86 bias\uff0c\u6240\u4ee5\u5f53\u4f60\u505a regularization \u7684\u65f6\u5019\uff0c\u9700\u8981\u8c03\u6574 regularization \u7684 weight\uff0c\u5728 variance \u548c bias \u4e4b\u95f4\u53d6\u5f97\u5e73\u8861 \u4e0d\u5e94\u8be5\u505a\u7684\u4e8b \u62ff\u505a\u597d\u7684 model \u901a\u8fc7 testing data \u5f97\u51fa\u7684 error \u6765\u8bc4\u4ef7\u8fd9\u4e2a model\uff0c\u7136\u540e\u89c9\u5f97\u8fd9\u4e2a model \u4e0d\u597d\uff0c\u56de\u53bb\u4fee\u6539\u53c2\u6570 training set \u548c validation set \u00b6 \u628a\u4f60\u7684 training set \u5206\u6210\u4e24\u7ec4\uff1a \u4e00\u7ec4\u662f\u771f\u6b63\u62ff\u6765 training model \u7684\uff0c\u53eb\u505a training set (\u8bad\u7ec3\u96c6) \u53e6\u5916\u4e00\u7ec4\u4e0d\u62ff\u5b83\u6765 training model\uff0c\u800c\u662f\u62ff\u5b83\u6765\u9009 model\uff0c\u53eb\u505a validation set (\u9a8c\u8bc1\u96c6) \u5148\u5728 training set \u4e0a\u627e\u51fa\u6bcf\u4e2a model \u6700\u597d\u7684 function \\(f^*\\) \uff0c\u7136\u540e\u7528 validation set \u6765\u9009\u62e9\u4f60\u7684 model \u5982\u679c\u611f\u89c9\u5206\u6210 2 \u90e8\u5206 training data \u53d8\u5c11\u7684\u8bdd\uff0c\u53ef\u4ee5\u8fd9\u6837\u505a\uff1a\u5df2\u7ecf\u4ece validation \u51b3\u5b9a model3 \u662f\u6700\u597d\u7684model\uff0c\u90a3\u5c31\u5b9a\u4f4f model3 \u4e0d\u53d8 (function\u7684\u8868\u8fbe\u5f0f\u4e0d\u53d8)\uff0c\u7136\u540e\u7528\u5168\u90e8\u7684 data \u5728 model3 \u4e0a\u9762\u518d\u8bad\u7ec3\u4e00\u6b21 (\u4f7f\u7528\u5168\u90e8\u7684 data \u53bb\u66f4\u65b0 model3 \u8868\u8fbe\u5f0f\u7684\u53c2\u6570) \u8fd9\u4e2a\u65f6\u5019\uff0c\u5982\u679c\u4f60\u628a\u8fd9\u4e2a\u8bad\u7ec3\u597d\u7684 model \u7684 \\(f^*\\) apply \u5230 public testing set \u4e0a\u9762\uff0c\u4f60\u53ef\u80fd\u4f1a\u5f97\u5230\u4e00\u4e2a\u5927\u4e8e0.5\u7684 error\uff0c\u867d\u7136\u8fd9\u4e48\u505a\uff0c\u4f60\u5f97\u5230\u7684 error \u8868\u9762\u4e0a\u770b\u8d77\u6765\u662f\u6bd4\u8f83\u5927\u7684\uff0c\u4f46\u662f \u8fd9\u4e2a\u65f6\u5019\u4f60\u5728 public set \u4e0a\u7684 error \u624d\u80fd\u591f\u771f\u6b63\u53cd\u6620\u4f60\u5728 private set \u4e0a\u7684 error \u5982\u4f55\u5212\u5206 training set \u548c validation set\uff1f validation set \u53ef\u80fd\u81ea\u5e26 bias\uff0c\u5bf9\u7ed3\u679c\u4e0d\u5229 N-flod Cross Validation \u5982\u679c\u4f60\u4e0d\u76f8\u4fe1\u67d0\u4e00\u6b21\u5206 train \u548c validation \u7684\u7ed3\u679c\u7684\u8bdd\uff0c\u90a3\u4f60\u5c31\u5206\u5f88\u591a\u79cd\u4e0d\u540c\u7684\u6837\u5b50 \u6bd4\u5982\u8bf4\uff0c\u5982\u679c\u4f60\u505a 3-flod \u7684 validation\uff0c\u610f\u601d\u5c31\u662f\u4f60\u628a training set \u5206\u6210\u4e09\u4efd\uff0c\u4f60\u6bcf\u4e00\u6b21\u62ff\u5176\u4e2d\u4e00\u4efd\u5f53\u505a validation set\uff0c\u53e6\u5916\u4e24\u4efd\u5f53 training \u5206\u522b\u5728\u6bcf\u4e2a\u60c5\u5883\u4e0b\u90fd\u8ba1\u7b97\u4e00\u4e0b3\u4e2amodel \u7684 error\uff0c\u7136\u540e\u8ba1\u7b97\u4e00\u4e0b\u5b83\u7684 average error\uff0c\u9009\u62e9\u4e00\u4e2a error \u6700\u5c0f\u7684 \u7136\u540e\u628a\u7528\u6574\u4e2a\u5b8c\u6574\u7684 training data \u91cd\u65b0\u8bad\u7ec3\u4e00\u904d\u53c2\u6570\uff0c\u518d\u53bb testing data \u4e0a test","title":"Regression"},{"location":"ML/1_Regression/#regression","text":"","title":"Regression"},{"location":"ML/1_Regression/#regression_1","text":"\u5b9a\u4e49\u4e00\u4e2a model \u5373 function set \u5b9a\u4e49\u4e00\u4e2a goodness of function \u635f\u5931\u51fd\u6570\u53bb\u8bc4\u4f30\u8be5 function \u7684\u597d\u574f \u627e\u4e00\u4e2a\u6700\u597d\u7684 function","title":"Regression \u5177\u4f53\u8fc7\u7a0b"},{"location":"ML/1_Regression/#linear-model","text":"Model (function set)\uff1a \\(y=b+w \\cdot X_{cp}\\) \uff0c\u53ef\u4ee5\u6269\u5c55\u4e3a \\(y=b+ \\sum w_ix_i\\) Loss function\uff1a \\(L(f)=L(w,b)=\\sum_{n=1}^{10}(\\widehat{y}^n-(b+w \\cdot x^{n}_{cp}))^2\\)","title":"Linear Model \u7ebf\u6027\u6a21\u578b"},{"location":"ML/1_Regression/#gradient-descent","text":"\u5355\u4e2a\u53c2\u6570\u76f4\u63a5\u6c42\u5fae\u5206\uff0c\u591a\u4e2a\u53c2\u6570\u6c42\u504f\u5fae\u5206 \\[ \\begin{align} L(w,b)=\\sum\\limits_{n=1}^{10}(\\widehat{y}^n-(b+w\\cdot x_{cp}^n))^2 \\\\ \\frac{\\partial L}{\\partial w}=\\sum\\limits_{n=1}^{10}2(\\widehat{y}^n-(b+w\\cdot x_{cp}^n))(-x_{cp}^n) \\\\ \\frac{\\partial L}{\\partial b}=\\sum\\limits_{n=1}^{10}2(\\widehat{y}^n-(b+w\\cdot x_{cp}^n))(-1) \\end{align} \\] \\[ \\begin{align} w^1=w^0-\u03b7\\frac{\\partial L}{\\partial w}|_{w=w^0,b=b^0} \\ \\ \\ \\ \\ \\ \\ \\ \\ b^1=b^0-\u03b7\\frac{\\partial L}{\\partial b}|_{w=w^0,b=b^0} \\\\ w^2=w^1-\u03b7\\frac{\\partial L}{\\partial w}|_{w=w^1,b=b^1} \\ \\ \\ \\ \\ \\ \\ \\ \\ b^2=b^1-\u03b7\\frac{\\partial L}{\\partial b}|_{w=w^1,b=b^1} \\\\ ... \\\\ w^{i+1}=w^{i}-\u03b7\\frac{\\partial L}{\\partial w}|_{w=w^{i},b=b^{i}} \\ \\ \\ \\ \\ \\ \\ \\ \\ b^{i+1}=b^{i}-\u03b7\\frac{\\partial L}{\\partial b}|_{w=w^{i},b=b^{i}} \\\\ if(\\frac{\\partial L}{\\partial w}==0 \\&\\& \\frac{\\partial L}{\\partial b}==0) \\ \\ \\ then \\ \\ stop \\end{align} \\] \u7f3a\u70b9\uff1a\u627e\u5230\u7684\u70b9\u672a\u5fc5\u662f\u6781\u5c0f\u503c\u70b9 # eg: y = b + w * x \u8ba1\u7b97\u68af\u5ea6\u5fae\u5206\u7684\u51fd\u6570 getGrad() def getGrad ( b , w ): # initial b_grad and w_grad b_grad = 0.0 w_grad = 0.0 for i in range ( 10 ): b_grad += ( - 2.0 ) * ( y_data [ i ] - ( b + w * x_data [ i ])) w_grad += ( - 2.0 * x_data [ i ]) * ( y_data [ i ] - ( b + w * x_data [ i ])) return ( b_grad , w_grad )","title":"Gradient Descent \u68af\u5ea6\u4e0b\u964d"},{"location":"ML/1_Regression/#_1","text":"\\((x_{cp})^2\\) \u7684 model \uff1atraining data \u4e2d model \u8d8a\u590d\u6742 error \u4f1a\u8d8a\u4f4e\uff0c\u4f46 testing data \u4e2d error \u4f1a\u53d8\u5927\uff0coverfitting \u8003\u8651\u79cd\u65cf\u3001\u7c7b\u522b\u7684\u5f71\u54cd \\[ \\begin{align} if \\ \\ x_s=Pidgey: \\ \\ \\ \\ \\ \\ \\ y=b_1+w_1\\cdot x_{cp} \\\\ if \\ \\ x_s=Weedle: \\ \\ \\ \\ \\ \\ y=b_2+w_2\\cdot x_{cp} \\\\ if \\ \\ x_s=Caterpie: \\ \\ \\ \\ y=b_3+w_3\\cdot x_{cp} \\\\ if \\ \\ x_s=Eevee: \\ \\ \\ \\ \\ \\ \\ \\ \\ y=b_4+w_4\\cdot x_{cp} \\end{align} \\]","title":"\u975e\u7ebf\u6027\u7684\u6a21\u578b"},{"location":"ML/1_Regression/#regularization-overfitting","text":"\u6b63\u5219\u5316\u89e3\u51b3\u8fc7\u62df\u5408\u95ee\u9898 $$ L=\\sum\\limits_i^n(\\widehat{y}^i-(b+\\sum\\limits_{j}w_jx_j))^2+\\lambda\\sum(w_i)^2 $$ \u5e0c\u671b \\(w_i\\) \u6bd4\u8f83\u5c0f\u800c\u5f97\u5230\u4e00\u4e2a\u5e73\u6ed1\u7684\u66f2\u7ebf\uff0c\u8fd9\u91cc\u7684 \u03bb \u9700\u8981\u6211\u4eec\u624b\u52a8\u53bb\u8c03\u6574\u4ee5\u53d6\u5f97\u6700\u597d\u7684\u503c","title":"regularization \u89e3\u51b3 overfitting"},{"location":"ML/1_Regression/#adaptive-learning-rates","text":"learning rate \u5927\u4e86\u5c0f\u4e86\u90fd\u4e0d\u597d \u4e00\u4e2a\u7b80\u7b54\u7684\u539f\u5219\uff1alearning rate \u901a\u5e38\u662f\u968f\u7740\u53c2\u6570\u7684 update \u8d8a\u6765\u8d8a\u5c0f\u7684 eg\uff1a \\(\\eta^t=\\eta/ \\sqrt{t+1}\\) \uff08\u7b2c t \u6b21 update\uff09","title":"Adaptive Learning rates"},{"location":"ML/1_Regression/#adagrad","text":"Divide the learning rate of each parameter by the root mean square(\u65b9\u5747\u6839) of its previous derivatives Adagrad \u5c06\u4e0d\u540c\u53c2\u6570\u7684 learning rate \u5206\u5f00\u8003\u8651\uff0cupdate\u5230\u540e\u9762\u901f\u5ea6\u4f1a\u8d8a\u6765\u8d8a\u6162\uff0c\u8fd9\u662fadaptive\u7b97\u6cd5\u4e2d\u6700\u7b80\u5355\u7684\u4e00\u79cd $$ \\begin{equation} \\begin{split} &Adagrad\\ &w^1=w^0-\\frac{\\eta^0}{\\sigma^0}\\cdot g^0, \\ \\ \\ \\sigma^0=\\sqrt{(g^0)^2} \\ &w^2=w^1-\\frac{\\eta^1}{\\sigma^1}\\cdot g^1, \\ \\ \\ \\sigma^1=\\sqrt{\\frac{1}{2}[(g^0)^2+(g^1)^2]} \\ &w^3=w^2-\\frac{\\eta2}{\\sigma^2}\\cdot g^2, \\ \\ \\ \\sigma^2=\\sqrt{\\frac{1}{3}[(g^0)^2+(g^1)^2+(g^2)^2]} \\ &... \\ &w^{t+1}=w^t-\\frac{\\eta^t}{\\sigma^t}\\cdot g^t, \\ \\ \\ \\sigma^t=\\sqrt{\\frac{1}{1+t}\\sum\\limits_{i=0}^{t}(g^i)^2} \\end{split} \\end{equation} $$ \\(g^t\\) \u8868\u793a Loss \u5bf9 w \u7684\u504f\u5fae\u5206 \u7531\u4e8e \\(\\eta^t=\\eta/ \\sqrt{t+1}\\) \u548c \\(\\sigma^t=\\sqrt{\\frac{1}{1+t}\\sum\\limits_{i=0}^{t}(g^i)^2}\\) \u4e2d\u90fd\u6709\u4e00\u4e2a \\(\\sqrt{\\frac{1}{1+t}}\\) \u7684\u56e0\u5b50\uff0c\u4e24\u8005\u76f8\u6d88\uff0c\u5373\u53ef\u5f97\u5230 adagrad \u7684\u6700\u7ec8\u8868\u8fbe\u5f0f\uff1a $$ w^{t+1}=w^t-\\frac{\\eta}{\\sqrt{\\sum\\limits_{i=0}^t(g^i)^2}}\\cdot g^t $$ Adagrad \u7684 contradiction \u89e3\u91ca \u6211\u4eec\u5728\u505a gradient descent \u7684\u65f6\u5019\uff0c\u5e0c\u671b\u7684\u662f\u5f53\u68af\u5ea6\u503c\u5373\u5fae\u5206\u503c \\(g^t\\) \u8d8a\u5927\u7684\u65f6\u5019\u66f4\u65b0\u7684\u6b65\u4f10\u8981\u66f4\u5927\u4e00\u4e9b\uff0c\u4f46\u662f Adagrad \u7684\u8868\u8fbe\u5f0f\u4e2d\uff0c\u5206\u6bcd\u8868\u793a\u68af\u5ea6\u8d8a\u5927\u6b65\u4f10\u8d8a\u5c0f\uff0c\u5206\u5b50\u5374\u8868\u793a\u68af\u5ea6\u8d8a\u5927\u6b65\u4f10\u8d8a\u5927\uff0c\u4e24\u8005\u4f3c\u4e4e\u76f8\u4e92\u77db\u76fe \u5728\u4e00\u4e9b paper \u91cc\u662f\u8fd9\u6837\u89e3\u91ca\u7684\uff1aAdagrad \u8981\u8003\u8651\u7684\u662f\uff0c\u8fd9\u4e2a gradient \u6709\u591a surprise\uff0c\u5373\u53cd\u5dee\u6709\u591a\u5927\uff0c\u5047\u8bbe t=4 \u7684\u65f6\u5019 \\(g^4\\) \u4e0e\u524d\u9762\u7684 gradient \u53cd\u5dee\u7279\u522b\u5927\uff0c\u90a3\u4e48 \\(g^t\\) \u4e0e \\(\\sqrt{\\frac{1}{t+1}\\sum\\limits_{i=0}^t(g^i)^2}\\) \u4e4b\u95f4\u7684\u5927\u5c0f\u53cd\u5dee\u5c31\u4f1a\u6bd4\u8f83\u5927\uff0c\u5b83\u4eec\u7684\u5546\u5c31\u4f1a\u628a\u8fd9\u4e00\u53cd\u5dee\u6548\u679c\u4f53\u73b0\u51fa\u6765 gradient \u8d8a\u5927\uff0c\u79bb\u6700\u4f4e\u70b9\u8d8a\u8fdc\u8fd9\u4ef6\u4e8b\u60c5\u5728\u6709\u591a\u4e2a\u53c2\u6570\u7684\u60c5\u51b5\u4e0b\u662f\u4e0d\u4e00\u5b9a\u6210\u7acb\u7684 \u5b9e\u9645\u4e0a\uff0c\u5bf9\u4e8e\u4e00\u4e2a\u4e8c\u6b21\u51fd\u6570 \\(y=ax^2+bx+c\\) \u6765\u8bf4\uff0c\u6700\u5c0f\u503c\u70b9\u7684 \\(x=-\\frac{b}{2a}\\) \uff0c\u800c\u5bf9\u4e8e\u4efb\u610f\u4e00\u70b9 \\(x_0\\) \uff0c\u5b83\u8fc8\u51fa\u6700\u597d\u7684\u6b65\u4f10\u957f\u5ea6\u662f \\(|x_0+\\frac{b}{2a}|=|\\frac{2ax_0+b}{2a}|\\) (\u8fd9\u6837\u5c31\u4e00\u6b65\u8fc8\u5230\u6700\u5c0f\u503c\u70b9\u4e86)\uff0c\u8054\u7cfb\u8be5\u51fd\u6570\u7684\u4e00\u9636\u548c\u4e8c\u9636\u5bfc\u6570 \\(y'=2ax+b\\) \u3001 \\(y''=2a\\) \uff0c\u53ef\u4ee5\u53d1\u73b0the best step is \\(|\\frac{y'}{y''}|\\) \uff0c\u4e5f\u5c31\u662f\u8bf4\u4ed6\u4e0d\u4ec5\u8ddf\u4e00\u9636\u5bfc\u6570(gradient)\u6709\u5173\uff0c\u8fd8\u8ddf\u4e8c\u9636\u5bfc\u5e08\u6709\u5173\uff0c\u56e0\u6b64\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u8fd9\u79cd\u65b9\u6cd5\u91cd\u65b0\u6bd4\u8f83\u4e0a\u9762\u7684a\u548cc\u70b9\uff0c\u5c31\u53ef\u4ee5\u5f97\u5230\u6bd4\u8f83\u6b63\u786e\u7684\u7b54\u6848 \u518d\u6765\u56de\u987e Adagrad \u7684\u8868\u8fbe\u5f0f\uff1a \\(w^{t+1}=w^t-\\frac{\\eta}{\\sqrt{\\sum\\limits_{i=0}^t(g^i)^2}}\\cdot g^t\\) \\(g^t\\) \u5c31\u662f\u4e00\u6b21\u5fae\u5206\uff0c\u800c\u5206\u6bcd\u4e2d\u7684 \\(\\sum\\limits_{i=0}^t(g^i)^2\\) \u53cd\u6620\u4e86\u4e8c\u6b21\u5fae\u5206\u7684\u5927\u5c0f\uff0c\u6240\u4ee5 Adagrad \u60f3\u8981\u505a\u7684\u4e8b\u60c5\u5c31\u662f\uff0c\u5728\u4e0d\u589e\u52a0\u4efb\u4f55\u989d\u5916\u8fd0\u7b97\u7684\u524d\u63d0\u4e0b\uff0c\u60f3\u529e\u6cd5\u53bb\u4f30\u6d4b\u4e8c\u6b21\u5fae\u5206\u7684\u503c","title":"Adagrad"},{"location":"ML/1_Regression/#stochastic-gradicent-descent","text":"\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u7684\u65b9\u6cd5\u53ef\u4ee5\u8ba9\u8bad\u7ec3\u66f4\u5feb\u901f\uff0c\u4f20\u7edf\u7684 gradient descent \u7684\u601d\u8def\u662f\u770b\u5b8c\u6240\u6709\u7684\u6837\u672c\u70b9\u4e4b\u540e\u518d\u6784\u5efa loss function\uff0c\u7136\u540e\u53bb update \u53c2\u6570\uff1b\u800c stochastic gradient descent \u7684\u505a\u6cd5\u662f\uff0c\u770b\u5230\u4e00\u4e2a\u6837\u672c\u70b9\u5c31 update \u4e00\u6b21\uff0c\u56e0\u6b64\u5b83\u7684 loss function \u4e0d\u662f\u6240\u6709\u6837\u672c\u70b9\u7684 error \u5e73\u65b9\u548c\uff0c\u800c\u662f\u8fd9\u4e2a\u968f\u673a\u6837\u672c\u70b9\u7684 error \u5e73\u65b9","title":"Stochastic Gradicent Descent"},{"location":"ML/1_Regression/#feature-scaling","text":"\u7279\u5f81\u7f29\u653e\uff0c\u5f53\u591a\u4e2a\u7279\u5f81\u7684\u5206\u5e03\u8303\u56f4\u5f88\u4e0d\u4e00\u6837\u65f6\uff0c\u6700\u597d\u5c06\u8fd9\u4e9b\u4e0d\u540c feature \u7684\u8303\u56f4\u7f29\u653e\u6210\u4e00\u6837\uff0c\u5373\u5c06\u7279\u5f81\u7684\u6307\u6807\u6807\u51c6\u5316 \u5982\u4f55\u505a feature scaling \u5047\u8bbe\u6709 R \u4e2a example (\u4e0a\u6807i\u8868\u793a\u7b2ci\u4e2a\u6837\u672c\u70b9)\uff0c \\(x^1,x^2,x^3,...,x^r,...x^R\\) \uff0c\u6bcf\u4e00\u7b14 example\uff0c\u5b83\u91cc\u9762\u90fd\u6709\u4e00\u7ec4 feature (\u4e0b\u6807j\u8868\u793a\u8be5\u6837\u672c\u70b9\u7684\u7b2cj\u4e2a\u7279\u5f81) \u5bf9\u6bcf\u4e00\u4e2a \\(demension_i\\) \uff0c\u90fd\u53bb\u7b97\u51fa\u5b83\u7684\u5e73\u5747\u503c \\(mean=m_i\\) \uff0c\u4ee5\u53ca\u6807\u51c6\u5dee \\(standard\\ deviation=\\sigma_i\\) \u5bf9\u7b2c r \u4e2a example \u7684\u7b2c i \u4e2a component\uff0c\u51cf\u6389\u5747\u503c\uff0c\u9664\u4ee5\u6807\u51c6\u5dee\uff0c\u5373 \\(x_i^r=\\frac{x_i^r-m_i}{\\sigma_i}\\) \uff0c\u5373\u628a\u6bcf\u4e00\u4e2a\u53c2\u6570\u5316\u6210\u6807\u51c6\u7684\u6b63\u6001\u5206\u5e03 \u5bf9gradient decent\u7684\u5e2e\u52a9 \u5e2e\u52a9\u6211\u4eec\u66f4\u597d\u7684 update \u53c2\u6570","title":"Feature Scaling"},{"location":"ML/1_Regression/#bias-and-variance","text":"\u6bd4\u8f83\u7b80\u5355\u7684model\uff0cvariance\u6bd4\u8f83\u5c0f\uff0cbias\u6bd4\u8f83\u5927\uff0c\u751a\u81f3\u5b83\u7684\u8303\u56f4\u6ca1\u6709\u5305\u542b\u771f\u6b63\u7684 target \u800c\u6bd4\u8f83\u590d\u6742\u7684model\uff0cbias\u6bd4\u8f83\u5c0f\uff0cvariance\u6bd4\u8f83\u5927 \u5fc5\u987b\u8981\u77e5\u9053\u81ea\u5df1\u7684 error \u4e3b\u8981\u6765\u81ea\u4e8e\u54ea\u91cc\uff0c\u73b0\u5728\u7684\u95ee\u9898\u662f bias \u5927\uff0c\u8fd8\u662f variance \u5927\uff1f \u5982\u679c model \u6ca1\u6709\u529e\u6cd5 fit training data \u7684 examples\uff0c\u4ee3\u8868 bias \u6bd4\u8f83\u5927\uff0c\u8fd9\u65f6\u662f underfitting \u5982\u679c model \u53ef\u4ee5 fit training data\uff0c\u5728 training data \u4e0a\u5f97\u5230\u5c0f\u7684 error\uff0c\u4f46\u662f\u5728 testing data \u4e0a\uff0c\u5374\u5f97\u5230\u4e00\u4e2a\u5927\u7684 error\uff0c\u4ee3\u8868 variance \u6bd4\u8f83\u5927\uff0c\u8fd9\u65f6\u662f overfitting","title":"Bias and Variance"},{"location":"ML/1_Regression/#bias-or-variance","text":"bias \u6bd4\u8f83\u5927 redesign\uff0c\u91cd\u65b0\u8bbe\u8ba1\u4f60\u7684 model \u589e\u52a0\u66f4\u591a\u7684 features \u4f5c\u4e3a model \u7684 input \u8f93\u5165\u53d8\u91cf \u6bd4\u5982 pokemon \u7684\u4f8b\u5b50\u91cc\uff0c\u53ea\u8003\u8651\u8fdb\u5316\u524d cp \u503c\u53ef\u80fd\u4e0d\u591f\uff0c\u8fd8\u8981\u8003\u8651 hp \u503c\u3001species \u79cd\u7c7b...\u4f5c\u4e3amodel \u65b0\u7684 input \u53d8\u91cf \u8ba9 model \u53d8\u5f97\u66f4\u590d\u6742\uff0c\u589e\u52a0\u9ad8\u6b21\u9879 \u6bd4\u5982\u539f\u672c\u53ea\u662f linear model\uff0c\u73b0\u5728\u8003\u8651\u589e\u52a0\u4e8c\u6b21\u9879\u3001\u4e09\u6b21\u9879... variance \u6bd4\u8f83\u5927 \u589e\u52a0data \u5982\u679c\u6ca1\u6709\u529e\u6cd5 collect \u66f4\u591a\u7684 data\uff0c\u5176\u5b9e\u6709\u4e00\u62db\uff0c\u6839\u636e\u4f60\u5bf9\u8fd9\u4e2a\u95ee\u9898\u7684\u7406\u89e3\uff0c\u81ea\u5df1\u53bbgenerate \u66f4\u591a\u201c\u5047\u7684\u201d data \u6bd4\u5982\u624b\u5199\u6570\u5b57\u8bc6\u522b\uff0c\u56e0\u4e3a\u6bcf\u4e2a\u4eba\u624b\u5199\u6570\u5b57\u7684\u89d2\u5ea6\u90fd\u4e0d\u4e00\u6837\uff0c\u90a3\u5c31\u628a\u6240\u6709 training data \u91cc\u9762\u7684\u6570\u5b57\u90fd\u5de6\u8f6c15\u00b0\uff0c\u53f3\u8f6c15\u00b0 \u6bd4\u5982\u505a\u706b\u8f66\u7684\u5f71\u50cf\u8fa8\u8bc6\uff0c\u53ea\u6709\u4ece\u5de6\u8fb9\u5f00\u8fc7\u6765\u7684\u706b\u8f66\u5f71\u50cf\u8d44\u6599\uff0c\u6ca1\u6709\u4ece\u53f3\u8fb9\u5f00\u8fc7\u6765\u7684\u706b\u8f66\u5f71\u50cf\u8d44\u6599\uff0c\u8be5\u600e\u4e48\u529e\uff1f\u5b9e\u9645\u4e0a\u53ef\u4ee5\u628a\u6bcf\u5f20\u56fe\u7247\u90fd\u5de6\u53f3\u98a0\u5012\uff0c\u5c31 generate \u51fa\u53f3\u8fb9\u7684\u706b\u8f66\u6570\u636e\u4e86\uff0c\u8fd9\u6837\u5c31\u591a\u4e86\u4e00\u500d data \u51fa\u6765 \u6bd4\u5982\u505a\u8bed\u97f3\u8fa8\u8bc6\u7684\u65f6\u5019\uff0c\u53ea\u6709\u7537\u751f\u8bf4\u7684\u201c\u4f60\u597d\u201d\uff0c\u6ca1\u6709\u5973\u751f\u8bf4\u7684\u201c\u4f60\u597d\u201d\uff0c\u90a3\u5c31\u7528\u7537\u751f\u7684\u58f0\u97f3\u7528\u4e00\u4e2a\u53d8\u58f0\u5668\u628a\u5b83\u8f6c\u5316\u4e00\u4e0b\uff0c\u8fd9\u6837\u7537\u5973\u751f\u7684\u58f0\u97f3\u5c31\u53ef\u4ee5\u4e92\u76f8\u8f6c\u5316\uff0c\u8fd9\u6837 data \u5c31\u53ef\u4ee5\u591a\u51fa\u6765 \u6bd4\u5982\u73b0\u5728\u4f60\u53ea\u6709\u5f55\u97f3\u5ba4\u91cc\u5f55\u4e0b\u7684\u58f0\u97f3\uff0c\u4f46\u662f detection \u5b9e\u9645\u8981\u5728\u771f\u5b9e\u573a\u666f\u4e0b\u4f7f\u7528\u7684\uff0c\u90a3\u4f60\u5c31\u53bb\u771f\u5b9e\u573a\u666f\u4e0b\u5f55\u4e00\u4e9b\u566a\u97f3\u52a0\u5230\u539f\u672c\u7684\u58f0\u97f3\u91cc\uff0c\u5c31\u53ef\u4ee5 generate \u51fa\u7b26\u5408\u6761\u4ef6\u7684 data \u4e86 Regularization(\u6b63\u89c4\u5316) \u5c31\u662f\u5728 loss function \u91cc\u9762\u518d\u52a0\u4e00\u4e2a\u4e0e model \u9ad8\u6b21\u9879\u7cfb\u6570\u76f8\u5173\u7684 term\uff0c\u5b83\u4f1a\u5e0c\u671b\u4f60\u7684 model \u91cc\u9ad8\u6b21\u9879\u7684\u53c2\u6570\u8d8a\u5c0f\u8d8a\u597d\uff0c\u4e5f\u5c31\u662f\u8bf4\u5e0c\u671b\u4f60\u4eca\u5929\u627e\u51fa\u6765\u7684\u66f2\u7ebf\u8d8a\u5e73\u6ed1\u8d8a\u597d\uff1b\u8fd9\u4e2a\u65b0\u52a0\u7684 term\u524d\u9762\u53ef\u4ee5\u6709\u4e00\u4e2a weight\uff0c\u4ee3\u8868\u4f60\u5e0c\u671b\u4f60\u7684\u66f2\u7ebf\u6709\u591a\u5e73\u6ed1 \u52a0\u4e86 regularization \u4ee5\u540e\uff0c\u56e0\u4e3a\u4f60\u5f3a\u8feb\u6240\u6709\u7684\u66f2\u7ebf\u90fd\u8981\u6bd4\u8f83\u5e73\u6ed1\uff0c\u6240\u4ee5\u8fd9\u4e2a\u65f6\u5019\u4e5f\u4f1a\u8ba9\u4f60\u7684variance \u53d8\u5c0f\uff1b\u4f46 regularization \u662f\u53ef\u80fd\u4f1a\u4f24\u5bb3 bias \u7684\uff0c\u56e0\u4e3a\u5b83\u5b9e\u9645\u4e0a\u8c03\u6574\u4e86 function set \u7684 space \u8303\u56f4\uff0c\u53d8\u6210\u5b83\u53ea\u5305\u542b\u90a3\u4e9b\u6bd4\u8f83\u5e73\u6ed1\u7684\u66f2\u7ebf\uff0c\u8fd9\u4e2a\u7f29\u5c0f\u7684 space \u53ef\u80fd\u6ca1\u6709\u5305\u542b\u539f\u5148\u5728\u66f4\u5927 space \u5185\u7684 \\(\\widehat{f}\\) \uff0c\u56e0\u6b64\u4f24\u5bb3\u4e86 bias\uff0c\u6240\u4ee5\u5f53\u4f60\u505a regularization \u7684\u65f6\u5019\uff0c\u9700\u8981\u8c03\u6574 regularization \u7684 weight\uff0c\u5728 variance \u548c bias \u4e4b\u95f4\u53d6\u5f97\u5e73\u8861 \u4e0d\u5e94\u8be5\u505a\u7684\u4e8b \u62ff\u505a\u597d\u7684 model \u901a\u8fc7 testing data \u5f97\u51fa\u7684 error \u6765\u8bc4\u4ef7\u8fd9\u4e2a model\uff0c\u7136\u540e\u89c9\u5f97\u8fd9\u4e2a model \u4e0d\u597d\uff0c\u56de\u53bb\u4fee\u6539\u53c2\u6570","title":"\u5982\u4f55\u5904\u7406 bias \u5927 or variance \u5927\u7684\u60c5\u51b5\u5462\uff1f"},{"location":"ML/1_Regression/#training-set-validation-set","text":"\u628a\u4f60\u7684 training set \u5206\u6210\u4e24\u7ec4\uff1a \u4e00\u7ec4\u662f\u771f\u6b63\u62ff\u6765 training model \u7684\uff0c\u53eb\u505a training set (\u8bad\u7ec3\u96c6) \u53e6\u5916\u4e00\u7ec4\u4e0d\u62ff\u5b83\u6765 training model\uff0c\u800c\u662f\u62ff\u5b83\u6765\u9009 model\uff0c\u53eb\u505a validation set (\u9a8c\u8bc1\u96c6) \u5148\u5728 training set \u4e0a\u627e\u51fa\u6bcf\u4e2a model \u6700\u597d\u7684 function \\(f^*\\) \uff0c\u7136\u540e\u7528 validation set \u6765\u9009\u62e9\u4f60\u7684 model \u5982\u679c\u611f\u89c9\u5206\u6210 2 \u90e8\u5206 training data \u53d8\u5c11\u7684\u8bdd\uff0c\u53ef\u4ee5\u8fd9\u6837\u505a\uff1a\u5df2\u7ecf\u4ece validation \u51b3\u5b9a model3 \u662f\u6700\u597d\u7684model\uff0c\u90a3\u5c31\u5b9a\u4f4f model3 \u4e0d\u53d8 (function\u7684\u8868\u8fbe\u5f0f\u4e0d\u53d8)\uff0c\u7136\u540e\u7528\u5168\u90e8\u7684 data \u5728 model3 \u4e0a\u9762\u518d\u8bad\u7ec3\u4e00\u6b21 (\u4f7f\u7528\u5168\u90e8\u7684 data \u53bb\u66f4\u65b0 model3 \u8868\u8fbe\u5f0f\u7684\u53c2\u6570) \u8fd9\u4e2a\u65f6\u5019\uff0c\u5982\u679c\u4f60\u628a\u8fd9\u4e2a\u8bad\u7ec3\u597d\u7684 model \u7684 \\(f^*\\) apply \u5230 public testing set \u4e0a\u9762\uff0c\u4f60\u53ef\u80fd\u4f1a\u5f97\u5230\u4e00\u4e2a\u5927\u4e8e0.5\u7684 error\uff0c\u867d\u7136\u8fd9\u4e48\u505a\uff0c\u4f60\u5f97\u5230\u7684 error \u8868\u9762\u4e0a\u770b\u8d77\u6765\u662f\u6bd4\u8f83\u5927\u7684\uff0c\u4f46\u662f \u8fd9\u4e2a\u65f6\u5019\u4f60\u5728 public set \u4e0a\u7684 error \u624d\u80fd\u591f\u771f\u6b63\u53cd\u6620\u4f60\u5728 private set \u4e0a\u7684 error \u5982\u4f55\u5212\u5206 training set \u548c validation set\uff1f validation set \u53ef\u80fd\u81ea\u5e26 bias\uff0c\u5bf9\u7ed3\u679c\u4e0d\u5229 N-flod Cross Validation \u5982\u679c\u4f60\u4e0d\u76f8\u4fe1\u67d0\u4e00\u6b21\u5206 train \u548c validation \u7684\u7ed3\u679c\u7684\u8bdd\uff0c\u90a3\u4f60\u5c31\u5206\u5f88\u591a\u79cd\u4e0d\u540c\u7684\u6837\u5b50 \u6bd4\u5982\u8bf4\uff0c\u5982\u679c\u4f60\u505a 3-flod \u7684 validation\uff0c\u610f\u601d\u5c31\u662f\u4f60\u628a training set \u5206\u6210\u4e09\u4efd\uff0c\u4f60\u6bcf\u4e00\u6b21\u62ff\u5176\u4e2d\u4e00\u4efd\u5f53\u505a validation set\uff0c\u53e6\u5916\u4e24\u4efd\u5f53 training \u5206\u522b\u5728\u6bcf\u4e2a\u60c5\u5883\u4e0b\u90fd\u8ba1\u7b97\u4e00\u4e0b3\u4e2amodel \u7684 error\uff0c\u7136\u540e\u8ba1\u7b97\u4e00\u4e0b\u5b83\u7684 average error\uff0c\u9009\u62e9\u4e00\u4e2a error \u6700\u5c0f\u7684 \u7136\u540e\u628a\u7528\u6574\u4e2a\u5b8c\u6574\u7684 training data \u91cd\u65b0\u8bad\u7ec3\u4e00\u904d\u53c2\u6570\uff0c\u518d\u53bb testing data \u4e0a test","title":"training set \u548c validation set"},{"location":"ML/2_Classification/","text":"Classification \u00b6 \u6982\u8ff0 \u00b6 \u5206\u7c7b\uff0cfunction \u7684\u7ed3\u679c\u662f\u79bb\u6563\u578b\u7684\uff0c\u5fc5\u7136\u5c5e\u4e8e\u7ed3\u679c\u96c6\u4e2d\u7684\u67d0\u4e00\u4e2a\uff0c\u6bd4\u5982\u5b9d\u53ef\u68a6\u7684\u5c5e\u6027\uff08\u5f53\u7136\u5b9d\u53ef\u68a6\u6709\u591a\u5c5e\u6027\uff09 Regression\uff1f \u00b6 Regression \u5e76\u4e0d\u9002\u7528\u4e8e output \u662f\u79bb\u6563\u7684\u51fd\u6570 \u800c\u4e14\u9700\u8981\u6ce8\u610f\u7684\u662f\u5982\u679c\u662f \u591a\u5143\u5206\u7c7b\uff0c\u4e0d\u80fd\u628a class1's target \u8bbe\u4e3a 1\uff0c class2's target \u8bbe\u4e3a 2\uff0cclass3's target \u8bbe\u4e3a 3\uff0c\u56e0\u4e3a\u8fd9\u6837\u505a\u5c31\u9ed8\u8ba4 class1 \u548c class2 \u76f8\u6bd4 \u548c class3 \u66f4\u52a0\u63a5\u8fd1 Ideal Alternatives \u00b6 Function Model\uff1afunction f(x) \u91cc\u9762\u8bbe\u53e6\u5916\u4e00\u4e2afunction g(x) \\[ x\\Rightarrow f(x)= \\begin{cases} g(x)>0&output=class1 \\\\ g(x)<0&output=class2 \\end{cases} \\] \u4e3a\u4ec0\u4e48\u53c8\u80fd\u7528\u6570\u503c\u8868\u793a class \u4e86\uff1f \u56e0\u4e3a\u90a3\u662f\u9488\u5bf9 Regression \u7684 Loss function \u800c\u8a00\u7684\uff0c\u6240\u4ee5\u6211\u4eec\u9700\u8981\u91cd\u65b0\u5b9a\u4e49\u4e00\u4e2a Loss Function $$ Loss=\\sum\\limits_n\\delta(f(x^n)\u2260\\hat{y}^n) $$ \u4e0d\u8fc7\u8fd9\u4e2a Loss Function \u65e0\u6cd5\u5fae\u5206\uff0c\u4e5f\u6709 Perceptron\u3001SVM \u8fd9\u4e9b\u65b9\u6cd5\u53ef\u4ee5\u7528\uff0c\u4f46\u8fd9\u91cc\u5148\u7528\u53e6\u5916\u4e00\u4e2asolution\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898 Generative model \u00b6 \u57fa\u4e8e\u6982\u7387\u8bba\u4e2d\u7684 \u8d1d\u53f6\u65af\u516c\u5f0f \uff1a \\(P(A|B)=\\frac{P(AB)}{P(B)}\\) \u5728\u5df2\u77e5 input x \u7684\u60c5\u51b5\u4e0b\u8ba1\u7b97 \\(P(C_1|x)\\) \u548c \\(P(C_2|x)\\) $$ P(C_1|x)=\\frac{P(C_1)P(x|C_1)}{P(C_1)P(x|C_1 )+P(C_2)P(x|C_2)} $$ \\[ P(C_2|x)=\\frac{P(C_2)P(x|C_2)}{P(C_1)P(x|C_1)+P(C_2)P(x|C_2)} \\] Prior \u00b6 \u6a21\u578b\u9700\u8981\u5f97\u5230\u56db\u4e2a\u503c \\(P(C_1) \\ P(C_2) \\ P(x|C_1) \\ P(x|C_2)\\) \\(P(C_1) \\ P(C_2)\\) \uff1a \u7b97\u51fa training data \u4e2d \u5c5e\u4e8e class1 \u548c class2 \u5404\u81ea\u5360\u603b\u6837\u672c\u91cf\u7684\u6bd4\u4f8b\u5373\u53ef \\(P(x|C_1) \\ P(x|C_2)\\) \uff1a \u591a\u7ef4\u9ad8\u65af\u5206\u5e03\uff1a\u671f\u671b \\(u\\) \u548c \u534f\u65b9\u5dee \\(\\Sigma\\) \u90fd\u662f matrix $$ f_{u,\\Sigma}(x)=\\frac{1}{(2\\pi)^{\\frac{D}{2}}}\\frac{1}{|\\Sigma|^{\\frac{1}{2}}}exp{-\\frac{1}{2}(x-u)^T\\Sigma^{-1}(x-u)} $$ \u5229\u7528\u6781\u5927\u4f3c\u7136\u4f30\u8ba1 \\(u^*,\\Sigma^*=\\arg \\max\\limits_{u,\\Sigma} L(u,\\Sigma)\\) \u53bb\u4f30\u8ba1 \\(u\uff0c\\Sigma\\) \u7684\u53d6\u503c\uff0c\u8fd9\u91cc\u7684\u6781\u5927\u4f3c\u7136\u4f30\u8ba1\u7684\u503c\u5c31\u662f\u8bc4\u4ef7\u4e86\u8fd9\u7ec4\u53c2\u6570\u7684\u597d\u574f\uff0c\u6211\u4eec\u8981\u627e\u5230\u4f7f\u6781\u5927\u4f3c\u7136\u4f30\u8ba1\u503c\u6700\u5927\u7684\u4e00\u7ec4\u53c2\u6570\uff0c\u5176\u5b9e\u5c31\u662f\u6240\u6709\u6837\u672c\u70b9\u7684\u5747\u503c\u548c\u534f\u65b9\u5dee \u6ce8\uff1a\u6570\u5b66\u671f\u671b\uff1a \\(u=E(X)\\) \uff0c\u534f\u65b9\u5dee\uff1a \\(\\Sigma=cov(X,Y)=E[(X-u)(Y-u)^T]\\) \uff0c\u5bf9\u540c\u4e00\u4e2a\u53d8\u91cf\u6765\u8bf4\uff0c\u534f\u65b9\u5dee\u4e3a \\(cov(X,X)=E[(X-u)(X-u)^T]=D(X)\\) \u5f97\u5230 \\(x|C_1 \\ x|C_2\\) \u7684\u9ad8\u65af\u5206\u5e03\u540e\u628a \\(x\\) \u4ee3\u5165\u5373\u53ef\u5f97\u5230 \\(P(x|C_1) \\ P(x|C_2)\\) Do Classification \u00b6 \\[ \\begin{align} if \\ P(C_1|x) > 0.5 \\Rightarrow x \\ belongs \\ class1 \\\\ if \\ P(C_2|x) > 0.5 \\Rightarrow x \\ belongs \\ class2 \\end{align} \\] \u5728\u53ea\u8003\u8651\u5b9d\u53ef\u68a6\u7684 Defense \u548c SP Denfense \u65f6\u8fd9\u6837\u505a\u51fa\u6765\u7684\u6548\u679c\u7684\u51fa\u6765\u7684\u51c6\u786e\u7387\u5e76\u4e0d\u9ad8\uff0c\u5373\u4f7f\u8003\u8651\u4e866\u4e2a features \u51c6\u786e\u7387\u4e5f\u53ea\u6709 64%\uff0c\u8868\u73b0\u6bd4\u8f83\u7cdf\u7cd5 Modifying Model \u00b6 \u4e0a\u9762\u7684 model \u5176\u5b9e\u5e76\u4e0d\u5e38\u89c1\uff0c\u56e0\u4e3a\u4e00\u822c\u4e0d\u4f1a\u6bcf\u4e2a Gaussion \u90fd\u6709\u81ea\u5df1\u7684 mean \u548c covariance\uff0c\u6bd4\u5982\u6211\u4eec\u7684 class1 \u7528\u7684\u662f \\(u_1\\) \u548c \\(\\Sigma_1\\) \uff0cclass2 \u7528\u7684\u662f \\(u_2\\) \u548c \\(\\Sigma_2\\) \uff0c\u6bd4\u8f83\u5e38\u89c1\u7684\u505a\u6cd5\u662f\uff0c \u4e0d\u540c\u7684 class \u53ef\u4ee5share \u540c\u4e00\u4e2a cocovariance matrix \u5176\u5b9e variance \u662f\u8ddf input \u7684 feature size \u7684\u5e73\u65b9\u6210\u6b63\u6bd4\u7684\uff0c\u6240\u4ee5\u5f53 feature \u7684\u6570\u91cf\u5f88\u5927\u7684\u65f6\u5019\uff0c \\(\\Sigma\\) \u5927\u5c0f\u7684\u589e\u957f\u662f\u53ef\u4ee5\u975e\u5e38\u5feb\u7684\uff0c\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u7ed9\u4e0d\u540c\u7684 Gaussian \u4ee5\u4e0d\u540c\u7684 covariance matrix\uff0c\u4f1a\u9020\u6210model \u7684\u53c2\u6570\u592a\u591a\uff0c\u800c\u53c2\u6570\u591a\u4f1a\u5bfc\u81f4\u8be5 model \u7684 variance \u8fc7\u5927\uff0c\u51fa\u73b0 overfitting \u7684\u73b0\u8c61\uff0c\u56e0\u6b64\u5bf9\u4e0d\u540c\u7684 class \u4f7f\u7528\u540c\u4e00\u4e2a covariance matrix\uff0c\u53ef\u4ee5\u6709\u6548\u51cf\u5c11\u53c2\u6570 \u6b64\u65f6\u5c31\u628a \\(u_1\\) \u3001 \\(u_2\\) \u548c\u5171\u540c\u7684 \\(\\Sigma\\) \u4e00\u8d77\u53bb\u5408\u6210\u4e00\u4e2a\u6781\u5927\u4f3c\u7136\u51fd\u6570\uff0c\u6b64\u65f6\u4f1a\u53d1\u73b0\uff0c\u5f97\u5230\u7684 \\(u_1\\) \u548c \\(u_2\\) \u548c\u539f\u6765\u4e00\u6837\uff0c\u8fd8\u662f\u5404\u81ea\u7684\u5747\u503c\uff0c\u800c \\(\\Sigma\\) \u5219\u662f\u539f\u5148\u4e24\u4e2a \\(\\Sigma_1\\) \u548c \\(\\Sigma_2\\) \u7684\u52a0\u6743 \u7ed3\u679c\u53ef\u89c6\u5316\u540e\u4f1a\u53d1\u73b0\u8003\u8651 2 \u4e2a\u53c2\u6570\u65f6\uff0c\u5206\u754c\u7ebf\u7531\u66f2\u7ebf\u53d8\u6210\u4e86\u76f4\u7ebf \u8fd9\u6837\u7684 model \u4e5f\u79f0\u4e4b\u4e3a linear model (\u5c3d\u7ba1 Gaussian \u4e0d\u662f linear \u7684\uff0c\u4f46\u662f\u5b83\u5206\u4e24\u4e2a class \u7684boundary \u662f linear) \u5982\u679c\u518d\u628a\u8003\u8651\u6240\u6709\u7684 feature\uff0c\u90a3\u4e48\u51c6\u786e\u7387\u5c06\u4f1a\u53d8\u6210 74%\uff0c\u4f46\u9ad8\u7ef4\u7a7a\u95f4\u65e0\u6cd5\u53ef\u89c6\u5316 \u5176\u4ed6 \u00b6 Naive Bayes Classifier \u00b6 \u6734\u7d20\u8d1d\u53f6\u65af\u5206\u7c7b\u6cd5 \u4e3a\u4e86\u51cf\u5c11\u53c2\u6570\u5047\u8bbe \\(x=[x_1,x_2,...x_n]\\) \u6bcf\u4e2a\u53c2\u6570\u4e4b\u95f4\u662f\u76f8\u4e92\u72ec\u7acb\u7684\uff0c\u90a3\u6bcf\u4e00\u4e2a\u53c2\u6570\u90fd\u53ef\u4ee5\u5199\u4e00\u4e2a\u4e00\u7ef4\u7684 Gaussion\uff0c \\(\\Sigma\\) \u9664\u4e86\u5bf9\u89d2\u7ebf\u4e4b\u5916\u90fd\u662f 0\uff0c\u8fd9\u6837\u5f97\u51fa\u7684\u7ed3\u679c\u4f1a\u6bd4\u8f83\u7cdf\u7cd5\uff0c\u56e0\u4e3a\u663e\u7136\u6218\u6597\u529b\u548c\u9632\u5fa1\u529b\u662f\u6210\u6b63\u6bd4\u7684\uff0ccovariance \u4e0d\u53ef\u80fd\u4e3a0 \u603b\u4e4b\uff0c\u5bfb\u627e model \u603b\u7684\u539f\u5219\u662f\uff0c\u5c3d\u91cf\u51cf\u5c11\u4e0d\u5fc5\u8981\u7684\u53c2\u6570\uff0c\u4f46\u662f\u5fc5\u7136\u7684\u53c2\u6570\u7edd\u5bf9\u4e0d\u80fd\u5c11 \u90a3\u600e\u4e48\u53bb\u9009\u62e9\u5206\u5e03\u51fd\u6570\u5462\uff1f\u6709\u5f88\u591a\u65f6\u5019\u51ed\u76f4\u89c9\u5c31\u53ef\u4ee5\u770b\u51fa\u6765\uff0c\u6bd4\u5982\u5b9d\u53ef\u68a6\u6709\u67d0\u4e2afeature\u662fbinary\u7684\uff0c\u5b83\u4ee3\u8868\u7684\u662f\uff1a\u662f\u6216\u4e0d\u662f\uff0c\u8fd9\u4e2a\u65f6\u5019\u5c31\u4e0d\u592a\u53ef\u80fd\u662f\u9ad8\u65af\u5206\u5e03\u4e86\uff0c\u800c\u5f88\u6709\u53ef\u80fd\u662f\u4f2f\u52aa\u5229\u5206\u5e03(\u4e24\u70b9\u5206\u5e03) Analysis Posterior Probability \u00b6 \u5206\u6790\u4e00\u4e0b\u540e\u9a8c\u6982\u7387 \\(P(C_1|x)\\) \u8868\u8fbe\u5f0f\u540c\u9664\u4ee5\u5206\u5b50\uff0c\u53ef\u4ee5\u5f97\u5230 \\(\\sigma(z)=\\frac{1}{1+e^{-z}}\\) \uff0c\u8fd9\u4e2afunction\u53eb\u505asigmoid function\uff08S\u51fd\u6570\uff09 \u63a8\u5bfc\u4e00\u4e0b Z \u7684\u771f\u6b63\u7684\u6837\u5b50 \u63a8\u5bfc\u8fc7\u7a0b\u6bd4\u8f83\u590d\u6742\uff0c\u4f46\u662f\u7ed3\u679c\u5f88\u7b80\u5355\uff1a $$ z=(\\mu^1-\\mu^2)^T\\Sigma^{-1}x-\\frac{1}{2}(\\mu^1)^T\\Sigma^{-1}\\mu^1+\\frac{1}{2}(\\mu^2)^T\\Sigma^{-1}\\mu^2+ln\\frac{N_1}{N_2} $$ \u53ef\u4ee5\u770b\u6210\uff1a \\(z=w^Tx+b\\) \u5f53 \\(\\Sigma_1 \\ \\Sigma_2\\) \u5171\u7528\u4e00\u4e2a \\(\\Sigma\\) \u5e76\u7ecf\u8fc7\u5316\u7b80\u76f8\u6d88\u540e\uff0c \\(x\\) \u7684\u7cfb\u6570 \\(w\\) \u662f\u4e00\u4e2a vector\uff0c\u540e\u9762\u7684\u662f\u4e00\u4e2a\u5e38\u6570\u9879 b \\(P(C_1|x)=\\sigma (w\\cdot x+b)\\) \u8fd9\u4e2a\u5f0f\u5b50\u5c31\u89e3\u91ca\u4e86\uff0c\u5f53 class1 \u548c class2 \u5171\u7528 \\(\\Sigma\\) \u7684\u65f6\u5019\uff0c\u5b83\u4eec\u4e4b\u95f4\u7684 boundary \u4f1a\u662f linear \u7684 \u90a3\u4e48\u80fd\u4e0d\u80fd\u76f4\u63a5\u6c42\u51fa \\(w\uff0cb\\) \u5462\uff1f","title":"Classification"},{"location":"ML/2_Classification/#classification","text":"","title":"Classification"},{"location":"ML/2_Classification/#_1","text":"\u5206\u7c7b\uff0cfunction \u7684\u7ed3\u679c\u662f\u79bb\u6563\u578b\u7684\uff0c\u5fc5\u7136\u5c5e\u4e8e\u7ed3\u679c\u96c6\u4e2d\u7684\u67d0\u4e00\u4e2a\uff0c\u6bd4\u5982\u5b9d\u53ef\u68a6\u7684\u5c5e\u6027\uff08\u5f53\u7136\u5b9d\u53ef\u68a6\u6709\u591a\u5c5e\u6027\uff09","title":"\u6982\u8ff0"},{"location":"ML/2_Classification/#regression","text":"Regression \u5e76\u4e0d\u9002\u7528\u4e8e output \u662f\u79bb\u6563\u7684\u51fd\u6570 \u800c\u4e14\u9700\u8981\u6ce8\u610f\u7684\u662f\u5982\u679c\u662f \u591a\u5143\u5206\u7c7b\uff0c\u4e0d\u80fd\u628a class1's target \u8bbe\u4e3a 1\uff0c class2's target \u8bbe\u4e3a 2\uff0cclass3's target \u8bbe\u4e3a 3\uff0c\u56e0\u4e3a\u8fd9\u6837\u505a\u5c31\u9ed8\u8ba4 class1 \u548c class2 \u76f8\u6bd4 \u548c class3 \u66f4\u52a0\u63a5\u8fd1","title":"Regression\uff1f"},{"location":"ML/2_Classification/#ideal-alternatives","text":"Function Model\uff1afunction f(x) \u91cc\u9762\u8bbe\u53e6\u5916\u4e00\u4e2afunction g(x) \\[ x\\Rightarrow f(x)= \\begin{cases} g(x)>0&output=class1 \\\\ g(x)<0&output=class2 \\end{cases} \\] \u4e3a\u4ec0\u4e48\u53c8\u80fd\u7528\u6570\u503c\u8868\u793a class \u4e86\uff1f \u56e0\u4e3a\u90a3\u662f\u9488\u5bf9 Regression \u7684 Loss function \u800c\u8a00\u7684\uff0c\u6240\u4ee5\u6211\u4eec\u9700\u8981\u91cd\u65b0\u5b9a\u4e49\u4e00\u4e2a Loss Function $$ Loss=\\sum\\limits_n\\delta(f(x^n)\u2260\\hat{y}^n) $$ \u4e0d\u8fc7\u8fd9\u4e2a Loss Function \u65e0\u6cd5\u5fae\u5206\uff0c\u4e5f\u6709 Perceptron\u3001SVM \u8fd9\u4e9b\u65b9\u6cd5\u53ef\u4ee5\u7528\uff0c\u4f46\u8fd9\u91cc\u5148\u7528\u53e6\u5916\u4e00\u4e2asolution\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898","title":"Ideal Alternatives"},{"location":"ML/2_Classification/#generative-model","text":"\u57fa\u4e8e\u6982\u7387\u8bba\u4e2d\u7684 \u8d1d\u53f6\u65af\u516c\u5f0f \uff1a \\(P(A|B)=\\frac{P(AB)}{P(B)}\\) \u5728\u5df2\u77e5 input x \u7684\u60c5\u51b5\u4e0b\u8ba1\u7b97 \\(P(C_1|x)\\) \u548c \\(P(C_2|x)\\) $$ P(C_1|x)=\\frac{P(C_1)P(x|C_1)}{P(C_1)P(x|C_1 )+P(C_2)P(x|C_2)} $$ \\[ P(C_2|x)=\\frac{P(C_2)P(x|C_2)}{P(C_1)P(x|C_1)+P(C_2)P(x|C_2)} \\]","title":"Generative model"},{"location":"ML/2_Classification/#prior","text":"\u6a21\u578b\u9700\u8981\u5f97\u5230\u56db\u4e2a\u503c \\(P(C_1) \\ P(C_2) \\ P(x|C_1) \\ P(x|C_2)\\) \\(P(C_1) \\ P(C_2)\\) \uff1a \u7b97\u51fa training data \u4e2d \u5c5e\u4e8e class1 \u548c class2 \u5404\u81ea\u5360\u603b\u6837\u672c\u91cf\u7684\u6bd4\u4f8b\u5373\u53ef \\(P(x|C_1) \\ P(x|C_2)\\) \uff1a \u591a\u7ef4\u9ad8\u65af\u5206\u5e03\uff1a\u671f\u671b \\(u\\) \u548c \u534f\u65b9\u5dee \\(\\Sigma\\) \u90fd\u662f matrix $$ f_{u,\\Sigma}(x)=\\frac{1}{(2\\pi)^{\\frac{D}{2}}}\\frac{1}{|\\Sigma|^{\\frac{1}{2}}}exp{-\\frac{1}{2}(x-u)^T\\Sigma^{-1}(x-u)} $$ \u5229\u7528\u6781\u5927\u4f3c\u7136\u4f30\u8ba1 \\(u^*,\\Sigma^*=\\arg \\max\\limits_{u,\\Sigma} L(u,\\Sigma)\\) \u53bb\u4f30\u8ba1 \\(u\uff0c\\Sigma\\) \u7684\u53d6\u503c\uff0c\u8fd9\u91cc\u7684\u6781\u5927\u4f3c\u7136\u4f30\u8ba1\u7684\u503c\u5c31\u662f\u8bc4\u4ef7\u4e86\u8fd9\u7ec4\u53c2\u6570\u7684\u597d\u574f\uff0c\u6211\u4eec\u8981\u627e\u5230\u4f7f\u6781\u5927\u4f3c\u7136\u4f30\u8ba1\u503c\u6700\u5927\u7684\u4e00\u7ec4\u53c2\u6570\uff0c\u5176\u5b9e\u5c31\u662f\u6240\u6709\u6837\u672c\u70b9\u7684\u5747\u503c\u548c\u534f\u65b9\u5dee \u6ce8\uff1a\u6570\u5b66\u671f\u671b\uff1a \\(u=E(X)\\) \uff0c\u534f\u65b9\u5dee\uff1a \\(\\Sigma=cov(X,Y)=E[(X-u)(Y-u)^T]\\) \uff0c\u5bf9\u540c\u4e00\u4e2a\u53d8\u91cf\u6765\u8bf4\uff0c\u534f\u65b9\u5dee\u4e3a \\(cov(X,X)=E[(X-u)(X-u)^T]=D(X)\\) \u5f97\u5230 \\(x|C_1 \\ x|C_2\\) \u7684\u9ad8\u65af\u5206\u5e03\u540e\u628a \\(x\\) \u4ee3\u5165\u5373\u53ef\u5f97\u5230 \\(P(x|C_1) \\ P(x|C_2)\\)","title":"Prior"},{"location":"ML/2_Classification/#do-classification","text":"\\[ \\begin{align} if \\ P(C_1|x) > 0.5 \\Rightarrow x \\ belongs \\ class1 \\\\ if \\ P(C_2|x) > 0.5 \\Rightarrow x \\ belongs \\ class2 \\end{align} \\] \u5728\u53ea\u8003\u8651\u5b9d\u53ef\u68a6\u7684 Defense \u548c SP Denfense \u65f6\u8fd9\u6837\u505a\u51fa\u6765\u7684\u6548\u679c\u7684\u51fa\u6765\u7684\u51c6\u786e\u7387\u5e76\u4e0d\u9ad8\uff0c\u5373\u4f7f\u8003\u8651\u4e866\u4e2a features \u51c6\u786e\u7387\u4e5f\u53ea\u6709 64%\uff0c\u8868\u73b0\u6bd4\u8f83\u7cdf\u7cd5","title":"Do Classification"},{"location":"ML/2_Classification/#modifying-model","text":"\u4e0a\u9762\u7684 model \u5176\u5b9e\u5e76\u4e0d\u5e38\u89c1\uff0c\u56e0\u4e3a\u4e00\u822c\u4e0d\u4f1a\u6bcf\u4e2a Gaussion \u90fd\u6709\u81ea\u5df1\u7684 mean \u548c covariance\uff0c\u6bd4\u5982\u6211\u4eec\u7684 class1 \u7528\u7684\u662f \\(u_1\\) \u548c \\(\\Sigma_1\\) \uff0cclass2 \u7528\u7684\u662f \\(u_2\\) \u548c \\(\\Sigma_2\\) \uff0c\u6bd4\u8f83\u5e38\u89c1\u7684\u505a\u6cd5\u662f\uff0c \u4e0d\u540c\u7684 class \u53ef\u4ee5share \u540c\u4e00\u4e2a cocovariance matrix \u5176\u5b9e variance \u662f\u8ddf input \u7684 feature size \u7684\u5e73\u65b9\u6210\u6b63\u6bd4\u7684\uff0c\u6240\u4ee5\u5f53 feature \u7684\u6570\u91cf\u5f88\u5927\u7684\u65f6\u5019\uff0c \\(\\Sigma\\) \u5927\u5c0f\u7684\u589e\u957f\u662f\u53ef\u4ee5\u975e\u5e38\u5feb\u7684\uff0c\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u7ed9\u4e0d\u540c\u7684 Gaussian \u4ee5\u4e0d\u540c\u7684 covariance matrix\uff0c\u4f1a\u9020\u6210model \u7684\u53c2\u6570\u592a\u591a\uff0c\u800c\u53c2\u6570\u591a\u4f1a\u5bfc\u81f4\u8be5 model \u7684 variance \u8fc7\u5927\uff0c\u51fa\u73b0 overfitting \u7684\u73b0\u8c61\uff0c\u56e0\u6b64\u5bf9\u4e0d\u540c\u7684 class \u4f7f\u7528\u540c\u4e00\u4e2a covariance matrix\uff0c\u53ef\u4ee5\u6709\u6548\u51cf\u5c11\u53c2\u6570 \u6b64\u65f6\u5c31\u628a \\(u_1\\) \u3001 \\(u_2\\) \u548c\u5171\u540c\u7684 \\(\\Sigma\\) \u4e00\u8d77\u53bb\u5408\u6210\u4e00\u4e2a\u6781\u5927\u4f3c\u7136\u51fd\u6570\uff0c\u6b64\u65f6\u4f1a\u53d1\u73b0\uff0c\u5f97\u5230\u7684 \\(u_1\\) \u548c \\(u_2\\) \u548c\u539f\u6765\u4e00\u6837\uff0c\u8fd8\u662f\u5404\u81ea\u7684\u5747\u503c\uff0c\u800c \\(\\Sigma\\) \u5219\u662f\u539f\u5148\u4e24\u4e2a \\(\\Sigma_1\\) \u548c \\(\\Sigma_2\\) \u7684\u52a0\u6743 \u7ed3\u679c\u53ef\u89c6\u5316\u540e\u4f1a\u53d1\u73b0\u8003\u8651 2 \u4e2a\u53c2\u6570\u65f6\uff0c\u5206\u754c\u7ebf\u7531\u66f2\u7ebf\u53d8\u6210\u4e86\u76f4\u7ebf \u8fd9\u6837\u7684 model \u4e5f\u79f0\u4e4b\u4e3a linear model (\u5c3d\u7ba1 Gaussian \u4e0d\u662f linear \u7684\uff0c\u4f46\u662f\u5b83\u5206\u4e24\u4e2a class \u7684boundary \u662f linear) \u5982\u679c\u518d\u628a\u8003\u8651\u6240\u6709\u7684 feature\uff0c\u90a3\u4e48\u51c6\u786e\u7387\u5c06\u4f1a\u53d8\u6210 74%\uff0c\u4f46\u9ad8\u7ef4\u7a7a\u95f4\u65e0\u6cd5\u53ef\u89c6\u5316","title":"Modifying Model"},{"location":"ML/2_Classification/#_2","text":"","title":"\u5176\u4ed6"},{"location":"ML/2_Classification/#naive-bayes-classifier","text":"\u6734\u7d20\u8d1d\u53f6\u65af\u5206\u7c7b\u6cd5 \u4e3a\u4e86\u51cf\u5c11\u53c2\u6570\u5047\u8bbe \\(x=[x_1,x_2,...x_n]\\) \u6bcf\u4e2a\u53c2\u6570\u4e4b\u95f4\u662f\u76f8\u4e92\u72ec\u7acb\u7684\uff0c\u90a3\u6bcf\u4e00\u4e2a\u53c2\u6570\u90fd\u53ef\u4ee5\u5199\u4e00\u4e2a\u4e00\u7ef4\u7684 Gaussion\uff0c \\(\\Sigma\\) \u9664\u4e86\u5bf9\u89d2\u7ebf\u4e4b\u5916\u90fd\u662f 0\uff0c\u8fd9\u6837\u5f97\u51fa\u7684\u7ed3\u679c\u4f1a\u6bd4\u8f83\u7cdf\u7cd5\uff0c\u56e0\u4e3a\u663e\u7136\u6218\u6597\u529b\u548c\u9632\u5fa1\u529b\u662f\u6210\u6b63\u6bd4\u7684\uff0ccovariance \u4e0d\u53ef\u80fd\u4e3a0 \u603b\u4e4b\uff0c\u5bfb\u627e model \u603b\u7684\u539f\u5219\u662f\uff0c\u5c3d\u91cf\u51cf\u5c11\u4e0d\u5fc5\u8981\u7684\u53c2\u6570\uff0c\u4f46\u662f\u5fc5\u7136\u7684\u53c2\u6570\u7edd\u5bf9\u4e0d\u80fd\u5c11 \u90a3\u600e\u4e48\u53bb\u9009\u62e9\u5206\u5e03\u51fd\u6570\u5462\uff1f\u6709\u5f88\u591a\u65f6\u5019\u51ed\u76f4\u89c9\u5c31\u53ef\u4ee5\u770b\u51fa\u6765\uff0c\u6bd4\u5982\u5b9d\u53ef\u68a6\u6709\u67d0\u4e2afeature\u662fbinary\u7684\uff0c\u5b83\u4ee3\u8868\u7684\u662f\uff1a\u662f\u6216\u4e0d\u662f\uff0c\u8fd9\u4e2a\u65f6\u5019\u5c31\u4e0d\u592a\u53ef\u80fd\u662f\u9ad8\u65af\u5206\u5e03\u4e86\uff0c\u800c\u5f88\u6709\u53ef\u80fd\u662f\u4f2f\u52aa\u5229\u5206\u5e03(\u4e24\u70b9\u5206\u5e03)","title":"Naive Bayes Classifier"},{"location":"ML/2_Classification/#analysis-posterior-probability","text":"\u5206\u6790\u4e00\u4e0b\u540e\u9a8c\u6982\u7387 \\(P(C_1|x)\\) \u8868\u8fbe\u5f0f\u540c\u9664\u4ee5\u5206\u5b50\uff0c\u53ef\u4ee5\u5f97\u5230 \\(\\sigma(z)=\\frac{1}{1+e^{-z}}\\) \uff0c\u8fd9\u4e2afunction\u53eb\u505asigmoid function\uff08S\u51fd\u6570\uff09 \u63a8\u5bfc\u4e00\u4e0b Z \u7684\u771f\u6b63\u7684\u6837\u5b50 \u63a8\u5bfc\u8fc7\u7a0b\u6bd4\u8f83\u590d\u6742\uff0c\u4f46\u662f\u7ed3\u679c\u5f88\u7b80\u5355\uff1a $$ z=(\\mu^1-\\mu^2)^T\\Sigma^{-1}x-\\frac{1}{2}(\\mu^1)^T\\Sigma^{-1}\\mu^1+\\frac{1}{2}(\\mu^2)^T\\Sigma^{-1}\\mu^2+ln\\frac{N_1}{N_2} $$ \u53ef\u4ee5\u770b\u6210\uff1a \\(z=w^Tx+b\\) \u5f53 \\(\\Sigma_1 \\ \\Sigma_2\\) \u5171\u7528\u4e00\u4e2a \\(\\Sigma\\) \u5e76\u7ecf\u8fc7\u5316\u7b80\u76f8\u6d88\u540e\uff0c \\(x\\) \u7684\u7cfb\u6570 \\(w\\) \u662f\u4e00\u4e2a vector\uff0c\u540e\u9762\u7684\u662f\u4e00\u4e2a\u5e38\u6570\u9879 b \\(P(C_1|x)=\\sigma (w\\cdot x+b)\\) \u8fd9\u4e2a\u5f0f\u5b50\u5c31\u89e3\u91ca\u4e86\uff0c\u5f53 class1 \u548c class2 \u5171\u7528 \\(\\Sigma\\) \u7684\u65f6\u5019\uff0c\u5b83\u4eec\u4e4b\u95f4\u7684 boundary \u4f1a\u662f linear \u7684 \u90a3\u4e48\u80fd\u4e0d\u80fd\u76f4\u63a5\u6c42\u51fa \\(w\uff0cb\\) \u5462\uff1f","title":"Analysis Posterior Probability"},{"location":"ML/3_Logistic%20Regression/","text":"Logistic Regression \u00b6 Review \u00b6 \u5728 Classification \u4e2d\u5f97\u51fa\u7684\u7ed3\u679c\uff1a $$ \\begin{align} P_{w,b}(C_1|x)&=\\sigma(z)=\\frac{1}{1+e^{-z}} \\ z&=w\\cdot x+b=\\sum\\limits_i w_ix_i+b \\end{align} $$ \u5176\u4e2d \\(w\\) \u548c \\(x\\) \u90fd\u662f\u5411\u91cf\uff0c\u8fd9\u4e2a model \u662f\u53d7 \\(w\\) \u548c \\(b\\) \u63a7\u5236\u7684\uff0c\u56e0\u6b64\u6211\u4eec\u4e0d\u5fc5\u8981\u518d\u53bb\u50cf\u524d\u9762\u4e00\u6837\u8ba1\u7b97\u4e00\u5927\u5806\u4e1c\u897f\uff0c\u800c\u662f\u7528\u8fd9\u4e2a\u5168\u65b0\u7684\u7531 \\(w\\) \u548c \\(b\\) \u51b3\u5b9a\u7684 model \u2014\u2014 Logistic Regression(\u903b\u8f91\u56de\u5f52) Three Steps of machine learning \u00b6 Step 1\uff1afunction set \u00b6 \u8fd9\u91cc\u7684 function set \u5c31\u662f Logistic Regression\u2014\u2014\u903b\u8f91\u56de\u5f52 \\(x_i\\) \uff1ainput\uff0c \\(w_i\\) \uff1aweight\uff0c \\(b\\) \uff1abias\uff0c \\(\\sigma(z)\\) \uff1asigmoid function Step 2\uff1aGoodness of a function \u00b6 \u8bbe\u8ba1\u4e00\u4e2a Loss Function \u77e5\u9053\u4e86\u67d0\u4e00\u7ec4 \\(w\\) \u548c \\(b\\) \u5c31\u53ef\u4ee5\u8ba1\u7b97\u51fa Posterior Probability\uff08\u540e\u9a8c\u6982\u7387\uff09\uff0c\u7136\u540e\u5229\u7528\u540e\u9a8c\u6982\u7387\u53ef\u4ee5\u8ba1\u7b97\u51fa\u6781\u5927\u4f3c\u7136\u4f30\u8ba1\uff0c\u90a3\u4e48\u80fd\u591f\u4f7f\u6781\u5927\u4f3c\u7136\u4f30\u8ba1\u503c\u6700\u5927\u7684\u90a3\u7ec4 \\(w^*\\) \u548c \\(b^*\\) \u5c31\u662f\u6700\u6709\u53ef\u80fd\u4ea7\u751f\u5f53\u524d Training Data \u7684\u4e00\u7ec4\u53c2\u6570 \u8fd9\u91cc\u5047\u5b9a\u4e8c\u5143\u5206\u7c7b\uff0cclass1 \u7684\u6982\u7387\u662f 1-class2 \u7684\u6982\u7387 \u5c06\u4e0a\u5f0f\u53d8\u5f62\uff1a \\[ w^*,b^*=\\arg \\max\\limits_{w,b} L(w,b)=\\arg\\min\\limits_{w,b}(-\\ln L(w,b)) \\] \\[ \\begin{align} -\\ln L(w,b)=&-\\ln f_{w,b}(x^1)\\\\ &-\\ln f_{w,b}(x^2)\\\\ &-\\ln(1-f_{w,b}(x^3))\\\\ &\\ -... \\end{align} $$ \u4e3a\u4e86\u7edf\u4e00\u683c\u5f0f\uff0c\u628a output $\\hat{y}=1$ \u4ee3\u8868 class1\uff0coutput $\\hat{y}=0$ \u4ee3\u8868 class2 $$ \\begin{align} -\\ln L(w,b)=&-[\\hat{y}^1 \\ln f_{w,b}(x^1)+(1-\\hat{y}^1)ln(1-f_{w,b}(x^1))]\\\\ &-[\\hat{y}^2 \\ln f_{w,b}(x^2)+(1-\\hat{y}^2)ln(1-f_{w,b}(x^2))]\\\\ &-[\\hat{y}^3 \\ln f_{w,b}(x^3)+(1-\\hat{y}^3)ln(1-f_{w,b}(x^3))]\\\\ &\\ -... \\end{align} $$ $$ -\\ln L(w,b)=\\sum\\limits_n -[\\hat{y}^n \\ln f_{w,b}(x^n)+(1-\\hat{y}^n) \\ln(1-f_{w,b}(x^n))] \\] \u8fd9\u4e2a\u5f62\u5f0f\u5176\u5b9e\u5c31\u662f \u4e24\u4e2a Bernoulli distribution (\u4e24\u70b9\u5206\u5e03)\u7684 cross entropy (\u4ea4\u53c9\u71b5) \uff0c\u628a\u8fd9\u4e2a\u4f5c\u4e3a Loss Function \u4e8e\u662f\u6211\u4eec\u628a \u6781\u5927\u4f3c\u7136\u4f30\u8ba1 \u7684\u5f0f\u5b50\u53d8\u6210\u4e86 \u4ea4\u53c9\u71b5 \u4f5c\u4e3a Loss Function \u4ee5\u65b9\u4fbf\u5fae\u5206 Cross Entropy \u00b6 \u7b14\u8bb0 | \u4ec0\u4e48\u662fCross Entropy - \u77e5\u4e4e Cross Entropy: \u4e00\u822c\u7528\u6765\u91cf\u5316\u4e24\u4e2a\u6982\u7387\u5206\u5e03\u4e4b\u95f4\u5dee\u5f02\u7684\u635f\u5931\u51fd\u6570 \u5047\u8bbe\u5bf9\u4e8e \u4e00\u4e2a \u6570\u636e\u7684\u771f\u5b9e\u5206\u5e03\u4e3a p\uff0c\u9884\u6d4b\u5206\u5e03\u4e3a q \u90a3\u4e48 \\(H(p,q)=-\\sum_{x}{p(x)\\ log\\ q(x)}\\) \u5176\u4e2d x \u662f\u7c7b\u522b\u6570 Cross Entropy \u4ea4\u53c9\u71b5\u7684\u542b\u4e49\u662f\u8868\u8fbe\u4e24\u4e2a distribution \u6709\u591a\u63a5\u8fd1\uff0c\u5982\u679c p \u548c q \u8fd9\u4e24\u4e2a distribution \u4e00\u6a21\u4e00\u6837\u7684\u8bdd\uff0c\u90a3\u5b83\u4eec\u7b97\u51fa\u6765\u7684 Cross Entropy \u5c31\u662f 0 (\u8be6\u7ec6\u89e3\u91ca\u5728\u201c\u4fe1\u606f\u8bba\u201d\u4e2d)\uff0c\u800c\u8fd9\u91cc \\(f(x^n)\\) \u8868\u793a function \u7684 output\uff0c \\(\\hat{y}^n\\) \u8868\u793a\u9884\u671f\u7684 target\uff0c\u56e0\u6b64 \u4ea4\u53c9\u71b5\u5b9e\u9645\u4e0a\u8868\u8fbe\u7684\u662f\u5e0c\u671b\u8fd9\u4e2a function \u7684 output\u548c\u5b83\u7684 target \u8d8a\u63a5\u8fd1\u8d8a\u597d step 3\uff1aFind the best function \u00b6 \u5373\u627e\u5230\u4f7f Loss Function \u5373 Cross Entropy \u6700\u5c0f\u7684\u4e00\u7ec4 \\(w^*,b^*\\) \uff0c\u8fd9\u91cc\u8fd0\u7528 Gradient Descent $$ \\begin{align} P_{w,b}(C_1|x)=\\sigma(z)=\\frac{1}{1+e^{-z}} \\ z=w\\cdot x+b=\\sum\\limits_i w_ix_i+b \\end{align} $$ \\[ \\begin{align} f_{w,b}(x)=P_{w,b}(C_1|x) \\end{align} \\] \\[ -\\ln L(w,b)=\\sum\\limits_n -[\\hat{y}^n \\ln f_{w,b}(x^n)+(1-\\hat{y}^n) \\ln(1-f_{w,b}(x^n))] \\] Sigmoid Function \u7684\u5fae\u5206\u516c\u5f0f\uff1a $$ \\frac{\\partial \\sigma(z)}{\\partial z}=\\sigma(z)(1-\\sigma(z)) $$ \u8ba1\u7b97 \\(-\\ln L(w,b)=\\sum\\limits_n -[\\hat{y}^n \\ln f_{w,b}(x^n)+(1-\\hat{y}^n) \\ln(1-f_{w,b}(x^n))]\\) \u5bf9 \\(w_i\\) \u7684\u504f\u5fae\u5206\uff0c\u5176\u4e2d \\(\\hat{y}^n\\) \u548c \\(1-\\hat{y}^n\\) \u662f\u5e38\u6570\uff0c\u53ea\u9700\u8981\u5206\u522b\u6c42\u51fa \\(\\ln f_{w,b}(x^n)\\) \u548c \\(\\ln (1-f_{w,b}(x^n))\\) \u5bf9 \\(w_i\\) \u7684\u504f\u5fae\u5206\u5373\u53ef\uff0c\u6574\u4f53\u63a8\u5bfc\u8fc7\u7a0b\u5982\u4e0b\uff1a \u7ed3\u679c\u5e26\u5165\u5f97\uff1a \u6240\u4ee5\uff1a $$ w_{i+1}=w_i-\\eta \\sum\\limits_{n}-(\\hat{y}^n-f_{w,b}(x^n))x_i^n $$ \\(-\\eta\\) \uff1alearning rate \\(x_i\\) \uff1adata \\(\\hat{y}^n-f_{w,b}(x^n)\\) \uff1a\u4e0e\u7406\u60f3 function set \u7684\u5dee\u8ddd\uff0c\u5dee\u8ddd\u8d8a\u5927 update \u7684\u6b65\u4f10\u8d8a\u5927 \u540c\u7406\u53ef\u5f97\uff1a $$ b_{i+1}=w_i-\\eta \\sum\\limits_{n}-(\\hat{y}^n-f_{w,b}(x^n)) $$ \u6211\u4eec\u4f1a\u53d1\u73b0 Logistic Regression \u7684\u7ed3\u679c\u662f\u548c Linear Regresison \u7684\u5f0f\u5b50\u662f\u4e00\u6837\u7684 Comparison \u00b6 Logistic Regression && Linear Regression \u00b6 \u4e24\u8005\u90fd\u662f\u901a\u8fc7\u5bf9\u6bcf\u4e00\u4e2a feature \\(x_i\\) \u52a0\u6743\u6c42\u548c\u540e\u52a0\u4e0a\u4e00\u4e2a\u5e38\u6570\uff0c\u533a\u522b\u5728\u4e8e Logistic Regression \u6700\u540e\u53c8\u901a\u8fc7\u4e86\u4e00\u4e2a Sigmoid Function\uff0c\u5b83\u7684\u7ed3\u679c\u662f 0~1\uff0c\u800c Linear Regression \u4e0d\u7ecf\u8fc7 Sigmoid Function\uff0c\u7ed3\u679c\u53ef\u4ee5\u662f\u4efb\u610f\u503c Logistic Regression \u7684 Loss Function \u7528\u7684\u4ea4\u53c9\u71b5\u5b9a\u4e49\uff0c\u800c Linear Regression \u7528\u7684 Square Error Logistic Regression + Square Error \uff1f \u00b6 \u5047\u8bbe\u4f7f\u7528 Logistic Regression + Square Error\uff0c \u5982\u679c\u6b64\u65f6 \\(\\hat{y}^n=1\\) \uff0c\u800c\u4e14 function \u7684 output \\(f_{w,b}(x^n)=1\\) \u7684\u8bdd\uff0c\u8bf4\u660e\u73b0\u5728\u79bb target \u5f88\u63a5\u8fd1\u4e86\uff0c \\(f_{w,b}(x)-\\hat{y}=0\\) \uff0c\u4e8e\u662f\u5f97\u5230\u7684\u5fae\u5206 \\(\\frac{\\partial L}{\\partial w_i}\\) \u7b49\u4e8e 0\uff0c\u8fd9\u4ef6\u4e8b\u60c5\u662f\u5f88\u5408\u7406\u7684\uff1b\u4f46\u662f\u5f53 function \u7684 output \\(f_{w,b}(x^n)=0\\) \u7684\u65f6\u5019\uff0c\u8bf4\u660e\u79bb target \u8fd8\u5f88\u9065\u8fdc\uff0c\u4f46\u662f\u7531\u4e8e\u5728step3 \u4e2d\u6c42\u51fa\u6765\u7684 update \u8868\u8fbe\u5f0f\u4e2d\u6709\u4e00\u4e2a \\(f_{w,b}(x^n)\\) \uff0c\u56e0\u6b64\u8fd9\u4e2a\u65f6\u5019\u4e5f\u4f1a\u5bfc\u81f4\u5f97\u5230\u7684\u5fae\u5206 \\(\\frac{\\partial L}{\\partial w_i}\\) \u4e5f\u7b49\u4e8e 0 \u5c06 Loss Function \u9009\u62e9 Cross Entropy \u6216 Square Error \u7684\u53d8\u5316\u60c5\u51b5\u53ef\u89c6\u5316\u4e4b\u540e\u5982\u4e0b\u6240\u793a\uff08\u9ed1\u8272\uff1aCross Entropy \u7ea2\u8272\uff1aSquare Error\uff09 \u53ef\u89c1 Square Error \u4f1a\u5f88\u6162\uff0c\u751a\u81f3\u53ef\u80fd\u4e0d\u4f1a\u52a8 Discriminative && Generative \u00b6 \u628a Logistic Regression \u7684\u65b9\u6cd5\u79f0\u4e4b\u4e3a Discriminative \u7684\u65b9\u6cd5\uff0c\u7528 Gaussian \u6765\u63cf\u8ff0 Posterior Probability \u7684\u65b9\u6cd5\u79f0\u4e4b\u4e3a Generative \u7684\u65b9\u6cd5 \u4ed6\u4eec\u7684 Function Set \u90fd\u662f\u4e00\u6837\u7684\uff0c\u90fd\u662f \\(P(C_1|x)=\\sigma(w\\cdot x+b)\\) Logistic Regression \u662f\u901a\u8fc7 Gradient Descent \u7684\u65b9\u6cd5\u76f4\u63a5\u627e\u51fa \\(b\\) \u548c \\(w\\) \uff0c\u800c Generative Model \u7684\u65b9\u6cd5\u662f\u5148\u7b97 \\(u_1,u_2,\\Sigma^{-1}\\) \uff0c\u518d\u6c42 \\(b\\) \u548c \\(w\\) \u4f46\u8fd9\u4e24\u8005\u65b9\u6cd5\u7684\u51fa\u6765\u7684 \\(b\\) \u548c \\(w\\) \u662f\u4e0d\u4e00\u6837\u7684 \u539f\u56e0\u662f\u5728 Logistic Regression \u4e2d \u6ca1\u6709\u505a\u4efb\u4f55\u5b9e\u8d28\u6027\u7684\u5047\u8bbe \uff0c\u5355\u7eaf\u7684\u53bb\u627e \\(w\\) \u548c \\(b\\) \uff0c\u800c\u5728 Generative Model \u4e2d\u5047\u8bbe\u4e86 Gaussion Distribution Discriminative \u7684\u65b9\u6cd5\u5e38\u5e38\u4f1a\u6bd4 Generative \u7684\u65b9\u6cd5\u8868\u73b0\u5f97\u66f4\u597d discriminative model \u5e76\u4e0d\u662f\u5728\u6240\u6709\u7684\u60c5\u51b5\u4e0b\u90fd\u53ef\u4ee5\u8d62\u8fc7 Generative model\uff0cdiscriminative model \u662f\u5341\u5206\u4f9d\u8d56\u4e8e data \u7684\uff0c\u5f53 data \u6570\u91cf\u4e0d\u8db3\u6216\u662f data \u672c\u8eab\u7684 label\u5c31\u6709\u4e00\u4e9b\u95ee\u9898\uff0c\u90a3Generative model\u505a\u4e00\u4e9b\u5047\u8bbe\uff0c\u53cd\u800c\u53ef\u4ee5\u628a data \u7684\u4e0d\u8db3\u6216\u662f\u6709\u95ee\u9898\u90e8\u5206\u7684\u5f71\u54cd\u7ed9\u964d\u5230\u6700\u4f4e \u5728 Generative model \u4e2d\uff0cpriors probabilities \u548c class-dependent probabilities \u662f\u53ef\u4ee5\u62c6\u5f00\u6765\u8003\u8651\u7684\uff0c\u4ee5\u8bed\u97f3\u8fa8\u8bc6\u4e3a\u4f8b\uff0c\u73b0\u5728\u7528\u7684\u90fd\u662f neural network\uff0c\u662f\u4e00\u4e2adiscriminative \u7684\u65b9\u6cd5\uff0c\u4f46\u4e8b\u5b9e\u4e0a\u6574\u4e2a\u8bed\u97f3\u8fa8\u8bc6\u7684\u7cfb\u7edf\u662f\u4e00\u4e2a Generative \u7684 system\uff0c\u5b83\u7684 prior probability \u662f\u67d0\u4e00\u53e5\u8bdd\u88ab\u8bf4\u51fa\u6765\u7684\u51e0\u7387\uff0c\u800c\u60f3\u8981 estimate \u67d0\u4e00\u53e5\u8bdd\u88ab\u8bf4\u51fa\u6765\u7684\u51e0\u7387\u5e76\u4e0d\u9700\u8981\u6709\u58f0\u97f3\u7684 data\uff0c\u53ef\u4ee5\u53bb\u4e92\u8054\u7f51\u4e0a\u722c\u53d6\u5927\u91cf\u6587\u5b57\uff0c\u5c31\u53ef\u4ee5\u8ba1\u7b97\u51fa\u67d0\u4e00\u6bb5\u6587\u5b57\u51fa\u73b0\u7684\u51e0\u7387\uff0c\u5e76\u4e0d\u9700\u8981\u58f0\u97f3\u7684 data\uff0c\u8fd9\u4e2a\u5c31\u662f language model\uff0c\u800c class-dependent \u7684\u90e8\u5206\u624d\u9700\u8981\u58f0\u97f3\u548c\u6587\u5b57\u7684\u914d\u5408\uff0c\u8fd9\u6837\u7684\u5904\u7406\u53ef\u4ee5\u628a prior \u9884\u6d4b\u5730\u66f4\u7cbe\u786e Conclusion \u00b6 \u5bf9\u4e8e\u5206\u7c7b\u95ee\u9898\uff08\u4e3b\u8981\u662f\u4e8c\u5143\u5206\u7c7b\uff09\uff0c\u4e00\u822c\u6709\u4e24\u79cd\u65b9\u6cd5\u5904\u7406\uff1aGenerative \u7684\u65b9\u6cd5\uff0cDiscriminative \u7684\u65b9\u6cd5 $$ \\begin{align} P(C_i|x)=\\frac{P(C_i)P(x|C_i)}{\\sum\\limits_{j=1}^nP(C_j)P(x|C_j)} \\ \\sigma(z)=\\frac{1}{1+e^{-z}}=\\frac{1}{1+e^{-(b+\\sum\\limits_k w_k x_k)}} \\end{align} $$ \u4e24\u8005\u7684\u533a\u522b\u5728\u4e8e\uff1a Generative model \u901a\u5e38\u4f1a\u5047\u8bbe\u4e00\u4e2a\u6982\u7387\u5206\u5e03\uff0c\u7136\u540e\u53bb\u5229\u7528\u6781\u5927\u4f3c\u7136\u4f30\u8ba1\u8ba1\u7b97 \\(b\\) \u548c \\(w\\) \uff1bDiscriminative model \u4e0d\u505a\u4efb\u4f55\u5047\u8bbe\uff0c\u5229\u7528\u4ea4\u53c9\u71b5\u548c gradient descent \u8ba1\u7b97 \\(b\\) \u548c \\(w\\) Generative model \u7684\u597d\u5904\u662f\uff0c\u5b83\u5bf9data\u7684\u4f9d\u8d56\u5e76\u6ca1\u6709\u50cfdiscriminative model \u90a3\u4e48\u4e25\u91cd\uff0c\u5728data\u6570\u91cf\u5c11\u6216\u8005data\u672c\u8eab\u5c31\u5b58\u5728noise\u7684\u60c5\u51b5\u4e0b\u53d7\u5230\u7684\u5f71\u54cd\u4f1a\u66f4\u5c0f\uff0c\u800c\u5b83\u8fd8\u53ef\u4ee5\u505a\u5230 Prior \u90e8\u5206\u4e0e class-dependent \u90e8\u5206\u5206\u5f00\u5904\u7406\uff0c\u5982\u679c\u53ef\u4ee5\u501f\u52a9\u5176\u4ed6\u65b9\u5f0f\u63d0\u9ad8 Prior model \u7684\u51c6\u786e\u7387\uff0c\u5bf9\u6574\u4e00\u4e2a model \u662f\u6709\u6240\u5e2e\u52a9\u7684 (\u6bd4\u5982\u524d\u9762\u63d0\u5230\u7684\u8bed\u97f3\u8fa8\u8bc6) \u800c Discriminative model \u7684\u597d\u5904\u662f\uff0c\u5728 data \u5145\u8db3\u7684\u60c5\u51b5\u4e0b\uff0c\u5b83\u8bad\u7ec3\u51fa\u6765\u7684 model \u7684\u51c6\u786e\u7387\u4e00\u822c\u662f\u6bd4 Generative model \u8981\u6765\u7684\u9ad8\u7684 Multi-class Classification \u00b6 Softmax \u00b6 \u5047\u8bbe\u6709\u4e09\u4e2a Class\uff1a \\(C_1,C_2,C_3\\) \uff0c\u6bcf\u4e00\u4e2a Class \u90fd\u6709\u81ea\u5df1\u7684 weight \u548c bias\uff0c\u5206\u522b\u662f \\(w_1,w_2,w_3\\) (vector)\uff0c \\(b_1,b_2,b_3\\) (const)\uff0cinput x \u4e5f\u662f\u4e00\u4e2a vector \u90a3\u4e48 \\(z_i=w^ix+b_i\\) softmax\uff1a\u5f3a\u5316\u6700\u5927\u503c\uff0c\u56e0\u4e3a\u505a exponential \u4f1a\u8ba9\u539f\u672c\u5927\u7684\u503c\u53d8\u5f97\u66f4\u5927 \u7136\u540e\u628a \\(z_1,z_2,z_3\\) \u4e22\u8fdb\u4e00\u4e2a softmax \u7684 function \u53d6 exponential\uff0c\u5f97\u5230 \\(e^{z_1},e^{z_2},e^{z_3}\\) \u5f52\u4e00\u5316\uff0c\u5f97\u5230 \\(y_1=\\frac{e^{z_1}}{\\sum\\limits_{j=1}^3 e^{z_j}}\\) \u3001 \\(y_2=\\frac{e^{z_2}}{\\sum\\limits_{j=1}^3 e^{z_j}}\\) \u3001 \\(y_3=\\frac{e^{z_3}}{\\sum\\limits_{j=1}^3 e^{z_j}}\\) softmax \u7684 output\uff0c\u5c31\u62ff\u6765\u5f53 z \u7684 probability multi-class classification \u7684\u8fc7\u7a0b \u00b6 input x \u7ecf\u8fc7\u4e09\u4e2a\u5f0f\u5b50\u540e\u5206\u522b\u751f\u6210 \\(z_1,z_2,z_3\\) \uff0c\u7ecf\u8fc7 softmax \u540e\u8f6c\u6362\u6210 \\(y_1,y_2,y_3\\) \uff0c\u8fd9\u5206\u522b\u662f\u4e09\u4e2a class \u7684 posterior probability \u4e3a\u4e86\u8ba1\u7b97\u4ea4\u53c9\u71b5\uff0c\u4e0d\u80fd\u628a targrt \u8bbe\u4e3a 1,2,3\uff0c\u8fd9\u91cc\u4f7f\u7528\u5411\u91cf \\[ \\hat{y}= \\begin{bmatrix} 1\\\\0\\\\0 \\end{bmatrix}_{x \\ \u2208 \\ class 1} \\hat{y}= \\begin{bmatrix} 0\\\\1\\\\0 \\end{bmatrix}_{x \\ \u2208 \\ class 2} \\hat{y}= \\begin{bmatrix} 0\\\\0\\\\1 \\end{bmatrix}_{x \\ \u2208 \\ class 3} \\] \u7136\u540e\u8ba1\u7b97 \\(y\uff0c\\hat{y}\\) \u4e4b\u95f4\u7684\u4ea4\u53c9\u71b5\uff0c \\(-\\sum\\limits_{i=1}^3 \\hat{y}_i \\ln y_i\\) Limitation of Logistic Regression \u00b6 Logistic Regression \u6709\u5f88\u5f3a\u7684\u9650\u5236\uff0c\u56e0\u4e3a\u4ed6\u7684 boundary \u662f\u4e00\u6761\u76f4\u7ebf\uff0c\u800c\u5bf9\u4e8e\u4e0b\u9762\u7684\u4f8b\u5b50 \\(x_1\\) \\(x_2\\) label 0 0 class2 0 1 class1 1 0 class1 1 1 class2 \u5728\u5750\u6807\u8f74\u4e0a\u662f\u4e0d\u53ef\u80fd\u753b\u4e00\u6761 boundary \u6765\u533a\u5206 class1 \u548c class2 \u7684 Feature Transformation \u00b6 \u5982\u679c\u539f\u6765\u7684 feature \u4e0d\u597d\u505a\u5212\u5206\uff0c\u53ef\u4ee5\u7528 Feature Transformation \uff0c\u8f6c\u6362\u4e4b\u540e\u53d8\u5f97\u53ef\u4ee5\u5212\u5206\u3002 \u5047\u5b9a\u65b0\u7684 x \u8f74 \\(x'_1\\) \u8868\u793a\u539f\u6765\u7684\u70b9\u5230 \\(\\begin{bmatrix}0\\\\0\\end{bmatrix}\\) \u7684\u8ddd\u79bb\uff0c\u65b0\u7684 y \u8f74 \\(x'_2\\) \u8868\u793a\u7684\u662f\u539f\u6765\u7684\u70b9\u5230 \\(\\begin{bmatrix}1\\\\1\\end{bmatrix}\\) \u7684\u8ddd\u79bb\uff0c\u91cd\u65b0\u6620\u5c04\u4e4b\u540e\u5c31\u53d8\u5f97\u53ef\u5212\u5206\u4e86 \u9ebb\u70e6\u7684\u662f\u5f88\u591a\u65f6\u5019\u6211\u4eec\u5e76\u4e0d\u77e5\u9053\u600e\u4e48\u505a Feature Transformation\uff0c\u4e8e\u662f\u6211\u4eec\u4f1a\u5e0c\u671b\u8fd9\u4e2a Transformation \u662f\u673a\u5668\u81ea\u5df1\u4ea7\u751f\u7684\uff0c\u600e\u4e48\u8ba9\u673a\u5668\u81ea\u5df1\u4ea7\u751f\u5462\uff1f \u6211\u4eec\u53ef\u4ee5\u8ba9\u5f88\u591aLogistic Regression cascade\uff08\u8fde\u63a5\uff09\u8d77\u6765 \u5373\u5148\u901a\u8fc7\u4e00\u4e2a Logistic Regression \u7684 Transform \u4f7f\u5f97\u65b0\u7684 feature \\(x'_1,x'_2\\) \u662f\u53ef\u4ee5\u5212\u5206\u7684\uff0c\u7136\u540e\u518d\u7ecf\u8fc7\u4e00\u4e2a Logistic Regression \u5c31\u53ef\u4ee5\u628a class1 \u548c class2 \u5206\u5f00 \u6240\u4ee5\u6574\u4e2a\u6d41\u7a0b\u662f\uff1a\u5148\u901a\u8fc7 n\uff08n\u4e3a\u6bcf\u4e2a\u6837\u672c\u70b9\u7684feature\u6570\u91cf\uff09\u4e2a Logistic Regression \u505a feature Transformation\uff0c\u7136\u540e\u518d\u7528\u4e00\u4e2a Logistic Regression \u505a classification\uff08\u5982\u679c\u662f\u591a\u5143\u5206\u7c7b\u9700\u8981\u7528\u5230\u591a\u4e2a Logistic Regression \u753b\u51fa\u591a\u6761\u76f4\u63a5\u5212\u5206\u6240\u6709\u7684\u7c7b\uff09 \u6211\u4eec\u5982\u679c\u628a\u8fd9\u5176\u4e2d\u7684\u6bcf\u4e2a Logistic Regression \u53eb\u505a\u4e00\u4e2a Neuron\uff0c\u628a\u8fd9\u4e9b Logistic Regression \u4e32\u8d77\u6765\u5f62\u6210\u7684 network \u53eb\u505a Neural Network\uff0c\u5341\u4e5d\u7c7b\u795e\u7ecf\u7f51\u7edc\uff0c\u5c31\u662f Deep Learning","title":"Logistic Regression"},{"location":"ML/3_Logistic%20Regression/#logistic-regression","text":"","title":"Logistic Regression"},{"location":"ML/3_Logistic%20Regression/#review","text":"\u5728 Classification \u4e2d\u5f97\u51fa\u7684\u7ed3\u679c\uff1a $$ \\begin{align} P_{w,b}(C_1|x)&=\\sigma(z)=\\frac{1}{1+e^{-z}} \\ z&=w\\cdot x+b=\\sum\\limits_i w_ix_i+b \\end{align} $$ \u5176\u4e2d \\(w\\) \u548c \\(x\\) \u90fd\u662f\u5411\u91cf\uff0c\u8fd9\u4e2a model \u662f\u53d7 \\(w\\) \u548c \\(b\\) \u63a7\u5236\u7684\uff0c\u56e0\u6b64\u6211\u4eec\u4e0d\u5fc5\u8981\u518d\u53bb\u50cf\u524d\u9762\u4e00\u6837\u8ba1\u7b97\u4e00\u5927\u5806\u4e1c\u897f\uff0c\u800c\u662f\u7528\u8fd9\u4e2a\u5168\u65b0\u7684\u7531 \\(w\\) \u548c \\(b\\) \u51b3\u5b9a\u7684 model \u2014\u2014 Logistic Regression(\u903b\u8f91\u56de\u5f52)","title":"Review"},{"location":"ML/3_Logistic%20Regression/#three-steps-of-machine-learning","text":"","title":"Three Steps of machine learning"},{"location":"ML/3_Logistic%20Regression/#step-1function-set","text":"\u8fd9\u91cc\u7684 function set \u5c31\u662f Logistic Regression\u2014\u2014\u903b\u8f91\u56de\u5f52 \\(x_i\\) \uff1ainput\uff0c \\(w_i\\) \uff1aweight\uff0c \\(b\\) \uff1abias\uff0c \\(\\sigma(z)\\) \uff1asigmoid function","title":"Step 1\uff1afunction set"},{"location":"ML/3_Logistic%20Regression/#step-2goodness-of-a-function","text":"\u8bbe\u8ba1\u4e00\u4e2a Loss Function \u77e5\u9053\u4e86\u67d0\u4e00\u7ec4 \\(w\\) \u548c \\(b\\) \u5c31\u53ef\u4ee5\u8ba1\u7b97\u51fa Posterior Probability\uff08\u540e\u9a8c\u6982\u7387\uff09\uff0c\u7136\u540e\u5229\u7528\u540e\u9a8c\u6982\u7387\u53ef\u4ee5\u8ba1\u7b97\u51fa\u6781\u5927\u4f3c\u7136\u4f30\u8ba1\uff0c\u90a3\u4e48\u80fd\u591f\u4f7f\u6781\u5927\u4f3c\u7136\u4f30\u8ba1\u503c\u6700\u5927\u7684\u90a3\u7ec4 \\(w^*\\) \u548c \\(b^*\\) \u5c31\u662f\u6700\u6709\u53ef\u80fd\u4ea7\u751f\u5f53\u524d Training Data \u7684\u4e00\u7ec4\u53c2\u6570 \u8fd9\u91cc\u5047\u5b9a\u4e8c\u5143\u5206\u7c7b\uff0cclass1 \u7684\u6982\u7387\u662f 1-class2 \u7684\u6982\u7387 \u5c06\u4e0a\u5f0f\u53d8\u5f62\uff1a \\[ w^*,b^*=\\arg \\max\\limits_{w,b} L(w,b)=\\arg\\min\\limits_{w,b}(-\\ln L(w,b)) \\] \\[ \\begin{align} -\\ln L(w,b)=&-\\ln f_{w,b}(x^1)\\\\ &-\\ln f_{w,b}(x^2)\\\\ &-\\ln(1-f_{w,b}(x^3))\\\\ &\\ -... \\end{align} $$ \u4e3a\u4e86\u7edf\u4e00\u683c\u5f0f\uff0c\u628a output $\\hat{y}=1$ \u4ee3\u8868 class1\uff0coutput $\\hat{y}=0$ \u4ee3\u8868 class2 $$ \\begin{align} -\\ln L(w,b)=&-[\\hat{y}^1 \\ln f_{w,b}(x^1)+(1-\\hat{y}^1)ln(1-f_{w,b}(x^1))]\\\\ &-[\\hat{y}^2 \\ln f_{w,b}(x^2)+(1-\\hat{y}^2)ln(1-f_{w,b}(x^2))]\\\\ &-[\\hat{y}^3 \\ln f_{w,b}(x^3)+(1-\\hat{y}^3)ln(1-f_{w,b}(x^3))]\\\\ &\\ -... \\end{align} $$ $$ -\\ln L(w,b)=\\sum\\limits_n -[\\hat{y}^n \\ln f_{w,b}(x^n)+(1-\\hat{y}^n) \\ln(1-f_{w,b}(x^n))] \\] \u8fd9\u4e2a\u5f62\u5f0f\u5176\u5b9e\u5c31\u662f \u4e24\u4e2a Bernoulli distribution (\u4e24\u70b9\u5206\u5e03)\u7684 cross entropy (\u4ea4\u53c9\u71b5) \uff0c\u628a\u8fd9\u4e2a\u4f5c\u4e3a Loss Function \u4e8e\u662f\u6211\u4eec\u628a \u6781\u5927\u4f3c\u7136\u4f30\u8ba1 \u7684\u5f0f\u5b50\u53d8\u6210\u4e86 \u4ea4\u53c9\u71b5 \u4f5c\u4e3a Loss Function \u4ee5\u65b9\u4fbf\u5fae\u5206","title":"Step 2\uff1aGoodness of a function"},{"location":"ML/3_Logistic%20Regression/#cross-entropy","text":"\u7b14\u8bb0 | \u4ec0\u4e48\u662fCross Entropy - \u77e5\u4e4e Cross Entropy: \u4e00\u822c\u7528\u6765\u91cf\u5316\u4e24\u4e2a\u6982\u7387\u5206\u5e03\u4e4b\u95f4\u5dee\u5f02\u7684\u635f\u5931\u51fd\u6570 \u5047\u8bbe\u5bf9\u4e8e \u4e00\u4e2a \u6570\u636e\u7684\u771f\u5b9e\u5206\u5e03\u4e3a p\uff0c\u9884\u6d4b\u5206\u5e03\u4e3a q \u90a3\u4e48 \\(H(p,q)=-\\sum_{x}{p(x)\\ log\\ q(x)}\\) \u5176\u4e2d x \u662f\u7c7b\u522b\u6570 Cross Entropy \u4ea4\u53c9\u71b5\u7684\u542b\u4e49\u662f\u8868\u8fbe\u4e24\u4e2a distribution \u6709\u591a\u63a5\u8fd1\uff0c\u5982\u679c p \u548c q \u8fd9\u4e24\u4e2a distribution \u4e00\u6a21\u4e00\u6837\u7684\u8bdd\uff0c\u90a3\u5b83\u4eec\u7b97\u51fa\u6765\u7684 Cross Entropy \u5c31\u662f 0 (\u8be6\u7ec6\u89e3\u91ca\u5728\u201c\u4fe1\u606f\u8bba\u201d\u4e2d)\uff0c\u800c\u8fd9\u91cc \\(f(x^n)\\) \u8868\u793a function \u7684 output\uff0c \\(\\hat{y}^n\\) \u8868\u793a\u9884\u671f\u7684 target\uff0c\u56e0\u6b64 \u4ea4\u53c9\u71b5\u5b9e\u9645\u4e0a\u8868\u8fbe\u7684\u662f\u5e0c\u671b\u8fd9\u4e2a function \u7684 output\u548c\u5b83\u7684 target \u8d8a\u63a5\u8fd1\u8d8a\u597d","title":"Cross Entropy"},{"location":"ML/3_Logistic%20Regression/#step-3find-the-best-function","text":"\u5373\u627e\u5230\u4f7f Loss Function \u5373 Cross Entropy \u6700\u5c0f\u7684\u4e00\u7ec4 \\(w^*,b^*\\) \uff0c\u8fd9\u91cc\u8fd0\u7528 Gradient Descent $$ \\begin{align} P_{w,b}(C_1|x)=\\sigma(z)=\\frac{1}{1+e^{-z}} \\ z=w\\cdot x+b=\\sum\\limits_i w_ix_i+b \\end{align} $$ \\[ \\begin{align} f_{w,b}(x)=P_{w,b}(C_1|x) \\end{align} \\] \\[ -\\ln L(w,b)=\\sum\\limits_n -[\\hat{y}^n \\ln f_{w,b}(x^n)+(1-\\hat{y}^n) \\ln(1-f_{w,b}(x^n))] \\] Sigmoid Function \u7684\u5fae\u5206\u516c\u5f0f\uff1a $$ \\frac{\\partial \\sigma(z)}{\\partial z}=\\sigma(z)(1-\\sigma(z)) $$ \u8ba1\u7b97 \\(-\\ln L(w,b)=\\sum\\limits_n -[\\hat{y}^n \\ln f_{w,b}(x^n)+(1-\\hat{y}^n) \\ln(1-f_{w,b}(x^n))]\\) \u5bf9 \\(w_i\\) \u7684\u504f\u5fae\u5206\uff0c\u5176\u4e2d \\(\\hat{y}^n\\) \u548c \\(1-\\hat{y}^n\\) \u662f\u5e38\u6570\uff0c\u53ea\u9700\u8981\u5206\u522b\u6c42\u51fa \\(\\ln f_{w,b}(x^n)\\) \u548c \\(\\ln (1-f_{w,b}(x^n))\\) \u5bf9 \\(w_i\\) \u7684\u504f\u5fae\u5206\u5373\u53ef\uff0c\u6574\u4f53\u63a8\u5bfc\u8fc7\u7a0b\u5982\u4e0b\uff1a \u7ed3\u679c\u5e26\u5165\u5f97\uff1a \u6240\u4ee5\uff1a $$ w_{i+1}=w_i-\\eta \\sum\\limits_{n}-(\\hat{y}^n-f_{w,b}(x^n))x_i^n $$ \\(-\\eta\\) \uff1alearning rate \\(x_i\\) \uff1adata \\(\\hat{y}^n-f_{w,b}(x^n)\\) \uff1a\u4e0e\u7406\u60f3 function set \u7684\u5dee\u8ddd\uff0c\u5dee\u8ddd\u8d8a\u5927 update \u7684\u6b65\u4f10\u8d8a\u5927 \u540c\u7406\u53ef\u5f97\uff1a $$ b_{i+1}=w_i-\\eta \\sum\\limits_{n}-(\\hat{y}^n-f_{w,b}(x^n)) $$ \u6211\u4eec\u4f1a\u53d1\u73b0 Logistic Regression \u7684\u7ed3\u679c\u662f\u548c Linear Regresison \u7684\u5f0f\u5b50\u662f\u4e00\u6837\u7684","title":"step 3\uff1aFind the best function"},{"location":"ML/3_Logistic%20Regression/#comparison","text":"","title":"Comparison"},{"location":"ML/3_Logistic%20Regression/#logistic-regression-linear-regression","text":"\u4e24\u8005\u90fd\u662f\u901a\u8fc7\u5bf9\u6bcf\u4e00\u4e2a feature \\(x_i\\) \u52a0\u6743\u6c42\u548c\u540e\u52a0\u4e0a\u4e00\u4e2a\u5e38\u6570\uff0c\u533a\u522b\u5728\u4e8e Logistic Regression \u6700\u540e\u53c8\u901a\u8fc7\u4e86\u4e00\u4e2a Sigmoid Function\uff0c\u5b83\u7684\u7ed3\u679c\u662f 0~1\uff0c\u800c Linear Regression \u4e0d\u7ecf\u8fc7 Sigmoid Function\uff0c\u7ed3\u679c\u53ef\u4ee5\u662f\u4efb\u610f\u503c Logistic Regression \u7684 Loss Function \u7528\u7684\u4ea4\u53c9\u71b5\u5b9a\u4e49\uff0c\u800c Linear Regression \u7528\u7684 Square Error","title":"Logistic Regression &amp;&amp; Linear Regression"},{"location":"ML/3_Logistic%20Regression/#logistic-regression-square-error","text":"\u5047\u8bbe\u4f7f\u7528 Logistic Regression + Square Error\uff0c \u5982\u679c\u6b64\u65f6 \\(\\hat{y}^n=1\\) \uff0c\u800c\u4e14 function \u7684 output \\(f_{w,b}(x^n)=1\\) \u7684\u8bdd\uff0c\u8bf4\u660e\u73b0\u5728\u79bb target \u5f88\u63a5\u8fd1\u4e86\uff0c \\(f_{w,b}(x)-\\hat{y}=0\\) \uff0c\u4e8e\u662f\u5f97\u5230\u7684\u5fae\u5206 \\(\\frac{\\partial L}{\\partial w_i}\\) \u7b49\u4e8e 0\uff0c\u8fd9\u4ef6\u4e8b\u60c5\u662f\u5f88\u5408\u7406\u7684\uff1b\u4f46\u662f\u5f53 function \u7684 output \\(f_{w,b}(x^n)=0\\) \u7684\u65f6\u5019\uff0c\u8bf4\u660e\u79bb target \u8fd8\u5f88\u9065\u8fdc\uff0c\u4f46\u662f\u7531\u4e8e\u5728step3 \u4e2d\u6c42\u51fa\u6765\u7684 update \u8868\u8fbe\u5f0f\u4e2d\u6709\u4e00\u4e2a \\(f_{w,b}(x^n)\\) \uff0c\u56e0\u6b64\u8fd9\u4e2a\u65f6\u5019\u4e5f\u4f1a\u5bfc\u81f4\u5f97\u5230\u7684\u5fae\u5206 \\(\\frac{\\partial L}{\\partial w_i}\\) \u4e5f\u7b49\u4e8e 0 \u5c06 Loss Function \u9009\u62e9 Cross Entropy \u6216 Square Error \u7684\u53d8\u5316\u60c5\u51b5\u53ef\u89c6\u5316\u4e4b\u540e\u5982\u4e0b\u6240\u793a\uff08\u9ed1\u8272\uff1aCross Entropy \u7ea2\u8272\uff1aSquare Error\uff09 \u53ef\u89c1 Square Error \u4f1a\u5f88\u6162\uff0c\u751a\u81f3\u53ef\u80fd\u4e0d\u4f1a\u52a8","title":"Logistic Regression + Square Error \uff1f"},{"location":"ML/3_Logistic%20Regression/#discriminative-generative","text":"\u628a Logistic Regression \u7684\u65b9\u6cd5\u79f0\u4e4b\u4e3a Discriminative \u7684\u65b9\u6cd5\uff0c\u7528 Gaussian \u6765\u63cf\u8ff0 Posterior Probability \u7684\u65b9\u6cd5\u79f0\u4e4b\u4e3a Generative \u7684\u65b9\u6cd5 \u4ed6\u4eec\u7684 Function Set \u90fd\u662f\u4e00\u6837\u7684\uff0c\u90fd\u662f \\(P(C_1|x)=\\sigma(w\\cdot x+b)\\) Logistic Regression \u662f\u901a\u8fc7 Gradient Descent \u7684\u65b9\u6cd5\u76f4\u63a5\u627e\u51fa \\(b\\) \u548c \\(w\\) \uff0c\u800c Generative Model \u7684\u65b9\u6cd5\u662f\u5148\u7b97 \\(u_1,u_2,\\Sigma^{-1}\\) \uff0c\u518d\u6c42 \\(b\\) \u548c \\(w\\) \u4f46\u8fd9\u4e24\u8005\u65b9\u6cd5\u7684\u51fa\u6765\u7684 \\(b\\) \u548c \\(w\\) \u662f\u4e0d\u4e00\u6837\u7684 \u539f\u56e0\u662f\u5728 Logistic Regression \u4e2d \u6ca1\u6709\u505a\u4efb\u4f55\u5b9e\u8d28\u6027\u7684\u5047\u8bbe \uff0c\u5355\u7eaf\u7684\u53bb\u627e \\(w\\) \u548c \\(b\\) \uff0c\u800c\u5728 Generative Model \u4e2d\u5047\u8bbe\u4e86 Gaussion Distribution Discriminative \u7684\u65b9\u6cd5\u5e38\u5e38\u4f1a\u6bd4 Generative \u7684\u65b9\u6cd5\u8868\u73b0\u5f97\u66f4\u597d discriminative model \u5e76\u4e0d\u662f\u5728\u6240\u6709\u7684\u60c5\u51b5\u4e0b\u90fd\u53ef\u4ee5\u8d62\u8fc7 Generative model\uff0cdiscriminative model \u662f\u5341\u5206\u4f9d\u8d56\u4e8e data \u7684\uff0c\u5f53 data \u6570\u91cf\u4e0d\u8db3\u6216\u662f data \u672c\u8eab\u7684 label\u5c31\u6709\u4e00\u4e9b\u95ee\u9898\uff0c\u90a3Generative model\u505a\u4e00\u4e9b\u5047\u8bbe\uff0c\u53cd\u800c\u53ef\u4ee5\u628a data \u7684\u4e0d\u8db3\u6216\u662f\u6709\u95ee\u9898\u90e8\u5206\u7684\u5f71\u54cd\u7ed9\u964d\u5230\u6700\u4f4e \u5728 Generative model \u4e2d\uff0cpriors probabilities \u548c class-dependent probabilities \u662f\u53ef\u4ee5\u62c6\u5f00\u6765\u8003\u8651\u7684\uff0c\u4ee5\u8bed\u97f3\u8fa8\u8bc6\u4e3a\u4f8b\uff0c\u73b0\u5728\u7528\u7684\u90fd\u662f neural network\uff0c\u662f\u4e00\u4e2adiscriminative \u7684\u65b9\u6cd5\uff0c\u4f46\u4e8b\u5b9e\u4e0a\u6574\u4e2a\u8bed\u97f3\u8fa8\u8bc6\u7684\u7cfb\u7edf\u662f\u4e00\u4e2a Generative \u7684 system\uff0c\u5b83\u7684 prior probability \u662f\u67d0\u4e00\u53e5\u8bdd\u88ab\u8bf4\u51fa\u6765\u7684\u51e0\u7387\uff0c\u800c\u60f3\u8981 estimate \u67d0\u4e00\u53e5\u8bdd\u88ab\u8bf4\u51fa\u6765\u7684\u51e0\u7387\u5e76\u4e0d\u9700\u8981\u6709\u58f0\u97f3\u7684 data\uff0c\u53ef\u4ee5\u53bb\u4e92\u8054\u7f51\u4e0a\u722c\u53d6\u5927\u91cf\u6587\u5b57\uff0c\u5c31\u53ef\u4ee5\u8ba1\u7b97\u51fa\u67d0\u4e00\u6bb5\u6587\u5b57\u51fa\u73b0\u7684\u51e0\u7387\uff0c\u5e76\u4e0d\u9700\u8981\u58f0\u97f3\u7684 data\uff0c\u8fd9\u4e2a\u5c31\u662f language model\uff0c\u800c class-dependent \u7684\u90e8\u5206\u624d\u9700\u8981\u58f0\u97f3\u548c\u6587\u5b57\u7684\u914d\u5408\uff0c\u8fd9\u6837\u7684\u5904\u7406\u53ef\u4ee5\u628a prior \u9884\u6d4b\u5730\u66f4\u7cbe\u786e","title":"Discriminative &amp;&amp; Generative"},{"location":"ML/3_Logistic%20Regression/#conclusion","text":"\u5bf9\u4e8e\u5206\u7c7b\u95ee\u9898\uff08\u4e3b\u8981\u662f\u4e8c\u5143\u5206\u7c7b\uff09\uff0c\u4e00\u822c\u6709\u4e24\u79cd\u65b9\u6cd5\u5904\u7406\uff1aGenerative \u7684\u65b9\u6cd5\uff0cDiscriminative \u7684\u65b9\u6cd5 $$ \\begin{align} P(C_i|x)=\\frac{P(C_i)P(x|C_i)}{\\sum\\limits_{j=1}^nP(C_j)P(x|C_j)} \\ \\sigma(z)=\\frac{1}{1+e^{-z}}=\\frac{1}{1+e^{-(b+\\sum\\limits_k w_k x_k)}} \\end{align} $$ \u4e24\u8005\u7684\u533a\u522b\u5728\u4e8e\uff1a Generative model \u901a\u5e38\u4f1a\u5047\u8bbe\u4e00\u4e2a\u6982\u7387\u5206\u5e03\uff0c\u7136\u540e\u53bb\u5229\u7528\u6781\u5927\u4f3c\u7136\u4f30\u8ba1\u8ba1\u7b97 \\(b\\) \u548c \\(w\\) \uff1bDiscriminative model \u4e0d\u505a\u4efb\u4f55\u5047\u8bbe\uff0c\u5229\u7528\u4ea4\u53c9\u71b5\u548c gradient descent \u8ba1\u7b97 \\(b\\) \u548c \\(w\\) Generative model \u7684\u597d\u5904\u662f\uff0c\u5b83\u5bf9data\u7684\u4f9d\u8d56\u5e76\u6ca1\u6709\u50cfdiscriminative model \u90a3\u4e48\u4e25\u91cd\uff0c\u5728data\u6570\u91cf\u5c11\u6216\u8005data\u672c\u8eab\u5c31\u5b58\u5728noise\u7684\u60c5\u51b5\u4e0b\u53d7\u5230\u7684\u5f71\u54cd\u4f1a\u66f4\u5c0f\uff0c\u800c\u5b83\u8fd8\u53ef\u4ee5\u505a\u5230 Prior \u90e8\u5206\u4e0e class-dependent \u90e8\u5206\u5206\u5f00\u5904\u7406\uff0c\u5982\u679c\u53ef\u4ee5\u501f\u52a9\u5176\u4ed6\u65b9\u5f0f\u63d0\u9ad8 Prior model \u7684\u51c6\u786e\u7387\uff0c\u5bf9\u6574\u4e00\u4e2a model \u662f\u6709\u6240\u5e2e\u52a9\u7684 (\u6bd4\u5982\u524d\u9762\u63d0\u5230\u7684\u8bed\u97f3\u8fa8\u8bc6) \u800c Discriminative model \u7684\u597d\u5904\u662f\uff0c\u5728 data \u5145\u8db3\u7684\u60c5\u51b5\u4e0b\uff0c\u5b83\u8bad\u7ec3\u51fa\u6765\u7684 model \u7684\u51c6\u786e\u7387\u4e00\u822c\u662f\u6bd4 Generative model \u8981\u6765\u7684\u9ad8\u7684","title":"Conclusion"},{"location":"ML/3_Logistic%20Regression/#multi-class-classification","text":"","title":"Multi-class Classification"},{"location":"ML/3_Logistic%20Regression/#softmax","text":"\u5047\u8bbe\u6709\u4e09\u4e2a Class\uff1a \\(C_1,C_2,C_3\\) \uff0c\u6bcf\u4e00\u4e2a Class \u90fd\u6709\u81ea\u5df1\u7684 weight \u548c bias\uff0c\u5206\u522b\u662f \\(w_1,w_2,w_3\\) (vector)\uff0c \\(b_1,b_2,b_3\\) (const)\uff0cinput x \u4e5f\u662f\u4e00\u4e2a vector \u90a3\u4e48 \\(z_i=w^ix+b_i\\) softmax\uff1a\u5f3a\u5316\u6700\u5927\u503c\uff0c\u56e0\u4e3a\u505a exponential \u4f1a\u8ba9\u539f\u672c\u5927\u7684\u503c\u53d8\u5f97\u66f4\u5927 \u7136\u540e\u628a \\(z_1,z_2,z_3\\) \u4e22\u8fdb\u4e00\u4e2a softmax \u7684 function \u53d6 exponential\uff0c\u5f97\u5230 \\(e^{z_1},e^{z_2},e^{z_3}\\) \u5f52\u4e00\u5316\uff0c\u5f97\u5230 \\(y_1=\\frac{e^{z_1}}{\\sum\\limits_{j=1}^3 e^{z_j}}\\) \u3001 \\(y_2=\\frac{e^{z_2}}{\\sum\\limits_{j=1}^3 e^{z_j}}\\) \u3001 \\(y_3=\\frac{e^{z_3}}{\\sum\\limits_{j=1}^3 e^{z_j}}\\) softmax \u7684 output\uff0c\u5c31\u62ff\u6765\u5f53 z \u7684 probability","title":"Softmax"},{"location":"ML/3_Logistic%20Regression/#multi-class-classification_1","text":"input x \u7ecf\u8fc7\u4e09\u4e2a\u5f0f\u5b50\u540e\u5206\u522b\u751f\u6210 \\(z_1,z_2,z_3\\) \uff0c\u7ecf\u8fc7 softmax \u540e\u8f6c\u6362\u6210 \\(y_1,y_2,y_3\\) \uff0c\u8fd9\u5206\u522b\u662f\u4e09\u4e2a class \u7684 posterior probability \u4e3a\u4e86\u8ba1\u7b97\u4ea4\u53c9\u71b5\uff0c\u4e0d\u80fd\u628a targrt \u8bbe\u4e3a 1,2,3\uff0c\u8fd9\u91cc\u4f7f\u7528\u5411\u91cf \\[ \\hat{y}= \\begin{bmatrix} 1\\\\0\\\\0 \\end{bmatrix}_{x \\ \u2208 \\ class 1} \\hat{y}= \\begin{bmatrix} 0\\\\1\\\\0 \\end{bmatrix}_{x \\ \u2208 \\ class 2} \\hat{y}= \\begin{bmatrix} 0\\\\0\\\\1 \\end{bmatrix}_{x \\ \u2208 \\ class 3} \\] \u7136\u540e\u8ba1\u7b97 \\(y\uff0c\\hat{y}\\) \u4e4b\u95f4\u7684\u4ea4\u53c9\u71b5\uff0c \\(-\\sum\\limits_{i=1}^3 \\hat{y}_i \\ln y_i\\)","title":"multi-class classification \u7684\u8fc7\u7a0b"},{"location":"ML/3_Logistic%20Regression/#limitation-of-logistic-regression","text":"Logistic Regression \u6709\u5f88\u5f3a\u7684\u9650\u5236\uff0c\u56e0\u4e3a\u4ed6\u7684 boundary \u662f\u4e00\u6761\u76f4\u7ebf\uff0c\u800c\u5bf9\u4e8e\u4e0b\u9762\u7684\u4f8b\u5b50 \\(x_1\\) \\(x_2\\) label 0 0 class2 0 1 class1 1 0 class1 1 1 class2 \u5728\u5750\u6807\u8f74\u4e0a\u662f\u4e0d\u53ef\u80fd\u753b\u4e00\u6761 boundary \u6765\u533a\u5206 class1 \u548c class2 \u7684","title":"Limitation of Logistic Regression"},{"location":"ML/3_Logistic%20Regression/#feature-transformation","text":"\u5982\u679c\u539f\u6765\u7684 feature \u4e0d\u597d\u505a\u5212\u5206\uff0c\u53ef\u4ee5\u7528 Feature Transformation \uff0c\u8f6c\u6362\u4e4b\u540e\u53d8\u5f97\u53ef\u4ee5\u5212\u5206\u3002 \u5047\u5b9a\u65b0\u7684 x \u8f74 \\(x'_1\\) \u8868\u793a\u539f\u6765\u7684\u70b9\u5230 \\(\\begin{bmatrix}0\\\\0\\end{bmatrix}\\) \u7684\u8ddd\u79bb\uff0c\u65b0\u7684 y \u8f74 \\(x'_2\\) \u8868\u793a\u7684\u662f\u539f\u6765\u7684\u70b9\u5230 \\(\\begin{bmatrix}1\\\\1\\end{bmatrix}\\) \u7684\u8ddd\u79bb\uff0c\u91cd\u65b0\u6620\u5c04\u4e4b\u540e\u5c31\u53d8\u5f97\u53ef\u5212\u5206\u4e86 \u9ebb\u70e6\u7684\u662f\u5f88\u591a\u65f6\u5019\u6211\u4eec\u5e76\u4e0d\u77e5\u9053\u600e\u4e48\u505a Feature Transformation\uff0c\u4e8e\u662f\u6211\u4eec\u4f1a\u5e0c\u671b\u8fd9\u4e2a Transformation \u662f\u673a\u5668\u81ea\u5df1\u4ea7\u751f\u7684\uff0c\u600e\u4e48\u8ba9\u673a\u5668\u81ea\u5df1\u4ea7\u751f\u5462\uff1f \u6211\u4eec\u53ef\u4ee5\u8ba9\u5f88\u591aLogistic Regression cascade\uff08\u8fde\u63a5\uff09\u8d77\u6765 \u5373\u5148\u901a\u8fc7\u4e00\u4e2a Logistic Regression \u7684 Transform \u4f7f\u5f97\u65b0\u7684 feature \\(x'_1,x'_2\\) \u662f\u53ef\u4ee5\u5212\u5206\u7684\uff0c\u7136\u540e\u518d\u7ecf\u8fc7\u4e00\u4e2a Logistic Regression \u5c31\u53ef\u4ee5\u628a class1 \u548c class2 \u5206\u5f00 \u6240\u4ee5\u6574\u4e2a\u6d41\u7a0b\u662f\uff1a\u5148\u901a\u8fc7 n\uff08n\u4e3a\u6bcf\u4e2a\u6837\u672c\u70b9\u7684feature\u6570\u91cf\uff09\u4e2a Logistic Regression \u505a feature Transformation\uff0c\u7136\u540e\u518d\u7528\u4e00\u4e2a Logistic Regression \u505a classification\uff08\u5982\u679c\u662f\u591a\u5143\u5206\u7c7b\u9700\u8981\u7528\u5230\u591a\u4e2a Logistic Regression \u753b\u51fa\u591a\u6761\u76f4\u63a5\u5212\u5206\u6240\u6709\u7684\u7c7b\uff09 \u6211\u4eec\u5982\u679c\u628a\u8fd9\u5176\u4e2d\u7684\u6bcf\u4e2a Logistic Regression \u53eb\u505a\u4e00\u4e2a Neuron\uff0c\u628a\u8fd9\u4e9b Logistic Regression \u4e32\u8d77\u6765\u5f62\u6210\u7684 network \u53eb\u505a Neural Network\uff0c\u5341\u4e5d\u7c7b\u795e\u7ecf\u7f51\u7edc\uff0c\u5c31\u662f Deep Learning","title":"Feature Transformation"},{"location":"ML/4_Deep%20learning/","text":"Deep Learning \u00b6 Neural Network \u00b6 Concept \u00b6 \u628a\u591a\u4e2a Logistic Regression \u524d\u540e connect \u5728\u4e00\u8d77\uff0c\u7136\u540e\u628a\u4e00\u4e2a Logistic Regression \u79f0\u4e4b\u4e3a neuron\uff0c\u6574\u4e2a\u79f0\u4e4b\u4e3a neural network Fully Connect Feedforward Network \u00b6 Neural Network \u7684\u8fde\u63a5\u65b9\u5f0f\u662f\u9700\u8981\u4f60\u624b\u52a8\u53bb\u8bbe\u8ba1\u7684\uff0c\u6700\u5e38\u89c1\u7684\u8fde\u63a5\u65b9\u5f0f\u53eb\u505a Fully Connect Feedforward Network (\u5168\u8fde\u63a5\u524d\u9988\u7f51\u7edc) Neural Network \u662f\u4e00\u5c42\u4e00\u5c42\u7684\u7ed3\u6784\uff0clayer \u548c layer \u4e4b\u95f4 neuron \u662f\u4e24\u4e24\u4e92\u76f8\u8fde\u63a5\u7684\uff0clayer1 \u7684 neuron output \u4f1a\u8fde\u63a5\u7ed9 layer2 \u7684\u6bcf\u4e00\u4e2a neuron \u4f5c\u4e3a input \u5206\u4e3a\u4e09\u7c7b\uff1ainput layer\uff0coutput layer\uff0chidden layer \u6bcf\u4e00\u4e2a neuron \u91cc\u9762\u7684 sigmoid function\uff0c\u5728 Deep Learning \u4e2d\u88ab\u79f0\u4e3a activation function (\u6fc0\u52b1\u51fd\u6570)\uff0c\u5e76\u4e0d\u4e00\u5b9a\u8981\u7528 sigmoid function\uff08\u800c\u4e14 sigmoid function \u73b0\u5728\u5df2\u7ecf\u7528\u7684\u5f88\u5c11\u4e86\uff09 \u6709\u5f88\u591a\u5c42 layers \u7684 neural network\uff0c\u88ab\u79f0\u4e3a DNN(Deep Neural Network) \u8fd9\u91cc\u9762\u7684\u6240\u6709\u53d8\u91cf\u90fd\u7528\u77e9\u9635\u7684\u5f62\u5f0f\u8868\u793a\uff0c\u56e0\u4e3a\u8fd9\u6837\u53ef\u4ee5\u5229\u7528 GPU \u52a0\u901f Output Layer \u00b6 \u6211\u4eec\u53ef\u4ee5\u628a hidden layers \u8fd9\u90e8\u5206\uff0c\u770b\u505a\u662f\u4e00\u4e2a feature extractor(\u7279\u5f81\u63d0\u53d6\u5668) \uff0c\u8fd9\u4e2a feature extractor \u5c31 replace \u4e86\u6211\u4eec\u4e4b\u524d\u624b\u52a8\u505a feature engineering\uff0cfeature transformation \u8fd9\u4e9b\u4e8b\u60c5\uff0c\u7ecf\u8fc7\u8fd9\u4e2a feature extractor \u5f97\u5230\u7684 \\(x_1,x_2,...,x_k\\) \u5c31\u53ef\u4ee5\u88ab\u5f53\u4f5c\u4e00\u7ec4\u65b0\u7684 feature output layer \u505a\u7684\u4e8b\u60c5\uff0c\u5176\u5b9e\u5c31\u662f\u628a\u5b83\u5f53\u505a\u4e00\u4e2a Multi-class classifier \uff0c\u5b83\u662f\u62ff\u7ecf\u8fc7 feature extractor \u8f6c\u6362\u540e\u7684\u90a3\u4e00\u7ec4\u6bd4\u8f83\u597d\u7684 feature (\u80fd\u591f\u88ab\u5f88\u597d\u5730separate) \u8fdb\u884c\u5206\u7c7b\u7684\uff0c\u7531\u4e8e\u6211\u4eec\u628a output layer \u770b\u505a\u662f\u4e00\u4e2a Multi-class classifier\uff0c\u6240\u4ee5\u6211\u4eec\u4f1a\u5728\u6700\u540e\u4e00\u4e2a layer \u52a0\u4e0a softmax Backpropagation \u00b6 Backpropagation(\u53cd\u5411\u4f20\u64ad)\uff0c\u5c31\u662f\u544a\u8bc9\u6211\u4eec\u7528 gradient descent \u6765 train\u4e00\u4e2a neural network \u7684\u65f6\u5019\u8be5\u600e\u4e48\u505a\uff0c\u5b83\u53ea\u662f\u6c42\u5fae\u5206\u7684\u4e00\u79cd\u65b9\u6cd5\uff0c\u800c\u4e0d\u662f\u4e00\u79cd\u65b0\u7684\u7b97\u6cd5 \u5bf9\u6574\u4e2a neural network\uff0c\u6211\u4eec\u5b9a\u4e49\u4e86\u4e00\u4e2a loss function\uff1a \\(L(\\theta)=\\sum\\limits_{n=1}^N l^n(\\theta)\\) \uff0c\u5b83\u7b49\u4e8e\u6240\u6709 training data \u7684 loss \u4e4b\u548c\uff0c\u5176\u4e2d \\(l^n\\) \u662f\u6837\u672c \\(x^n\\) \u4e0e target \\(\\hat{y}^n\\) \u7684 cross entropy\uff1b\u7136\u540e summary \u6240\u6709\u7684training data \u7684 cross entropy \u540e\u5f97\u5230 \\(L(\\theta)\\) \uff0c\u5bf9\u5176\u505a\u67d0\u4e00\u4e2a\u53c2\u6570w\u505a\u504f\u5fae\u5206\uff0c\u8868\u8fbe\u5f0f\u5982\u4e0b\uff1a $$ \\frac{\\partial L(\\theta)}{\\partial w}=\\sum\\limits_{n=1}^N\\frac{\\partial l^n(\\theta)}{\\partial w} $$ \u6240\u4ee5\u6211\u4eec\u53ea\u9700\u8981\u8003\u8651\u5982\u4f55\u8ba1\u7b97\u5bf9\u67d0\u4e00\u7b14 data \u7684 \\(\\frac{\\partial l^n(\\theta)}{\\partial w}\\) \u5373\u53ef \u5bf9\u4e8e\u5176\u4e2d\u4e00\u4e2a neuron\uff0c\u6709 \\(z=b+w_1 x_1+w_2 x_2\\) \uff0c\u90a3\u4e48 \\(\\frac{\\partial l}{\\partial w}=\\frac{\\partial z}{\\partial w} \\frac{\\partial l}{\\partial z}\\) \u4e2d\uff0c\u524d\u9762\u7684\u4e00\u4e2a\u662f\u6bd4\u8f83\u597d\u7b97\u7684\uff0c\u540e\u9762\u7684\u4e00\u4e2a\u662f\u6bd4\u8f83\u9ebb\u70e6\u7684 Forward pass \u00b6 \u5148\u8003\u8651 \\(\\frac{\\partial z}{\\partial w}\\) \u8fd9\u4e00\u9879\uff0c\u53ef\u4ee5\u79d2\u7b97\u51fa\u6765\uff0c \\(\\frac{\\partial z}{\\partial w_1}=x_1 ,\\ \\frac{\\partial z}{\\partial w_2}=x_2\\) \uff0c\u5373 \\(w_1,w_2\\) \u7cfb\u6570\u5bf9\u5e94\u7684\u8f93\u5165\u503c\uff0c\u540c\u65f6\u4e5f\u662f\u524d\u4e00\u4e2a layer \u7684\u8f93\u51fa\u503c Backward pass \u00b6 \u518d\u8003\u8651 \\(\\frac{\\partial l}{\\partial z}\\) \u8fd9\u4e00\u9879\uff0c\u5b83\u662f\u6bd4\u8f83\u590d\u6742\u7684\uff0c\u8fd9\u91cc\u6211\u4eec\u4f9d\u65e7\u5047\u8bbe activation function \u662f sigmoid function $$ \\frac{\\partial l}{\\partial z}=\\frac{\\partial a}{\\partial z} \\frac{\\partial l}{\\partial a} $$ \u524d\u9762 \\(\\frac{\\partial a}{\\partial z}\\) \u5c31\u662f sigmoid function \u7684\u504f\u5fae\u5206 \u540e\u9762 \\(\\frac{\\partial l}{\\partial a}\\) \u4e3a\u5982\u4e0b\u5f62\u5f0f\uff1a $$ \\frac{\\partial l}{\\partial a}=\\frac{\\partial z'}{\\partial a} \\frac{\\partial l}{\\partial z'}+\\frac{\\partial z''}{\\partial a} \\frac{\\partial l}{\\partial z''} $$ \u8fd9\u6837\u770b\u6765\u5176\u5b9e\u662f\u4e00\u4e2a\u9012\u5f52\u7684\u5f62\u5f0f\uff0c\u5728 output layer \u5f80\u524d\u7b97\u4fbf\u53ef\u4ee5\u6c42\u51fa\u6240\u6709\u7684 \\(\\frac{\\partial l}{\\partial a}\\) \u8ba8\u8bba\u4e00\u4e0b output layer \u7684\u7ed3\u679c\uff1a $$ \\frac{\\partial l}{\\partial z'}=\\frac{\\partial y_1}{\\partial z'} \\frac{\\partial l}{\\partial y_1} $$ \u5176\u4e2d \\(\\frac{\\partial y_1}{\\partial z'}\\) \u5c31\u662f output layer\u7684 activation function (softmax) \u5bf9 \\(z'\\) \u7684\u504f\u5fae\u5206 \u800c \\(\\frac{\\partial l}{\\partial y_1}\\) \u5c31\u662f loss \u5bf9 \\(y_1\\) \u7684\u504f\u5fae\u5206\uff0c\u5b83\u53d6\u51b3\u4e8e\u4f60\u7684 loss function \u662f\u600e\u4e48\u5b9a\u4e49\u7684\uff0c\u4e5f\u5c31\u662f\u4f60\u7684 output \u548c target \u4e4b\u95f4\u662f\u600e\u4e48 evaluate \u7684\uff0c\u4f60\u53ef\u4ee5\u7528 cross entropy\uff0c\u4e5f\u53ef\u4ee5\u7528 mean square error\uff0c\u7528\u4e0d\u540c\u7684\u5b9a\u4e49\uff0c \\(\\frac{\\partial l}{\\partial y_1}\\) \u7684\u503c\u5c31\u4e0d\u4e00\u6837 Why Deep? \u00b6 \u4e3a\u4ec0\u4e48\u6211\u4eec\u8981 deep learning\uff1f\u4e00\u4e2a\u5f88\u76f4\u89c9\u7684\u7b54\u6848\u662f\uff0c\u8d8a deep\uff0cperformance \u5c31\u8d8a\u597d\uff0c\u4e00\u822c\u6765\u8bf4\uff0c\u968f\u7740 deep learning \u4e2d\u7684 layers \u6570\u91cf\u589e\u52a0\uff0cerror \u7387\u4e0d\u65ad\u964d\u4f4e \u751a\u81f3\u6709\u4e00\u4e2a\u7406\u8bba\u662f\u8fd9\u6837\u8bf4\u7684\uff0c\u4efb\u4f55\u8fde\u7eed\u7684 function\uff0c\u5b83 input \u662f\u4e00\u4e2a N \u7ef4\u7684 vector\uff0coutput \u662f\u4e00\u4e2a M \u7ef4\u7684 vector\uff0c\u5b83\u90fd\u53ef\u4ee5\u7528\u4e00\u4e2a hidden layer \u7684 neural network \u6765\u8868\u793a\uff0c\u53ea\u8981\u4f60\u8fd9\u4e2a hidden layer \u7684 neuron \u591f\u591a\uff0c\u5b83\u53ef\u4ee5\u8868\u793a\u6210\u4efb\u4f55\u7684 function\uff0c\u65e2\u7136\u4e00\u4e2a hidden layer \u7684 neural network \u53ef\u4ee5\u8868\u793a\u6210\u4efb\u4f55\u7684 function\uff0c\u800c\u6211\u4eec\u5728\u505a machine learning \u7684\u65f6\u5019\uff0c\u9700\u8981\u7684\u4e1c\u897f\u5c31\u53ea\u662f\u4e00\u4e2a function \u800c\u5df2\uff0c\u90a3\u505a deep \u6709\u4ec0\u4e48\u7279\u6b8a\u7684\u610f\u4e49\u5462\uff1f Design network structure V.s. Feature Engineering \u00b6 \u4e0b\u9762\u804a\u4e00\u4e9b\u7ecf\u9a8c\u4e4b\u8c08 network structure \u7684 design \u662f\u4e00\u4ef6\u4e0d\u5bb9\u6613\u7684\u4e8b\uff0c\u5f88\u591a\u65f6\u5019\u9700\u8981\u9760\u7ecf\u9a8c\u76f4\u89c9\uff0c\u4e43\u81f3\u4e00\u4e9b domain knowledge (\u4e13\u4e1a\u9886\u57df\u7684\u77e5\u8bc6) \u672c\u6765\u4e0d\u662f deep learning \u7684 model\uff0c\u8981\u5f97\u5230\u4e00\u4e2a\u597d\u7684\u7ed3\u679c\uff0c\u5f80\u5f80\u9700\u8981\u505a feature engineering (\u7279\u5f81\u5de5\u7a0b)\uff0c\u4e5f\u5c31\u662f\u505a feature transform\uff0c\u7136\u540e\u627e\u4e00\u7ec4\u597d\u7684 feature\uff1b\u4e00\u5f00\u59cb\u5b66\u4e60 deep learning \u7684\u65f6\u5019\uff0c\u597d\u50cf\u4f1a\u89c9\u5f97 deep learning \u7684 layers \u4e4b\u95f4\u4e5f\u662f\u5728\u505a feature transform\uff0c\u4f46\u5b9e\u9645\u4e0a\u5728\u505a deep learning \u7684\u65f6\u5019\uff0c\u5f80\u5f80\u4e0d\u9700\u8981\u4e00\u4e2a\u597d\u7684 feature \uff0c\u6bd4\u5982\u8bf4\u5728\u505a\u5f71\u50cf\u8fa8\u8bc6\u7684\u65f6\u5019\uff0c\u4f60\u53ef\u4ee5\u628a\u6240\u6709\u7684 pixel \u76f4\u63a5\u4e22\u8fdb\u53bb\uff0c\u4f46\u662f\u5728\u8fc7\u53bb\u505a\u56fe\u50cf\u8bc6\u522b\uff0c\u4f60\u662f\u9700\u8981\u5bf9\u56fe\u50cf\u62bd\u53d6\u51fa\u4e00\u4e9b\u4eba\u5b9a\u7684 feature \u51fa\u6765\u7684\uff0c\u8fd9\u4ef6\u4e8b\u60c5\u5c31\u662ffeature transform\uff0c\u4f46\u662f\u6709\u4e86deep learning \u4e4b\u540e\uff0c\u4f60\u5b8c\u5168\u53ef\u4ee5\u76f4\u63a5\u4e22 pixel \u8fdb\u53bb\u786c\u505a deep learning \u5236\u9020\u4e86\u65b0\u7684\u95ee\u9898\uff0c\u5c31\u662f design network \u7684 structure\uff0c\u6240\u4ee5\u95ee\u9898\u53d8\u6210\u4e86 design structure \u548c feature transform \u54ea\u4e00\u4e2a\u66f4\u5bb9\u6613 \u5bf9\u4e8e\u4e00\u4e9b feature transform \u5f88\u96be\u505a\u7684\u4e8b\u60c5\u6bd4\u5982 \u8bed\u97f3\u548c\u6620\u50cf \u8fa8\u8bc6\uff0c\u7528 deep learning \u5c31\u8fdb\u6b65\u7684\u5f88\u5feb\uff1b\u4f46\u5728\u6587\u5b57\u65b9\u9762\u6bd4\u5982\u8bbe\u8ba1\u4e00\u4e2a rule \u53bb detect \u4e00\u7bc7 document \u662f\u6b63\u9762\u7684\u60c5\u7eea\u8fd8\u662f\u8d1f\u9762\u7684\u60c5\u7eea\u65f6\uff0cdeep learning \u76f8\u8f83\u4e8e\u4f20\u7edf\u7684\u65b9\u6cd5\u8fdb\u6b65\u4e0d\u660e\u663e \u957f\u4e45\u800c\u8a00\uff0c\u53ef\u80fd\u6587\u5b57\u5904\u7406\u4e2d\u4f1a\u6709\u4e00\u4e9b\u9690\u85cf\u7684\u8d44\u8baf\u662f\u4eba\u81ea\u5df1\u4e5f\u4e0d\u77e5\u9053\u7684\uff0c\u6240\u4ee5\u8ba9\u673a\u5668\u81ea\u5df1\u53bb\u5b66\u8fd9\u4ef6\u4e8b\u60c5\uff0c\u8fd8\u662f\u53ef\u4ee5\u5360\u5230\u4e00\u4e9b\u4f18\u52bf\uff0c\u53ea\u662f\u773c\u4e0b\u5b83\u8ddf\u4f20\u7edf\u65b9\u6cd5\u7684\u5dee\u5f02\u770b\u8d77\u6765\u5e76\u6ca1\u6709\u90a3\u4e48\u7684\u60ca\u4eba\uff0c\u4f46\u8fd8\u662f\u6709\u8fdb\u6b65\u7684 Tips for Deep Learning \u00b6 \u9488\u5bf9 training set \u548c testing set \u4e0a\u7684 performance \u5206\u522b\u63d0\u51fa\u9488\u5bf9\u6027\u7684\u89e3\u51b3\u65b9\u6cd5 1\u3001\u5728 training set \u4e0a\u51c6\u786e\u7387\u4e0d\u9ad8\uff1a new activation function\uff1aReLU\u3001Maxout adaptive learning rate\uff1aAdagrad\u3001RMSProp\u3001Momentum\u3001Adam 2\u3001\u5728 testing set \u4e0a\u51c6\u786e\u7387\u4e0d\u9ad8\uff1aEarly Stopping\u3001Regularization or Dropout Good Results on Training Data\uff1f \u00b6 \u50cf k nearest neighbor\uff0cdecision tree \u8fd9\u7c7b\u65b9\u6cd5\uff0c\u5b83\u4eec\u5728 training set \u4e0a\u6b63\u786e\u7387\u90fd\u662f100\uff0c\u8fd9\u624d\u662f\u975e\u5e38\u5bb9\u6613 overfitting \u7684\uff0c\u800c\u5bf9 deep learning \u6765\u8bf4\uff0coverfitting \u5f80\u5f80\u4e0d\u4f1a\u662f\u4f60\u9047\u5230\u7684\u7b2c\u4e00\u4e2a\u95ee\u9898 \u5982\u4f55\u5728 Training Data \u4e0a\u5f97\u5230\u597d\u7684 performance \u5462\uff1f \u5206\u4e3a\u4e24\u4e2a\u6a21\u5757\uff0cNew activation function \u548c Adaptive Learning Rate New activation function \u00b6 training \u7684\u7ed3\u679c\u4e0d\u597d\u53ef\u80fd\u662f network \u7684\u67b6\u6784\u8bbe\u8ba1\u7684\u4e0d\u597d\uff0c\u6bd4\u5982\u8bf4\u7528\u7684 activation function \u662f\u5bf9 training \u6bd4\u8f83\u4e0d\u5229\u7684\uff0c\u5c1d\u8bd5\u7740\u6362\u4e00\u4e9b\u65b0\u7684 activation function\uff0c\u4e5f\u8bb8\u53ef\u4ee5\u5e26\u6765\u6bd4\u8f83\u597d\u7684\u7ed3\u679c \u4e0b\u56fe\u662f\u624b\u5199\u6570\u5b57\u8fa8\u8bc6\u7528 sigmoid function \u65f6\u968f\u7740\u5c42\u6570\u589e\u52a0\u5728 training data \u4e0a\u7684\u60c5\u51b5 Vanishing Gradient Problem \u00b6 \u4e0a\u9762\u8fd9\u4e2a\u95ee\u9898\u7684\u539f\u56e0\u4e0d\u662f overfitting\uff0c\u800c\u662f Vanishing Gradient (\u68af\u5ea6\u6d88\u5931) network \u5f88\u6df1\u7684\u65f6\u5019\uff0c\u5728\u9760\u8fd1 input \u7684\u5730\u65b9\u7684\u53c2\u6570\u7684 gradient \u662f\u6bd4\u8f83\u5c0f\u7684\uff0c\u5728\u9760\u8fd1 output \u7684\u5730\u65b9\u7684 gradient \u662f\u6bd4\u8f83\u5927\u7684\uff1b\u56e0\u6b64\u5728\u8bbe\u5b9a\u76f8\u540c\u7684 learning rate \u65f6\uff0c\u9760\u8fd1 input \u7684\u5730\u65b9\u7684\u53c2\u6570\u7684 update \u662f\u5f88\u6162\u7684 \u4e3a\u4ec0\u4e48\u4f1a\u6709\u8fd9\u4e2a\u73b0\u8c61\u53d1\u751f\u5462\uff1f\u5982\u679c\u628a Backpropagation \u7684\u5f0f\u5b50\u5199\u51fa\u6765\u7684\u8bdd\uff0c\u5c31\u53ef\u4ee5\u5f88\u8f7b\u6613\u5730\u53d1\u73b0\u7528 sigmoid function \u4f1a\u5bfc\u81f4\u8fd9\u4ef6\u4e8b\u60c5\u7684\u53d1\u751f\uff1b\u4f46\u662f\u5176\u5b9e\u4ece\u76f4\u89c9\u4e0a\u6765\u60f3\u4f60\u4e5f\u53ef\u4ee5\u4e86\u89e3\u8fd9\u4ef6\u4e8b\u60c5\u53d1\u751f\u7684\u539f\u56e0\uff1asigmoid function \u4f1a\u628a\u8d1f\u65e0\u7a77\u5927\u5230\u6b63\u65e0\u7a77\u5927\u4e4b\u95f4\u7684\u503c\u90fd\u538b\u7f29\u5230 0~1 \u4e4b\u95f4\uff0c\u6240\u4ee5\u5373\u4f7f \\(\\Delta w\\) \u200b \u5f88\u5927\uff0c\u5982\u679c network \u5f88\u6df1\uff0c\u8870\u51cf\u7684\u6b21\u6570\u5c31\u8d8a\u591a\uff0c\u5bf9 output \u7684\u5f71\u54cd\u5c31\u5f88\u5c0f \u90a3\u4e48\u5982\u4f55\u89e3\u51b3\u5462\uff1f\u6bd4\u8f83\u65e9\u5e74\u7684\u505a\u6cd5\u662f\u53bbtrain RBM\uff0c\u601d\u60f3\u5c31\u662f\uff1a\u5148\u628a\u7b2c\u4e00\u4e2alayer train\u597d\uff0c\u518d\u53bbtrain\u7b2c\u4e8c\u4e2a\uff0c\u7136\u540e\u518d\u7b2c\u4e09\u4e2a... \u4f46\u5176\u5b9e\u6539\u4e00\u4e0b activation function \u53ef\u80fd\u5c31\u53ef\u4ee5 handle \u8fd9\u4e2a\u95ee\u9898 ReLU \u00b6 \u73b0\u5728\u6bd4\u8f83\u5e38\u7528\u7684 activation function \u53eb\u505a Rectified Linear Unit (\u6574\u6d41\u7ebf\u6027\u5355\u5143\u51fd\u6570\uff0c\u53c8\u79f0\u4fee\u6b63\u7ebf\u6027\u5355\u5143)\uff0c\u5b83\u7684\u7f29\u5199\u662fReLU \u9009\u62e9 ReLU \u7684\u7406\u7531\u5982\u4e0b\uff1a \u8ddf sigmoid function \u6bd4\u8d77\u6765\uff0cReLU \u7684\u8fd0\u7b97\u5feb\u5f88\u591a ReLU \u7684\u60f3\u6cd5\u7ed3\u5408\u4e86\u751f\u7269\u4e0a\u7684\u89c2\u5bdf ( Pengel \u7684 paper ) \u65e0\u7a77\u591a bias \u4e0d\u540c\u7684 sigmoid function \u53e0\u52a0\u7684\u7ed3\u679c\u4f1a\u53d8\u6210 ReLU ReLU \u53ef\u4ee5\u5904\u7406 Vanishing gradient \u7684\u95ee\u9898 ( the most important thing ) \u7528 ReLU \u65f6\uff0coutput \u8981\u4e48 = 0\uff0c \u8981\u4e48 = input\uff0c\u5f53 output = 0\u65f6\uff0c\u90a3\u4e2a neuron \u5bf9\u6574\u4e2a network \u662f\u6ca1\u6709\u4efb\u4f55\u4f5c\u7528\u7684\uff0c\u56e0\u6b64\u53ef\u4ee5\u4ece network \u4e2d\u62ff\u6389\uff0c\u62ff\u6389\u4e4b\u540e network \u5c31\u53d8\u6210\u4e86\u4e00\u5171\u7626\u957f\u7684 linear network\uff0clinear \u7684\u597d\u5904\u65f6\u4e0d\u4f1a\u6709 Vanishing Gradient Q\uff1alinear function \u4f1a\u4e0d\u4f1a\u5f88\u5f31\uff1f A\uff1a\u4f7f\u7528 ReLU \u540e\u7684 network \u6574\u4f53\u8fd8\u662f non-linear\uff0cinput \u505a\u51fa\u8f83\u5927\u6539\u53d8\u65f6\uff0c\u5c31\u4f1a\u5bfc\u81f4 neuron \u7684 operation region \u7684\u6539\u53d8 Q\uff1aReLU \u662f\u5206\u65ad\u8fd8\u662f\uff0c\u6ca1\u529e\u6cd5\u5fae\u5206 A\uff1a\u5728\u5b9e\u9645\u64cd\u4f5c\u4e0a\uff0c\u5f53 region \u7684\u8303\u56f4\u5904\u4e8e z>0 \u65f6\uff0c\u5fae\u5206\u503c gradient \u5c31\u662f 1\uff1b\u5f53 region \u7684\u8303\u56f4\u5904\u4e8e z<0 \u65f6\uff0c\u5fae\u5206\u503c gradient \u5c31\u662f 0\uff1b\u5f53 z \u4e3a 0 \u65f6\uff0c\u5c31\u4e0d\u8981\u7ba1\u5b83 ReLU-variant \u00b6 ReLU \u5728 update \u53c2\u6570\u65f6\u5728 input<0 \u65f6\u65e0\u6cd5\u66f4\u65b0\u53c2\u6570\uff0c\u5982\u679c\u5728 input<0 \u65f6\uff0c\u5fae\u5206\u8fd8\u80fd\u6709\u4e00\u70b9\u7684\u503c\uff0c\u6bd4\u5982\u4ee4 \\(a=0.01z\\) \u200b\u200b\uff0c\u8fd9\u4e2a\u4e1c\u897f\u5c31\u53eb\u505a Leaky ReLU \u90a3\u4e48 \\(z\\) \u7684\u7cfb\u6570\u53ef\u4e0d\u53ef\u4ee5\u662f\u5176\u4ed6\u7684\u5462\uff1f\u4e8e\u662f\u5c31\u63d0\u51fa\u4e86 Parametric ReLU \uff0c \\(a=\\alpha \\cdot z\\) \uff0c\u5176\u4e2d \\(\\alpha\\) \u200b \u4e0d\u662f\u56fa\u5b9a\u7684\u503c\uff0c\u800c\u662f network \u7684\u4e00\u4e2a\u53c2\u6570\uff0c\u901a\u8fc7 training data \u5b66\u4e60\u51fa\u6765 \u66f4\u8fdb\u4e00\u6b65\uff0c\u4e3a\u4ec0\u4e48\u4e00\u5b9a\u8981\u662f ReLU \u7684\u6837\u5b50\u5462\uff1factivation function \u53ef\u4e0d\u53ef\u4ee5\u6709\u522b\u7684\u6837\u5b50\u5462\uff1f\u6240\u4ee5\u540e\u6765\u6709\u4e86\u4e00\u4e2a\u66f4\u8fdb\u9636\u7684\u60f3\u6cd5\uff0c\u53eb\u505a Maxout network Maxout \u00b6 Maxout \u7684\u60f3\u6cd5\u662f\uff0c\u8ba9 network \u81ea\u52a8\u53bb\u5b66\u4e60\u5b83\u7684 activation function\uff0c\u90a3 Maxout network \u5c31\u53ef\u4ee5\u81ea\u52a8\u5b66\u51fa ReLU\uff0c\u4e5f\u53ef\u4ee5\u5b66\u51fa\u5176\u4ed6\u7684 activation function\uff0c\u8fd9\u4e00\u5207\u90fd\u662f\u7531 training data \u6765\u51b3\u5b9a\u7684 \u5047\u8bbe\u73b0\u5728\u6709 input \\(x_1,x_2\\) \uff0c\u5b83\u4eec\u4e58\u4e0a\u51e0\u7ec4\u4e0d\u540c\u7684 weight \u5206\u522b\u5f97\u5230 5,7,-1,1\uff0c\u8fd9\u4e9b\u503c\u672c\u6765\u662f\u4e0d\u540c neuron \u7684 input\uff0c\u5b83\u4eec\u8981\u901a\u8fc7 activation function \u53d8\u4e3a neuron \u7684 output\uff1b\u4f46\u5728Maxout network \u91cc\uff0c\u6211\u4eec\u4e8b\u5148\u51b3\u5b9a\u597d\u5c06\u67d0\u51e0\u4e2a \"neuron\" \u7684 input \u5206\u4e3a\u4e00\u4e2a group\uff0c\u6bd4\u59825,7 \u5206\u4e3a\u4e00\u4e2a group\uff0c\u7136\u540e\u5728\u8fd9\u4e2a group \u91cc\u9009\u53d6\u4e00\u4e2a\u6700\u5927\u503c 7 \u4f5c\u4e3a output \u8fd9\u4e2a\u8fc7\u7a0b\u5c31\u597d\u50cf\u5728\u4e00\u4e2a layer \u4e0a\u505a Max Pooling \u4e00\u6837\uff0c\u5b83\u548c\u539f\u6765\u7684 network \u4e0d\u540c\u4e4b\u5904\u5728\u4e8e\uff0c\u5b83\u628a\u539f\u6765\u51e0\u4e2a \"neuron\" \u7684 input \u6309\u4e00\u5b9a\u89c4\u5219\u7ec4\u6210\u4e86\u4e00\u4e2a group\uff0c\u7136\u540e\u5e76\u6ca1\u6709\u4f7f\u5b83\u4eec\u901a\u8fc7 activation function\uff0c\u800c\u662f\u9009\u53d6\u5176\u4e2d\u7684\u6700\u5927\u503c\u5f53\u505a\u8fd9\u51e0\u4e2a \"neuron\" \u7684 output \u5f53\u7136\uff0c\u5b9e\u9645\u4e0a\u539f\u6765\u7684 \"neuron\" \u65e9\u5c31\u5df2\u7ecf\u4e0d\u5b58\u5728\u4e86\uff0c\u8fd9\u51e0\u4e2a\u88ab\u5408\u5e76\u7684 \"neuron\" \u5e94\u5f53\u88ab\u770b\u505a\u662f\u4e00\u4e2a\u65b0\u7684 neuron\uff0c\u8fd9\u4e2a\u65b0\u7684 neuron \u7684 input \u662f\u539f\u6765\u51e0\u4e2a \"neuron\" \u7684 input \u7ec4\u6210\u7684 vector\uff0coutput \u5219\u53d6 input \u7684\u6700\u5927\u503c\uff0c\u800c\u5e76\u975e\u7531 activation function \u4ea7\u751f group \u7684\u5927\u5c0f\u7531\u81ea\u5df1\u51b3\u5b9a \u90a3\u5982\u679c\u8bf4 Maxout \u53ef\u4ee5\u6a21\u4eff\u51fa\u5176\u4ed6\u7684 activation function\uff0c\u90a3\u662f\u5982\u4f55\u6a21\u4eff\u51fa ReLU \u7684\u5462\uff1f \u5176\u5b9e\u53ea\u8981 \\(z_2\\) \u7684 2 \u4e2a\u53c2\u6570\u90fd\u8bbe\u4e3a 0\uff0c\u7136\u540e\u505a Max Pooling \u5373\u53ef \u90a3\u6a21\u4eff\u51fa\u5176\u4ed6\u7684 activation function \u5462\uff1f \u6bd4\u5982 \\(z_2\\) \u7684\u53c2\u6570 w \u548c b \u4e0d\u662f0\uff0c\u800c\u662f \\(w',b'\\) \u200b\uff0c\u6b64\u65f6\u5982\u4e0b\u56fe\uff0cMax Pooling \u4f7f 2 \u6761\u76f4\u7ebf\u5f62\u6210\u4e00\u4e2a V \u5b57\u578b Maxout \u53ef\u4ee5\u5b9e\u73b0\u4efb\u4f55 piecewise linear convex activation function (\u5206\u6bb5\u7ebf\u6027\u51f8\u6fc0\u6d3b\u51fd\u6570)\uff0c\u5206\u51e0\u6bb5\u53d6\u51b3\u4e8e\u4e00\u4e2a group \u6709\u51e0\u4e2a input How to train Maxout \u00b6 \u5176\u5b9e Max operation \u5c31\u662f linear \u7684 operation\uff0c\u5c31\u50cf\u524d\u9762 ReLU \u63d0\u5230\u7684\u4e00\u6837\uff0c\u6574\u4f53\u6765\u8bf4\u4e0d\u662f Linear \u7684\uff0c\u4f46\u662f\u5f53\u628a data \u653e\u8fdb\u53bb\u540e\u4e00\u4e9b neuron \u5c31\u88ab\u6682\u65f6\u9690\u85cf\u4e86\uff0c\u6b64\u65f6\u5c31\u662f linear \u7684\uff1b\u8fd9\u4e9b\u88ab\u9690\u85cf\u7684 neuron \u4f1a\u5728\u4e0d\u540c\u7684 input data \u4e2d\u88ab\u8bad\u7ec3\u5230 Adaptive Learning Rate \u00b6 \u524d\u9762\u5df2\u7ecf\u8bb2\u8fc7 Adagrad \u7684\u505a\u6cd5\uff0c\u4f46\u5b9e\u9645\u95ee\u9898\u4e2d\u53ef\u80fd\u8fdc\u6bd4 Adagrad \u80fd\u505a\u7684\u95ee\u9898\u8981\u6765\u7684\u590d\u6742 RMSProp \u00b6 loss function \u4e5f\u6709\u53ef\u80fd\u4e00\u4f1a\u513f\u5e73\u5766\u4e00\u4f1a\u513f\u9661\u5ced\uff0c\u6240\u4ee5\u4f60\u8981\u968f\u65f6\u6839\u636e gradient \u7684\u5927\u5c0f\u6765\u5feb\u901f\u5730\u8c03\u6574 learning rate\uff0c\u771f\u6b63\u8981\u5904\u7406 deep learning \u7684\u95ee\u9898\uff0c\u7528 Adagrad \u53ef\u80fd\u662f\u4e0d\u591f\u7684\uff0c\u4f60\u9700\u8981\u66f4 dynamic \u7684\u8c03\u6574 learning rate \u7684\u65b9\u6cd5\uff0c\u6240\u4ee5\u4ea7\u751f \u4e86Adagrad \u7684\u8fdb\u9636\u7248\u2014\u2014 RMSProp learning rate \u4f9d\u65e7\u8bbe\u7f6e\u4e3a\u4e00\u4e2a\u56fa\u5b9a\u7684\u503c \\(\\eta\\) \u9664\u6389\u4e00\u4e2a\u53d8\u5316\u7684\u503c \\(\\sigma\\) \uff0c\u8fd9\u4e2a \\(\\sigma\\) \u7b49\u4e8e\u4e0a\u4e00\u4e2a \\(\\sigma\\) \u548c\u5f53\u524d\u68af\u5ea6 \\(g\\) \u7684\u52a0\u6743\u65b9\u5747\u6839\uff08\u7279\u522b\u7684\u662f\uff0c\u5728\u7b2c\u4e00\u4e2a\u65f6\u95f4\u70b9\uff0c \\(\\sigma^0\\) \u5c31\u662f\u7b2c\u4e00\u4e2a\u7b97\u51fa\u6765\u7684gradient\u503c \\(g^0\\) \u200b\uff09\uff0c\u5373\uff1a $$ \\begin{align} w^{t+1}&=w^t-\\frac{\\eta}{\\sigma^t}g^t \\ \\sigma^t&=\\sqrt{\\alpha(\\sigma^{t-1})^2+(1-\\alpha)(g^t)^2} \\end{align} $$ \\(\\alpha\\) \u200b \u503c\u662f\u53ef\u4ee5\u81ea\u7531\u8c03\u6574\u7684\uff0cRMSProp \u8ddf Adagrad \u4e0d\u540c\u4e4b\u5904\u5728\u4e8e\uff0cAdagrad \u7684\u5206\u6bcd\u662f\u5bf9\u8fc7\u7a0b\u4e2d\u6240\u6709\u7684 gradient \u53d6\u5e73\u65b9\u548c\u5f00\u6839\u53f7\uff0c\u4e5f\u5c31\u662f\u8bf4 Adagrad \u8003\u8651\u7684\u662f\u6574\u4e2a\u8fc7\u7a0b\u5e73\u5747\u7684 gradient \u4fe1\u606f\uff1b\u800c RMSProp \u867d\u7136\u4e5f\u662f\u5bf9\u6240\u6709\u7684 gradient \u8fdb\u884c\u5e73\u65b9\u548c\u5f00\u6839\u53f7\uff0c\u4f46\u662f\u5b83 \u7528\u4e00\u4e2a \\(\\alpha\\) \u200b \u6765\u8c03\u6574\u5bf9\u4e0d\u540c gradient \u7684\u4f7f\u7528\u7a0b\u5ea6 \uff0c\u6bd4\u5982\u4f60\u628a \\(\\alpha\\) \u7684\u503c\u8bbe\u7684\u5c0f\u4e00\u70b9\uff0c\u610f\u601d\u5c31\u662f\u4f60\u66f4\u503e\u5411\u4e8e\u76f8\u4fe1\u65b0\u7684 gradient \u6240\u544a\u8bc9\u4f60\u7684 error surface \u7684\u5e73\u6ed1\u6216\u9661\u5ced\u7a0b\u5ea6\uff0c\u800c\u6bd4\u8f83\u65e0\u89c6\u4e8e\u65e7\u7684gradient \u6240\u63d0\u4f9b\u7ed9\u4f60\u7684 information Momentum \u00b6 \u9664\u4e86 learning rate \u7684\u95ee\u9898\u4ee5\u5916\uff0c\u5728\u505a deep learning \u7684\u65f6\u5019\uff0c\u5f88\u591a\u4eba\u62c5\u5fc3\u4f1a\u5361\u5728 local minimum\u3001saddle point \u6216\u662f plateau \u7684\u5730\u65b9\uff1b\u4f46\u5176\u5b9e Yann LeCun \u5728 07 \u5e74\u7684\u65f6\u5019\uff0c\u5c31\u63d0\u51fa\u4e86\u4e00\u4e2a\u86ee\u7279\u522b\u7684\u8bf4\u6cd5\uff0c\u4ed6\u8bf4\u4f60\u4e0d\u8981\u592a\u62c5\u5fc3 local minima \u7684\u95ee\u9898\uff0c\u56e0\u4e3a\u4e00\u65e6\u51fa\u73b0 local minima\uff0c\u5b83\u5c31\u5fc5\u987b\u5728\u6bcf\u4e00\u4e2a dimension \u90fd\u662f\u5c71\u8c37\u7684\u4f4e\u8c37\u5f62\u72b6\uff0c\u53c2\u6570\u975e\u5e38\u591a\u65f6\u8fd9\u79cd\u6982\u7387\u662f\u975e\u5e38\u5c0f\u7684 \u6709\u4e00\u4e2a heuristic(\u542f\u53d1\u6027) \u7684\u65b9\u6cd5\u53ef\u4ee5\u7a0d\u5fae\u5904\u7406\u4e00\u4e0b\u4e0a\u9762\u6240\u8bf4\u7684 \"\u5361\u4f4f\" \u7684\u95ee\u9898\uff0c\u5b83\u7684\u7075\u611f\u6765\u81ea\u4e8e\u771f\u5b9e\u4e16\u754c\uff1a\u628a\u60ef\u6027\u52a0\u5230 gradient descent \u91cc\u9762\uff0c\u8fd9\u4ef6\u4e8b\u60c5\u5c31\u53eb\u505a Momentum how to do Momentum\uff1f \u5f53\u6211\u4eec\u5728 gradient descent \u91cc\u52a0\u4e0a Momentum \u7684\u65f6\u5019\uff0c\u6bcf\u4e00\u6b21 update \u7684\u65b9\u5411\uff0c\u4e0d\u518d\u53ea\u8003\u8651 gradient \u7684\u65b9\u5411\uff0c\u8fd8\u8981\u8003\u8651\u4e0a\u4e00\u6b21 update \u7684\u65b9\u5411\uff0c\u90a3\u8fd9\u91cc\u6211\u4eec\u5c31\u7528\u4e00\u4e2a\u53d8\u91cf \\(v\\) \u53bb\u8bb0\u5f55\u524d\u4e00\u4e2a\u65f6\u95f4\u70b9 update \u7684\u65b9\u5411 \u968f\u673a\u9009\u4e00\u4e2a\u521d\u59cb\u503c \\(\\theta^0\\) \uff0c\u521d\u59cb\u5316 \\(v^0=0\\) \uff0c\u63a5\u4e0b\u6765\u8ba1\u7b97 \\(\\theta^0\\) \u5904\u7684 gradient\uff0c\u7136\u540e\u6211\u4eec\u8981\u79fb\u52a8\u7684\u65b9\u5411\u662f\u7531\u524d\u4e00\u4e2a\u65f6\u95f4\u70b9\u7684\u79fb\u52a8\u65b9\u5411 \\(v^0\\) \u548c gradient \u7684\u53cd\u65b9\u5411 \\(\\nabla L(\\theta^0)\\) \u6765\u51b3\u5b9a\u7684\uff0c\u5373 $$ v^1=\\lambda v^0-\\eta \\nabla L(\\theta^0) $$ \u6ce8\uff1a\u8fd9\u91cc\u7684 \\(\\lambda\\) \u4e5f\u662f\u4e00\u4e2a\u624b\u52a8\u8c03\u6574\u7684\u53c2\u6570\uff0c\u5b83\u8868\u793a\u60ef\u6027\u5bf9\u524d\u8fdb\u65b9\u5411\u7684\u5f71\u54cd\u6709\u591a\u5927 \u5176\u5b9e\u6bcf\u4e00\u4e2a\u65f6\u95f4\u70b9\u8981\u79fb\u52a8\u7684\u6b65\u4f10 \\(v^i\\) \u200b\uff0c\u5305\u62ec\u5927\u5c0f\u548c\u65b9\u5411\uff0c\u90fd\u662f\u524d\u9762\u6240\u6709 gradient \u7684\u52a0\u6743\u548c\uff0c\u4f46\u8d8a\u4e4b\u524d\u7684 gradient \u7684\u6743\u91cd\u8d8a\u5c0f Adam \u00b6 \u5176\u5b9e RMSProp \u52a0\u4e0a Momentum\uff0c\u5c31\u53ef\u4ee5\u5f97\u5230 Adam \u6839\u636e\u4e0b\u9762\u7684 paper \u6765\u5feb\u901f\u63cf\u8ff0\u4e00\u4e0b Adam \u7684 algorithm\uff1a \u5148\u521d\u59cb\u5316 \\(m_0=0\\) \u200b\uff0c \\(m_0\\) \u200b\u5c31\u662f Momentum \u4e2d\uff0c\u524d\u4e00\u4e2a\u65f6\u95f4\u70b9\u7684 movement \u518d\u521d\u59cb\u5316 \\(v_0=0\\) \u200b\uff0c \\(v_0\\) \u200b \u5c31\u662f RMSProp \u91cc\u8ba1\u7b97 gradient \u7684 root mean square \u7684 \\(\\sigma\\) \u200b \u6700\u540e\u521d\u59cb\u5316 \\(t=0\\) \u200b\uff0ct \u7528\u6765\u8868\u793a\u65f6\u95f4\u70b9 \u5148\u7b97\u51fa gradient \\(g_t\\) $$ g_t=\\nabla {\\theta}f_t(\\theta {t-1}) $$ \u518d\u6839\u636e\u8fc7\u53bb\u8981\u8d70\u7684 movement \\(m_{t-1}\\) \u548c gradient \\(g_t\\) \uff0c\u7b97\u51fa\u73b0\u5728\u8981\u8d70\u7684 movement \\(m_t\\) \u2014\u2014Momentum $$ m_t=\\beta_1 m_{t-1}+(1-\\beta_1) g_t $$ \u7136\u540e\u6839\u636e\u524d\u4e00\u4e2a\u65f6\u95f4\u70b9\u7684 \\(v_{t-1}\\) \u200b\u200b \u548c gradient \\(g_t\\) \u200b\u200b \u7684\u5e73\u65b9\uff0c\u7b97\u4e00\u4e0b\u653e\u5728\u5206\u6bcd\u7684 \\(v_t\\) \u200b\u200b\u2014\u2014RMSProp $$ v_t=\\beta_2 v_{t-1}+(1-\\beta_2) g_t^2 $$ \u63a5\u4e0b\u6765\u505a\u4e86\u4e00\u4e2a\u539f\u6765 RMSProp \u548c Momentum \u91cc\u6ca1\u6709\u7684\u4e1c\u897f\uff0c\u5c31\u662f bias correction\uff0c\u5b83\u4f7f \\(m_t\\) \u200b\u200b\u200b \u548c \\(v_t\\) \u200b\u200b\u200b\u200b \u90fd\u9664\u4e0a\u4e00\u4e2a\u503c\uff0c\u8fd9\u4e2a\u503c\u672c\u6765\u6bd4\u8f83\u5c0f\uff0c\u540e\u6765\u4f1a\u8d8a\u6765\u8d8a\u63a5\u8fd1\u4e8e1\uff08 \\(\\beta_1^t\\) \u548c \\(\\beta_2^t\\) \u4f1a\u8d8a\u6765\u8d8a\u5c0f\uff09 $$ \\begin{align} \\hat{m}_t=\\frac{m_t}{1-\\beta_1^t} \\ \\hat{v}_t=\\frac{v_t}{1-\\beta_2^t} \\end{align} $$ \u6700\u540e\u505a update\uff0c\u628a Momentum \u5efa\u8bae\u4f60\u7684\u65b9\u5411 \\(\\hat{m_t}\\) \u4e58\u4e0a learning rate \\(\\alpha\\) \uff0c\u518d\u9664\u6389 RMSProp normalize \u540e\u5efa\u8bae\u7684 learning rate \u5206\u6bcd\uff0c\u7136\u540e\u5f97\u5230 update \u7684 movement $$ \\theta_t=\\theta_{t-1}-\\frac{\\alpha \\cdot \\hat{m}_t}{\\sqrt{\\hat{v}_t}+\\epsilon} $$ Good Results on Testing Data\uff1f \u00b6 \u5982\u679c training data \u4e0a\u5f97\u5230\u4e86\u597d\u7684 performance\uff0c\u4f46\u662f testing set \u4e0a\u6ca1\u6709\uff0c\u90a3\u624d\u662f overfitting \u56de\u53bb\u89e3\u51b3 overfitting \u65f6\u589e\u52a0\u4e86\u65b0\u7684 technique \u540e\u4f1a\u8ba9 training set \u4e0a\u7684\u7ed3\u679c\u53d8\u574f\uff0c\u6240\u4ee5\u9700\u8981\u91cd\u65b0\u68c0\u67e5 model \u5728 training set \u4e0a\u7684\u7ed3\u679c\uff1b\u5982\u679c\u53d8\u574f\u7684\u8bdd\uff0c\u53ef\u80fd\u5c31\u9700\u8981\u4ece\u5934\u5bf9 network training \u7684 process \u505a\u4e00\u4e9b\u8c03\u6574\uff1b\u5982\u679c training set \u548c testing set \u4e0a\u90fd\u6709\u597d\u7684\u7ed3\u679c\uff0c\u90a3\u5c31\u6210\u529f\u4e86 \u5206\u4e3a\u4e09\u4e2a\u6a21\u5757\uff0cEarly Stopping\u3001Regularization \u548c Dropout \u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0cEarly Stopping \u548c Regularization \u662f\u5f88 typical \u7684\u505a\u6cd5\uff0c\u5b83\u4eec\u4e0d\u662f\u7279\u522b\u4e3adeep learning \u6240\u8bbe\u8ba1\u7684\uff1b\u800c Dropout \u662f\u4e00\u4e2a\u86ee\u6709 deep learning \u7279\u8272\u7684\u505a\u6cd5 Early Stopping \u00b6 \u7406\u60f3\u4e0a\u5047\u5982\u4f60\u77e5\u9053 testing data \u4e0a\u7684 loss \u53d8\u5316\u60c5\u51b5\uff0c\u4f60\u4f1a\u5728 testing set \u7684 loss \u6700\u5c0f\u7684\u65f6\u5019\u505c\u4e0b\u6765\uff0c\u800c\u4e0d\u662f\u5728 training set \u7684 loss \u6700\u5c0f\u7684\u65f6\u5019\u505c\u4e0b\u6765\uff1b\u4f46 testing set \u5b9e\u9645\u4e0a\u662f\u672a\u77e5\u7684\u4e1c\u897f\uff0c\u6240\u4ee5\u6211\u4eec\u9700\u8981\u7528 validation set \u6765\u66ff\u4ee3\u5b83\u53bb\u505a\u8fd9\u4ef6\u4e8b\u60c5 Regularization \u00b6 regularization \u5c31\u662f\u5728\u539f\u6765\u7684 loss function \u4e0a\u989d\u5916\u589e\u52a0\u51e0\u4e2a term\uff0c\u5bf9\u6bcf\u4e00\u4e2a\u53c2\u6570\u90fd\u8bbe\u7f6e\u4e00\u4e2a\u60e9\u7f5a\u9879\uff0c\u53ef\u4ee5\u8ba9\u6700\u540e\u7684 model \u53d8\u5e73\u6ed1\u4ee5\u9632\u6b62 overfitting \u4e0b\u9762\u7684\u8303\u6570\u4f3c\u4e4e\u548c\u5176\u4ed6\u5730\u65b9\u4e0d\u592a\u4e00\u6837 L2 regularization\uff1a\u5b9a\u4e49\u65b0\u7684 loss function $$ \\begin{align} L'(\\theta)&=L(\\theta)+\\frac{1}{2}\\lambda||\\theta||_2 \\ ||\\theta||_2&=(w_1)^2+(w_2)^2+... \\end{align} $$ L1 regularization\uff1a\u5b9a\u4e49\u65b0\u7684 loss function $$ \\begin{align} L'(\\theta)&=L(\\theta)+\\frac{1}{2}\\lambda||\\theta||_1 \\ ||\\theta||_2&=|w_1|+|w_2|+... \\end{align} $$ Q\uff1aL1 regularization \u5982\u4f55\u5fae\u5206\uff1f A\uff1aV \u5b57\u5f62\uff0c\u53f3\u8fb9\u662f 1\uff0c\u5de6\u8fb9\u662f -1\uff0c \u4e3a 0 \u968f\u4fbf\u7ed9\u4e00\u4e2a\u503c\u6bd4\u5982 0 L2 regularization \u5f53\u53c2\u6570\u6bd4\u8f83\u5c0f\u7684\u65f6\u5019\u4e0b\u964d\u7684\u4f1a\u5f88\u6162\uff0c\u53c2\u6570\u6bd4\u8f83\u5927\u7684\u65f6\u5019\u4e0b\u964d\u7684\u65f6\u5019\u4f1a\u5f88\u5feb\uff0c\u6240\u4ee5\u6700\u540e train \u51fa\u6765\u7684\u53c2\u6570\u90fd\u662f\u6bd4\u8f83\u5c0f\u7684 L1 regularization \u6bcf\u6b21\u90fd\u4e0b\u964d\u56fa\u5b9a\u7684\u503c\uff0c\u6240\u4ee5 train \u51fa\u6765\u6709\u5f88\u591a\u53c2\u6570\u63a5\u8fd1 0\uff0c\u4e5f\u4f1a\u6709\u5f88\u5927\u7684\u503c \uff08\u8fd9 2 \u79cd loss function \u7ecf\u5e38\u7528\u4e8e\u6570\u636e\u964d\u7ef4\u4e4b\u4e2d\uff0c\u5982 \u5cad\u56de\u5f52 \u548c Lasso\uff09 Dropout \u00b6 training \u7684\u65f6\u5019\uff0c\u6bcf\u6b21 update \u53c2\u6570\u4e4b\u524d\uff0c\u6211\u4eec\u5bf9\u6bcf\u4e00\u4e2a neuron (\u4e5f\u5305\u62ec input layer \u7684 \"neuron\") \u505asampling (\u62bd\u6837) \uff0c\u6bcf\u4e2a neuron \u90fd\u6709 p% \u7684\u51e0\u7387\u4f1a\u88ab\u4e22\u6389\uff0c\u5982\u679c\u67d0\u4e2a neuron \u88ab\u4e22\u6389\u7684\u8bdd\uff0c\u8ddf\u5b83\u76f8\u8fde\u7684weight\u4e5f\u90fd\u8981\u88ab\u4e22\u6389 \u5b9e\u9645\u4e0a\u5c31\u662f\u6bcf\u6b21 update \u53c2\u6570\u4e4b\u524d\u90fd\u901a\u8fc7\u62bd\u6837\u53ea\u4fdd\u7559 network \u4e2d\u7684\u4e00\u90e8\u5206 neuron \u6765\u505a\u8bad\u7ec3 \u6ce8\uff1a\u6bcf\u6b21 update \u53c2\u6570\u4e4b\u524d\u90fd\u8981\u505a\u4e00\u904d sampling\uff0c\u6240\u4ee5\u6bcf\u6b21 update \u53c2\u6570\u7684\u65f6\u5019\uff0c\u62ff\u6765 training \u7684 network structure \u90fd\u662f\u4e0d\u4e00\u6837\u7684\uff1b\u4f60\u53ef\u80fd\u4f1a\u89c9\u5f97\u8fd9\u4e2a\u65b9\u6cd5\u8ddf\u524d\u9762\u63d0\u5230\u7684 Maxout \u4f1a\u6709\u4e00\u70b9\u50cf\uff0c\u4f46\u5b9e\u9645\u4e0a\uff0cMaxout \u662f\u6bcf\u4e00\u7b14 data \u5bf9\u5e94\u7684 network structure \u4e0d\u540c\uff0c\u800c Dropout \u662f\u6bcf\u4e00\u6b21 update \u7684network structure \u90fd\u662f\u4e0d\u540c\u7684 (\u6bcf\u4e00\u4e2a minibatch \u5bf9\u5e94\u7740\u4e00\u6b21 update\uff0c\u800c\u4e00\u4e2a minibatch \u91cc\u542b\u6709\u5f88\u591a\u7b14 data) \u4f7f\u7528 dropout\uff0c\u5f97\u5230\u7684 train performance \u5176\u5b9e\u662f\u4f1a\u53d8\u5dee\u7684\uff0c\u4f46\u8fd9\u5e76\u4e0d\u662f\u95ee\u9898\uff0c\u56e0\u4e3a\uff1a Dropout \u771f\u6b63\u8981\u505a\u7684\u4e8b\u60c5\uff0c\u5c31\u662f\u8981\u8ba9\u4f60\u5728 training set \u4e0a\u7684\u7ed3\u679c\u53d8\u5dee\uff0c\u4f46\u662f\u5728 testing set \u4e0a\u7684\u7ed3\u679c\u662f\u53d8\u597d\u7684 \u8981\u6ce8\u610f\u7684\u662f Dropout \u662f\u5728 training \u4e0a\u8868\u73b0\u597d\u800c testing \u4e0a\u8868\u73b0\u4e0d\u597d\u624d\u505a\u7684 \u9700\u8981\u6ce8\u610f\u7684\u4e8b\uff1a testing \u7684\u65f6\u5019\u4e0d\u505a dropout\uff0c\u6240\u6709\u7684 neuron \u90fd\u8981\u88ab\u7528\u5230 \u5047\u8bbe\u5728 training \u7684\u65f6\u5019\uff0cdropout rate \u662fp%\uff0c\u4ece training data \u4e2d\u88ab learn \u51fa\u6765\u7684\u6240\u6709 weight \u90fd\u8981\u4e58\u4e0a (1-p%) \u624d\u80fd\u88ab\u5f53\u505a testing \u7684 weight \u4f7f\u7528 Do not always blame overfitting \u00b6 \u4e0d\u80fd\u53ea\u770b\u53f3\u8fb9\u7684\u56fe\u5c31\u8bf4\u662f overfitting\uff0c\u56e0\u4e3a\u53ef\u80fd\u672c\u6765 56-layer \u7684 model \u5c31\u6bd4 20-layer \u7684model \u8868\u73b0\u7684\u66f4\u5dee\uff1b\u4e5f\u4e0d\u80fd\u8bf4\u662f underfitting\uff0c\u56e0\u4e3a underfitting \u7684\u672c\u610f\u662f\u6307 model \u7684 complexity \u4e0d\u8db3\uff0c\u6240\u4ee5\u8fd9\u79cd\u60c5\u51b5\u5176\u5b9e\u53ea\u662f\u6ca1\u6709 train \u597d\uff0c\u6bd4\u5982\u6709 local minimum \u7684\u95ee\u9898\uff0c\u6709 saddle point \u7684\u95ee\u9898\uff0c\u6709 plateau \u7684\u95ee\u9898... Why Deep? \u00b6 \u5728\u76f8\u540c\u53c2\u6570\u7684\u60c5\u51b5\u4e0b\uff0cshallow network \u548c deep network \u76f8\u6bd4\u4e00\u822c\u662f deep network \u8868\u73b0\u4f1a\u597d\u4e00\u4e9b deep learning \u4e2d\u7684\u6bcf\u4e00\u5c42\u7684 layer \u90fd\u662f\u4e00\u4e2a\u5b50\u4efb\u52a1\uff0c\u505a\u597d\u540e\u7531\u4e0b\u4e00\u5c42\u53bb\u505a\u8fdb\u4e00\u6b65\u7684\u4efb\u52a1\uff0c\u800c shallow network \u505a\u4e0d\u5230\u8fd9\u6837 \u4e00\u4e2a\u5f88\u597d\u7684\u4f8b\u5b50\u662f\uff0c\u8981\u628a input \u7684\u4eba\u7269\u5206\u4e3a\u56db\u7c7b\uff1a\u957f\u5934\u53d1\u5973\u751f\u3001\u957f\u5934\u53d1\u7537\u751f\u3001\u77ed\u5934\u53d1\u5973\u751f\u3001\u77ed\u5934\u53d1\u7537\u751f \u5982\u679c\u7528 shallow network \u5c31\u662f\u5206\u522b\u72ec\u7acb\u5730 train \u56db\u4e2a classifier (\u5c31\u76f8\u5f53\u4e8e\u8bad\u7ec3\u56db\u4e2a\u72ec\u7acb\u7684 model)\uff0c\u7136\u540e\u5c31\u53ef\u4ee5\u89e3\u51b3\u8fd9\u4e2a\u5206\u7c7b\u7684\u95ee\u9898\uff1b\u4f46\u662f\u6709\u4e00\u4e2a\u95ee\u9898\u662f\uff0c\u957f\u5934\u53d1\u7537\u751f\u7684 data \u662f\u6bd4\u8f83\u5c11\u7684\uff0c\u6ca1\u6709\u592a\u591a\u7684 training data\uff0c\u6240\u4ee5\uff0c\u4f60 train \u51fa\u6765\u7684 classifier \u5c31\u6bd4\u8f83 weak\uff0c\u53bb detect \u957f\u5934\u53d1\u7537\u751f\u7684 performance \u5c31\u6bd4\u8f83\u5dee \u4f46\u662f\u7537\u751f\u4e0e\u5973\u751f\u7684 data\uff0c\u957f\u53d1\u4e0e\u77ed\u53d1\u7684 data \u662f\u5f88\u591a\u7684\uff0c\u6240\u4ee5\u5982\u679c\u7528 deep network \u7684\u8bdd\uff0c\u7ecf\u8fc7\u524d\u9762\u51e0\u5c42 layer \u7684\u7279\u5f81\u62bd\u53d6\uff0c\u5c31\u53ef\u4ee5\u5934\u53d1\u7684 data \u4e22\u7ed9\u4e00\u4e2a Classifier2\uff0c\u628a\u7537\u751f\u6216\u5973\u751f\u7684 data \u4e22\u7ed9\u4e00\u4e2a Classifier1\uff0c\u8fd9\u6837\u5c31\u771f\u6b63\u505a\u5230\u4e86\u5145\u5206\u3001\u9ad8\u6548\u5730\u5229\u7528\u6570\u636e\uff0c\u6700\u7ec8\u7684 Classifier \u518d\u6839\u636e Classifier1 \u548c Classifier2 \u63d0\u4f9b\u7684\u4fe1\u606f\u7ed9\u51fa\u56db\u7c7b\u4eba\u7684\u5206\u7c7b\u7ed3\u679c","title":"Deep Learning"},{"location":"ML/4_Deep%20learning/#deep-learning","text":"","title":"Deep Learning"},{"location":"ML/4_Deep%20learning/#neural-network","text":"","title":"Neural Network"},{"location":"ML/4_Deep%20learning/#concept","text":"\u628a\u591a\u4e2a Logistic Regression \u524d\u540e connect \u5728\u4e00\u8d77\uff0c\u7136\u540e\u628a\u4e00\u4e2a Logistic Regression \u79f0\u4e4b\u4e3a neuron\uff0c\u6574\u4e2a\u79f0\u4e4b\u4e3a neural network","title":"Concept"},{"location":"ML/4_Deep%20learning/#fully-connect-feedforward-network","text":"Neural Network \u7684\u8fde\u63a5\u65b9\u5f0f\u662f\u9700\u8981\u4f60\u624b\u52a8\u53bb\u8bbe\u8ba1\u7684\uff0c\u6700\u5e38\u89c1\u7684\u8fde\u63a5\u65b9\u5f0f\u53eb\u505a Fully Connect Feedforward Network (\u5168\u8fde\u63a5\u524d\u9988\u7f51\u7edc) Neural Network \u662f\u4e00\u5c42\u4e00\u5c42\u7684\u7ed3\u6784\uff0clayer \u548c layer \u4e4b\u95f4 neuron \u662f\u4e24\u4e24\u4e92\u76f8\u8fde\u63a5\u7684\uff0clayer1 \u7684 neuron output \u4f1a\u8fde\u63a5\u7ed9 layer2 \u7684\u6bcf\u4e00\u4e2a neuron \u4f5c\u4e3a input \u5206\u4e3a\u4e09\u7c7b\uff1ainput layer\uff0coutput layer\uff0chidden layer \u6bcf\u4e00\u4e2a neuron \u91cc\u9762\u7684 sigmoid function\uff0c\u5728 Deep Learning \u4e2d\u88ab\u79f0\u4e3a activation function (\u6fc0\u52b1\u51fd\u6570)\uff0c\u5e76\u4e0d\u4e00\u5b9a\u8981\u7528 sigmoid function\uff08\u800c\u4e14 sigmoid function \u73b0\u5728\u5df2\u7ecf\u7528\u7684\u5f88\u5c11\u4e86\uff09 \u6709\u5f88\u591a\u5c42 layers \u7684 neural network\uff0c\u88ab\u79f0\u4e3a DNN(Deep Neural Network) \u8fd9\u91cc\u9762\u7684\u6240\u6709\u53d8\u91cf\u90fd\u7528\u77e9\u9635\u7684\u5f62\u5f0f\u8868\u793a\uff0c\u56e0\u4e3a\u8fd9\u6837\u53ef\u4ee5\u5229\u7528 GPU \u52a0\u901f","title":"Fully Connect Feedforward Network"},{"location":"ML/4_Deep%20learning/#output-layer","text":"\u6211\u4eec\u53ef\u4ee5\u628a hidden layers \u8fd9\u90e8\u5206\uff0c\u770b\u505a\u662f\u4e00\u4e2a feature extractor(\u7279\u5f81\u63d0\u53d6\u5668) \uff0c\u8fd9\u4e2a feature extractor \u5c31 replace \u4e86\u6211\u4eec\u4e4b\u524d\u624b\u52a8\u505a feature engineering\uff0cfeature transformation \u8fd9\u4e9b\u4e8b\u60c5\uff0c\u7ecf\u8fc7\u8fd9\u4e2a feature extractor \u5f97\u5230\u7684 \\(x_1,x_2,...,x_k\\) \u5c31\u53ef\u4ee5\u88ab\u5f53\u4f5c\u4e00\u7ec4\u65b0\u7684 feature output layer \u505a\u7684\u4e8b\u60c5\uff0c\u5176\u5b9e\u5c31\u662f\u628a\u5b83\u5f53\u505a\u4e00\u4e2a Multi-class classifier \uff0c\u5b83\u662f\u62ff\u7ecf\u8fc7 feature extractor \u8f6c\u6362\u540e\u7684\u90a3\u4e00\u7ec4\u6bd4\u8f83\u597d\u7684 feature (\u80fd\u591f\u88ab\u5f88\u597d\u5730separate) \u8fdb\u884c\u5206\u7c7b\u7684\uff0c\u7531\u4e8e\u6211\u4eec\u628a output layer \u770b\u505a\u662f\u4e00\u4e2a Multi-class classifier\uff0c\u6240\u4ee5\u6211\u4eec\u4f1a\u5728\u6700\u540e\u4e00\u4e2a layer \u52a0\u4e0a softmax","title":"Output Layer"},{"location":"ML/4_Deep%20learning/#backpropagation","text":"Backpropagation(\u53cd\u5411\u4f20\u64ad)\uff0c\u5c31\u662f\u544a\u8bc9\u6211\u4eec\u7528 gradient descent \u6765 train\u4e00\u4e2a neural network \u7684\u65f6\u5019\u8be5\u600e\u4e48\u505a\uff0c\u5b83\u53ea\u662f\u6c42\u5fae\u5206\u7684\u4e00\u79cd\u65b9\u6cd5\uff0c\u800c\u4e0d\u662f\u4e00\u79cd\u65b0\u7684\u7b97\u6cd5 \u5bf9\u6574\u4e2a neural network\uff0c\u6211\u4eec\u5b9a\u4e49\u4e86\u4e00\u4e2a loss function\uff1a \\(L(\\theta)=\\sum\\limits_{n=1}^N l^n(\\theta)\\) \uff0c\u5b83\u7b49\u4e8e\u6240\u6709 training data \u7684 loss \u4e4b\u548c\uff0c\u5176\u4e2d \\(l^n\\) \u662f\u6837\u672c \\(x^n\\) \u4e0e target \\(\\hat{y}^n\\) \u7684 cross entropy\uff1b\u7136\u540e summary \u6240\u6709\u7684training data \u7684 cross entropy \u540e\u5f97\u5230 \\(L(\\theta)\\) \uff0c\u5bf9\u5176\u505a\u67d0\u4e00\u4e2a\u53c2\u6570w\u505a\u504f\u5fae\u5206\uff0c\u8868\u8fbe\u5f0f\u5982\u4e0b\uff1a $$ \\frac{\\partial L(\\theta)}{\\partial w}=\\sum\\limits_{n=1}^N\\frac{\\partial l^n(\\theta)}{\\partial w} $$ \u6240\u4ee5\u6211\u4eec\u53ea\u9700\u8981\u8003\u8651\u5982\u4f55\u8ba1\u7b97\u5bf9\u67d0\u4e00\u7b14 data \u7684 \\(\\frac{\\partial l^n(\\theta)}{\\partial w}\\) \u5373\u53ef \u5bf9\u4e8e\u5176\u4e2d\u4e00\u4e2a neuron\uff0c\u6709 \\(z=b+w_1 x_1+w_2 x_2\\) \uff0c\u90a3\u4e48 \\(\\frac{\\partial l}{\\partial w}=\\frac{\\partial z}{\\partial w} \\frac{\\partial l}{\\partial z}\\) \u4e2d\uff0c\u524d\u9762\u7684\u4e00\u4e2a\u662f\u6bd4\u8f83\u597d\u7b97\u7684\uff0c\u540e\u9762\u7684\u4e00\u4e2a\u662f\u6bd4\u8f83\u9ebb\u70e6\u7684","title":"Backpropagation"},{"location":"ML/4_Deep%20learning/#forward-pass","text":"\u5148\u8003\u8651 \\(\\frac{\\partial z}{\\partial w}\\) \u8fd9\u4e00\u9879\uff0c\u53ef\u4ee5\u79d2\u7b97\u51fa\u6765\uff0c \\(\\frac{\\partial z}{\\partial w_1}=x_1 ,\\ \\frac{\\partial z}{\\partial w_2}=x_2\\) \uff0c\u5373 \\(w_1,w_2\\) \u7cfb\u6570\u5bf9\u5e94\u7684\u8f93\u5165\u503c\uff0c\u540c\u65f6\u4e5f\u662f\u524d\u4e00\u4e2a layer \u7684\u8f93\u51fa\u503c","title":"Forward pass"},{"location":"ML/4_Deep%20learning/#backward-pass","text":"\u518d\u8003\u8651 \\(\\frac{\\partial l}{\\partial z}\\) \u8fd9\u4e00\u9879\uff0c\u5b83\u662f\u6bd4\u8f83\u590d\u6742\u7684\uff0c\u8fd9\u91cc\u6211\u4eec\u4f9d\u65e7\u5047\u8bbe activation function \u662f sigmoid function $$ \\frac{\\partial l}{\\partial z}=\\frac{\\partial a}{\\partial z} \\frac{\\partial l}{\\partial a} $$ \u524d\u9762 \\(\\frac{\\partial a}{\\partial z}\\) \u5c31\u662f sigmoid function \u7684\u504f\u5fae\u5206 \u540e\u9762 \\(\\frac{\\partial l}{\\partial a}\\) \u4e3a\u5982\u4e0b\u5f62\u5f0f\uff1a $$ \\frac{\\partial l}{\\partial a}=\\frac{\\partial z'}{\\partial a} \\frac{\\partial l}{\\partial z'}+\\frac{\\partial z''}{\\partial a} \\frac{\\partial l}{\\partial z''} $$ \u8fd9\u6837\u770b\u6765\u5176\u5b9e\u662f\u4e00\u4e2a\u9012\u5f52\u7684\u5f62\u5f0f\uff0c\u5728 output layer \u5f80\u524d\u7b97\u4fbf\u53ef\u4ee5\u6c42\u51fa\u6240\u6709\u7684 \\(\\frac{\\partial l}{\\partial a}\\) \u8ba8\u8bba\u4e00\u4e0b output layer \u7684\u7ed3\u679c\uff1a $$ \\frac{\\partial l}{\\partial z'}=\\frac{\\partial y_1}{\\partial z'} \\frac{\\partial l}{\\partial y_1} $$ \u5176\u4e2d \\(\\frac{\\partial y_1}{\\partial z'}\\) \u5c31\u662f output layer\u7684 activation function (softmax) \u5bf9 \\(z'\\) \u7684\u504f\u5fae\u5206 \u800c \\(\\frac{\\partial l}{\\partial y_1}\\) \u5c31\u662f loss \u5bf9 \\(y_1\\) \u7684\u504f\u5fae\u5206\uff0c\u5b83\u53d6\u51b3\u4e8e\u4f60\u7684 loss function \u662f\u600e\u4e48\u5b9a\u4e49\u7684\uff0c\u4e5f\u5c31\u662f\u4f60\u7684 output \u548c target \u4e4b\u95f4\u662f\u600e\u4e48 evaluate \u7684\uff0c\u4f60\u53ef\u4ee5\u7528 cross entropy\uff0c\u4e5f\u53ef\u4ee5\u7528 mean square error\uff0c\u7528\u4e0d\u540c\u7684\u5b9a\u4e49\uff0c \\(\\frac{\\partial l}{\\partial y_1}\\) \u7684\u503c\u5c31\u4e0d\u4e00\u6837","title":"Backward pass"},{"location":"ML/4_Deep%20learning/#why-deep","text":"\u4e3a\u4ec0\u4e48\u6211\u4eec\u8981 deep learning\uff1f\u4e00\u4e2a\u5f88\u76f4\u89c9\u7684\u7b54\u6848\u662f\uff0c\u8d8a deep\uff0cperformance \u5c31\u8d8a\u597d\uff0c\u4e00\u822c\u6765\u8bf4\uff0c\u968f\u7740 deep learning \u4e2d\u7684 layers \u6570\u91cf\u589e\u52a0\uff0cerror \u7387\u4e0d\u65ad\u964d\u4f4e \u751a\u81f3\u6709\u4e00\u4e2a\u7406\u8bba\u662f\u8fd9\u6837\u8bf4\u7684\uff0c\u4efb\u4f55\u8fde\u7eed\u7684 function\uff0c\u5b83 input \u662f\u4e00\u4e2a N \u7ef4\u7684 vector\uff0coutput \u662f\u4e00\u4e2a M \u7ef4\u7684 vector\uff0c\u5b83\u90fd\u53ef\u4ee5\u7528\u4e00\u4e2a hidden layer \u7684 neural network \u6765\u8868\u793a\uff0c\u53ea\u8981\u4f60\u8fd9\u4e2a hidden layer \u7684 neuron \u591f\u591a\uff0c\u5b83\u53ef\u4ee5\u8868\u793a\u6210\u4efb\u4f55\u7684 function\uff0c\u65e2\u7136\u4e00\u4e2a hidden layer \u7684 neural network \u53ef\u4ee5\u8868\u793a\u6210\u4efb\u4f55\u7684 function\uff0c\u800c\u6211\u4eec\u5728\u505a machine learning \u7684\u65f6\u5019\uff0c\u9700\u8981\u7684\u4e1c\u897f\u5c31\u53ea\u662f\u4e00\u4e2a function \u800c\u5df2\uff0c\u90a3\u505a deep \u6709\u4ec0\u4e48\u7279\u6b8a\u7684\u610f\u4e49\u5462\uff1f","title":"Why Deep?"},{"location":"ML/4_Deep%20learning/#design-network-structure-vs-feature-engineering","text":"\u4e0b\u9762\u804a\u4e00\u4e9b\u7ecf\u9a8c\u4e4b\u8c08 network structure \u7684 design \u662f\u4e00\u4ef6\u4e0d\u5bb9\u6613\u7684\u4e8b\uff0c\u5f88\u591a\u65f6\u5019\u9700\u8981\u9760\u7ecf\u9a8c\u76f4\u89c9\uff0c\u4e43\u81f3\u4e00\u4e9b domain knowledge (\u4e13\u4e1a\u9886\u57df\u7684\u77e5\u8bc6) \u672c\u6765\u4e0d\u662f deep learning \u7684 model\uff0c\u8981\u5f97\u5230\u4e00\u4e2a\u597d\u7684\u7ed3\u679c\uff0c\u5f80\u5f80\u9700\u8981\u505a feature engineering (\u7279\u5f81\u5de5\u7a0b)\uff0c\u4e5f\u5c31\u662f\u505a feature transform\uff0c\u7136\u540e\u627e\u4e00\u7ec4\u597d\u7684 feature\uff1b\u4e00\u5f00\u59cb\u5b66\u4e60 deep learning \u7684\u65f6\u5019\uff0c\u597d\u50cf\u4f1a\u89c9\u5f97 deep learning \u7684 layers \u4e4b\u95f4\u4e5f\u662f\u5728\u505a feature transform\uff0c\u4f46\u5b9e\u9645\u4e0a\u5728\u505a deep learning \u7684\u65f6\u5019\uff0c\u5f80\u5f80\u4e0d\u9700\u8981\u4e00\u4e2a\u597d\u7684 feature \uff0c\u6bd4\u5982\u8bf4\u5728\u505a\u5f71\u50cf\u8fa8\u8bc6\u7684\u65f6\u5019\uff0c\u4f60\u53ef\u4ee5\u628a\u6240\u6709\u7684 pixel \u76f4\u63a5\u4e22\u8fdb\u53bb\uff0c\u4f46\u662f\u5728\u8fc7\u53bb\u505a\u56fe\u50cf\u8bc6\u522b\uff0c\u4f60\u662f\u9700\u8981\u5bf9\u56fe\u50cf\u62bd\u53d6\u51fa\u4e00\u4e9b\u4eba\u5b9a\u7684 feature \u51fa\u6765\u7684\uff0c\u8fd9\u4ef6\u4e8b\u60c5\u5c31\u662ffeature transform\uff0c\u4f46\u662f\u6709\u4e86deep learning \u4e4b\u540e\uff0c\u4f60\u5b8c\u5168\u53ef\u4ee5\u76f4\u63a5\u4e22 pixel \u8fdb\u53bb\u786c\u505a deep learning \u5236\u9020\u4e86\u65b0\u7684\u95ee\u9898\uff0c\u5c31\u662f design network \u7684 structure\uff0c\u6240\u4ee5\u95ee\u9898\u53d8\u6210\u4e86 design structure \u548c feature transform \u54ea\u4e00\u4e2a\u66f4\u5bb9\u6613 \u5bf9\u4e8e\u4e00\u4e9b feature transform \u5f88\u96be\u505a\u7684\u4e8b\u60c5\u6bd4\u5982 \u8bed\u97f3\u548c\u6620\u50cf \u8fa8\u8bc6\uff0c\u7528 deep learning \u5c31\u8fdb\u6b65\u7684\u5f88\u5feb\uff1b\u4f46\u5728\u6587\u5b57\u65b9\u9762\u6bd4\u5982\u8bbe\u8ba1\u4e00\u4e2a rule \u53bb detect \u4e00\u7bc7 document \u662f\u6b63\u9762\u7684\u60c5\u7eea\u8fd8\u662f\u8d1f\u9762\u7684\u60c5\u7eea\u65f6\uff0cdeep learning \u76f8\u8f83\u4e8e\u4f20\u7edf\u7684\u65b9\u6cd5\u8fdb\u6b65\u4e0d\u660e\u663e \u957f\u4e45\u800c\u8a00\uff0c\u53ef\u80fd\u6587\u5b57\u5904\u7406\u4e2d\u4f1a\u6709\u4e00\u4e9b\u9690\u85cf\u7684\u8d44\u8baf\u662f\u4eba\u81ea\u5df1\u4e5f\u4e0d\u77e5\u9053\u7684\uff0c\u6240\u4ee5\u8ba9\u673a\u5668\u81ea\u5df1\u53bb\u5b66\u8fd9\u4ef6\u4e8b\u60c5\uff0c\u8fd8\u662f\u53ef\u4ee5\u5360\u5230\u4e00\u4e9b\u4f18\u52bf\uff0c\u53ea\u662f\u773c\u4e0b\u5b83\u8ddf\u4f20\u7edf\u65b9\u6cd5\u7684\u5dee\u5f02\u770b\u8d77\u6765\u5e76\u6ca1\u6709\u90a3\u4e48\u7684\u60ca\u4eba\uff0c\u4f46\u8fd8\u662f\u6709\u8fdb\u6b65\u7684","title":"Design network structure V.s. Feature Engineering"},{"location":"ML/4_Deep%20learning/#tips-for-deep-learning","text":"\u9488\u5bf9 training set \u548c testing set \u4e0a\u7684 performance \u5206\u522b\u63d0\u51fa\u9488\u5bf9\u6027\u7684\u89e3\u51b3\u65b9\u6cd5 1\u3001\u5728 training set \u4e0a\u51c6\u786e\u7387\u4e0d\u9ad8\uff1a new activation function\uff1aReLU\u3001Maxout adaptive learning rate\uff1aAdagrad\u3001RMSProp\u3001Momentum\u3001Adam 2\u3001\u5728 testing set \u4e0a\u51c6\u786e\u7387\u4e0d\u9ad8\uff1aEarly Stopping\u3001Regularization or Dropout","title":"Tips for Deep Learning"},{"location":"ML/4_Deep%20learning/#good-results-on-training-data","text":"\u50cf k nearest neighbor\uff0cdecision tree \u8fd9\u7c7b\u65b9\u6cd5\uff0c\u5b83\u4eec\u5728 training set \u4e0a\u6b63\u786e\u7387\u90fd\u662f100\uff0c\u8fd9\u624d\u662f\u975e\u5e38\u5bb9\u6613 overfitting \u7684\uff0c\u800c\u5bf9 deep learning \u6765\u8bf4\uff0coverfitting \u5f80\u5f80\u4e0d\u4f1a\u662f\u4f60\u9047\u5230\u7684\u7b2c\u4e00\u4e2a\u95ee\u9898 \u5982\u4f55\u5728 Training Data \u4e0a\u5f97\u5230\u597d\u7684 performance \u5462\uff1f \u5206\u4e3a\u4e24\u4e2a\u6a21\u5757\uff0cNew activation function \u548c Adaptive Learning Rate","title":"Good Results on Training Data\uff1f"},{"location":"ML/4_Deep%20learning/#new-activation-function","text":"training \u7684\u7ed3\u679c\u4e0d\u597d\u53ef\u80fd\u662f network \u7684\u67b6\u6784\u8bbe\u8ba1\u7684\u4e0d\u597d\uff0c\u6bd4\u5982\u8bf4\u7528\u7684 activation function \u662f\u5bf9 training \u6bd4\u8f83\u4e0d\u5229\u7684\uff0c\u5c1d\u8bd5\u7740\u6362\u4e00\u4e9b\u65b0\u7684 activation function\uff0c\u4e5f\u8bb8\u53ef\u4ee5\u5e26\u6765\u6bd4\u8f83\u597d\u7684\u7ed3\u679c \u4e0b\u56fe\u662f\u624b\u5199\u6570\u5b57\u8fa8\u8bc6\u7528 sigmoid function \u65f6\u968f\u7740\u5c42\u6570\u589e\u52a0\u5728 training data \u4e0a\u7684\u60c5\u51b5","title":"New activation function"},{"location":"ML/4_Deep%20learning/#vanishing-gradient-problem","text":"\u4e0a\u9762\u8fd9\u4e2a\u95ee\u9898\u7684\u539f\u56e0\u4e0d\u662f overfitting\uff0c\u800c\u662f Vanishing Gradient (\u68af\u5ea6\u6d88\u5931) network \u5f88\u6df1\u7684\u65f6\u5019\uff0c\u5728\u9760\u8fd1 input \u7684\u5730\u65b9\u7684\u53c2\u6570\u7684 gradient \u662f\u6bd4\u8f83\u5c0f\u7684\uff0c\u5728\u9760\u8fd1 output \u7684\u5730\u65b9\u7684 gradient \u662f\u6bd4\u8f83\u5927\u7684\uff1b\u56e0\u6b64\u5728\u8bbe\u5b9a\u76f8\u540c\u7684 learning rate \u65f6\uff0c\u9760\u8fd1 input \u7684\u5730\u65b9\u7684\u53c2\u6570\u7684 update \u662f\u5f88\u6162\u7684 \u4e3a\u4ec0\u4e48\u4f1a\u6709\u8fd9\u4e2a\u73b0\u8c61\u53d1\u751f\u5462\uff1f\u5982\u679c\u628a Backpropagation \u7684\u5f0f\u5b50\u5199\u51fa\u6765\u7684\u8bdd\uff0c\u5c31\u53ef\u4ee5\u5f88\u8f7b\u6613\u5730\u53d1\u73b0\u7528 sigmoid function \u4f1a\u5bfc\u81f4\u8fd9\u4ef6\u4e8b\u60c5\u7684\u53d1\u751f\uff1b\u4f46\u662f\u5176\u5b9e\u4ece\u76f4\u89c9\u4e0a\u6765\u60f3\u4f60\u4e5f\u53ef\u4ee5\u4e86\u89e3\u8fd9\u4ef6\u4e8b\u60c5\u53d1\u751f\u7684\u539f\u56e0\uff1asigmoid function \u4f1a\u628a\u8d1f\u65e0\u7a77\u5927\u5230\u6b63\u65e0\u7a77\u5927\u4e4b\u95f4\u7684\u503c\u90fd\u538b\u7f29\u5230 0~1 \u4e4b\u95f4\uff0c\u6240\u4ee5\u5373\u4f7f \\(\\Delta w\\) \u200b \u5f88\u5927\uff0c\u5982\u679c network \u5f88\u6df1\uff0c\u8870\u51cf\u7684\u6b21\u6570\u5c31\u8d8a\u591a\uff0c\u5bf9 output \u7684\u5f71\u54cd\u5c31\u5f88\u5c0f \u90a3\u4e48\u5982\u4f55\u89e3\u51b3\u5462\uff1f\u6bd4\u8f83\u65e9\u5e74\u7684\u505a\u6cd5\u662f\u53bbtrain RBM\uff0c\u601d\u60f3\u5c31\u662f\uff1a\u5148\u628a\u7b2c\u4e00\u4e2alayer train\u597d\uff0c\u518d\u53bbtrain\u7b2c\u4e8c\u4e2a\uff0c\u7136\u540e\u518d\u7b2c\u4e09\u4e2a... \u4f46\u5176\u5b9e\u6539\u4e00\u4e0b activation function \u53ef\u80fd\u5c31\u53ef\u4ee5 handle \u8fd9\u4e2a\u95ee\u9898","title":"Vanishing Gradient Problem"},{"location":"ML/4_Deep%20learning/#relu","text":"\u73b0\u5728\u6bd4\u8f83\u5e38\u7528\u7684 activation function \u53eb\u505a Rectified Linear Unit (\u6574\u6d41\u7ebf\u6027\u5355\u5143\u51fd\u6570\uff0c\u53c8\u79f0\u4fee\u6b63\u7ebf\u6027\u5355\u5143)\uff0c\u5b83\u7684\u7f29\u5199\u662fReLU \u9009\u62e9 ReLU \u7684\u7406\u7531\u5982\u4e0b\uff1a \u8ddf sigmoid function \u6bd4\u8d77\u6765\uff0cReLU \u7684\u8fd0\u7b97\u5feb\u5f88\u591a ReLU \u7684\u60f3\u6cd5\u7ed3\u5408\u4e86\u751f\u7269\u4e0a\u7684\u89c2\u5bdf ( Pengel \u7684 paper ) \u65e0\u7a77\u591a bias \u4e0d\u540c\u7684 sigmoid function \u53e0\u52a0\u7684\u7ed3\u679c\u4f1a\u53d8\u6210 ReLU ReLU \u53ef\u4ee5\u5904\u7406 Vanishing gradient \u7684\u95ee\u9898 ( the most important thing ) \u7528 ReLU \u65f6\uff0coutput \u8981\u4e48 = 0\uff0c \u8981\u4e48 = input\uff0c\u5f53 output = 0\u65f6\uff0c\u90a3\u4e2a neuron \u5bf9\u6574\u4e2a network \u662f\u6ca1\u6709\u4efb\u4f55\u4f5c\u7528\u7684\uff0c\u56e0\u6b64\u53ef\u4ee5\u4ece network \u4e2d\u62ff\u6389\uff0c\u62ff\u6389\u4e4b\u540e network \u5c31\u53d8\u6210\u4e86\u4e00\u5171\u7626\u957f\u7684 linear network\uff0clinear \u7684\u597d\u5904\u65f6\u4e0d\u4f1a\u6709 Vanishing Gradient Q\uff1alinear function \u4f1a\u4e0d\u4f1a\u5f88\u5f31\uff1f A\uff1a\u4f7f\u7528 ReLU \u540e\u7684 network \u6574\u4f53\u8fd8\u662f non-linear\uff0cinput \u505a\u51fa\u8f83\u5927\u6539\u53d8\u65f6\uff0c\u5c31\u4f1a\u5bfc\u81f4 neuron \u7684 operation region \u7684\u6539\u53d8 Q\uff1aReLU \u662f\u5206\u65ad\u8fd8\u662f\uff0c\u6ca1\u529e\u6cd5\u5fae\u5206 A\uff1a\u5728\u5b9e\u9645\u64cd\u4f5c\u4e0a\uff0c\u5f53 region \u7684\u8303\u56f4\u5904\u4e8e z>0 \u65f6\uff0c\u5fae\u5206\u503c gradient \u5c31\u662f 1\uff1b\u5f53 region \u7684\u8303\u56f4\u5904\u4e8e z<0 \u65f6\uff0c\u5fae\u5206\u503c gradient \u5c31\u662f 0\uff1b\u5f53 z \u4e3a 0 \u65f6\uff0c\u5c31\u4e0d\u8981\u7ba1\u5b83","title":"ReLU"},{"location":"ML/4_Deep%20learning/#relu-variant","text":"ReLU \u5728 update \u53c2\u6570\u65f6\u5728 input<0 \u65f6\u65e0\u6cd5\u66f4\u65b0\u53c2\u6570\uff0c\u5982\u679c\u5728 input<0 \u65f6\uff0c\u5fae\u5206\u8fd8\u80fd\u6709\u4e00\u70b9\u7684\u503c\uff0c\u6bd4\u5982\u4ee4 \\(a=0.01z\\) \u200b\u200b\uff0c\u8fd9\u4e2a\u4e1c\u897f\u5c31\u53eb\u505a Leaky ReLU \u90a3\u4e48 \\(z\\) \u7684\u7cfb\u6570\u53ef\u4e0d\u53ef\u4ee5\u662f\u5176\u4ed6\u7684\u5462\uff1f\u4e8e\u662f\u5c31\u63d0\u51fa\u4e86 Parametric ReLU \uff0c \\(a=\\alpha \\cdot z\\) \uff0c\u5176\u4e2d \\(\\alpha\\) \u200b \u4e0d\u662f\u56fa\u5b9a\u7684\u503c\uff0c\u800c\u662f network \u7684\u4e00\u4e2a\u53c2\u6570\uff0c\u901a\u8fc7 training data \u5b66\u4e60\u51fa\u6765 \u66f4\u8fdb\u4e00\u6b65\uff0c\u4e3a\u4ec0\u4e48\u4e00\u5b9a\u8981\u662f ReLU \u7684\u6837\u5b50\u5462\uff1factivation function \u53ef\u4e0d\u53ef\u4ee5\u6709\u522b\u7684\u6837\u5b50\u5462\uff1f\u6240\u4ee5\u540e\u6765\u6709\u4e86\u4e00\u4e2a\u66f4\u8fdb\u9636\u7684\u60f3\u6cd5\uff0c\u53eb\u505a Maxout network","title":"ReLU-variant"},{"location":"ML/4_Deep%20learning/#maxout","text":"Maxout \u7684\u60f3\u6cd5\u662f\uff0c\u8ba9 network \u81ea\u52a8\u53bb\u5b66\u4e60\u5b83\u7684 activation function\uff0c\u90a3 Maxout network \u5c31\u53ef\u4ee5\u81ea\u52a8\u5b66\u51fa ReLU\uff0c\u4e5f\u53ef\u4ee5\u5b66\u51fa\u5176\u4ed6\u7684 activation function\uff0c\u8fd9\u4e00\u5207\u90fd\u662f\u7531 training data \u6765\u51b3\u5b9a\u7684 \u5047\u8bbe\u73b0\u5728\u6709 input \\(x_1,x_2\\) \uff0c\u5b83\u4eec\u4e58\u4e0a\u51e0\u7ec4\u4e0d\u540c\u7684 weight \u5206\u522b\u5f97\u5230 5,7,-1,1\uff0c\u8fd9\u4e9b\u503c\u672c\u6765\u662f\u4e0d\u540c neuron \u7684 input\uff0c\u5b83\u4eec\u8981\u901a\u8fc7 activation function \u53d8\u4e3a neuron \u7684 output\uff1b\u4f46\u5728Maxout network \u91cc\uff0c\u6211\u4eec\u4e8b\u5148\u51b3\u5b9a\u597d\u5c06\u67d0\u51e0\u4e2a \"neuron\" \u7684 input \u5206\u4e3a\u4e00\u4e2a group\uff0c\u6bd4\u59825,7 \u5206\u4e3a\u4e00\u4e2a group\uff0c\u7136\u540e\u5728\u8fd9\u4e2a group \u91cc\u9009\u53d6\u4e00\u4e2a\u6700\u5927\u503c 7 \u4f5c\u4e3a output \u8fd9\u4e2a\u8fc7\u7a0b\u5c31\u597d\u50cf\u5728\u4e00\u4e2a layer \u4e0a\u505a Max Pooling \u4e00\u6837\uff0c\u5b83\u548c\u539f\u6765\u7684 network \u4e0d\u540c\u4e4b\u5904\u5728\u4e8e\uff0c\u5b83\u628a\u539f\u6765\u51e0\u4e2a \"neuron\" \u7684 input \u6309\u4e00\u5b9a\u89c4\u5219\u7ec4\u6210\u4e86\u4e00\u4e2a group\uff0c\u7136\u540e\u5e76\u6ca1\u6709\u4f7f\u5b83\u4eec\u901a\u8fc7 activation function\uff0c\u800c\u662f\u9009\u53d6\u5176\u4e2d\u7684\u6700\u5927\u503c\u5f53\u505a\u8fd9\u51e0\u4e2a \"neuron\" \u7684 output \u5f53\u7136\uff0c\u5b9e\u9645\u4e0a\u539f\u6765\u7684 \"neuron\" \u65e9\u5c31\u5df2\u7ecf\u4e0d\u5b58\u5728\u4e86\uff0c\u8fd9\u51e0\u4e2a\u88ab\u5408\u5e76\u7684 \"neuron\" \u5e94\u5f53\u88ab\u770b\u505a\u662f\u4e00\u4e2a\u65b0\u7684 neuron\uff0c\u8fd9\u4e2a\u65b0\u7684 neuron \u7684 input \u662f\u539f\u6765\u51e0\u4e2a \"neuron\" \u7684 input \u7ec4\u6210\u7684 vector\uff0coutput \u5219\u53d6 input \u7684\u6700\u5927\u503c\uff0c\u800c\u5e76\u975e\u7531 activation function \u4ea7\u751f group \u7684\u5927\u5c0f\u7531\u81ea\u5df1\u51b3\u5b9a \u90a3\u5982\u679c\u8bf4 Maxout \u53ef\u4ee5\u6a21\u4eff\u51fa\u5176\u4ed6\u7684 activation function\uff0c\u90a3\u662f\u5982\u4f55\u6a21\u4eff\u51fa ReLU \u7684\u5462\uff1f \u5176\u5b9e\u53ea\u8981 \\(z_2\\) \u7684 2 \u4e2a\u53c2\u6570\u90fd\u8bbe\u4e3a 0\uff0c\u7136\u540e\u505a Max Pooling \u5373\u53ef \u90a3\u6a21\u4eff\u51fa\u5176\u4ed6\u7684 activation function \u5462\uff1f \u6bd4\u5982 \\(z_2\\) \u7684\u53c2\u6570 w \u548c b \u4e0d\u662f0\uff0c\u800c\u662f \\(w',b'\\) \u200b\uff0c\u6b64\u65f6\u5982\u4e0b\u56fe\uff0cMax Pooling \u4f7f 2 \u6761\u76f4\u7ebf\u5f62\u6210\u4e00\u4e2a V \u5b57\u578b Maxout \u53ef\u4ee5\u5b9e\u73b0\u4efb\u4f55 piecewise linear convex activation function (\u5206\u6bb5\u7ebf\u6027\u51f8\u6fc0\u6d3b\u51fd\u6570)\uff0c\u5206\u51e0\u6bb5\u53d6\u51b3\u4e8e\u4e00\u4e2a group \u6709\u51e0\u4e2a input","title":"Maxout"},{"location":"ML/4_Deep%20learning/#how-to-train-maxout","text":"\u5176\u5b9e Max operation \u5c31\u662f linear \u7684 operation\uff0c\u5c31\u50cf\u524d\u9762 ReLU \u63d0\u5230\u7684\u4e00\u6837\uff0c\u6574\u4f53\u6765\u8bf4\u4e0d\u662f Linear \u7684\uff0c\u4f46\u662f\u5f53\u628a data \u653e\u8fdb\u53bb\u540e\u4e00\u4e9b neuron \u5c31\u88ab\u6682\u65f6\u9690\u85cf\u4e86\uff0c\u6b64\u65f6\u5c31\u662f linear \u7684\uff1b\u8fd9\u4e9b\u88ab\u9690\u85cf\u7684 neuron \u4f1a\u5728\u4e0d\u540c\u7684 input data \u4e2d\u88ab\u8bad\u7ec3\u5230","title":"How to train Maxout"},{"location":"ML/4_Deep%20learning/#adaptive-learning-rate","text":"\u524d\u9762\u5df2\u7ecf\u8bb2\u8fc7 Adagrad \u7684\u505a\u6cd5\uff0c\u4f46\u5b9e\u9645\u95ee\u9898\u4e2d\u53ef\u80fd\u8fdc\u6bd4 Adagrad \u80fd\u505a\u7684\u95ee\u9898\u8981\u6765\u7684\u590d\u6742","title":"Adaptive Learning Rate"},{"location":"ML/4_Deep%20learning/#rmsprop","text":"loss function \u4e5f\u6709\u53ef\u80fd\u4e00\u4f1a\u513f\u5e73\u5766\u4e00\u4f1a\u513f\u9661\u5ced\uff0c\u6240\u4ee5\u4f60\u8981\u968f\u65f6\u6839\u636e gradient \u7684\u5927\u5c0f\u6765\u5feb\u901f\u5730\u8c03\u6574 learning rate\uff0c\u771f\u6b63\u8981\u5904\u7406 deep learning \u7684\u95ee\u9898\uff0c\u7528 Adagrad \u53ef\u80fd\u662f\u4e0d\u591f\u7684\uff0c\u4f60\u9700\u8981\u66f4 dynamic \u7684\u8c03\u6574 learning rate \u7684\u65b9\u6cd5\uff0c\u6240\u4ee5\u4ea7\u751f \u4e86Adagrad \u7684\u8fdb\u9636\u7248\u2014\u2014 RMSProp learning rate \u4f9d\u65e7\u8bbe\u7f6e\u4e3a\u4e00\u4e2a\u56fa\u5b9a\u7684\u503c \\(\\eta\\) \u9664\u6389\u4e00\u4e2a\u53d8\u5316\u7684\u503c \\(\\sigma\\) \uff0c\u8fd9\u4e2a \\(\\sigma\\) \u7b49\u4e8e\u4e0a\u4e00\u4e2a \\(\\sigma\\) \u548c\u5f53\u524d\u68af\u5ea6 \\(g\\) \u7684\u52a0\u6743\u65b9\u5747\u6839\uff08\u7279\u522b\u7684\u662f\uff0c\u5728\u7b2c\u4e00\u4e2a\u65f6\u95f4\u70b9\uff0c \\(\\sigma^0\\) \u5c31\u662f\u7b2c\u4e00\u4e2a\u7b97\u51fa\u6765\u7684gradient\u503c \\(g^0\\) \u200b\uff09\uff0c\u5373\uff1a $$ \\begin{align} w^{t+1}&=w^t-\\frac{\\eta}{\\sigma^t}g^t \\ \\sigma^t&=\\sqrt{\\alpha(\\sigma^{t-1})^2+(1-\\alpha)(g^t)^2} \\end{align} $$ \\(\\alpha\\) \u200b \u503c\u662f\u53ef\u4ee5\u81ea\u7531\u8c03\u6574\u7684\uff0cRMSProp \u8ddf Adagrad \u4e0d\u540c\u4e4b\u5904\u5728\u4e8e\uff0cAdagrad \u7684\u5206\u6bcd\u662f\u5bf9\u8fc7\u7a0b\u4e2d\u6240\u6709\u7684 gradient \u53d6\u5e73\u65b9\u548c\u5f00\u6839\u53f7\uff0c\u4e5f\u5c31\u662f\u8bf4 Adagrad \u8003\u8651\u7684\u662f\u6574\u4e2a\u8fc7\u7a0b\u5e73\u5747\u7684 gradient \u4fe1\u606f\uff1b\u800c RMSProp \u867d\u7136\u4e5f\u662f\u5bf9\u6240\u6709\u7684 gradient \u8fdb\u884c\u5e73\u65b9\u548c\u5f00\u6839\u53f7\uff0c\u4f46\u662f\u5b83 \u7528\u4e00\u4e2a \\(\\alpha\\) \u200b \u6765\u8c03\u6574\u5bf9\u4e0d\u540c gradient \u7684\u4f7f\u7528\u7a0b\u5ea6 \uff0c\u6bd4\u5982\u4f60\u628a \\(\\alpha\\) \u7684\u503c\u8bbe\u7684\u5c0f\u4e00\u70b9\uff0c\u610f\u601d\u5c31\u662f\u4f60\u66f4\u503e\u5411\u4e8e\u76f8\u4fe1\u65b0\u7684 gradient \u6240\u544a\u8bc9\u4f60\u7684 error surface \u7684\u5e73\u6ed1\u6216\u9661\u5ced\u7a0b\u5ea6\uff0c\u800c\u6bd4\u8f83\u65e0\u89c6\u4e8e\u65e7\u7684gradient \u6240\u63d0\u4f9b\u7ed9\u4f60\u7684 information","title":"RMSProp"},{"location":"ML/4_Deep%20learning/#momentum","text":"\u9664\u4e86 learning rate \u7684\u95ee\u9898\u4ee5\u5916\uff0c\u5728\u505a deep learning \u7684\u65f6\u5019\uff0c\u5f88\u591a\u4eba\u62c5\u5fc3\u4f1a\u5361\u5728 local minimum\u3001saddle point \u6216\u662f plateau \u7684\u5730\u65b9\uff1b\u4f46\u5176\u5b9e Yann LeCun \u5728 07 \u5e74\u7684\u65f6\u5019\uff0c\u5c31\u63d0\u51fa\u4e86\u4e00\u4e2a\u86ee\u7279\u522b\u7684\u8bf4\u6cd5\uff0c\u4ed6\u8bf4\u4f60\u4e0d\u8981\u592a\u62c5\u5fc3 local minima \u7684\u95ee\u9898\uff0c\u56e0\u4e3a\u4e00\u65e6\u51fa\u73b0 local minima\uff0c\u5b83\u5c31\u5fc5\u987b\u5728\u6bcf\u4e00\u4e2a dimension \u90fd\u662f\u5c71\u8c37\u7684\u4f4e\u8c37\u5f62\u72b6\uff0c\u53c2\u6570\u975e\u5e38\u591a\u65f6\u8fd9\u79cd\u6982\u7387\u662f\u975e\u5e38\u5c0f\u7684 \u6709\u4e00\u4e2a heuristic(\u542f\u53d1\u6027) \u7684\u65b9\u6cd5\u53ef\u4ee5\u7a0d\u5fae\u5904\u7406\u4e00\u4e0b\u4e0a\u9762\u6240\u8bf4\u7684 \"\u5361\u4f4f\" \u7684\u95ee\u9898\uff0c\u5b83\u7684\u7075\u611f\u6765\u81ea\u4e8e\u771f\u5b9e\u4e16\u754c\uff1a\u628a\u60ef\u6027\u52a0\u5230 gradient descent \u91cc\u9762\uff0c\u8fd9\u4ef6\u4e8b\u60c5\u5c31\u53eb\u505a Momentum how to do Momentum\uff1f \u5f53\u6211\u4eec\u5728 gradient descent \u91cc\u52a0\u4e0a Momentum \u7684\u65f6\u5019\uff0c\u6bcf\u4e00\u6b21 update \u7684\u65b9\u5411\uff0c\u4e0d\u518d\u53ea\u8003\u8651 gradient \u7684\u65b9\u5411\uff0c\u8fd8\u8981\u8003\u8651\u4e0a\u4e00\u6b21 update \u7684\u65b9\u5411\uff0c\u90a3\u8fd9\u91cc\u6211\u4eec\u5c31\u7528\u4e00\u4e2a\u53d8\u91cf \\(v\\) \u53bb\u8bb0\u5f55\u524d\u4e00\u4e2a\u65f6\u95f4\u70b9 update \u7684\u65b9\u5411 \u968f\u673a\u9009\u4e00\u4e2a\u521d\u59cb\u503c \\(\\theta^0\\) \uff0c\u521d\u59cb\u5316 \\(v^0=0\\) \uff0c\u63a5\u4e0b\u6765\u8ba1\u7b97 \\(\\theta^0\\) \u5904\u7684 gradient\uff0c\u7136\u540e\u6211\u4eec\u8981\u79fb\u52a8\u7684\u65b9\u5411\u662f\u7531\u524d\u4e00\u4e2a\u65f6\u95f4\u70b9\u7684\u79fb\u52a8\u65b9\u5411 \\(v^0\\) \u548c gradient \u7684\u53cd\u65b9\u5411 \\(\\nabla L(\\theta^0)\\) \u6765\u51b3\u5b9a\u7684\uff0c\u5373 $$ v^1=\\lambda v^0-\\eta \\nabla L(\\theta^0) $$ \u6ce8\uff1a\u8fd9\u91cc\u7684 \\(\\lambda\\) \u4e5f\u662f\u4e00\u4e2a\u624b\u52a8\u8c03\u6574\u7684\u53c2\u6570\uff0c\u5b83\u8868\u793a\u60ef\u6027\u5bf9\u524d\u8fdb\u65b9\u5411\u7684\u5f71\u54cd\u6709\u591a\u5927 \u5176\u5b9e\u6bcf\u4e00\u4e2a\u65f6\u95f4\u70b9\u8981\u79fb\u52a8\u7684\u6b65\u4f10 \\(v^i\\) \u200b\uff0c\u5305\u62ec\u5927\u5c0f\u548c\u65b9\u5411\uff0c\u90fd\u662f\u524d\u9762\u6240\u6709 gradient \u7684\u52a0\u6743\u548c\uff0c\u4f46\u8d8a\u4e4b\u524d\u7684 gradient \u7684\u6743\u91cd\u8d8a\u5c0f","title":"Momentum"},{"location":"ML/4_Deep%20learning/#adam","text":"\u5176\u5b9e RMSProp \u52a0\u4e0a Momentum\uff0c\u5c31\u53ef\u4ee5\u5f97\u5230 Adam \u6839\u636e\u4e0b\u9762\u7684 paper \u6765\u5feb\u901f\u63cf\u8ff0\u4e00\u4e0b Adam \u7684 algorithm\uff1a \u5148\u521d\u59cb\u5316 \\(m_0=0\\) \u200b\uff0c \\(m_0\\) \u200b\u5c31\u662f Momentum \u4e2d\uff0c\u524d\u4e00\u4e2a\u65f6\u95f4\u70b9\u7684 movement \u518d\u521d\u59cb\u5316 \\(v_0=0\\) \u200b\uff0c \\(v_0\\) \u200b \u5c31\u662f RMSProp \u91cc\u8ba1\u7b97 gradient \u7684 root mean square \u7684 \\(\\sigma\\) \u200b \u6700\u540e\u521d\u59cb\u5316 \\(t=0\\) \u200b\uff0ct \u7528\u6765\u8868\u793a\u65f6\u95f4\u70b9 \u5148\u7b97\u51fa gradient \\(g_t\\) $$ g_t=\\nabla {\\theta}f_t(\\theta {t-1}) $$ \u518d\u6839\u636e\u8fc7\u53bb\u8981\u8d70\u7684 movement \\(m_{t-1}\\) \u548c gradient \\(g_t\\) \uff0c\u7b97\u51fa\u73b0\u5728\u8981\u8d70\u7684 movement \\(m_t\\) \u2014\u2014Momentum $$ m_t=\\beta_1 m_{t-1}+(1-\\beta_1) g_t $$ \u7136\u540e\u6839\u636e\u524d\u4e00\u4e2a\u65f6\u95f4\u70b9\u7684 \\(v_{t-1}\\) \u200b\u200b \u548c gradient \\(g_t\\) \u200b\u200b \u7684\u5e73\u65b9\uff0c\u7b97\u4e00\u4e0b\u653e\u5728\u5206\u6bcd\u7684 \\(v_t\\) \u200b\u200b\u2014\u2014RMSProp $$ v_t=\\beta_2 v_{t-1}+(1-\\beta_2) g_t^2 $$ \u63a5\u4e0b\u6765\u505a\u4e86\u4e00\u4e2a\u539f\u6765 RMSProp \u548c Momentum \u91cc\u6ca1\u6709\u7684\u4e1c\u897f\uff0c\u5c31\u662f bias correction\uff0c\u5b83\u4f7f \\(m_t\\) \u200b\u200b\u200b \u548c \\(v_t\\) \u200b\u200b\u200b\u200b \u90fd\u9664\u4e0a\u4e00\u4e2a\u503c\uff0c\u8fd9\u4e2a\u503c\u672c\u6765\u6bd4\u8f83\u5c0f\uff0c\u540e\u6765\u4f1a\u8d8a\u6765\u8d8a\u63a5\u8fd1\u4e8e1\uff08 \\(\\beta_1^t\\) \u548c \\(\\beta_2^t\\) \u4f1a\u8d8a\u6765\u8d8a\u5c0f\uff09 $$ \\begin{align} \\hat{m}_t=\\frac{m_t}{1-\\beta_1^t} \\ \\hat{v}_t=\\frac{v_t}{1-\\beta_2^t} \\end{align} $$ \u6700\u540e\u505a update\uff0c\u628a Momentum \u5efa\u8bae\u4f60\u7684\u65b9\u5411 \\(\\hat{m_t}\\) \u4e58\u4e0a learning rate \\(\\alpha\\) \uff0c\u518d\u9664\u6389 RMSProp normalize \u540e\u5efa\u8bae\u7684 learning rate \u5206\u6bcd\uff0c\u7136\u540e\u5f97\u5230 update \u7684 movement $$ \\theta_t=\\theta_{t-1}-\\frac{\\alpha \\cdot \\hat{m}_t}{\\sqrt{\\hat{v}_t}+\\epsilon} $$","title":"Adam"},{"location":"ML/4_Deep%20learning/#good-results-on-testing-data","text":"\u5982\u679c training data \u4e0a\u5f97\u5230\u4e86\u597d\u7684 performance\uff0c\u4f46\u662f testing set \u4e0a\u6ca1\u6709\uff0c\u90a3\u624d\u662f overfitting \u56de\u53bb\u89e3\u51b3 overfitting \u65f6\u589e\u52a0\u4e86\u65b0\u7684 technique \u540e\u4f1a\u8ba9 training set \u4e0a\u7684\u7ed3\u679c\u53d8\u574f\uff0c\u6240\u4ee5\u9700\u8981\u91cd\u65b0\u68c0\u67e5 model \u5728 training set \u4e0a\u7684\u7ed3\u679c\uff1b\u5982\u679c\u53d8\u574f\u7684\u8bdd\uff0c\u53ef\u80fd\u5c31\u9700\u8981\u4ece\u5934\u5bf9 network training \u7684 process \u505a\u4e00\u4e9b\u8c03\u6574\uff1b\u5982\u679c training set \u548c testing set \u4e0a\u90fd\u6709\u597d\u7684\u7ed3\u679c\uff0c\u90a3\u5c31\u6210\u529f\u4e86 \u5206\u4e3a\u4e09\u4e2a\u6a21\u5757\uff0cEarly Stopping\u3001Regularization \u548c Dropout \u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0cEarly Stopping \u548c Regularization \u662f\u5f88 typical \u7684\u505a\u6cd5\uff0c\u5b83\u4eec\u4e0d\u662f\u7279\u522b\u4e3adeep learning \u6240\u8bbe\u8ba1\u7684\uff1b\u800c Dropout \u662f\u4e00\u4e2a\u86ee\u6709 deep learning \u7279\u8272\u7684\u505a\u6cd5","title":"Good Results on Testing Data\uff1f"},{"location":"ML/4_Deep%20learning/#early-stopping","text":"\u7406\u60f3\u4e0a\u5047\u5982\u4f60\u77e5\u9053 testing data \u4e0a\u7684 loss \u53d8\u5316\u60c5\u51b5\uff0c\u4f60\u4f1a\u5728 testing set \u7684 loss \u6700\u5c0f\u7684\u65f6\u5019\u505c\u4e0b\u6765\uff0c\u800c\u4e0d\u662f\u5728 training set \u7684 loss \u6700\u5c0f\u7684\u65f6\u5019\u505c\u4e0b\u6765\uff1b\u4f46 testing set \u5b9e\u9645\u4e0a\u662f\u672a\u77e5\u7684\u4e1c\u897f\uff0c\u6240\u4ee5\u6211\u4eec\u9700\u8981\u7528 validation set \u6765\u66ff\u4ee3\u5b83\u53bb\u505a\u8fd9\u4ef6\u4e8b\u60c5","title":"Early Stopping"},{"location":"ML/4_Deep%20learning/#regularization","text":"regularization \u5c31\u662f\u5728\u539f\u6765\u7684 loss function \u4e0a\u989d\u5916\u589e\u52a0\u51e0\u4e2a term\uff0c\u5bf9\u6bcf\u4e00\u4e2a\u53c2\u6570\u90fd\u8bbe\u7f6e\u4e00\u4e2a\u60e9\u7f5a\u9879\uff0c\u53ef\u4ee5\u8ba9\u6700\u540e\u7684 model \u53d8\u5e73\u6ed1\u4ee5\u9632\u6b62 overfitting \u4e0b\u9762\u7684\u8303\u6570\u4f3c\u4e4e\u548c\u5176\u4ed6\u5730\u65b9\u4e0d\u592a\u4e00\u6837 L2 regularization\uff1a\u5b9a\u4e49\u65b0\u7684 loss function $$ \\begin{align} L'(\\theta)&=L(\\theta)+\\frac{1}{2}\\lambda||\\theta||_2 \\ ||\\theta||_2&=(w_1)^2+(w_2)^2+... \\end{align} $$ L1 regularization\uff1a\u5b9a\u4e49\u65b0\u7684 loss function $$ \\begin{align} L'(\\theta)&=L(\\theta)+\\frac{1}{2}\\lambda||\\theta||_1 \\ ||\\theta||_2&=|w_1|+|w_2|+... \\end{align} $$ Q\uff1aL1 regularization \u5982\u4f55\u5fae\u5206\uff1f A\uff1aV \u5b57\u5f62\uff0c\u53f3\u8fb9\u662f 1\uff0c\u5de6\u8fb9\u662f -1\uff0c \u4e3a 0 \u968f\u4fbf\u7ed9\u4e00\u4e2a\u503c\u6bd4\u5982 0 L2 regularization \u5f53\u53c2\u6570\u6bd4\u8f83\u5c0f\u7684\u65f6\u5019\u4e0b\u964d\u7684\u4f1a\u5f88\u6162\uff0c\u53c2\u6570\u6bd4\u8f83\u5927\u7684\u65f6\u5019\u4e0b\u964d\u7684\u65f6\u5019\u4f1a\u5f88\u5feb\uff0c\u6240\u4ee5\u6700\u540e train \u51fa\u6765\u7684\u53c2\u6570\u90fd\u662f\u6bd4\u8f83\u5c0f\u7684 L1 regularization \u6bcf\u6b21\u90fd\u4e0b\u964d\u56fa\u5b9a\u7684\u503c\uff0c\u6240\u4ee5 train \u51fa\u6765\u6709\u5f88\u591a\u53c2\u6570\u63a5\u8fd1 0\uff0c\u4e5f\u4f1a\u6709\u5f88\u5927\u7684\u503c \uff08\u8fd9 2 \u79cd loss function \u7ecf\u5e38\u7528\u4e8e\u6570\u636e\u964d\u7ef4\u4e4b\u4e2d\uff0c\u5982 \u5cad\u56de\u5f52 \u548c Lasso\uff09","title":"Regularization"},{"location":"ML/4_Deep%20learning/#dropout","text":"training \u7684\u65f6\u5019\uff0c\u6bcf\u6b21 update \u53c2\u6570\u4e4b\u524d\uff0c\u6211\u4eec\u5bf9\u6bcf\u4e00\u4e2a neuron (\u4e5f\u5305\u62ec input layer \u7684 \"neuron\") \u505asampling (\u62bd\u6837) \uff0c\u6bcf\u4e2a neuron \u90fd\u6709 p% \u7684\u51e0\u7387\u4f1a\u88ab\u4e22\u6389\uff0c\u5982\u679c\u67d0\u4e2a neuron \u88ab\u4e22\u6389\u7684\u8bdd\uff0c\u8ddf\u5b83\u76f8\u8fde\u7684weight\u4e5f\u90fd\u8981\u88ab\u4e22\u6389 \u5b9e\u9645\u4e0a\u5c31\u662f\u6bcf\u6b21 update \u53c2\u6570\u4e4b\u524d\u90fd\u901a\u8fc7\u62bd\u6837\u53ea\u4fdd\u7559 network \u4e2d\u7684\u4e00\u90e8\u5206 neuron \u6765\u505a\u8bad\u7ec3 \u6ce8\uff1a\u6bcf\u6b21 update \u53c2\u6570\u4e4b\u524d\u90fd\u8981\u505a\u4e00\u904d sampling\uff0c\u6240\u4ee5\u6bcf\u6b21 update \u53c2\u6570\u7684\u65f6\u5019\uff0c\u62ff\u6765 training \u7684 network structure \u90fd\u662f\u4e0d\u4e00\u6837\u7684\uff1b\u4f60\u53ef\u80fd\u4f1a\u89c9\u5f97\u8fd9\u4e2a\u65b9\u6cd5\u8ddf\u524d\u9762\u63d0\u5230\u7684 Maxout \u4f1a\u6709\u4e00\u70b9\u50cf\uff0c\u4f46\u5b9e\u9645\u4e0a\uff0cMaxout \u662f\u6bcf\u4e00\u7b14 data \u5bf9\u5e94\u7684 network structure \u4e0d\u540c\uff0c\u800c Dropout \u662f\u6bcf\u4e00\u6b21 update \u7684network structure \u90fd\u662f\u4e0d\u540c\u7684 (\u6bcf\u4e00\u4e2a minibatch \u5bf9\u5e94\u7740\u4e00\u6b21 update\uff0c\u800c\u4e00\u4e2a minibatch \u91cc\u542b\u6709\u5f88\u591a\u7b14 data) \u4f7f\u7528 dropout\uff0c\u5f97\u5230\u7684 train performance \u5176\u5b9e\u662f\u4f1a\u53d8\u5dee\u7684\uff0c\u4f46\u8fd9\u5e76\u4e0d\u662f\u95ee\u9898\uff0c\u56e0\u4e3a\uff1a Dropout \u771f\u6b63\u8981\u505a\u7684\u4e8b\u60c5\uff0c\u5c31\u662f\u8981\u8ba9\u4f60\u5728 training set \u4e0a\u7684\u7ed3\u679c\u53d8\u5dee\uff0c\u4f46\u662f\u5728 testing set \u4e0a\u7684\u7ed3\u679c\u662f\u53d8\u597d\u7684 \u8981\u6ce8\u610f\u7684\u662f Dropout \u662f\u5728 training \u4e0a\u8868\u73b0\u597d\u800c testing \u4e0a\u8868\u73b0\u4e0d\u597d\u624d\u505a\u7684 \u9700\u8981\u6ce8\u610f\u7684\u4e8b\uff1a testing \u7684\u65f6\u5019\u4e0d\u505a dropout\uff0c\u6240\u6709\u7684 neuron \u90fd\u8981\u88ab\u7528\u5230 \u5047\u8bbe\u5728 training \u7684\u65f6\u5019\uff0cdropout rate \u662fp%\uff0c\u4ece training data \u4e2d\u88ab learn \u51fa\u6765\u7684\u6240\u6709 weight \u90fd\u8981\u4e58\u4e0a (1-p%) \u624d\u80fd\u88ab\u5f53\u505a testing \u7684 weight \u4f7f\u7528","title":"Dropout"},{"location":"ML/4_Deep%20learning/#do-not-always-blame-overfitting","text":"\u4e0d\u80fd\u53ea\u770b\u53f3\u8fb9\u7684\u56fe\u5c31\u8bf4\u662f overfitting\uff0c\u56e0\u4e3a\u53ef\u80fd\u672c\u6765 56-layer \u7684 model \u5c31\u6bd4 20-layer \u7684model \u8868\u73b0\u7684\u66f4\u5dee\uff1b\u4e5f\u4e0d\u80fd\u8bf4\u662f underfitting\uff0c\u56e0\u4e3a underfitting \u7684\u672c\u610f\u662f\u6307 model \u7684 complexity \u4e0d\u8db3\uff0c\u6240\u4ee5\u8fd9\u79cd\u60c5\u51b5\u5176\u5b9e\u53ea\u662f\u6ca1\u6709 train \u597d\uff0c\u6bd4\u5982\u6709 local minimum \u7684\u95ee\u9898\uff0c\u6709 saddle point \u7684\u95ee\u9898\uff0c\u6709 plateau \u7684\u95ee\u9898...","title":"Do not always blame overfitting"},{"location":"ML/4_Deep%20learning/#why-deep_1","text":"\u5728\u76f8\u540c\u53c2\u6570\u7684\u60c5\u51b5\u4e0b\uff0cshallow network \u548c deep network \u76f8\u6bd4\u4e00\u822c\u662f deep network \u8868\u73b0\u4f1a\u597d\u4e00\u4e9b deep learning \u4e2d\u7684\u6bcf\u4e00\u5c42\u7684 layer \u90fd\u662f\u4e00\u4e2a\u5b50\u4efb\u52a1\uff0c\u505a\u597d\u540e\u7531\u4e0b\u4e00\u5c42\u53bb\u505a\u8fdb\u4e00\u6b65\u7684\u4efb\u52a1\uff0c\u800c shallow network \u505a\u4e0d\u5230\u8fd9\u6837 \u4e00\u4e2a\u5f88\u597d\u7684\u4f8b\u5b50\u662f\uff0c\u8981\u628a input \u7684\u4eba\u7269\u5206\u4e3a\u56db\u7c7b\uff1a\u957f\u5934\u53d1\u5973\u751f\u3001\u957f\u5934\u53d1\u7537\u751f\u3001\u77ed\u5934\u53d1\u5973\u751f\u3001\u77ed\u5934\u53d1\u7537\u751f \u5982\u679c\u7528 shallow network \u5c31\u662f\u5206\u522b\u72ec\u7acb\u5730 train \u56db\u4e2a classifier (\u5c31\u76f8\u5f53\u4e8e\u8bad\u7ec3\u56db\u4e2a\u72ec\u7acb\u7684 model)\uff0c\u7136\u540e\u5c31\u53ef\u4ee5\u89e3\u51b3\u8fd9\u4e2a\u5206\u7c7b\u7684\u95ee\u9898\uff1b\u4f46\u662f\u6709\u4e00\u4e2a\u95ee\u9898\u662f\uff0c\u957f\u5934\u53d1\u7537\u751f\u7684 data \u662f\u6bd4\u8f83\u5c11\u7684\uff0c\u6ca1\u6709\u592a\u591a\u7684 training data\uff0c\u6240\u4ee5\uff0c\u4f60 train \u51fa\u6765\u7684 classifier \u5c31\u6bd4\u8f83 weak\uff0c\u53bb detect \u957f\u5934\u53d1\u7537\u751f\u7684 performance \u5c31\u6bd4\u8f83\u5dee \u4f46\u662f\u7537\u751f\u4e0e\u5973\u751f\u7684 data\uff0c\u957f\u53d1\u4e0e\u77ed\u53d1\u7684 data \u662f\u5f88\u591a\u7684\uff0c\u6240\u4ee5\u5982\u679c\u7528 deep network \u7684\u8bdd\uff0c\u7ecf\u8fc7\u524d\u9762\u51e0\u5c42 layer \u7684\u7279\u5f81\u62bd\u53d6\uff0c\u5c31\u53ef\u4ee5\u5934\u53d1\u7684 data \u4e22\u7ed9\u4e00\u4e2a Classifier2\uff0c\u628a\u7537\u751f\u6216\u5973\u751f\u7684 data \u4e22\u7ed9\u4e00\u4e2a Classifier1\uff0c\u8fd9\u6837\u5c31\u771f\u6b63\u505a\u5230\u4e86\u5145\u5206\u3001\u9ad8\u6548\u5730\u5229\u7528\u6570\u636e\uff0c\u6700\u7ec8\u7684 Classifier \u518d\u6839\u636e Classifier1 \u548c Classifier2 \u63d0\u4f9b\u7684\u4fe1\u606f\u7ed9\u51fa\u56db\u7c7b\u4eba\u7684\u5206\u7c7b\u7ed3\u679c","title":"Why Deep?"},{"location":"ML/5_Convolutional%20Neural%20Network/","text":"Convolutional Neural Network \u00b6 CNN \u5e38\u5e38\u88ab\u7528\u5728\u5f71\u50cf\u5904\u7406\u4e0a\uff0c\u5b83\u7684 theory base \u5c31\u662f\u4e09\u4e2aproperty\uff0c\u548c\u4e24\u4e2a\u67b6\u6784 convolution \u67b6\u6784\uff1a\u9488\u5bf9property 1\u548cproperty 2 max pooling \u67b6\u6784\uff1a\u9488\u5bf9property 3 Why CNN for Image\uff1f \u00b6 CNN vs DNN \u00b6 \u5728 train neural network \u7684\u65f6\u5019\uff0c\u6bcf\u4e00\u4e2a neuron \u90fd\u4ee3\u8868\u4e86\u4e00\u4e2a\u6700\u57fa\u672c\u7684 classifier \u4e3e\u4f8b\u5b50\u6765\u8bf4\uff0c\u7b2c\u4e00\u5c42 layer \u505a\u7684\u4e8b\u60c5\u5c31\u662f detect \u6709\u6ca1\u6709\u7eff\u8272\uff0c \u9ec4\u8272\uff0c\u659c\u6761\u7eb9\uff1b\u7136\u540e\u7b2c\u4e8c\u5c42\u505a\u66f4\u52a0\u590d\u6742\u7684\u4e8b\u60c5\uff0c\u6bd4\u5982\u770b\u5230\u76f4\u7ebf\u6a2a\u7ebf\u5c31\u662f\u6846\u7a97\u6846\u7684\u4e00\u90e8\u5206\uff0c\u770b\u5230\u68d5\u8272\u76f4\u6761\u7eb9\u5c31\u662f\u6728\u7eb9\uff1b\u7b2c\u4e09\u5c42 layer \u66f4\u590d\u6742... \u73b0\u5728\u7684\u95ee\u9898\u662f\uff0c\u5982\u679c\u6211\u4eec\u76f4\u63a5\u7528\u4e00\u822c\u7684 fully connected \u7684 feedforward network \u6765\u505a\u56fe\u50cf\u5904\u7406\u7684\u65f6\u5019\uff0c\u5f80\u5f80\u4f1a\u9700\u8981\u592a\u591a\u7684\u53c2\u6570 \u4e00\u5f20\u5f88\u5c0f\u7684 100*100 \u7684\u5f69\u56fe\u9700\u8981 100*100*3 \u7684 vector\uff0c\u52a0\u4e0a neuron \u53c2\u6570\u8fc7\u591a CNN \u505a\u7684\u5c31\u662f\u901a\u8fc7\u4e00\u4e9b\u5bf9\u5f71\u50cf\u5904\u7406\u7684\u7406\u89e3\u628a\u4e00\u4e9b\u7528\u4e0d\u5230\u7684\u53c2\u6570\u8fc7\u6ee4\u6389 Three Property for CNN theory base \u00b6 \u80fd\u7528\u8f83\u5c11\u7684\u7684\u53c2\u6570\u6765\u505a\u56fe\u50cf\u5904\u7406\u7684\u539f\u56e0\u662f\u4ee5\u4e0b\u4e09\u4e2a\u5bf9\u5f71\u50cf\u5904\u7406\u7684\u89c2\u5bdf\uff0c\u4e5f\u662f CNN \u67b6\u6784\u63d0\u51fa\u7684\u57fa\u7840 Some patterns are much smaller than the whole image \u00b6 \u5728\u5f71\u50cf\u5904\u7406\u91cc\uff0c\u4e00\u4e9b neuron \u505a\u7684\u4e8b\u60c5\u662f detect \u6709\u6ca1\u6709\u4e00\u79cd\u4e1c\u897f\u6216\u8005 pattern \u7684\u51fa\u73b0\uff0c\u8fd9\u4e2a pattern \u662f\u6bd4\u6574\u5f20 img \u5c0f\u5f88\u591a\u7684\uff0c\u6240\u4ee5\u4e0d\u9700\u8981\u770b\u6574\u5f20\u56fe\u7247\uff1b\u6bd4\u5982\u8981\u5224\u65ad\u56fe\u7247\u6709\u6ca1\u6709\u4e00\u5f20\u9e1f\u7684\u56fe\uff0c\u4e00\u4e9b neuron \u770b\u6709\u6ca1\u6709\u9e1f\u5634\uff0c\u4e00\u4e9b\u770b\u6709\u6ca1\u6709\u722a\u5b50\uff0c\u8fd9\u4e9b neuron \u90fd\u53ea\u9700\u8981\u8fde\u63a5\u5230 img \u4e0a\u7684\u4e00\u5c0f\u5757\u533a\u57df\uff0c\u4e0d\u9700\u8981\u5b8c\u6574\u7684\u56fe\uff0c\u6240\u4ee5\u5bf9\u5e94\u7740\u66f4\u5c0f\u7684\u53c2\u6570 The same patterns appear in different regions \u00b6 \u540c\u6837\u7684 pattern \u53ef\u80fd\u51fa\u73b0\u5728 img \u4e2d\u4e0d\u540c\u7684\u90e8\u5206\uff0c\u6bd4\u5982\u9e1f\u5634\u53ef\u80fd\u5728 img \u4e2d\u95f4\uff0c\u4e5f\u53ef\u80fd\u5728\u5de6\u4e0a\u89d2\uff0c\u6240\u4ee5\u53ef\u4ee5 share \u540c\u6837\u7684 neuron\uff0c\u540c\u6837\u7684\u53c2\u6570\u53bb detect\uff0c\u8fd9\u6837\u80fd\u51cf\u5c0f\u53c2\u6570 Subsampling the pixels will not change the object \u00b6 \u5bf9\u4e00\u5f20 image \u505a subsampling (\u4e8c\u6b21\u62bd\u6837)\uff0c\u6bd4\u5982\u628a\u5947\u6570\u884c\uff0c\u5076\u6570\u5217\u7684 pixel \u5220\u53bb\uff0c\u5e76\u4e0d\u5bf9\u5f71\u54cd\u4eba\u5bf9\u4e00\u5f20\u56fe\u7247\u7684\u7406\u89e3\uff0c\u4f9d\u65e7\u53ef\u4ee5\u8bc6\u522b\u56fe\u7247\u4e2d\u51fa\u73b0\u4e86\u4ec0\u4e48\uff0c\u6240\u4ee5\u505a subsampling \u4e5f\u80fd\u51cf\u5c0f\u53c2\u6570 The whole CNN structure \u00b6 CNN \u7684\u6574\u4f53\u67b6\u6784\uff1a\u901a\u8fc7 n \u6b21\u7684 Convolution + Max Pooling\uff0c\u8fd9\u4e2a n \u662f\u5728\u5b9a\u8fd9\u4e2anetwork \u7684\u67b6\u6784\u65f6\u5c31\u8981\u4e8b\u5148\u51b3\u5b9a\u597d\uff0c\u7136\u540e\u505a Flatten\uff0c\u7136\u540e\u662f\u4e00\u822c\u7684 Fully connected network \u91cc\u9762\u53bb\uff0c\u6700\u7ec8\u5f97\u5230\u5f71\u50cf\u8fa8\u8bc6\u7684\u7ed3\u679c Convolution \u7684 layer \u5904\u7406\u4e0a\u9762\u63d0\u5230\u7684\u524d 2 \u4e2a Property\uff0cMax Pooling \u5904\u7406\u7b2c\u4e09\u4e2a Convolution \u00b6 Property1 \u00b6 \u6bcf\u4e2a Filter \u662f\u4e00\u4e2a matrix\uff0c\u5176\u4e2d\u7684\u6bcf\u4e00\u4e2a\u503c\u90fd\u662f train \u51fa\u6765\u7684\uff0c\u800c\u4e0d\u662f\u4eba\u53bb\u8bbe\u8ba1 \u6bcf\u4e00\u4e2a Filter \u7684\u5927\u5c0f\u610f\u5473\u7740\u4ed6\u53ea\u4f1a\u5728\u8fd9\u4e2a\u533a\u57df\u5185 detect Property2 \u00b6 Filter \u4ece\u5de6\u4e0a\u89d2\u5f00\u59cb\u505a silde window\uff0c\u6bcf\u6b21\u79fb\u52a8\u4e00\u5b9a\u7684\u8ddd\u79bb\uff0c\u53eb\u505a stride\uff0c\u4e5f\u662f\u81ea\u5df1\u8bbe\u5b9a\uff0c\u6bcf\u6b21\u505c\u4e0b\u90fd\u505a\u5377\u79ef\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u6700\u7ec8\u5f97\u5230\u4e86\u4e00\u4e2a \\(4\\times4\\) \u7684 matrix\uff0c\u5176\u4e2d\u7684\u6700\u5927\u503c 2 \u4e2a 3 \u4ee3\u8868 detect \u7684 pattern \u5728\u5de6\u4e0a\u548c\u5de6\u4e0b Feature Map\uff1a \u4e00\u4e2a convolution \u7684 layer \u91cc\u9762\u4f1a\u6709\u5f88\u591a filter\uff0c\u4e0d\u540c\u7684 filter \u7684\u53c2\u6570\u4e0d\u540c\uff0c\u6bcf\u4e2a filter \u90fd\u4f1a\u5f97\u5230\u4e00\u4e2a matrix\uff0c\u6240\u6709\u7684 matrix \u5408\u8d77\u6765\u5c31\u53eb\u505a Feature Map(\u7279\u5f81\u6620\u5c04) \uff0c\u7531\u591a\u5c11\u4e2a filter\uff0c\u5c31\u6709\u591a\u5c11\u4e2a\u6620\u5c04\u540e\u7684 matrix CNN \u5bf9 \u4e0d\u540c scale \u7684\u76f8\u540c pattern \u7684\u5904\u7406 \u4e0a\u5b58\u5728\u4e00\u5b9a\u7684\u56f0\u96be\uff0c\u5982\u679c\u4f60\u4eca\u5929\u6709\u540c\u4e00\u4e2a pattern\uff0c\u5b83\u6709\u4e0d\u540c\u7684 size\uff0c\u6709\u5927\u7684\u9e1f\u5634\uff0c\u4e5f\u6709\u5c0f\u7684\u9e1f\u5634\uff0cCNN \u5e76\u4e0d\u80fd\u591f\u81ea\u52a8\u5904\u7406\u8fd9\u4e2a\u95ee\u9898\uff1bDeepMind \u66fe\u7ecf\u53d1\u8fc7\u4e00\u7bc7 paper\uff0c\u4e0a\u9762\u63d0\u5230\u4e86\u5f53\u4f60 input \u4e00\u5f20 image \u7684\u65f6\u5019\uff0c\u5b83\u5728 CNN \u524d\u9762\uff0c\u518d\u63a5\u53e6\u5916\u4e00\u4e2a network\uff0c\u8fd9\u4e2a network \u505a\u7684\u4e8b\u60c5\u662f\uff0c\u5b83\u4f1aoutput\u4e00\u4e9bscalar\uff0c\u544a\u8bc9\u4f60\u8bf4\uff0c\u5b83\u8981\u628a\u8fd9\u4e2a image \u7684\u91cc\u9762\u7684\u54ea\u4e9b\u4f4d\u7f6e\u505a\u65cb\u8f6c\u3001\u7f29\u653e\uff0c\u7136\u540e\uff0c\u518d\u4e22\u5230 CNN \u91cc\u9762\uff0c\u8fd9\u6837\u4f60\u5176\u5b9e\u4f1a\u5f97\u5230\u6bd4\u8f83\u597d\u7684 performance Colorful image\uff1a \u5982\u679c\u4e0d\u662f\u9ed1\u767d\u7684\u56fe\u800c\u662f\u5f69\u8272\u7684\u56fe\uff0c\u90a3\u4e48 filter \u5c31\u4e0d\u662f\u4e00\u4e2a matrix\uff0c\u662f\u4e00\u4e2a 3 \u5c42\u7684 \u7acb\u65b9\u4f53\uff08RGB\uff09\uff0c\u505a\u5b8c\u5377\u79ef\u540e\u4e5f\u662f 3 \u5c42\u7684 Convolution vs Fully connected \u00b6 convolution \u5176\u5b9e\u4e5f\u662f\u4e00\u4e2a neural network\uff0cfilter \u53ef\u4ee5\u770b\u6210 fully connected \u7684 layer \u628a\u4e00\u4e9bweight \u62ff\u6389\uff0c\u6bcf\u4e00\u4e2a neuron \u53ea\u68c0\u6d4b img \u4e2d\u7684\u90e8\u5206\u533a\u57df\uff0c\u800c\u4e14\u516c\u7528\u540c\u4e00\u4e2a weight\uff0c\u6240\u4ee5\u51cf\u5c0f\u4e86\u53c2\u6570 CNN \u7684\u672c\u8d28\u662f\u51cf\u5c0f\u4e86\u53c2\u6570 Max Pooling \u00b6 Max Pooling \u5c31\u662f\u505a subsampling\uff0cfilter \u540e\u5f97\u5230\u7684 matrix \u4e2d\u4ee5 4 \u4e2a\u4e3a\u4e00\u7ec4\u53d6\u6700\u5927\u503c\uff0c\u8fd9\u6837 img \u5c31\u4f1a\u7f29\u5c0f \u5982\u4f55\u5fae\u5206\u540e\u9762\u4f1a\u8bb2 Convolution + Max Pooling \u00b6 Convolution + Max Pooling \u53ef\u4ee5\u5f97\u5230\u4e00\u4e2a\u8f83\u5c0f\u7684 img\uff0c\u53ef\u4ee5\u53cd\u590d\u505a\u5f97\u5230\u4e00\u4e2a \u66f4\u5c0f\u7684 img \u6709\u4e00\u4e2a\u95ee\u9898\u662f\uff0c\u4e00\u4e2a Convolution \u6709 25 \u4e2a filter \u5f97\u5230 25 \u4e2a feature map\uff0crepeat \u7b2c\u4e8c\u4e2a Convolution \u4e5f\u6709 25 \u4e2a filter\uff0c\u662f\u4e0d\u662f\u4f1a\u6709 25*25 \u4e2a feature map \u5176\u5b9e\u4e0d\u662f\uff0c\u7b2c\u4e8c\u6b21 feature map \u4f1a\u8003\u8651\u6df1\u5ea6\uff0couyput \u8fd8\u662f 25 \u4e2a Flatten \u00b6 convolution \u548c max pooling\u4e4b\u540e\uff0c\u5c31\u662f FLatten \u548c Fully connected Feedforward network \u7684\u90e8\u5206 Flatten \u5c31\u662f\u628a feature map \u62c9\u76f4\uff0c\u7136\u540e\u4e22\u8fdb Fully connected Feedforward network CNN in Keras \u00b6 \u4e0e DNN \u6ca1\u4ec0\u4e48\u4e0d\u540c\uff0c\u9700\u8981\u6539\u53d8\u7684\u662f network structure\uff0c\u4ee5\u53ca input \u7684 format \u5728 input \u4e2d\uff0c\u5982\u679c\u662f\u4e00\u4e2a\u5f69\u56fe\uff0c\u5c31\u9700\u8981\u8f93\u5165\u4e00\u4e2a\u9ad8\u7ef4\u7684 matrix\uff08RGB\uff09\uff0c\u53eb\u505a tensor model2 . add ( Convolution2D ( 25 , 3 , 3 , input_shape = ( 28 , 28 , 1 )) ) Convolution2D \uff1a\u5206\u522b\u8868\u793a 25 \u4e2a filter\uff0c\u6bcf\u4e2a filter \u90fd\u662f 3*3 input_shape \uff1a\u4ee5\u624b\u5199\u6570\u5b57\u8fa8\u8bc6\u4e3a\u4f8b\u662f\u9ed1\u767d\u7684\uff0c\u6240\u4ee5\u662f\uff0828\uff0c28\uff0c1\uff09\uff0c\u5982\u679c\u662f\u5f69\u8272\u7684\u5c31\u8981 (28\uff0c28\uff0c3) model2 . add ( MaxPooling2D ( 2 , 2 ) ) MaxPooling2D \uff1a\u5206\u6210 2*2 \u7684\u533a\u57df \u4ee5\u4e0b\u56fe\u4e3a\u4f8b\uff0c\u7b2c\u4e00\u6b21 Convolution + Max Pooling \u540e\u5f97\u5230\u4e86 25*13*13 \u7684 feature map\uff0c\u7b2c\u4e8c\u6b21\u7684 Convolution \u7684 filter \u5176\u5b9e\u662f 3*3*25 \u7684 \u90a3\u8fd9\u6837\u4e00\u4e2a 25*13*13 \u548c 25*3*3 \u7684 cubic \u505a\u5185\u79ef\u4e4b\u540e\u4e0d\u5e94\u8be5\u662f 25*11*11 \u7684 cubic \u5417\uff1f\u5176\u5b9e\u8fd8\u4f1a\u5bf9\u6bcf\u4e00\u5c42\u505a\u6c42\u548c\u8fd0\u7b97\uff0c\u8fd9\u6837\u5c31\u662f 11*11 \u4e86\uff0c\u6240\u4ee5\u7b2c\u4e8c\u6b21\u7684 Convolution \u540e \u6bcf\u4e00\u4e2a filter \u90fd\u5f97\u5230\u4e00\u4e2a 11*11 \u7684 matrix Appendix\uff1aCNN in Keras \u00b6 import numpy as np from keras.models import Sequential from keras.layers import Convolution2D , MaxPooling2D , Flatten , Conv2D from keras.layers.core import Dense , Dropout , Activation from keras.optimizers import SGD , Adam from keras.utils import np_utils from keras.datasets import mnist # categorical_crossentropy def load_mnist_data ( number ): # the data, shuffled and split between train and test sets ( x_train , y_train ), ( x_test , y_test ) = mnist . load_data () x_train = x_train [ 0 : number ] y_train = y_train [ 0 : number ] x_train = x_train . reshape ( number , 784 ) x_test = x_test . reshape ( 10000 , 784 ) x_train = x_train . astype ( 'float32' ) x_test = x_test . astype ( 'float32' ) # convert class vectors to binary class matrices y_train = np_utils . to_categorical ( y_train , 10 ) y_test = np_utils . to_categorical ( y_test , 10 ) x_train = x_train / 255 x_test = x_test / 255 return ( x_train , y_train ), ( x_test , y_test ) if __name__ == '__main__' : ( x_train , y_train ), ( x_test , y_test ) = load_mnist_data ( 10000 ) # do DNN model = Sequential () model . add ( Dense ( input_dim = 28 * 28 , units = 500 , activation = 'relu' )) model . add ( Dense ( units = 500 , activation = 'relu' )) model . add ( Dense ( units = 500 , activation = 'relu' )) model . add ( Dense ( units = 10 , activation = 'softmax' )) model . summary () model . compile ( loss = 'categorical_crossentropy' , optimizer = 'adam' , metrics = [ 'accuracy' ]) model . fit ( x_train , y_train , batch_size = 100 , epochs = 20 ) result_train = model . evaluate ( x_train , y_train ) print ( ' \\n Train Acc: \\n ' , result_train [ 1 ]) result_test = model . evaluate ( x_test , y_test ) print ( ' \\n Test Acc: \\n ' , result_test [ 1 ]) # do CNN x_train = x_train . reshape ( x_train . shape [ 0 ], 1 , 28 , 28 ) x_test = x_test . reshape ( x_test . shape [ 0 ], 1 , 28 , 28 ) model2 = Sequential () model2 . add ( Conv2D ( 25 , ( 3 , 3 ), input_shape = ( 1 , 28 , 28 ), data_format = 'channels_first' )) model2 . add ( MaxPooling2D (( 2 , 2 ))) model2 . add ( Conv2D ( 50 , ( 3 , 3 ))) model2 . add ( MaxPooling2D (( 2 , 2 ))) model2 . add ( Flatten ()) model2 . add ( Dense ( units = 100 , activation = 'relu' )) model2 . add ( Dense ( units = 10 , activation = 'softmax' )) model2 . summary () model2 . compile ( loss = 'categorical_crossentropy' , optimizer = 'adam' , metrics = [ 'accuracy' ]) model2 . fit ( x_train , y_train , batch_size = 100 , epochs = 20 ) result_train = model2 . evaluate ( x_train , y_train ) print ( ' \\n Train CNN Acc: \\n ' , result_train [ 1 ]) result_test = model2 . evaluate ( x_test , y_test ) print ( ' \\n Test CNN Acc: \\n ' , result_test [ 1 ]) What does CNN learn\uff1f \u00b6 what does filter do \u00b6 \u5728 CNN \u4e2d\u7b2c\u4e00\u4e2a Convolution \u7684 filter \u662f\u6bd4\u8f83\u5bb9\u6613\u7406\u89e3\u7684\uff0c\u770b\u5b83\u6700\u7ec8\u7684\u503c\u662f\u4ec0\u4e48\u5c31\u77e5\u9053\u5b83\u5728 detect \u4ec0\u4e48\u4e1c\u897f\uff0c\u4f46\u662f\u540e\u9762\u7684\u5c31\u4e0d\u597d\u5206\u6790\u4e86\uff0c\u5b83\u8003\u8651\u7684\u8303\u56f4\u4e0d\u4ec5\u662f 3*3 \u7684 pixel\uff0c\u8fd8\u662f\u957f\u5bbd\u4e3a 3*3\uff0c\u9ad8\u4e3a 25 \u7684 cubic\uff08\u4ee5\u4e0a\u9762\u4e3a\u4f8b\u5b50\uff09\uff0c\u90a3\u4e00\u4e2a filter \u5230\u5e95\u5728\u505a\u4ec0\u4e48\u5462\uff1f \u628a\u7b2c\u4e8c\u4e2a Convolution \u7684\u67d0\u4e00\u4e2a filter \u7684 output \u62ff\u51fa\u6765\uff0c\u662f\u4e00\u4e2a 11*11 \u7684 matrix\uff0c\u91cc\u9762\u7684\u6bcf\u4e00\u4e2a element \u8bb0\u4f5c \\(a^k_{ij}\\) \u200b\uff0ck \u8868\u793a\u7b2c k \u4e2a filter \\(a^k\\) \u200b \u53eb\u505a Degree of the activation of the k-th filter \uff0c\u8868\u793a\u73b0\u5728\u7684\u7b2c k \u4e2a filter\uff0c\u5b83\u6709\u591a\u88ab activate\uff0c\u76f4\u89c2\u6765\u8bb2\u5c31\u662f\u63cf\u8ff0\u73b0\u5728 input \u7684\u4e1c\u897f\u8ddf\u7b2c k \u4e2a filter \u6709\u591a\u63a5\u8fd1\uff0c\u5b83\u5bf9 filter \u7684\u6fc0\u6d3b\u7a0b\u5ea6\u6709\u591a\u5c11\uff0c\u662f 11 11 \u7684 matrix \u7684 summation $$ a^k=\\sum\\limits^{11} {i=1}\\sum\\limits^{11} {j=1} a^k_{ij} $$ \u7136\u540e\u627e\u5230\u4e00\u4e2a img \\(x^*\\) \u200b\uff0c\u4f7f\u5f97 \\(a^k\\) \u6700\u5927\uff0c\u90a3\u8fd9\u4e2a \\(x^*\\) \u5c31\u662f filter \u5728\u627e\u7684\u56fe\u5f62 $$ x^ =\\arg \\max\\limits_x a^k $$ \u4e0a\u56fe\u6311\u9009\u4e86 12 \u4e2a\u4f7f\u5f97\u5176\u4e2d filter \u7684 activation \u6700\u5927\u7684\u56fe\u50cf\u7684\u4f8b\u5b50\uff0c\u90fd\u662f\u4e00\u4e9b texture what does neuron do \u00b6 \u8981\u77e5\u9053 Flatten \u540e\u7684 network \u91cc\u9762\u7684 neuron \u5b66\u5230\u7684\u662f\u4ec0\u4e48\u4e5f\u662f\u4e00\u6837\u7684\uff0c\u5b9a\u4e49\u7b2c j \u4e2a neuron \u7684 output \u662f \\(a_j\\) \u200b\u200b\uff0c\u90a3\u4e48\u4e0b\u9762\u7684 \\(x^*\\) \u5c31\u662f\u5b83\u5b66\u5230\u7684\u56fe\u50cf $$ x^*=\\arg \\max\\limits_x a_j $$ \u76f8\u6bd4\u4e8e filter \u7684\u56fe\u50cf\u4e0d\u518d\u662f texture\uff0c\u800c\u662f\u5b8c\u6574\u7684\u56fe\u50cf what about output \u00b6 \u53ef\u4ee5\u7ee7\u7eed\u7528\u4e0a\u9762\u7684\u65b9\u6cd5\u5f97\u51fa\u4f7f\u5f97\u6bcf\u4e2a output \u7684 activation \u6700\u5927\u7684\u56fe\u50cf\uff0c\u7ed3\u679c\u5982\u4e0b\uff1a \u6240\u4ee5\u8fd9\u4e2a neural network\uff0c\u5b83\u6240\u5b66\u5230\u7684\u4e1c\u897f\u8ddf\u6211\u4eec\u4eba\u7c7b\u4e00\u822c\u7684\u60f3\u8c61\u8ba4\u77e5\u662f\u4e0d\u4e00\u6837\u7684 \u90a3\u6211\u4eec\u6709\u6ca1\u6709\u529e\u6cd5\uff0c\u8ba9\u4e0a\u9762\u8fd9\u4e2a\u56fe\u770b\u8d77\u6765\u66f4\u50cf\u6570\u5b57\u5462\uff1f \u60f3\u6cd5\u662f\u52a0\u4e0a regularization\uff0c\u5982\u679c\u767d\u8272\u7684\u662f\u58a8\u6c34\uff0c\u90a3\u767d\u8272\u7684\u533a\u57df\u5e94\u8be5\u662f\u6709\u9650\u7684\uff0c\u4e0d\u4f1a\u6574\u5f20\u56fe\u90fd\u662f\u767d\u767d\u7684\uff0c\u8fd9\u91cc\u5229\u7528 L1 \u7684 regularization\uff0c\u628a\u6bcf\u4e2a pixel \u7684\u503c\u6c42\u548c $$ x^*=\\arg \\max\\limits_x (y^i-\\sum\\limits_{i,j} |x_{ij}|) $$ \u7ed3\u679c\u5982\u4e0b\uff0c\u5982\u679c\u518d\u52a0\u4e00\u4e9b constraint \u6bd4\u5982 \u76f8\u90bb\u7684\u989c\u8272 pixel \u989c\u8272\u8981\u4e00\u6837\u7ed3\u679c\u4f1a\u66f4\u597d Deep Dream \u00b6 \u7565 Deep Style \u00b6 \u7565 More Application\u2014\u2014Playing Go \u00b6 Why CNN for Playing Go \u00b6 AlphaGo \u7528\u4e86 CNN\uff0c\u90a3\u4ec0\u4e48\u65f6\u5019\u624d\u9002\u5408\u7528 CNN \u5462\uff1f \u8981\u6709image\u8be5\u6709\u7684\u90a3\u4e9b\u7279\u6027\uff0c\u4e5f\u5c31\u5f00\u5934\u6240\u8bf4\u7684\uff0c\u6839\u636e\u89c2\u5bdf\u5230\u7684\u4e09\u4e2a property\uff0c\u6211\u4eec\u624d\u8bbe\u8ba1\u51fa\u4e86 CNN \u8fd9\u6837\u7684network\u67b6\u6784\uff1a Some patterns are much smaller than the whole image The same patterns appear in different regions Subsampling the pixels will not change the object CNN \u80fd\u591f\u5e94\u7528\u5728 Alpha-Go \u4e0a\uff0c\u662f\u56e0\u4e3a\u56f4\u68cb\u6709\u4e00\u4e9b\u7279\u6027\u548c\u56fe\u50cf\u5904\u7406\u662f\u5f88\u76f8\u4f3c\u7684 property 1\uff1a\u56f4\u68cb\u4e2d\u4e00\u4e9b pattern \u6bd4\u5982 \u4e09\u4e2a\u5b50\u56f4\u4e00\u4e2a\u5b50 property 2\uff1a\u540c\u4e00\u4e2a pattern \u53ef\u4ee5\u51fa\u73b0\u5728\u4e0d\u540c\u4f4d\u7f6e \u4f46\u662f\u5176\u5b9e AlphaGo \u5e76\u6ca1\u6709 MaxPooling\uff0c\u56e0\u4e3a\u8fd9\u663e\u7136\u65e0\u6cd5\u5728\u56f4\u68cb\u4e2d\u4f7f\u7528\uff0c\u6240\u4ee5 structure \u9700\u8981\u5177\u4f53\u95ee\u9898\uff0c\u5177\u4f53\u5206\u6790 More Application\u2014\u2014Speech\u3001Text \u00b6 Convolution \u4e2d\u7684 silde window \u4e0d\u662f\u4e00\u5b9a\u8981\u65e2\u6709\u4e0a\u4e0b\u4e5f\u6709\u5de6\u53f3\u7684\uff0c\u6bd4\u5982\u8bed\u97f3\u8fa8\u8bc6\u4e2d\uff0c\u901a\u5e38\u53ea\u5728\u9891\u7387\u65b9\u5411\u4e0a\u79fb\u52a8 filter\uff0c\u800c\u4e0d\u5728\u65f6\u95f4\u4e0a\uff1b\u800c\u5728\u6587\u5b57\u8bc6\u522b\u4e2d\uff0cfilter \u53ea\u5728\u65f6\u95f4\uff08word\uff09\u7684\u987a\u5e8f\u4e0a\u79fb\u52a8 Conclusion \u00b6 \u4e09\u4e2a property \u00b6 Some patterns are much smaller than the whole image The same patterns appear in different regions Subsampling the pixels will not change the object \u4e24\u4e2a\u67b6\u6784 \u00b6 convolution \u67b6\u6784\uff1a\u9488\u5bf9 property 1 \u548c property 2 max pooling \u67b6\u6784\uff1a\u9488\u5bf9 property 3 \u4e00\u4e2a\u7406\u5ff5 \u00b6 \u9488\u5bf9\u4e0d\u540c\u7684 application \u8981\u8bbe\u8ba1\u7b26\u5408\u5b83\u7279\u6027\u7684 network structure\uff0c\u800c\u4e0d\u662f\u751f\u786c\u5957\u7528\uff0c\u8fd9\u5c31\u662f CNN \u67b6\u6784\u7684\u8bbe\u8ba1\u7406\u5ff5","title":"CNN"},{"location":"ML/5_Convolutional%20Neural%20Network/#convolutional-neural-network","text":"CNN \u5e38\u5e38\u88ab\u7528\u5728\u5f71\u50cf\u5904\u7406\u4e0a\uff0c\u5b83\u7684 theory base \u5c31\u662f\u4e09\u4e2aproperty\uff0c\u548c\u4e24\u4e2a\u67b6\u6784 convolution \u67b6\u6784\uff1a\u9488\u5bf9property 1\u548cproperty 2 max pooling \u67b6\u6784\uff1a\u9488\u5bf9property 3","title":"Convolutional Neural Network"},{"location":"ML/5_Convolutional%20Neural%20Network/#why-cnn-for-image","text":"","title":"Why CNN for Image\uff1f"},{"location":"ML/5_Convolutional%20Neural%20Network/#cnn-vs-dnn","text":"\u5728 train neural network \u7684\u65f6\u5019\uff0c\u6bcf\u4e00\u4e2a neuron \u90fd\u4ee3\u8868\u4e86\u4e00\u4e2a\u6700\u57fa\u672c\u7684 classifier \u4e3e\u4f8b\u5b50\u6765\u8bf4\uff0c\u7b2c\u4e00\u5c42 layer \u505a\u7684\u4e8b\u60c5\u5c31\u662f detect \u6709\u6ca1\u6709\u7eff\u8272\uff0c \u9ec4\u8272\uff0c\u659c\u6761\u7eb9\uff1b\u7136\u540e\u7b2c\u4e8c\u5c42\u505a\u66f4\u52a0\u590d\u6742\u7684\u4e8b\u60c5\uff0c\u6bd4\u5982\u770b\u5230\u76f4\u7ebf\u6a2a\u7ebf\u5c31\u662f\u6846\u7a97\u6846\u7684\u4e00\u90e8\u5206\uff0c\u770b\u5230\u68d5\u8272\u76f4\u6761\u7eb9\u5c31\u662f\u6728\u7eb9\uff1b\u7b2c\u4e09\u5c42 layer \u66f4\u590d\u6742... \u73b0\u5728\u7684\u95ee\u9898\u662f\uff0c\u5982\u679c\u6211\u4eec\u76f4\u63a5\u7528\u4e00\u822c\u7684 fully connected \u7684 feedforward network \u6765\u505a\u56fe\u50cf\u5904\u7406\u7684\u65f6\u5019\uff0c\u5f80\u5f80\u4f1a\u9700\u8981\u592a\u591a\u7684\u53c2\u6570 \u4e00\u5f20\u5f88\u5c0f\u7684 100*100 \u7684\u5f69\u56fe\u9700\u8981 100*100*3 \u7684 vector\uff0c\u52a0\u4e0a neuron \u53c2\u6570\u8fc7\u591a CNN \u505a\u7684\u5c31\u662f\u901a\u8fc7\u4e00\u4e9b\u5bf9\u5f71\u50cf\u5904\u7406\u7684\u7406\u89e3\u628a\u4e00\u4e9b\u7528\u4e0d\u5230\u7684\u53c2\u6570\u8fc7\u6ee4\u6389","title":"CNN vs DNN"},{"location":"ML/5_Convolutional%20Neural%20Network/#three-property-for-cnn-theory-base","text":"\u80fd\u7528\u8f83\u5c11\u7684\u7684\u53c2\u6570\u6765\u505a\u56fe\u50cf\u5904\u7406\u7684\u539f\u56e0\u662f\u4ee5\u4e0b\u4e09\u4e2a\u5bf9\u5f71\u50cf\u5904\u7406\u7684\u89c2\u5bdf\uff0c\u4e5f\u662f CNN \u67b6\u6784\u63d0\u51fa\u7684\u57fa\u7840","title":"Three Property for CNN theory base"},{"location":"ML/5_Convolutional%20Neural%20Network/#some-patterns-are-much-smaller-than-the-whole-image","text":"\u5728\u5f71\u50cf\u5904\u7406\u91cc\uff0c\u4e00\u4e9b neuron \u505a\u7684\u4e8b\u60c5\u662f detect \u6709\u6ca1\u6709\u4e00\u79cd\u4e1c\u897f\u6216\u8005 pattern \u7684\u51fa\u73b0\uff0c\u8fd9\u4e2a pattern \u662f\u6bd4\u6574\u5f20 img \u5c0f\u5f88\u591a\u7684\uff0c\u6240\u4ee5\u4e0d\u9700\u8981\u770b\u6574\u5f20\u56fe\u7247\uff1b\u6bd4\u5982\u8981\u5224\u65ad\u56fe\u7247\u6709\u6ca1\u6709\u4e00\u5f20\u9e1f\u7684\u56fe\uff0c\u4e00\u4e9b neuron \u770b\u6709\u6ca1\u6709\u9e1f\u5634\uff0c\u4e00\u4e9b\u770b\u6709\u6ca1\u6709\u722a\u5b50\uff0c\u8fd9\u4e9b neuron \u90fd\u53ea\u9700\u8981\u8fde\u63a5\u5230 img \u4e0a\u7684\u4e00\u5c0f\u5757\u533a\u57df\uff0c\u4e0d\u9700\u8981\u5b8c\u6574\u7684\u56fe\uff0c\u6240\u4ee5\u5bf9\u5e94\u7740\u66f4\u5c0f\u7684\u53c2\u6570","title":"Some patterns are much smaller than the whole image"},{"location":"ML/5_Convolutional%20Neural%20Network/#the-same-patterns-appear-in-different-regions","text":"\u540c\u6837\u7684 pattern \u53ef\u80fd\u51fa\u73b0\u5728 img \u4e2d\u4e0d\u540c\u7684\u90e8\u5206\uff0c\u6bd4\u5982\u9e1f\u5634\u53ef\u80fd\u5728 img \u4e2d\u95f4\uff0c\u4e5f\u53ef\u80fd\u5728\u5de6\u4e0a\u89d2\uff0c\u6240\u4ee5\u53ef\u4ee5 share \u540c\u6837\u7684 neuron\uff0c\u540c\u6837\u7684\u53c2\u6570\u53bb detect\uff0c\u8fd9\u6837\u80fd\u51cf\u5c0f\u53c2\u6570","title":"The same patterns appear in different regions"},{"location":"ML/5_Convolutional%20Neural%20Network/#subsampling-the-pixels-will-not-change-the-object","text":"\u5bf9\u4e00\u5f20 image \u505a subsampling (\u4e8c\u6b21\u62bd\u6837)\uff0c\u6bd4\u5982\u628a\u5947\u6570\u884c\uff0c\u5076\u6570\u5217\u7684 pixel \u5220\u53bb\uff0c\u5e76\u4e0d\u5bf9\u5f71\u54cd\u4eba\u5bf9\u4e00\u5f20\u56fe\u7247\u7684\u7406\u89e3\uff0c\u4f9d\u65e7\u53ef\u4ee5\u8bc6\u522b\u56fe\u7247\u4e2d\u51fa\u73b0\u4e86\u4ec0\u4e48\uff0c\u6240\u4ee5\u505a subsampling \u4e5f\u80fd\u51cf\u5c0f\u53c2\u6570","title":"Subsampling the pixels will not change the object"},{"location":"ML/5_Convolutional%20Neural%20Network/#the-whole-cnn-structure","text":"CNN \u7684\u6574\u4f53\u67b6\u6784\uff1a\u901a\u8fc7 n \u6b21\u7684 Convolution + Max Pooling\uff0c\u8fd9\u4e2a n \u662f\u5728\u5b9a\u8fd9\u4e2anetwork \u7684\u67b6\u6784\u65f6\u5c31\u8981\u4e8b\u5148\u51b3\u5b9a\u597d\uff0c\u7136\u540e\u505a Flatten\uff0c\u7136\u540e\u662f\u4e00\u822c\u7684 Fully connected network \u91cc\u9762\u53bb\uff0c\u6700\u7ec8\u5f97\u5230\u5f71\u50cf\u8fa8\u8bc6\u7684\u7ed3\u679c Convolution \u7684 layer \u5904\u7406\u4e0a\u9762\u63d0\u5230\u7684\u524d 2 \u4e2a Property\uff0cMax Pooling \u5904\u7406\u7b2c\u4e09\u4e2a","title":"The whole CNN structure"},{"location":"ML/5_Convolutional%20Neural%20Network/#convolution","text":"","title":"Convolution"},{"location":"ML/5_Convolutional%20Neural%20Network/#property1","text":"\u6bcf\u4e2a Filter \u662f\u4e00\u4e2a matrix\uff0c\u5176\u4e2d\u7684\u6bcf\u4e00\u4e2a\u503c\u90fd\u662f train \u51fa\u6765\u7684\uff0c\u800c\u4e0d\u662f\u4eba\u53bb\u8bbe\u8ba1 \u6bcf\u4e00\u4e2a Filter \u7684\u5927\u5c0f\u610f\u5473\u7740\u4ed6\u53ea\u4f1a\u5728\u8fd9\u4e2a\u533a\u57df\u5185 detect","title":"Property1"},{"location":"ML/5_Convolutional%20Neural%20Network/#property2","text":"Filter \u4ece\u5de6\u4e0a\u89d2\u5f00\u59cb\u505a silde window\uff0c\u6bcf\u6b21\u79fb\u52a8\u4e00\u5b9a\u7684\u8ddd\u79bb\uff0c\u53eb\u505a stride\uff0c\u4e5f\u662f\u81ea\u5df1\u8bbe\u5b9a\uff0c\u6bcf\u6b21\u505c\u4e0b\u90fd\u505a\u5377\u79ef\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u6700\u7ec8\u5f97\u5230\u4e86\u4e00\u4e2a \\(4\\times4\\) \u7684 matrix\uff0c\u5176\u4e2d\u7684\u6700\u5927\u503c 2 \u4e2a 3 \u4ee3\u8868 detect \u7684 pattern \u5728\u5de6\u4e0a\u548c\u5de6\u4e0b Feature Map\uff1a \u4e00\u4e2a convolution \u7684 layer \u91cc\u9762\u4f1a\u6709\u5f88\u591a filter\uff0c\u4e0d\u540c\u7684 filter \u7684\u53c2\u6570\u4e0d\u540c\uff0c\u6bcf\u4e2a filter \u90fd\u4f1a\u5f97\u5230\u4e00\u4e2a matrix\uff0c\u6240\u6709\u7684 matrix \u5408\u8d77\u6765\u5c31\u53eb\u505a Feature Map(\u7279\u5f81\u6620\u5c04) \uff0c\u7531\u591a\u5c11\u4e2a filter\uff0c\u5c31\u6709\u591a\u5c11\u4e2a\u6620\u5c04\u540e\u7684 matrix CNN \u5bf9 \u4e0d\u540c scale \u7684\u76f8\u540c pattern \u7684\u5904\u7406 \u4e0a\u5b58\u5728\u4e00\u5b9a\u7684\u56f0\u96be\uff0c\u5982\u679c\u4f60\u4eca\u5929\u6709\u540c\u4e00\u4e2a pattern\uff0c\u5b83\u6709\u4e0d\u540c\u7684 size\uff0c\u6709\u5927\u7684\u9e1f\u5634\uff0c\u4e5f\u6709\u5c0f\u7684\u9e1f\u5634\uff0cCNN \u5e76\u4e0d\u80fd\u591f\u81ea\u52a8\u5904\u7406\u8fd9\u4e2a\u95ee\u9898\uff1bDeepMind \u66fe\u7ecf\u53d1\u8fc7\u4e00\u7bc7 paper\uff0c\u4e0a\u9762\u63d0\u5230\u4e86\u5f53\u4f60 input \u4e00\u5f20 image \u7684\u65f6\u5019\uff0c\u5b83\u5728 CNN \u524d\u9762\uff0c\u518d\u63a5\u53e6\u5916\u4e00\u4e2a network\uff0c\u8fd9\u4e2a network \u505a\u7684\u4e8b\u60c5\u662f\uff0c\u5b83\u4f1aoutput\u4e00\u4e9bscalar\uff0c\u544a\u8bc9\u4f60\u8bf4\uff0c\u5b83\u8981\u628a\u8fd9\u4e2a image \u7684\u91cc\u9762\u7684\u54ea\u4e9b\u4f4d\u7f6e\u505a\u65cb\u8f6c\u3001\u7f29\u653e\uff0c\u7136\u540e\uff0c\u518d\u4e22\u5230 CNN \u91cc\u9762\uff0c\u8fd9\u6837\u4f60\u5176\u5b9e\u4f1a\u5f97\u5230\u6bd4\u8f83\u597d\u7684 performance Colorful image\uff1a \u5982\u679c\u4e0d\u662f\u9ed1\u767d\u7684\u56fe\u800c\u662f\u5f69\u8272\u7684\u56fe\uff0c\u90a3\u4e48 filter \u5c31\u4e0d\u662f\u4e00\u4e2a matrix\uff0c\u662f\u4e00\u4e2a 3 \u5c42\u7684 \u7acb\u65b9\u4f53\uff08RGB\uff09\uff0c\u505a\u5b8c\u5377\u79ef\u540e\u4e5f\u662f 3 \u5c42\u7684","title":"Property2"},{"location":"ML/5_Convolutional%20Neural%20Network/#convolution-vs-fully-connected","text":"convolution \u5176\u5b9e\u4e5f\u662f\u4e00\u4e2a neural network\uff0cfilter \u53ef\u4ee5\u770b\u6210 fully connected \u7684 layer \u628a\u4e00\u4e9bweight \u62ff\u6389\uff0c\u6bcf\u4e00\u4e2a neuron \u53ea\u68c0\u6d4b img \u4e2d\u7684\u90e8\u5206\u533a\u57df\uff0c\u800c\u4e14\u516c\u7528\u540c\u4e00\u4e2a weight\uff0c\u6240\u4ee5\u51cf\u5c0f\u4e86\u53c2\u6570 CNN \u7684\u672c\u8d28\u662f\u51cf\u5c0f\u4e86\u53c2\u6570","title":"Convolution vs Fully connected"},{"location":"ML/5_Convolutional%20Neural%20Network/#max-pooling","text":"Max Pooling \u5c31\u662f\u505a subsampling\uff0cfilter \u540e\u5f97\u5230\u7684 matrix \u4e2d\u4ee5 4 \u4e2a\u4e3a\u4e00\u7ec4\u53d6\u6700\u5927\u503c\uff0c\u8fd9\u6837 img \u5c31\u4f1a\u7f29\u5c0f \u5982\u4f55\u5fae\u5206\u540e\u9762\u4f1a\u8bb2","title":"Max Pooling"},{"location":"ML/5_Convolutional%20Neural%20Network/#convolution-max-pooling","text":"Convolution + Max Pooling \u53ef\u4ee5\u5f97\u5230\u4e00\u4e2a\u8f83\u5c0f\u7684 img\uff0c\u53ef\u4ee5\u53cd\u590d\u505a\u5f97\u5230\u4e00\u4e2a \u66f4\u5c0f\u7684 img \u6709\u4e00\u4e2a\u95ee\u9898\u662f\uff0c\u4e00\u4e2a Convolution \u6709 25 \u4e2a filter \u5f97\u5230 25 \u4e2a feature map\uff0crepeat \u7b2c\u4e8c\u4e2a Convolution \u4e5f\u6709 25 \u4e2a filter\uff0c\u662f\u4e0d\u662f\u4f1a\u6709 25*25 \u4e2a feature map \u5176\u5b9e\u4e0d\u662f\uff0c\u7b2c\u4e8c\u6b21 feature map \u4f1a\u8003\u8651\u6df1\u5ea6\uff0couyput \u8fd8\u662f 25 \u4e2a","title":"Convolution + Max Pooling"},{"location":"ML/5_Convolutional%20Neural%20Network/#flatten","text":"convolution \u548c max pooling\u4e4b\u540e\uff0c\u5c31\u662f FLatten \u548c Fully connected Feedforward network \u7684\u90e8\u5206 Flatten \u5c31\u662f\u628a feature map \u62c9\u76f4\uff0c\u7136\u540e\u4e22\u8fdb Fully connected Feedforward network","title":"Flatten"},{"location":"ML/5_Convolutional%20Neural%20Network/#cnn-in-keras","text":"\u4e0e DNN \u6ca1\u4ec0\u4e48\u4e0d\u540c\uff0c\u9700\u8981\u6539\u53d8\u7684\u662f network structure\uff0c\u4ee5\u53ca input \u7684 format \u5728 input \u4e2d\uff0c\u5982\u679c\u662f\u4e00\u4e2a\u5f69\u56fe\uff0c\u5c31\u9700\u8981\u8f93\u5165\u4e00\u4e2a\u9ad8\u7ef4\u7684 matrix\uff08RGB\uff09\uff0c\u53eb\u505a tensor model2 . add ( Convolution2D ( 25 , 3 , 3 , input_shape = ( 28 , 28 , 1 )) ) Convolution2D \uff1a\u5206\u522b\u8868\u793a 25 \u4e2a filter\uff0c\u6bcf\u4e2a filter \u90fd\u662f 3*3 input_shape \uff1a\u4ee5\u624b\u5199\u6570\u5b57\u8fa8\u8bc6\u4e3a\u4f8b\u662f\u9ed1\u767d\u7684\uff0c\u6240\u4ee5\u662f\uff0828\uff0c28\uff0c1\uff09\uff0c\u5982\u679c\u662f\u5f69\u8272\u7684\u5c31\u8981 (28\uff0c28\uff0c3) model2 . add ( MaxPooling2D ( 2 , 2 ) ) MaxPooling2D \uff1a\u5206\u6210 2*2 \u7684\u533a\u57df \u4ee5\u4e0b\u56fe\u4e3a\u4f8b\uff0c\u7b2c\u4e00\u6b21 Convolution + Max Pooling \u540e\u5f97\u5230\u4e86 25*13*13 \u7684 feature map\uff0c\u7b2c\u4e8c\u6b21\u7684 Convolution \u7684 filter \u5176\u5b9e\u662f 3*3*25 \u7684 \u90a3\u8fd9\u6837\u4e00\u4e2a 25*13*13 \u548c 25*3*3 \u7684 cubic \u505a\u5185\u79ef\u4e4b\u540e\u4e0d\u5e94\u8be5\u662f 25*11*11 \u7684 cubic \u5417\uff1f\u5176\u5b9e\u8fd8\u4f1a\u5bf9\u6bcf\u4e00\u5c42\u505a\u6c42\u548c\u8fd0\u7b97\uff0c\u8fd9\u6837\u5c31\u662f 11*11 \u4e86\uff0c\u6240\u4ee5\u7b2c\u4e8c\u6b21\u7684 Convolution \u540e \u6bcf\u4e00\u4e2a filter \u90fd\u5f97\u5230\u4e00\u4e2a 11*11 \u7684 matrix","title":"CNN in Keras"},{"location":"ML/5_Convolutional%20Neural%20Network/#appendixcnn-in-keras","text":"import numpy as np from keras.models import Sequential from keras.layers import Convolution2D , MaxPooling2D , Flatten , Conv2D from keras.layers.core import Dense , Dropout , Activation from keras.optimizers import SGD , Adam from keras.utils import np_utils from keras.datasets import mnist # categorical_crossentropy def load_mnist_data ( number ): # the data, shuffled and split between train and test sets ( x_train , y_train ), ( x_test , y_test ) = mnist . load_data () x_train = x_train [ 0 : number ] y_train = y_train [ 0 : number ] x_train = x_train . reshape ( number , 784 ) x_test = x_test . reshape ( 10000 , 784 ) x_train = x_train . astype ( 'float32' ) x_test = x_test . astype ( 'float32' ) # convert class vectors to binary class matrices y_train = np_utils . to_categorical ( y_train , 10 ) y_test = np_utils . to_categorical ( y_test , 10 ) x_train = x_train / 255 x_test = x_test / 255 return ( x_train , y_train ), ( x_test , y_test ) if __name__ == '__main__' : ( x_train , y_train ), ( x_test , y_test ) = load_mnist_data ( 10000 ) # do DNN model = Sequential () model . add ( Dense ( input_dim = 28 * 28 , units = 500 , activation = 'relu' )) model . add ( Dense ( units = 500 , activation = 'relu' )) model . add ( Dense ( units = 500 , activation = 'relu' )) model . add ( Dense ( units = 10 , activation = 'softmax' )) model . summary () model . compile ( loss = 'categorical_crossentropy' , optimizer = 'adam' , metrics = [ 'accuracy' ]) model . fit ( x_train , y_train , batch_size = 100 , epochs = 20 ) result_train = model . evaluate ( x_train , y_train ) print ( ' \\n Train Acc: \\n ' , result_train [ 1 ]) result_test = model . evaluate ( x_test , y_test ) print ( ' \\n Test Acc: \\n ' , result_test [ 1 ]) # do CNN x_train = x_train . reshape ( x_train . shape [ 0 ], 1 , 28 , 28 ) x_test = x_test . reshape ( x_test . shape [ 0 ], 1 , 28 , 28 ) model2 = Sequential () model2 . add ( Conv2D ( 25 , ( 3 , 3 ), input_shape = ( 1 , 28 , 28 ), data_format = 'channels_first' )) model2 . add ( MaxPooling2D (( 2 , 2 ))) model2 . add ( Conv2D ( 50 , ( 3 , 3 ))) model2 . add ( MaxPooling2D (( 2 , 2 ))) model2 . add ( Flatten ()) model2 . add ( Dense ( units = 100 , activation = 'relu' )) model2 . add ( Dense ( units = 10 , activation = 'softmax' )) model2 . summary () model2 . compile ( loss = 'categorical_crossentropy' , optimizer = 'adam' , metrics = [ 'accuracy' ]) model2 . fit ( x_train , y_train , batch_size = 100 , epochs = 20 ) result_train = model2 . evaluate ( x_train , y_train ) print ( ' \\n Train CNN Acc: \\n ' , result_train [ 1 ]) result_test = model2 . evaluate ( x_test , y_test ) print ( ' \\n Test CNN Acc: \\n ' , result_test [ 1 ])","title":"Appendix\uff1aCNN in Keras"},{"location":"ML/5_Convolutional%20Neural%20Network/#what-does-cnn-learn","text":"","title":"What does CNN learn\uff1f"},{"location":"ML/5_Convolutional%20Neural%20Network/#what-does-filter-do","text":"\u5728 CNN \u4e2d\u7b2c\u4e00\u4e2a Convolution \u7684 filter \u662f\u6bd4\u8f83\u5bb9\u6613\u7406\u89e3\u7684\uff0c\u770b\u5b83\u6700\u7ec8\u7684\u503c\u662f\u4ec0\u4e48\u5c31\u77e5\u9053\u5b83\u5728 detect \u4ec0\u4e48\u4e1c\u897f\uff0c\u4f46\u662f\u540e\u9762\u7684\u5c31\u4e0d\u597d\u5206\u6790\u4e86\uff0c\u5b83\u8003\u8651\u7684\u8303\u56f4\u4e0d\u4ec5\u662f 3*3 \u7684 pixel\uff0c\u8fd8\u662f\u957f\u5bbd\u4e3a 3*3\uff0c\u9ad8\u4e3a 25 \u7684 cubic\uff08\u4ee5\u4e0a\u9762\u4e3a\u4f8b\u5b50\uff09\uff0c\u90a3\u4e00\u4e2a filter \u5230\u5e95\u5728\u505a\u4ec0\u4e48\u5462\uff1f \u628a\u7b2c\u4e8c\u4e2a Convolution \u7684\u67d0\u4e00\u4e2a filter \u7684 output \u62ff\u51fa\u6765\uff0c\u662f\u4e00\u4e2a 11*11 \u7684 matrix\uff0c\u91cc\u9762\u7684\u6bcf\u4e00\u4e2a element \u8bb0\u4f5c \\(a^k_{ij}\\) \u200b\uff0ck \u8868\u793a\u7b2c k \u4e2a filter \\(a^k\\) \u200b \u53eb\u505a Degree of the activation of the k-th filter \uff0c\u8868\u793a\u73b0\u5728\u7684\u7b2c k \u4e2a filter\uff0c\u5b83\u6709\u591a\u88ab activate\uff0c\u76f4\u89c2\u6765\u8bb2\u5c31\u662f\u63cf\u8ff0\u73b0\u5728 input \u7684\u4e1c\u897f\u8ddf\u7b2c k \u4e2a filter \u6709\u591a\u63a5\u8fd1\uff0c\u5b83\u5bf9 filter \u7684\u6fc0\u6d3b\u7a0b\u5ea6\u6709\u591a\u5c11\uff0c\u662f 11 11 \u7684 matrix \u7684 summation $$ a^k=\\sum\\limits^{11} {i=1}\\sum\\limits^{11} {j=1} a^k_{ij} $$ \u7136\u540e\u627e\u5230\u4e00\u4e2a img \\(x^*\\) \u200b\uff0c\u4f7f\u5f97 \\(a^k\\) \u6700\u5927\uff0c\u90a3\u8fd9\u4e2a \\(x^*\\) \u5c31\u662f filter \u5728\u627e\u7684\u56fe\u5f62 $$ x^ =\\arg \\max\\limits_x a^k $$ \u4e0a\u56fe\u6311\u9009\u4e86 12 \u4e2a\u4f7f\u5f97\u5176\u4e2d filter \u7684 activation \u6700\u5927\u7684\u56fe\u50cf\u7684\u4f8b\u5b50\uff0c\u90fd\u662f\u4e00\u4e9b texture","title":"what does filter do"},{"location":"ML/5_Convolutional%20Neural%20Network/#what-does-neuron-do","text":"\u8981\u77e5\u9053 Flatten \u540e\u7684 network \u91cc\u9762\u7684 neuron \u5b66\u5230\u7684\u662f\u4ec0\u4e48\u4e5f\u662f\u4e00\u6837\u7684\uff0c\u5b9a\u4e49\u7b2c j \u4e2a neuron \u7684 output \u662f \\(a_j\\) \u200b\u200b\uff0c\u90a3\u4e48\u4e0b\u9762\u7684 \\(x^*\\) \u5c31\u662f\u5b83\u5b66\u5230\u7684\u56fe\u50cf $$ x^*=\\arg \\max\\limits_x a_j $$ \u76f8\u6bd4\u4e8e filter \u7684\u56fe\u50cf\u4e0d\u518d\u662f texture\uff0c\u800c\u662f\u5b8c\u6574\u7684\u56fe\u50cf","title":"what does neuron do"},{"location":"ML/5_Convolutional%20Neural%20Network/#what-about-output","text":"\u53ef\u4ee5\u7ee7\u7eed\u7528\u4e0a\u9762\u7684\u65b9\u6cd5\u5f97\u51fa\u4f7f\u5f97\u6bcf\u4e2a output \u7684 activation \u6700\u5927\u7684\u56fe\u50cf\uff0c\u7ed3\u679c\u5982\u4e0b\uff1a \u6240\u4ee5\u8fd9\u4e2a neural network\uff0c\u5b83\u6240\u5b66\u5230\u7684\u4e1c\u897f\u8ddf\u6211\u4eec\u4eba\u7c7b\u4e00\u822c\u7684\u60f3\u8c61\u8ba4\u77e5\u662f\u4e0d\u4e00\u6837\u7684 \u90a3\u6211\u4eec\u6709\u6ca1\u6709\u529e\u6cd5\uff0c\u8ba9\u4e0a\u9762\u8fd9\u4e2a\u56fe\u770b\u8d77\u6765\u66f4\u50cf\u6570\u5b57\u5462\uff1f \u60f3\u6cd5\u662f\u52a0\u4e0a regularization\uff0c\u5982\u679c\u767d\u8272\u7684\u662f\u58a8\u6c34\uff0c\u90a3\u767d\u8272\u7684\u533a\u57df\u5e94\u8be5\u662f\u6709\u9650\u7684\uff0c\u4e0d\u4f1a\u6574\u5f20\u56fe\u90fd\u662f\u767d\u767d\u7684\uff0c\u8fd9\u91cc\u5229\u7528 L1 \u7684 regularization\uff0c\u628a\u6bcf\u4e2a pixel \u7684\u503c\u6c42\u548c $$ x^*=\\arg \\max\\limits_x (y^i-\\sum\\limits_{i,j} |x_{ij}|) $$ \u7ed3\u679c\u5982\u4e0b\uff0c\u5982\u679c\u518d\u52a0\u4e00\u4e9b constraint \u6bd4\u5982 \u76f8\u90bb\u7684\u989c\u8272 pixel \u989c\u8272\u8981\u4e00\u6837\u7ed3\u679c\u4f1a\u66f4\u597d","title":"what about output"},{"location":"ML/5_Convolutional%20Neural%20Network/#deep-dream","text":"\u7565","title":"Deep Dream"},{"location":"ML/5_Convolutional%20Neural%20Network/#deep-style","text":"\u7565","title":"Deep Style"},{"location":"ML/5_Convolutional%20Neural%20Network/#more-applicationplaying-go","text":"","title":"More Application\u2014\u2014Playing Go"},{"location":"ML/5_Convolutional%20Neural%20Network/#why-cnn-for-playing-go","text":"AlphaGo \u7528\u4e86 CNN\uff0c\u90a3\u4ec0\u4e48\u65f6\u5019\u624d\u9002\u5408\u7528 CNN \u5462\uff1f \u8981\u6709image\u8be5\u6709\u7684\u90a3\u4e9b\u7279\u6027\uff0c\u4e5f\u5c31\u5f00\u5934\u6240\u8bf4\u7684\uff0c\u6839\u636e\u89c2\u5bdf\u5230\u7684\u4e09\u4e2a property\uff0c\u6211\u4eec\u624d\u8bbe\u8ba1\u51fa\u4e86 CNN \u8fd9\u6837\u7684network\u67b6\u6784\uff1a Some patterns are much smaller than the whole image The same patterns appear in different regions Subsampling the pixels will not change the object CNN \u80fd\u591f\u5e94\u7528\u5728 Alpha-Go \u4e0a\uff0c\u662f\u56e0\u4e3a\u56f4\u68cb\u6709\u4e00\u4e9b\u7279\u6027\u548c\u56fe\u50cf\u5904\u7406\u662f\u5f88\u76f8\u4f3c\u7684 property 1\uff1a\u56f4\u68cb\u4e2d\u4e00\u4e9b pattern \u6bd4\u5982 \u4e09\u4e2a\u5b50\u56f4\u4e00\u4e2a\u5b50 property 2\uff1a\u540c\u4e00\u4e2a pattern \u53ef\u4ee5\u51fa\u73b0\u5728\u4e0d\u540c\u4f4d\u7f6e \u4f46\u662f\u5176\u5b9e AlphaGo \u5e76\u6ca1\u6709 MaxPooling\uff0c\u56e0\u4e3a\u8fd9\u663e\u7136\u65e0\u6cd5\u5728\u56f4\u68cb\u4e2d\u4f7f\u7528\uff0c\u6240\u4ee5 structure \u9700\u8981\u5177\u4f53\u95ee\u9898\uff0c\u5177\u4f53\u5206\u6790","title":"Why CNN for Playing Go"},{"location":"ML/5_Convolutional%20Neural%20Network/#more-applicationspeechtext","text":"Convolution \u4e2d\u7684 silde window \u4e0d\u662f\u4e00\u5b9a\u8981\u65e2\u6709\u4e0a\u4e0b\u4e5f\u6709\u5de6\u53f3\u7684\uff0c\u6bd4\u5982\u8bed\u97f3\u8fa8\u8bc6\u4e2d\uff0c\u901a\u5e38\u53ea\u5728\u9891\u7387\u65b9\u5411\u4e0a\u79fb\u52a8 filter\uff0c\u800c\u4e0d\u5728\u65f6\u95f4\u4e0a\uff1b\u800c\u5728\u6587\u5b57\u8bc6\u522b\u4e2d\uff0cfilter \u53ea\u5728\u65f6\u95f4\uff08word\uff09\u7684\u987a\u5e8f\u4e0a\u79fb\u52a8","title":"More Application\u2014\u2014Speech\u3001Text"},{"location":"ML/5_Convolutional%20Neural%20Network/#conclusion","text":"","title":"Conclusion"},{"location":"ML/5_Convolutional%20Neural%20Network/#property","text":"Some patterns are much smaller than the whole image The same patterns appear in different regions Subsampling the pixels will not change the object","title":"\u4e09\u4e2a property"},{"location":"ML/5_Convolutional%20Neural%20Network/#_1","text":"convolution \u67b6\u6784\uff1a\u9488\u5bf9 property 1 \u548c property 2 max pooling \u67b6\u6784\uff1a\u9488\u5bf9 property 3","title":"\u4e24\u4e2a\u67b6\u6784"},{"location":"ML/5_Convolutional%20Neural%20Network/#_2","text":"\u9488\u5bf9\u4e0d\u540c\u7684 application \u8981\u8bbe\u8ba1\u7b26\u5408\u5b83\u7279\u6027\u7684 network structure\uff0c\u800c\u4e0d\u662f\u751f\u786c\u5957\u7528\uff0c\u8fd9\u5c31\u662f CNN \u67b6\u6784\u7684\u8bbe\u8ba1\u7406\u5ff5","title":"\u4e00\u4e2a\u7406\u5ff5"},{"location":"ML/6_Recurrent%20Neural%20Network/","text":"Recurrent Neural Network \u00b6 RNN\uff1a\u5faa\u73af\u795e\u7ecf\u7f51\u7edc Basic Concept \u00b6 Slot Filling\uff1aSlot Filling \u5e0c\u671b\u5b9e\u73b0\u7684\u662f\u7ed9\u51fa\u4e00\u4e2a\u53e5\u5b50\uff0c\u5982 I would like to arrive Taipei on November 2nd \u540e\uff0c\u80fd\u591f\u5f97\u5230\u5176\u4e2d 2 \u4e2a\u4e3b\u8981\u5185\u5bb9\uff0cDestination\uff1aTaipei\uff0ctime of arrival\uff1aNovember 2nd\uff0c\u6240\u4ee5\u53eb Slot Filling\uff08\u69fd\u586b\u5145\uff09 input \u56e0\u4e3a\u662f\u5355\u8bcd\u6240\u4ee5\u53ef\u4ee5\u7528 1-of-N encoding\uff0c\u9664\u6b64\u4e4b\u5916\uff0c\u6211\u4eec\u8fd8\u8981\u52a0\u4e00\u4e2a dimension for \"Others\"\uff0c\u4e5f\u53ef\u4ee5\u7528 Word hashing 1111 \u4f46\u8fd8\u6709\u4e00\u4e2a\u95ee\u9898\u5c31\u662f\uff0c\u5e76\u4e0d\u4e00\u5b9a\u90fd\u662f arrive \u7684\uff0c\u4e5f\u6709\u53ef\u80fd\u662f leave Taipei \u7684\uff0c\u6240\u4ee5\u6211\u4eec\u8981\u7ed9 Neural network \u66f4\u591a\u7684 memory\uff0c\u53bb\u8bb0\u4f4f\u524d\u9762\u7684\u4fe1\u606f \u53ef\u4ee5\u7528 2 \u4e2a\u989d\u5916\u7684 memory \u53bb store \u524d\u9762\u7684\u4fe1\u606f\uff0c\u5e76\u628a\u4ed6\u4eec\u4e5f\u4f5c\u4e3ainput \u4ee5\u4e0b\u56fe\u4e3a\u4f8b\uff0cmemory \u7684\u521d\u59cb\u503c\u8bbe\u4e3a 0\uff0cNeural network \u7684 weight \u90fd\u662f 1\uff0cbias \u90fd\u662f 0\uff0c\u7b2c\u4e00\u5c42 layer \u7684 output \u4f1a\u5b58\u50a8\u5230 memory \u4e2d\u4f5c\u4e3a\u4e0b\u4e00\u6b21\u7684 input 22222 \u5927\u4f53\u7684\u6d41\u7a0b\u5982\u4e0b\uff08\u540c\u4e00\u4e2a network \u4f7f\u7528\u591a\u6b21\uff09 3333 \u5f53\u7136\u4e5f\u53ef\u4ee5\u662f deep \u7684\uff0c\u6bcf\u4e00\u5c42\u7684 layer \u7684 output \u90fd\u5b58\u50a8\u4e0b\u6765 4444 \u4e0a\u9762\u7684\u53eb\u505a Elman Network\uff0c\u8fd8\u6709\u5176\u4ed6\u4e0d\u540c sturcuture \u7684 network \u6bd4\u5982 Jordan Network \u80fd\u5f97\u5230\u66f4\u597d\u7684\u7ed3\u679c\uff0c\u56e0\u4e3a\u5b83\u7684 output \\(y^t\\) \u662f\u6709 target \u7684\u200b 5555 Bidirectional RNN RNN \u4e5f\u53ef\u4ee5\u662f\u53cc\u5411\u7684\uff0c\u6b63\u5411\u505a\u7684\u540c\u65f6\u9006\u5411\u505a\uff0c\u5e76\u5f97\u5230 \\(y^t\\) \u200b\u200b\u200b\uff0c\u8fd9\u6837\u7684\u8bdd Neuron Network \u80fd\u591f\u540c\u65f6\u770b\u4e24\u8fb9 6666 Long Short-term Memory\uff08LSTM\uff09 \u6bcf\u4e2a Memory Cell \u90fd\u6709\u4e00\u4e2a input gate\uff0coutput gate\uff0cforget gate\uff0c\u4ec0\u4e48\u65f6\u5019\u6253\u5f00 input gate\uff0c\u6253\u5f00 output gate\uff0c\u6253\u5f00 forget gate \u90fd\u662f network \u81ea\u5df1\u5b66\u5230\u7684 \u53ef\u4ee5\u770b\u6210\u6709 4 \u4e2a input\uff0c1 \u4e2a output 77777 \\(c^{'}\\) \u200b \u662f\u65b0\u7684\u5b58\u50a8\u5728 memory \u4e2d\u7684\u503c 8888 \u4e0b\u56fe\u662f\u4e2a\u4f8b\u5b50\uff0c \\(x_1\\) \u8868\u793a input data, \\(x_2 = 1\\) \u8868\u793a input gate \u6253\u5f00\uff0c \\(x_2=-1\\) \u8868\u793a forget gate \u6253\u5f00\uff0c \\(x_3=1\\) \u200b\u200b \u8868\u793a output gate \u6253\u5f00\uff0c\u6bcf\u4e00\u4e2a weight \u548c bias \u90fd\u662f train \u51fa\u6765\u7684 LSTM \u76f8\u6bd4\u4e8e\u666e\u901a\u7684 Network \u9700\u8981 4 \u500d\u7684\u53c2\u6570 999 LSTM \u7684\u771f\u6b63\u5f62\u6001\uff1a\u9664\u4e86\u5f53\u524d\u65f6\u95f4\u70b9\u7684 input \u5916\u8fd8\u6709\u4e0a\u4e00\u4e2a\u65f6\u95f4\u70b9\u7684 output \u548c peephole\uff08\u628a\u5b58\u5728 memory \u4e2d\u7684\u503c\u4e5f\u52a0\u8fdb input\uff09 Keras \u4e2d\u652f\u6301\u4e09\u79cd LSTM\uff1aLSTM\uff0cGRU\uff0cSimpleRNN 1010 How to learn? \u00b6 Loss Function \u00b6 \u6bcf\u4e00\u4e2a output \u7684\u4e0e label \u7684 cross entropy \u7684\u548c 1111 update \u7684\u65b9\u6cd5\u4e5f\u662f\u7528 backpropagation\uff0c\u53eb\u505a backpropagation through time\uff08BPTT\uff09\uff0c\u5728 time sequence \u4e0a\u8fd0\u4f5c\uff0c\u8fd9\u91cc\u4e0d\u5c55\u5f00 \u4e0d\u5e78\u7684\u662f\uff0cRNN-based network \u662f\u4e0d\u592a\u5bb9\u6613 train \u7684\uff0ctotal loss \u5e76\u4e0d\u662f\u4e00\u76f4\u4e0b\u964d\u7684\u800c\u4e14\u5728\u4e00\u4e9b\u5730\u65b9\u975e\u5e38\u7684\u5e73\u5766\uff0c\u4e00\u4e9b\u5730\u65b9\u975e\u5e38\u7684\u9661\u5ced 1212 Clipping \u00b6 \u901a\u8fc7 Clipping \u89e3\u51b3 total loss \u7684\u56fe\u50cf\u9661\u5ced\u7684\u95ee\u9898 Clipping \u662f\u5728 update \u7684\u8fc7\u7a0b\u4e2d\u5f53 gradient \u5927\u4e8e\u67d0\u4e2a\u503c\u65f6\uff0c\u8ba9\u5b83\u5c31\u7b49\u4e8e\u67d0\u4e2a\u503c\uff0c\u5373\u8bbe\u5b9a\u4e00\u4e2a threshold \u4f1a\u51fa\u73b0\u8fd9\u6837\u7684\u539f\u56e0\u4e0d\u662f\u56e0\u4e3a activation function\uff0c\u5f53\u628a sigmoid function \u6539\u6210 ReLU \u540e performance \u53cd\u800c\u4f1a\u53d8\u5dee \u4e0b\u9762\u7528\u4e00\u4e2a\u6700\u7b80\u5355\u7684\u4f8b\u5b50\u6765\u89e3\u91ca\u4e3a\u4ec0\u4e48\u4f1a\u6709\u8fd9\u79cd\u60c5\u51b5 \u5f53\u9664\u4e86 neuron transition \u4e4b\u95f4\u7684 weight \u90fd\u662f 1 \u65f6\uff0c\u7b2c\u4e00\u4e2a input \u6539\u53d8\u4e00\u70b9\uff0c\u5bf9 ouput \u7684\u5f71\u54cd\u5c31\u4f1a\u975e\u5e38\u5927\uff0clearning rate \u592a\u5927\u592a\u5c0f\u90fd\u4f1a\u6709\u95ee\u9898 1313 \u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u88ab\u5e7f\u6cdb\u91c7\u53d6\u7684\u65b9\u6cd5\u5c31\u662f LSTM\uff0c\u5b83\u53ef\u4ee5\u628a loss \u56fe\u50cf\u4e2d\u5e73\u5766\u7684\u5730\u65b9\u62ff\u6389\uff08\u907f\u514d gradient \u7279\u522b\u5c0f\uff09\uff0c\u8fd9\u6837\u5c31\u53ef\u4ee5\u653e\u5fc3\u7684\u628a learning rate \u8bbe\u5c0f\u4e00\u4e9b\uff1b\u56e0\u4e3a \u5982\u679c weight \u7684\u503c\u5bf9 memory \u7684\u4ea7\u751f\u4e86\u5f71\u54cd\uff0c\u8fd9\u4e2a\u5f71\u54cd\u4f1a\u4e00\u76f4\u5b58\u5728\uff08\u9664\u975e forget \u6389\uff09 Gated Recurrent Unit\uff08GRU\uff09simpler than LSTM \u53ea\u6709 2 \u4e2a gate\uff0c\u6240\u4ee5\u53c2\u6570\u6bd4 LSTM \u5c11\uff0c\u5982\u679c overfitting \u4e86\u53ef\u4ee5\u5c1d\u8bd5 More Applications \u00b6 Sentiment Analysis\uff1a\u5224\u65ad\u8bc4\u4ef7\u7684\u6b63\u8d1f\u9762 \u5224\u65ad\u6587\u7ae0\u7684 key term Both input and output are both sequences\uff0cbut the output is shorter\uff0c\u6bd4\u5982 Speech Recognition \u540e\u9762 Applications \u8fd8\u8bb2\u4e86\u5f88\u591a \u3002\u3002\u3002\u3002\u3002\u3002","title":"RNN"},{"location":"ML/6_Recurrent%20Neural%20Network/#recurrent-neural-network","text":"RNN\uff1a\u5faa\u73af\u795e\u7ecf\u7f51\u7edc","title":"Recurrent Neural Network"},{"location":"ML/6_Recurrent%20Neural%20Network/#basic-concept","text":"Slot Filling\uff1aSlot Filling \u5e0c\u671b\u5b9e\u73b0\u7684\u662f\u7ed9\u51fa\u4e00\u4e2a\u53e5\u5b50\uff0c\u5982 I would like to arrive Taipei on November 2nd \u540e\uff0c\u80fd\u591f\u5f97\u5230\u5176\u4e2d 2 \u4e2a\u4e3b\u8981\u5185\u5bb9\uff0cDestination\uff1aTaipei\uff0ctime of arrival\uff1aNovember 2nd\uff0c\u6240\u4ee5\u53eb Slot Filling\uff08\u69fd\u586b\u5145\uff09 input \u56e0\u4e3a\u662f\u5355\u8bcd\u6240\u4ee5\u53ef\u4ee5\u7528 1-of-N encoding\uff0c\u9664\u6b64\u4e4b\u5916\uff0c\u6211\u4eec\u8fd8\u8981\u52a0\u4e00\u4e2a dimension for \"Others\"\uff0c\u4e5f\u53ef\u4ee5\u7528 Word hashing 1111 \u4f46\u8fd8\u6709\u4e00\u4e2a\u95ee\u9898\u5c31\u662f\uff0c\u5e76\u4e0d\u4e00\u5b9a\u90fd\u662f arrive \u7684\uff0c\u4e5f\u6709\u53ef\u80fd\u662f leave Taipei \u7684\uff0c\u6240\u4ee5\u6211\u4eec\u8981\u7ed9 Neural network \u66f4\u591a\u7684 memory\uff0c\u53bb\u8bb0\u4f4f\u524d\u9762\u7684\u4fe1\u606f \u53ef\u4ee5\u7528 2 \u4e2a\u989d\u5916\u7684 memory \u53bb store \u524d\u9762\u7684\u4fe1\u606f\uff0c\u5e76\u628a\u4ed6\u4eec\u4e5f\u4f5c\u4e3ainput \u4ee5\u4e0b\u56fe\u4e3a\u4f8b\uff0cmemory \u7684\u521d\u59cb\u503c\u8bbe\u4e3a 0\uff0cNeural network \u7684 weight \u90fd\u662f 1\uff0cbias \u90fd\u662f 0\uff0c\u7b2c\u4e00\u5c42 layer \u7684 output \u4f1a\u5b58\u50a8\u5230 memory \u4e2d\u4f5c\u4e3a\u4e0b\u4e00\u6b21\u7684 input 22222 \u5927\u4f53\u7684\u6d41\u7a0b\u5982\u4e0b\uff08\u540c\u4e00\u4e2a network \u4f7f\u7528\u591a\u6b21\uff09 3333 \u5f53\u7136\u4e5f\u53ef\u4ee5\u662f deep \u7684\uff0c\u6bcf\u4e00\u5c42\u7684 layer \u7684 output \u90fd\u5b58\u50a8\u4e0b\u6765 4444 \u4e0a\u9762\u7684\u53eb\u505a Elman Network\uff0c\u8fd8\u6709\u5176\u4ed6\u4e0d\u540c sturcuture \u7684 network \u6bd4\u5982 Jordan Network \u80fd\u5f97\u5230\u66f4\u597d\u7684\u7ed3\u679c\uff0c\u56e0\u4e3a\u5b83\u7684 output \\(y^t\\) \u662f\u6709 target \u7684\u200b 5555 Bidirectional RNN RNN \u4e5f\u53ef\u4ee5\u662f\u53cc\u5411\u7684\uff0c\u6b63\u5411\u505a\u7684\u540c\u65f6\u9006\u5411\u505a\uff0c\u5e76\u5f97\u5230 \\(y^t\\) \u200b\u200b\u200b\uff0c\u8fd9\u6837\u7684\u8bdd Neuron Network \u80fd\u591f\u540c\u65f6\u770b\u4e24\u8fb9 6666 Long Short-term Memory\uff08LSTM\uff09 \u6bcf\u4e2a Memory Cell \u90fd\u6709\u4e00\u4e2a input gate\uff0coutput gate\uff0cforget gate\uff0c\u4ec0\u4e48\u65f6\u5019\u6253\u5f00 input gate\uff0c\u6253\u5f00 output gate\uff0c\u6253\u5f00 forget gate \u90fd\u662f network \u81ea\u5df1\u5b66\u5230\u7684 \u53ef\u4ee5\u770b\u6210\u6709 4 \u4e2a input\uff0c1 \u4e2a output 77777 \\(c^{'}\\) \u200b \u662f\u65b0\u7684\u5b58\u50a8\u5728 memory \u4e2d\u7684\u503c 8888 \u4e0b\u56fe\u662f\u4e2a\u4f8b\u5b50\uff0c \\(x_1\\) \u8868\u793a input data, \\(x_2 = 1\\) \u8868\u793a input gate \u6253\u5f00\uff0c \\(x_2=-1\\) \u8868\u793a forget gate \u6253\u5f00\uff0c \\(x_3=1\\) \u200b\u200b \u8868\u793a output gate \u6253\u5f00\uff0c\u6bcf\u4e00\u4e2a weight \u548c bias \u90fd\u662f train \u51fa\u6765\u7684 LSTM \u76f8\u6bd4\u4e8e\u666e\u901a\u7684 Network \u9700\u8981 4 \u500d\u7684\u53c2\u6570 999 LSTM \u7684\u771f\u6b63\u5f62\u6001\uff1a\u9664\u4e86\u5f53\u524d\u65f6\u95f4\u70b9\u7684 input \u5916\u8fd8\u6709\u4e0a\u4e00\u4e2a\u65f6\u95f4\u70b9\u7684 output \u548c peephole\uff08\u628a\u5b58\u5728 memory \u4e2d\u7684\u503c\u4e5f\u52a0\u8fdb input\uff09 Keras \u4e2d\u652f\u6301\u4e09\u79cd LSTM\uff1aLSTM\uff0cGRU\uff0cSimpleRNN 1010","title":"Basic Concept"},{"location":"ML/6_Recurrent%20Neural%20Network/#how-to-learn","text":"","title":"How to learn?"},{"location":"ML/6_Recurrent%20Neural%20Network/#loss-function","text":"\u6bcf\u4e00\u4e2a output \u7684\u4e0e label \u7684 cross entropy \u7684\u548c 1111 update \u7684\u65b9\u6cd5\u4e5f\u662f\u7528 backpropagation\uff0c\u53eb\u505a backpropagation through time\uff08BPTT\uff09\uff0c\u5728 time sequence \u4e0a\u8fd0\u4f5c\uff0c\u8fd9\u91cc\u4e0d\u5c55\u5f00 \u4e0d\u5e78\u7684\u662f\uff0cRNN-based network \u662f\u4e0d\u592a\u5bb9\u6613 train \u7684\uff0ctotal loss \u5e76\u4e0d\u662f\u4e00\u76f4\u4e0b\u964d\u7684\u800c\u4e14\u5728\u4e00\u4e9b\u5730\u65b9\u975e\u5e38\u7684\u5e73\u5766\uff0c\u4e00\u4e9b\u5730\u65b9\u975e\u5e38\u7684\u9661\u5ced 1212","title":"Loss Function"},{"location":"ML/6_Recurrent%20Neural%20Network/#clipping","text":"\u901a\u8fc7 Clipping \u89e3\u51b3 total loss \u7684\u56fe\u50cf\u9661\u5ced\u7684\u95ee\u9898 Clipping \u662f\u5728 update \u7684\u8fc7\u7a0b\u4e2d\u5f53 gradient \u5927\u4e8e\u67d0\u4e2a\u503c\u65f6\uff0c\u8ba9\u5b83\u5c31\u7b49\u4e8e\u67d0\u4e2a\u503c\uff0c\u5373\u8bbe\u5b9a\u4e00\u4e2a threshold \u4f1a\u51fa\u73b0\u8fd9\u6837\u7684\u539f\u56e0\u4e0d\u662f\u56e0\u4e3a activation function\uff0c\u5f53\u628a sigmoid function \u6539\u6210 ReLU \u540e performance \u53cd\u800c\u4f1a\u53d8\u5dee \u4e0b\u9762\u7528\u4e00\u4e2a\u6700\u7b80\u5355\u7684\u4f8b\u5b50\u6765\u89e3\u91ca\u4e3a\u4ec0\u4e48\u4f1a\u6709\u8fd9\u79cd\u60c5\u51b5 \u5f53\u9664\u4e86 neuron transition \u4e4b\u95f4\u7684 weight \u90fd\u662f 1 \u65f6\uff0c\u7b2c\u4e00\u4e2a input \u6539\u53d8\u4e00\u70b9\uff0c\u5bf9 ouput \u7684\u5f71\u54cd\u5c31\u4f1a\u975e\u5e38\u5927\uff0clearning rate \u592a\u5927\u592a\u5c0f\u90fd\u4f1a\u6709\u95ee\u9898 1313 \u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u88ab\u5e7f\u6cdb\u91c7\u53d6\u7684\u65b9\u6cd5\u5c31\u662f LSTM\uff0c\u5b83\u53ef\u4ee5\u628a loss \u56fe\u50cf\u4e2d\u5e73\u5766\u7684\u5730\u65b9\u62ff\u6389\uff08\u907f\u514d gradient \u7279\u522b\u5c0f\uff09\uff0c\u8fd9\u6837\u5c31\u53ef\u4ee5\u653e\u5fc3\u7684\u628a learning rate \u8bbe\u5c0f\u4e00\u4e9b\uff1b\u56e0\u4e3a \u5982\u679c weight \u7684\u503c\u5bf9 memory \u7684\u4ea7\u751f\u4e86\u5f71\u54cd\uff0c\u8fd9\u4e2a\u5f71\u54cd\u4f1a\u4e00\u76f4\u5b58\u5728\uff08\u9664\u975e forget \u6389\uff09 Gated Recurrent Unit\uff08GRU\uff09simpler than LSTM \u53ea\u6709 2 \u4e2a gate\uff0c\u6240\u4ee5\u53c2\u6570\u6bd4 LSTM \u5c11\uff0c\u5982\u679c overfitting \u4e86\u53ef\u4ee5\u5c1d\u8bd5","title":"Clipping"},{"location":"ML/6_Recurrent%20Neural%20Network/#more-applications","text":"Sentiment Analysis\uff1a\u5224\u65ad\u8bc4\u4ef7\u7684\u6b63\u8d1f\u9762 \u5224\u65ad\u6587\u7ae0\u7684 key term Both input and output are both sequences\uff0cbut the output is shorter\uff0c\u6bd4\u5982 Speech Recognition \u540e\u9762 Applications \u8fd8\u8bb2\u4e86\u5f88\u591a \u3002\u3002\u3002\u3002\u3002\u3002","title":"More Applications"},{"location":"ML/7_Semi-supervised%20Learning/","text":"Semi-supervised Learning \u00b6 \u534a\u76d1\u7763\u5b66\u4e60\uff1a Semi-supervised Learning for Generative Model Low-density Separation Assumption\uff1a\u975e\u9ed1\u5373\u767d Smoothness Assumption\uff1a\u8fd1\u6731\u8005\u8d64\uff0c\u8fd1\u58a8\u8005\u9ed1 Better Representation\uff1a\u53bb\u829c\u5b58\u83c1\uff0c\u5316\u7e41\u4e3a\u7b80 Introduction \u00b6 \u4e3a\u4ec0\u4e48\u8981\u505a Semi-supervised Learning\uff0c\u56e0\u4e3a data \u7684 input \u5f88\u5bb9\u6613\u5f97\u5230\uff0c\u4f46\u662f\u5f88\u591a\u90fd\u7f3a output\uff08label\uff09 Supervised Learning \u00b6 \\((x^r,\\hat y^r)_{r=1}^R\\) \u200b \u5728 training data \u4e2d\u6bcf\u4e00\u7ec4 data \u7684 input \\(x\\) \u200b \u90fd\u6709 output \\(y\\) \u200b\u200b\u200b\u200b Semi-supervised Learning \u00b6 \\(\\{(x^r,\\hat y^r)\\}_{r=1}^R\\} + \\{x^u\\}_{u=R}^{R+U}\\) \u200b Supervised Learning \u52a0\u4e0a\u6ca1\u6709 output \u7684 data\uff0c\u800c\u4e14\u901a\u5e38 \\(U>>R\\) \u200b\u200b \u200b Semi-supervised learning\u5206\u4e3a\u4ee5\u4e0b\u4e24\u79cd\u60c5\u51b5\uff1a Transductive Learning\uff1aunlabeled data is the testing data \u5373\uff0c\u628a testing data \u5f53\u505a\u65e0\u6807\u7b7e\u7684 training data \u4f7f\u7528\uff0c\u9002\u7528\u4e8e\u4e8b\u5148\u5df2\u7ecf\u77e5\u9053 testing data \u7684\u60c5\u51b5 (\u6bd4\u5982\u4e00\u4e9b\u6bd4\u8d5b\u7684\u65f6\u5019\uff0c\u53ea\u77e5\u9053 data \u7684 feature \u800c\u4e0d\u77e5\u9053 output) Inductive Learning\uff1aunlabeled data is not the testing data \u5373\uff0c\u4e0d\u628a testing data \u7684 feature \u62ff\u53bb\u7ed9\u673a\u5668\u8bad\u7ec3\uff0c\u9002\u7528\u4e8e\u4e8b\u5148\u5e76\u4e0d\u77e5\u9053 testing data \u7684\u60c5\u51b5 (\u66f4\u666e\u904d\u7684\u60c5\u51b5) Why semi-supervised learning help\uff1f \u00b6 unlabelled data \u867d\u7136\u53ea\u6709 input \u4f46\u5b83\u7684\u5206\u5e03\u53ef\u4ee5\u7ed9\u6211\u4eec\u4e00\u4e9b\u4fe1\u606f\uff0c\u4ee5\u4e0b\u4e3a\u4f8b semi-supervised learning \u7684\u4f7f\u7528\u5f80\u5f80\u4f34\u968f\u7740\u5047\u8bbe\uff0c\u800c\u8be5\u5047\u8bbe\u7684\u5408\u7406\u4e0e\u5426\uff0c\u51b3\u5b9a\u4e86\u7ed3\u679c\u7684\u597d\u574f\u7a0b\u5ea6\uff1b\u6bd4\u5982\u4e0a\u56fe\u4e2d\u7684 unlabeled data\uff0c\u5b83\u663e\u7136\u662f\u4e00\u53ea\u72d7\uff0c\u800c\u7279\u5f81\u5206\u5e03\u5374\u4e0e\u732b\u88ab\u5212\u5206\u5728\u4e86\u4e00\u8d77\uff0c\u5f88\u53ef\u80fd\u662f\u7531\u4e8e\u8fd9\u4e24\u5f20\u56fe\u7247\u7684\u80cc\u666f\u90fd\u662f\u7eff\u8272\u5bfc\u81f4\u7684\uff0c\u56e0\u6b64\u5047\u8bbe\u662f\u5426\u5408\u7406\u663e\u5f97\u81f3\u5173\u91cd\u8981 Generative Model \u00b6 \u5728\u76d1\u7763\u5b66\u4e60\u4e2d\u6211\u4eec\u5b66\u4e60\u8fc7\u901a\u8fc7\u540e\u9a8c\u6982\u7387\u5f97\u51fa x \u6240\u5c5e\u7684\u7c7b\u522b \u4e0b\u56fe\u5b9e\u7ebf\u662f Supervised Generative Model \u5f97\u51fa\u7684\u7ed3\u679c\uff0c\u7eff\u8272\u7684\u70b9\u662f\u6ca1\u6709 label \u7684 data\uff0c\u663e\u7136\u539f\u5148\u7684 \\(u,\\Sigma\\) \u662f\u4e0d\u5408\u7406\u7684 \u4ee5\u4e0a\u662f\u76f4\u89c2\u4e0a\u7684\u89e3\u91ca\uff0c\u63a5\u4e0b\u6765\u8fdb\u884c\u5177\u4f53\u63a8\u5bfc (\u5047\u8bbe\u505a\u4e8c\u5143\u5206\u7c7b)\uff1a \u5229\u7528\u6709 label \u7684 data \u521d\u59cb\u5316\u4e00\u7ec4\u53c2\u6570\uff1a \\(\\theta=\\{P(C_1),P(C_2),u^1,u^2,\\Sigma\\}\\) step1\uff1a\u5229\u7528\u4e0a\u9762\u521d\u59cb model \u8ba1\u7b97\u6bcf\u4e00\u7b14 unlabeled data \\(x^u\\) \u5c5e\u4e8e class1 \u7684\u6982\u7387 \\(P_{\\theta}(C_1|x^u)\\) step2\uff1aupdate model \u5982\u679c\u4e0d\u8003\u8651 unlabeled data\uff0c\u5219\u5148\u9a8c\u6982\u7387\u663e\u7136\u4e3a\u5c5e\u4e8e class1 \u7684\u6837\u672c\u70b9\u6570 \\(N_1\\) / \u603b\u7684\u6837\u672c\u70b9\u6570 \\(N\\) \uff0c\u5373 \\(P(C_1)=\\frac{N_1}{N}\\) \u200b \u800c\u8003\u8651 unlabeled data \u65f6\uff0c\u5206\u5b50\u8fd8\u8981\u52a0\u4e0a\u6240\u6709 unlabeled data \u5c5e\u4e8e class1 \u7684\u6982\u7387\u548c\uff0c\u6b64\u65f6\u5b83\u4eec\u88ab\u770b\u4f5c\u5c0f\u6570\uff0c\u53ef\u4ee5\u7406\u89e3\u4e3a\u6309\u7167\u6982\u7387\u4e00\u90e8\u5206\u5c5e\u4e8e \\(C_1\\) \uff0c\u4e00\u90e8\u5206\u5c5e\u4e8e \\(C_2\\) $$ P(C_1)=\\frac{N_1+\\sum_{x^u}P(C_1|x^u)}{N} $$ \u540c\u7406\uff0c\u5bf9\u4e8e\u5747\u503c\uff0c\u539f\u5148\u7684 mean \\(u_1=\\frac{1}{N_1}\\sum\\limits_{x^r\\in C_1} x^r\\) \u52a0\u4e0a\u6839\u636e\u6982\u7387\u5bf9 \\(x^u\\) \u6c42\u548c\u518d\u5f52\u4e00\u5316\u7684\u7ed3\u679c\u5373\u53ef $$ u_1=\\frac{1}{N_1}\\sum\\limits_{x^r\\in C_1} x^r+\\frac{1}{\\sum_{x^u}P(C_1|x^u)}\\sum\\limits_{x^u}P(C_1|x^u)x^u $$ \u5269\u4f59\u7684\u53c2\u6570\u540c\u7406\uff0c\u63a5\u4e0b\u6765\u5c31\u6709\u4e86\u4e00\u7ec4\u65b0\u7684\u53c2\u6570 \\(\\theta'\\) \uff0c\u4e8e\u662f\u56de\u5230 step1->step2->step1\u5faa\u73af \u7406\u8bba\u4e0a\u8be5\u65b9\u6cd5\u4fdd\u8bc1\u662f\u53ef\u4ee5\u6536\u655b\u7684\uff0c\u800c\u4e00\u5f00\u59cb\u7ed9 \\(\\theta\\) \u7684\u521d\u59cb\u503c\u4f1a\u5f71\u54cd\u6536\u655b\u7684\u7ed3\u679c\uff0c\u7c7b\u4f3c gradient descent \u4e0a\u8ff0\u7684 step1 \u5c31\u662f EM algorithm \u91cc\u7684 E\uff0cstep2 \u5219\u662f M \u4ee5\u4e0a\u7684\u63a8\u5bfc\u57fa\u4e8e\u7684\u57fa\u672c\u601d\u60f3\u662f\uff0c\u628a unlabeled data \\(x^u\\) \u770b\u6210\u662f\u53ef\u4ee5\u5212\u5206\u7684\uff0c\u4e00\u90e8\u5206\u5c5e\u4e8e \\(C_1\\) \uff0c\u4e00\u90e8\u5206\u5c5e\u4e8e \\(C_2\\) \uff0c\u6b64\u65f6\u5b83\u7684\u6982\u7387 \\(P_{\\theta}(x^u)=P_{\\theta}(x^u|C_1)P(C_1)+P_{\\theta}(x^u|C_2)P(C_2)\\) \uff0c\u5b9e\u9645\u4e0a\u6211\u4eec\u5728\u5229\u7528\u6781\u5927\u4f3c\u7136\u51fd\u6570\u66f4\u65b0\u53c2\u6570\u7684\u65f6\u5019\uff0c\u5c31\u5229\u7528\u4e86\u8be5\u62c6\u5206\u7684\u7ed3\u679c\uff1a \\[ max:logL(\\theta)=\\sum\\limits_{x^r} logP_{\\theta}(x^r)+\\sum\\limits_{x^u}logP_{\\theta}(x^u) \\] \u4f46\u8fd9\u4e2a\u5f0f\u5b50\u4e0d\u662f convex\uff0c\u6240\u4ee5\u89e3\u7684\u65f6\u5019\u8981\u7528 EM algorithm\uff0c\u5176\u5b9e\u5c31\u662f\u8981 iterative \u7684\u53bb solve\uff0c\u5c31\u662f\u4e0a\u9762\u7684 step EM\u7b97\u6cd5\u8be6\u89e3 - \u77e5\u4e4e Low-density Separation Assumption \u00b6 \u63a5\u4e0b\u6765\u4ecb\u7ecd\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u5b83\u57fa\u4e8e\u7684\u5047\u8bbe\u662f Low-density separation \u901a\u4fd7\u6765\u8bb2\uff0c\u5c31\u662f\u8fd9\u4e2a\u4e16\u754c\u662f\u975e\u9ed1\u5373\u767d\u7684\uff0c\u5728\u4e24\u4e2a class \u7684\u4ea4\u754c\u5904 data \u7684\u5bc6\u5ea6 (density)\u662f\u5f88\u4f4e\u7684\uff0c\u5b83\u4eec\u4e4b\u95f4\u4f1a\u6709\u4e00\u9053\u660e\u663e\u7684\u9e3f\u6c9f Self Training \u00b6 \u662f low-density separation \u6700\u5177\u4ee3\u8868\u6027\u4e5f\u6700\u7b80\u5355\u7684\u65b9\u6cd5 \u4ece labelled data \u4e2d\u8bad\u7ec3\u4e00\u4e2a model\uff08\u8bad\u7ec3\u65b9\u6cd5\u6ca1\u6709\u9650\u5236\uff09 \u7136\u540e\u7528\u8be5 model \u53bb\u5bf9 unlabelled data \u7b97\u51fa label\uff0c\u4e5f\u53eb\u505a pseudo label \u4ece unlabelled data \u4e2d\u9009\u51fa\u4e00\u4e9b data \u6dfb\u52a0\u5230 labelled data \u4e2d\uff0c\u5982\u4f55\u6311\u9009\u9700\u8981\u81ea\u5df1\u8bbe\u8ba1 \u56de\u5934\u518d\u53bb\u8bad\u7ec3 \u6ce8\uff1a\u8be5\u65b9\u6cd5\u5bf9 Regression \u662f\u4e0d\u9002\u7528\u7684\uff0c\u56e0\u4e3a Regression output \u662f\u4e00\u4e2a\u6570\u91cf \u5b9e\u9645\u4e0a\uff0c\u8be5\u65b9\u6cd5\u4e0e\u4e4b\u524d\u63d0\u5230\u7684 generative model \u8fd8\u662f\u633a\u50cf\u7684\uff0c\u533a\u522b\u5728\u4e8e\uff1a Self Training\u4f7f\u7528\u7684\u662f hard label\uff1a\u5047\u8bbe\u4e00\u7b14data\u5f3a\u5236\u5c5e\u4e8e\u67d0\u4e2a class Generative Model\u4f7f\u7528\u7684\u662f soft label\uff1a\u5047\u8bbe\u4e00\u7b14 data \u53ef\u4ee5\u6309\u7167\u6982\u7387\u5212\u5206\uff0c\u4e0d\u540c\u90e8\u5206\u5c5e\u4e8e\u4e0d\u540c class \u5728 neural network \u91cc\u4f7f\u7528 soft label \u662f\u6ca1\u6709\u7528\u7684\uff0c\u4e22\u8fdb\u53bb\u91cd\u65b0\u8bad\u7ec3\u540e\u4f9d\u65e7\u662f\u540c\u6837\u7684\u53c2\u6570\uff0c\u6240\u4ee5 low density separation \u5c31\u662f\u901a\u8fc7\u5f3a\u5236\u5206\u7c7b\u6765\u63d0\u5347\u5206\u7c7b\u6548\u679c\u7684\u65b9\u6cd5 Entropy-based Regularization \u00b6 hard label \u7684\u65b9\u5f0f\u6709\u4e9b\u592a\u6b66\u65ad\u4e86\uff0c\u800c entropy-based regularization \u5219\u505a\u4e86\u76f8\u5e94\u7684\u6539\u8fdb\uff1a \\(y^u=f^*_{\\theta^*}(x^u)\\) \uff0c\u5176\u4e2d \\(y^u\\) \u200b\u200b \u662f\u4e00\u4e2a \u6982\u7387\u5206\u5e03 (distribution) \uff0c\u5982\u679c\u901a\u8fc7 entropy-based regularization \u5f97\u5230\u7684\u5206\u5e03\u96c6\u4e2d\u5728\u67d0\u4e2a class \u4e0a\u7684\u8bdd\uff0c\u90a3\u8fd9\u4e2a model \u5c31\u662f\u597d\u7684\uff0c\u800c\u5982\u679c\u5206\u5e03\u662f\u6bd4\u8f83\u5206\u6563\u7684\uff0c\u90a3\u8fd9\u4e2a model \u5c31\u662f\u4e0d\u597d\u7684 \u5229\u7528\u4e00\u4e2a output \u7684 distribution \u7684 entropy \u6765\u544a\u8bc9\u4f60\u5b83\u7684\u96c6\u4e2d\u7a0b\u5ea6\uff1a $$ E(y^u)=-\\sum\\limits_{m=1}^5 y_m^u ln(y_m^u) $$ entropy \u8d8a\u5927\uff0cdistribution \u5c31\u8d8a\u5206\u6563\uff0centropy \u8d8a\u5c0f\uff0cdistribution \u5c31\u8d8a\u96c6\u4e2d \u6211\u4eec\u7684\u76ee\u6807\u662f\u5728 labeled data \u4e0a\u5206\u7c7b\u8981\u6b63\u786e\uff0c\u5728 unlabeled data \u4e0a\uff0coutput \u7684 entropy \u8981\u8d8a\u5c0f\u8d8a\u597d\uff0c\u6b64\u65f6\u5c31\u8981\u4fee\u6539 loss function $$ min:L=\\sum\\limits_{x^r} C(y^r,\\hat y^r) + \\lambda \\sum\\limits_{x^u} E(y^u) $$ labeled data \u7684 Cross Entropy \u548c unlabeled data \u7684 entropy \u52a0\u6743\u76f8\u52a0\uff08\u6743\u503c\u9700\u8981\u81ea\u5df1\u5b9a\uff09 \u53ef\u4ee5\u53d1\u73b0\u8be5\u5f0f\u957f\u5f97\u5f88\u50cf regularization\uff0c\u8fd9\u4e5f\u5c31\u662f entropy regularization \u7684\u540d\u79f0\u7531\u6765 Semi-supervised SVM \u00b6 SVM \u8981\u505a\u7684\u662f\uff0c\u7ed9\u4f60\u4e24\u4e2a class \u7684 data\uff0c\u53bb\u627e\u4e00\u4e2a boundary\uff1a \u8981\u6709\u6700\u5927\u7684 margin\uff0c\u8ba9\u8fd9\u4e24\u4e2a class \u5206\u7684\u8d8a\u5f00\u8d8a\u597d \u8981\u6709\u6700\u5c0f\u7684\u5206\u7c7b\u9519\u8bef \u5bf9\u4e8e unlabelled data \u5219\u7a77\u5c3d\u6240\u6709\u53ef\u80fd\u7684 label\uff0c\u7136\u540e\u5bf9\u6bcf\u4e00\u79cd\u53ef\u80fd\u7684\u7ed3\u679c\u90fd\u53bb\u7b97 SVM\uff0c\u518d\u627e\u51fa\u53ef\u4ee5\u8ba9 margin \u6700\u5927\uff0c\u540c\u65f6\u53c8 minimize error \u7684\u90a3\u79cd\u60c5\u51b5 SVM paper\uff1aThorsten Joachims, \u201d Transductive Inference for Text Classification using Support Vector Machines\u201d, ICML, 1999 paper \u4e2d\u7ed9\u51fa\u4e86 n \u5f88\u5927\u7684\u65f6\u5019\u7684\u89e3\u51b3\u65b9\u6cd5\uff0c\u601d\u60f3\u662f\uff1a\u4e00\u5f00\u59cb\u4f60\u5148\u5f97\u5230\u4e00\u4e9b label\uff0c\u7136\u540e\u6bcf\u6b21\u6539\u4e00\u7b14 unlabeled data \u7684 label\uff0c\u770b\u770b\u53ef\u4e0d\u53ef\u4ee5\u8ba9\u4f60\u7684 objective function \u53d8\u5927\uff0c\u5982\u679c\u53d8\u5927\u5c31\u53bb\u6539\u53d8\u8be5 label Smoothness Assumption \u00b6 Concepts \u00b6 smoothness assumption \u7684\u57fa\u672c\u7cbe\u795e\u662f\uff1a\u8fd1\u6731\u8005\u8d64\uff0c\u8fd1\u58a8\u8005\u9ed1 \u7c97\u7cd9\u7684\u5b9a\u4e49\u662f\u76f8\u4f3c\u7684 x \u5177\u6709\u76f8\u540c\u7684 \\(\\hat y\\) \uff0c\u7cbe\u786e\u7684\u5b9a\u4e49\u662f\uff1a x\u7684\u5206\u5e03\u662f\u4e0d\u5e73\u5747\u7684 \u5982\u679c \\(x^1\\) \u200b \u548c \\(x^2\\) \u200b \u5728\u4e00\u4e2a high density region \u4e0a\u5f88\u63a5\u8fd1\u7684\u8bdd\uff0c\u90a3\u4e48 \\(\\hat y^1\\) \u200b\u548c \\(\\hat y^2\\) \u200b\u5c31\u662f\u76f8\u540c\u7684 \u4e5f\u5c31\u662f\u8fd9\u4e24\u4e2a\u70b9\u53ef\u4ee5\u5728\u6837\u672c\u70b9\u9ad8\u5bc6\u5ea6\u96c6\u4e2d\u5206\u5e03\u7684\u533a\u57df\u5757\u4e2d\u6709\u4e00\u6761\u53ef\u8fde\u63a5\u7684\u8def\u5f84\uff0c\u5373 connected by a high density path digits detection \u00b6 \u624b\u5199\u6570\u5b57\u8fa8\u8bc6\u4e3a\u4f8b\uff0c\u663e\u7136\u6700\u53f3\u4fa7\u7684 2 \u548c 3 \u5728 pixel \u4e0a\u4f1a\u66f4\u63a5\u8fd1\u4e00\u4e9b\uff1b\u4f46\u5982\u679c\u628a\u6240\u6709\u8fde\u7eed\u53d8\u5316\u7684 2 \u653e\u8fdb\u6765\uff0c\u90a3\u5b83\u4eec\u5176\u5b9e\u90fd\u662f 2 \u4eba\u8138\u7684\u8fc7\u6e21\u6570\u636e\u4e5f\u540c\u7406 file classification \u00b6 Smoothness Assumption \u5728\u6587\u4ef6\u5206\u7c7b\u4e0a\u662f\u975e\u5e38\u6709\u7528\u7684 \u5047\u8bbe\u5bf9\u5929\u6587\u5b66 (astronomy) \u548c\u65c5\u884c (travel) \u7684\u6587\u7ae0\u8fdb\u884c\u5206\u7c7b\uff0c\u5b83\u4eec\u5404\u81ea\u6709\u4e13\u5c5e\u7684\u8bcd\u6c47\uff0c\u6b64\u65f6\u5982\u679c unlabeled data \u4e0e label data \u7684\u8bcd\u6c47\u662f\u76f8\u540c\u6216\u91cd\u5408 (overlap) \u7684\uff0c\u90a3\u4e48\u5c31\u5f88\u5bb9\u6613\u5206\u7c7b\uff1b\u4f46\u5728\u771f\u5b9e\u7684\u60c5\u51b5\u4e0b\uff0cunlabeled data \u548c labeled data \u4e4b\u95f4\u53ef\u80fd\u6ca1\u6709\u4efb\u4f55\u91cd\u590d\u7684 words\uff0c\u56e0\u4e3a\u4e16\u754c\u4e0a\u7684\u8bcd\u6c47\u592a\u591a\u4e86\uff0csparse \u7684\u5206\u5e03\u5f88\u96be\u4f1a\u4f7f overlap \u53d1\u751f \u4f46\u5982\u679cunlabeled data\u8db3\u591f\u591a\uff0c\u5c31\u4f1a\u4ee5\u4e00\u79cd\u76f8\u4f3c\u4f20\u9012\u7684\u5f62\u5f0f\uff0c\u5efa\u7acb\u8d77\u6587\u6863\u4e4b\u95f4\u76f8\u4f3c\u7684\u6865\u6881 cluster and then label \u00b6 \u5728\u5177\u4f53\u5b9e\u73b0\u4e0a\uff0c\u6709\u4e00\u79cd\u7b80\u5355\u7684\u65b9\u6cd5\u662fcluster and then label\uff0c\u4e5f\u5c31\u662f\u5148\u628a data \u5206\u6210\u51e0\u4e2a cluster \u540e\u518d\u53bb train\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u4e00\u5b9a\u4f1a\u5f97\u5230\u597d\u7684\u7ed3\u679c\uff0c\u56e0\u4e3a\u5b83\u7684\u5047\u8bbe\u662f\u4f60\u53ef\u4ee5\u628a\u540c\u4e00\u4e2a class \u7684\u6837\u672c\u70b9 cluster \u5728\u4e00\u8d77\uff0c\u800c\u8fd9\u5176\u5b9e\u662f\u6ca1\u90a3\u4e48\u5bb9\u6613\u7684\uff0c\u6bd4\u5982 \u5bf9\u56fe\u50cf\u7684\u5212\u5206 Graph-based Approach \u00b6 \u4e4b\u524d\u8bb2\u7684\u662f\u6bd4\u8f83\u76f4\u89c9\u7684\u505a\u6cd5\uff0c\u63a5\u4e0b\u6765\u5f15\u5165 Graph Structure \u6765\u8868\u8fbe connected by a high density path \u8fd9\u4ef6\u4e8b \u628a\u6240\u6709\u7684 data points \u90fd\u5efa\u6210\u4e00\u4e2a graph\uff0c\u6709\u65f6\u5019\u5efa\u7acb vertex \u4e4b\u95f4\u7684\u5173\u7cfb\u662f\u6bd4\u8f83\u5bb9\u6613\u7684\uff0c\u6bd4\u5982\u7f51\u9875\u4e4b\u95f4\u7684\u94fe\u63a5\u5173\u7cfb\u3001\u8bba\u6587\u4e4b\u95f4\u7684\u5f15\u7528\u5173\u7cfb\uff1b\u4f46\u6709\u65f6\u5019\u9700\u8981\u4f60\u81ea\u5df1\u53bb\u5bfb\u627e vertex \u4e4b\u95f4\u7684\u5173\u7cfb graph \u7684\u597d\u574f\uff0c\u5bf9\u7ed3\u679c\u8d77\u7740\u81f3\u5173\u91cd\u8981\u7684\u5f71\u54cd\uff0c\u800c\u5982\u4f55 build graph \u5374\u662f\u4e00\u4ef6 heuristic \u7684\u4e8b\u60c5\uff0c\u9700\u8981\u51ed\u7740\u7ecf\u9a8c\u548c\u76f4\u89c9\u6765\u505a \u9996\u5148\u5b9a\u4e49\u4e24\u4e2aobject \\(x^i,x^j\\) \u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6 \\(s(x^i, x^j)\\) \u7b97\u5b8c\u76f8\u4f3c\u5ea6\u540e\uff0c\u5c31\u53ef\u4ee5\u5efagraph\u4e86\uff0c\u65b9\u5f0f\u6709\u5f88\u591a\u79cd\uff1a k nearest neighbor\uff1ak \u90bb\u8fd1\u6cd5\uff0c\u4e0e\u5468\u56f4\u6700\u63a5\u8fd1\u7684 k \u4e2a\u70b9\u8fde\u63a5 e-neighborhood\uff1a\u6bcf\u4e2a point \u4e0e\u76f8\u4f3c\u5ea6\u8d85\u8fc7\u67d0\u4e2a\u7279\u5b9a threshold e \u7684\u70b9\u76f8\u8fde \u9664\u6b64\u4e4b\u5916\uff0c\u8fd8\u53ef\u4ee5\u7ed9 Edge \u7279\u5b9a\u7684 weight\uff0c\u8ba9\u5b83\u4e0e\u76f8\u4f3c\u5ea6 \\(s(x^i,x^j)\\) \u200b \u6210\u6b63\u6bd4 \u5efa\u8bae\u7528 RBM function \u6765\u786e\u5b9a\u76f8\u4f3c\u5ea6\uff1a \\(s(x^i,x^j)=e^{-\\gamma||x^i-x^j||^2 }\\) \u200b \u8fd9\u91cc \\(x^i,x^j\\) \u200b\u5747\u4e3avector\uff0c\u8ba1\u7b97\u5b83\u4eec\u7684 Euclidean Distance (\u6b27\u51e0\u91cc\u5f97\u8ddd\u79bb)\uff0c\u52a0\u4e0a\u53c2\u6570\u540e\u518d\u53bb exponential \u81f3\u4e8e\u52a0exponential\uff0c\u7ecf\u9a8c\u4e0a\u6765\u8bf4\u901a\u5e38\u662f\u53ef\u4ee5\u5e2e\u52a9\u63d0\u5347 performance\u7684\uff0c\u5728\u8fd9\u91cc\u53ea\u6709\u5f53 \\(x^i,x^j\\) \u200b \u975e\u5e38\u63a5\u8fd1\u7684\u65f6\u5019\uff0csingularity \u624d\u4f1a\u5927\uff1b\u53ea\u8981\u8ddd\u79bb\u7a0d\u5fae\u8fdc\u4e00\u70b9\uff0csingularity \u5c31\u4f1a\u4e0b\u964d\u5f97\u5f88\u5feb\uff0c\u53d8\u5f97\u5f88\u5c0f \u4f7f\u7528 exponential \u7684 RBM function \u53ef\u4ee5\u505a\u5230\u53ea\u6709\u975e\u5e38\u8fd1\u7684\u4e24\u4e2a\u70b9\u624d\u80fd\u76f8\u8fde\uff0c\u7a0d\u5fae\u8fdc\u4e00\u70b9\u5c31\u65e0\u6cd5\u76f8\u8fde\u7684\u6548\u679c graph-based approach \u9700\u8981\u6536\u96c6\u5230\u7684 data \u8db3\u591f\u591a\uff0c\u5426\u5219\u53ef\u80fd\u4f20\u9012\u5230\u4e00\u534a\uff0cgraph \u5c31\u65ad\u6389\u4e86\uff0cinformation \u7684\u4f20\u9012\u5c31\u5931\u6548\u4e86 \u4ecb\u7ecd\u5b8c\u4e86\u5982\u4f55\u5b9a\u6027\u4f7f\u7528 graph\uff0c\u63a5\u4e0b\u6765\u4ecb\u7ecd\u4e00\u4e0b\u5982\u4f55\u5b9a\u91cf\u4f7f\u7528 graph \u5b9a\u91cf\u7684\u4f7f\u7528\u65b9\u5f0f\u662f\u5b9a\u4e49 label \u7684 smoothness\uff0c\u4e0b\u56fe\u4e2d\uff0cedge \u4e0a\u7684\u6570\u5b57\u662f weight\uff0c \\(x^i\\) \u662fdata\uff0c \\(y^i\\) \u662f label\uff0c\u8ba1\u7b97 smoothness \u7684\u65b9\u5f0f\u4e3a\uff1a $$ S=\\frac{1}{2}\\sum\\limits_{i,j} w_{i,j}(y^i-y^j)^2 $$ \u6211\u4eec\u671f\u671b smooth \u7684\u503c \u8d8a\u5c0f\u8d8a\u597d \u5982\u679c\u628a labeled data \u548c unlabeled data \u7684 y \u7ec4\u6210\u4e00\u4e2a( R+U) dim vector\uff0c\u5373 $$ y=\\left [\\begin{matrix} ...y^i...y^j \\end{matrix} \\right ]^T $$ \u4e8e\u662f smooth \u53ef\u4ee5\u6539\u5199\u4e3a\uff1a $$ S=\\frac{1}{2}\\sum\\limits_{i,j} w_{i,j}(y^i-y^j)^2=y^TLy $$ \u5176\u4e2d L \u4e3a (R+U)\u00d7(R+U) matrix\uff0c\u79f0\u4e3a Graph Laplacian \uff0c \u5b9a\u4e49\u4e3a \\(L=D-W\\) W\uff1a\u628a data point \u4e24\u4e24\u4e4b\u95f4 weight \u7684\u5173\u7cfb\u5efa\u6210 matrix\uff0c\u4ee3\u8868\u4e86 \\(x^i\\) \u4e0e \\(x^j\\) \u4e4b\u95f4\u7684weight\u503c D\uff1a\u628a W \u7684\u6bcf\u4e00\u4e2a row \u4e0a\u7684\u503c\u52a0\u8d77\u6765\u653e\u5728\u8be5\u884c\u5bf9\u5e94\u7684 diagonal \u4e0a\u5373\u53ef \u5bf9 \\(S=y^TLy\\) \u6765\u8bf4\uff0cy \u662f label\uff0c\u662f neural network \u7684 output\uff0c\u53d6\u51b3\u4e8e neural network \u7684parameters\uff0c\u56e0\u6b64\u8981\u5728\u539f\u6765\u4ec5\u9488\u5bf9 labeled data \u7684 loss function \u4e2d\u52a0\u4e0a\u8fd9\u4e00\u9879\uff0c\u5f97\u5230\uff1a $$ L=\\sum\\limits_{x^r}C(y^r,\\hat y^r) + \\lambda S $$ \\(\\lambda S\\) \u200b\u200b \u5b9e\u9645\u4e0a\u4e5f\u662f\u4e00\u4e2a regularization \u8bad\u7ec3\u76ee\u6807\uff1a labeled data \u7684 cross entropy \u8d8a\u5c0f\u8d8a\u597d (neural network \u7684 output \u8ddf\u771f\u6b63\u7684 label \u8d8a\u63a5\u8fd1\u8d8a\u597d) smooth S \u8d8a\u5c0f\u8d8a\u597d (neural network \u7684 output\uff0c\u4e0d\u7ba1\u662f labeled \u8fd8\u662f unlabeled\uff0c\u90fd\u8981\u7b26\u5408 Smoothness Assumption \u7684\u5047\u8bbe) \u5177\u4f53\u8bad\u7ec3\u7684\u65f6\u5019\uff0c\u4e0d\u4e00\u5b9a\u53ea\u5c40\u9650\u4e8e neural network \u7684 output \u8981 smooth\uff0c\u53ef\u4ee5\u5bf9\u4e2d\u95f4\u4efb\u610f\u4e00\u4e2a hidden layer \u52a0\u4e0a smooth \u7684\u9650\u5236 Better Representation \u00b6 Better Representation \u7684\u7cbe\u795e\u662f\uff0c\u53bb\u829c\u5b58\u83c1\uff0c\u5316\u7e41\u4e3a\u7b80 \u5c31\u662f\u627e\u5230\u4e00\u4e2a data \u7684 feature \u6838\u5fc3 \u7b97\u6cd5\u5177\u4f53\u601d\u8def\u548c\u5185\u5bb9\u5230 unsupervised learning \u7684\u65f6\u5019\u518d\u4ecb\u7ecd","title":"Semi Supervised Learning"},{"location":"ML/7_Semi-supervised%20Learning/#semi-supervised-learning","text":"\u534a\u76d1\u7763\u5b66\u4e60\uff1a Semi-supervised Learning for Generative Model Low-density Separation Assumption\uff1a\u975e\u9ed1\u5373\u767d Smoothness Assumption\uff1a\u8fd1\u6731\u8005\u8d64\uff0c\u8fd1\u58a8\u8005\u9ed1 Better Representation\uff1a\u53bb\u829c\u5b58\u83c1\uff0c\u5316\u7e41\u4e3a\u7b80","title":"Semi-supervised Learning"},{"location":"ML/7_Semi-supervised%20Learning/#introduction","text":"\u4e3a\u4ec0\u4e48\u8981\u505a Semi-supervised Learning\uff0c\u56e0\u4e3a data \u7684 input \u5f88\u5bb9\u6613\u5f97\u5230\uff0c\u4f46\u662f\u5f88\u591a\u90fd\u7f3a output\uff08label\uff09","title":"Introduction"},{"location":"ML/7_Semi-supervised%20Learning/#supervised-learning","text":"\\((x^r,\\hat y^r)_{r=1}^R\\) \u200b \u5728 training data \u4e2d\u6bcf\u4e00\u7ec4 data \u7684 input \\(x\\) \u200b \u90fd\u6709 output \\(y\\) \u200b\u200b\u200b\u200b","title":"Supervised Learning"},{"location":"ML/7_Semi-supervised%20Learning/#semi-supervised-learning_1","text":"\\(\\{(x^r,\\hat y^r)\\}_{r=1}^R\\} + \\{x^u\\}_{u=R}^{R+U}\\) \u200b Supervised Learning \u52a0\u4e0a\u6ca1\u6709 output \u7684 data\uff0c\u800c\u4e14\u901a\u5e38 \\(U>>R\\) \u200b\u200b \u200b Semi-supervised learning\u5206\u4e3a\u4ee5\u4e0b\u4e24\u79cd\u60c5\u51b5\uff1a Transductive Learning\uff1aunlabeled data is the testing data \u5373\uff0c\u628a testing data \u5f53\u505a\u65e0\u6807\u7b7e\u7684 training data \u4f7f\u7528\uff0c\u9002\u7528\u4e8e\u4e8b\u5148\u5df2\u7ecf\u77e5\u9053 testing data \u7684\u60c5\u51b5 (\u6bd4\u5982\u4e00\u4e9b\u6bd4\u8d5b\u7684\u65f6\u5019\uff0c\u53ea\u77e5\u9053 data \u7684 feature \u800c\u4e0d\u77e5\u9053 output) Inductive Learning\uff1aunlabeled data is not the testing data \u5373\uff0c\u4e0d\u628a testing data \u7684 feature \u62ff\u53bb\u7ed9\u673a\u5668\u8bad\u7ec3\uff0c\u9002\u7528\u4e8e\u4e8b\u5148\u5e76\u4e0d\u77e5\u9053 testing data \u7684\u60c5\u51b5 (\u66f4\u666e\u904d\u7684\u60c5\u51b5)","title":"Semi-supervised Learning"},{"location":"ML/7_Semi-supervised%20Learning/#why-semi-supervised-learning-help","text":"unlabelled data \u867d\u7136\u53ea\u6709 input \u4f46\u5b83\u7684\u5206\u5e03\u53ef\u4ee5\u7ed9\u6211\u4eec\u4e00\u4e9b\u4fe1\u606f\uff0c\u4ee5\u4e0b\u4e3a\u4f8b semi-supervised learning \u7684\u4f7f\u7528\u5f80\u5f80\u4f34\u968f\u7740\u5047\u8bbe\uff0c\u800c\u8be5\u5047\u8bbe\u7684\u5408\u7406\u4e0e\u5426\uff0c\u51b3\u5b9a\u4e86\u7ed3\u679c\u7684\u597d\u574f\u7a0b\u5ea6\uff1b\u6bd4\u5982\u4e0a\u56fe\u4e2d\u7684 unlabeled data\uff0c\u5b83\u663e\u7136\u662f\u4e00\u53ea\u72d7\uff0c\u800c\u7279\u5f81\u5206\u5e03\u5374\u4e0e\u732b\u88ab\u5212\u5206\u5728\u4e86\u4e00\u8d77\uff0c\u5f88\u53ef\u80fd\u662f\u7531\u4e8e\u8fd9\u4e24\u5f20\u56fe\u7247\u7684\u80cc\u666f\u90fd\u662f\u7eff\u8272\u5bfc\u81f4\u7684\uff0c\u56e0\u6b64\u5047\u8bbe\u662f\u5426\u5408\u7406\u663e\u5f97\u81f3\u5173\u91cd\u8981","title":"Why semi-supervised learning help\uff1f"},{"location":"ML/7_Semi-supervised%20Learning/#generative-model","text":"\u5728\u76d1\u7763\u5b66\u4e60\u4e2d\u6211\u4eec\u5b66\u4e60\u8fc7\u901a\u8fc7\u540e\u9a8c\u6982\u7387\u5f97\u51fa x \u6240\u5c5e\u7684\u7c7b\u522b \u4e0b\u56fe\u5b9e\u7ebf\u662f Supervised Generative Model \u5f97\u51fa\u7684\u7ed3\u679c\uff0c\u7eff\u8272\u7684\u70b9\u662f\u6ca1\u6709 label \u7684 data\uff0c\u663e\u7136\u539f\u5148\u7684 \\(u,\\Sigma\\) \u662f\u4e0d\u5408\u7406\u7684 \u4ee5\u4e0a\u662f\u76f4\u89c2\u4e0a\u7684\u89e3\u91ca\uff0c\u63a5\u4e0b\u6765\u8fdb\u884c\u5177\u4f53\u63a8\u5bfc (\u5047\u8bbe\u505a\u4e8c\u5143\u5206\u7c7b)\uff1a \u5229\u7528\u6709 label \u7684 data \u521d\u59cb\u5316\u4e00\u7ec4\u53c2\u6570\uff1a \\(\\theta=\\{P(C_1),P(C_2),u^1,u^2,\\Sigma\\}\\) step1\uff1a\u5229\u7528\u4e0a\u9762\u521d\u59cb model \u8ba1\u7b97\u6bcf\u4e00\u7b14 unlabeled data \\(x^u\\) \u5c5e\u4e8e class1 \u7684\u6982\u7387 \\(P_{\\theta}(C_1|x^u)\\) step2\uff1aupdate model \u5982\u679c\u4e0d\u8003\u8651 unlabeled data\uff0c\u5219\u5148\u9a8c\u6982\u7387\u663e\u7136\u4e3a\u5c5e\u4e8e class1 \u7684\u6837\u672c\u70b9\u6570 \\(N_1\\) / \u603b\u7684\u6837\u672c\u70b9\u6570 \\(N\\) \uff0c\u5373 \\(P(C_1)=\\frac{N_1}{N}\\) \u200b \u800c\u8003\u8651 unlabeled data \u65f6\uff0c\u5206\u5b50\u8fd8\u8981\u52a0\u4e0a\u6240\u6709 unlabeled data \u5c5e\u4e8e class1 \u7684\u6982\u7387\u548c\uff0c\u6b64\u65f6\u5b83\u4eec\u88ab\u770b\u4f5c\u5c0f\u6570\uff0c\u53ef\u4ee5\u7406\u89e3\u4e3a\u6309\u7167\u6982\u7387\u4e00\u90e8\u5206\u5c5e\u4e8e \\(C_1\\) \uff0c\u4e00\u90e8\u5206\u5c5e\u4e8e \\(C_2\\) $$ P(C_1)=\\frac{N_1+\\sum_{x^u}P(C_1|x^u)}{N} $$ \u540c\u7406\uff0c\u5bf9\u4e8e\u5747\u503c\uff0c\u539f\u5148\u7684 mean \\(u_1=\\frac{1}{N_1}\\sum\\limits_{x^r\\in C_1} x^r\\) \u52a0\u4e0a\u6839\u636e\u6982\u7387\u5bf9 \\(x^u\\) \u6c42\u548c\u518d\u5f52\u4e00\u5316\u7684\u7ed3\u679c\u5373\u53ef $$ u_1=\\frac{1}{N_1}\\sum\\limits_{x^r\\in C_1} x^r+\\frac{1}{\\sum_{x^u}P(C_1|x^u)}\\sum\\limits_{x^u}P(C_1|x^u)x^u $$ \u5269\u4f59\u7684\u53c2\u6570\u540c\u7406\uff0c\u63a5\u4e0b\u6765\u5c31\u6709\u4e86\u4e00\u7ec4\u65b0\u7684\u53c2\u6570 \\(\\theta'\\) \uff0c\u4e8e\u662f\u56de\u5230 step1->step2->step1\u5faa\u73af \u7406\u8bba\u4e0a\u8be5\u65b9\u6cd5\u4fdd\u8bc1\u662f\u53ef\u4ee5\u6536\u655b\u7684\uff0c\u800c\u4e00\u5f00\u59cb\u7ed9 \\(\\theta\\) \u7684\u521d\u59cb\u503c\u4f1a\u5f71\u54cd\u6536\u655b\u7684\u7ed3\u679c\uff0c\u7c7b\u4f3c gradient descent \u4e0a\u8ff0\u7684 step1 \u5c31\u662f EM algorithm \u91cc\u7684 E\uff0cstep2 \u5219\u662f M \u4ee5\u4e0a\u7684\u63a8\u5bfc\u57fa\u4e8e\u7684\u57fa\u672c\u601d\u60f3\u662f\uff0c\u628a unlabeled data \\(x^u\\) \u770b\u6210\u662f\u53ef\u4ee5\u5212\u5206\u7684\uff0c\u4e00\u90e8\u5206\u5c5e\u4e8e \\(C_1\\) \uff0c\u4e00\u90e8\u5206\u5c5e\u4e8e \\(C_2\\) \uff0c\u6b64\u65f6\u5b83\u7684\u6982\u7387 \\(P_{\\theta}(x^u)=P_{\\theta}(x^u|C_1)P(C_1)+P_{\\theta}(x^u|C_2)P(C_2)\\) \uff0c\u5b9e\u9645\u4e0a\u6211\u4eec\u5728\u5229\u7528\u6781\u5927\u4f3c\u7136\u51fd\u6570\u66f4\u65b0\u53c2\u6570\u7684\u65f6\u5019\uff0c\u5c31\u5229\u7528\u4e86\u8be5\u62c6\u5206\u7684\u7ed3\u679c\uff1a \\[ max:logL(\\theta)=\\sum\\limits_{x^r} logP_{\\theta}(x^r)+\\sum\\limits_{x^u}logP_{\\theta}(x^u) \\] \u4f46\u8fd9\u4e2a\u5f0f\u5b50\u4e0d\u662f convex\uff0c\u6240\u4ee5\u89e3\u7684\u65f6\u5019\u8981\u7528 EM algorithm\uff0c\u5176\u5b9e\u5c31\u662f\u8981 iterative \u7684\u53bb solve\uff0c\u5c31\u662f\u4e0a\u9762\u7684 step EM\u7b97\u6cd5\u8be6\u89e3 - \u77e5\u4e4e","title":"Generative Model"},{"location":"ML/7_Semi-supervised%20Learning/#low-density-separation-assumption","text":"\u63a5\u4e0b\u6765\u4ecb\u7ecd\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u5b83\u57fa\u4e8e\u7684\u5047\u8bbe\u662f Low-density separation \u901a\u4fd7\u6765\u8bb2\uff0c\u5c31\u662f\u8fd9\u4e2a\u4e16\u754c\u662f\u975e\u9ed1\u5373\u767d\u7684\uff0c\u5728\u4e24\u4e2a class \u7684\u4ea4\u754c\u5904 data \u7684\u5bc6\u5ea6 (density)\u662f\u5f88\u4f4e\u7684\uff0c\u5b83\u4eec\u4e4b\u95f4\u4f1a\u6709\u4e00\u9053\u660e\u663e\u7684\u9e3f\u6c9f","title":"Low-density Separation Assumption"},{"location":"ML/7_Semi-supervised%20Learning/#self-training","text":"\u662f low-density separation \u6700\u5177\u4ee3\u8868\u6027\u4e5f\u6700\u7b80\u5355\u7684\u65b9\u6cd5 \u4ece labelled data \u4e2d\u8bad\u7ec3\u4e00\u4e2a model\uff08\u8bad\u7ec3\u65b9\u6cd5\u6ca1\u6709\u9650\u5236\uff09 \u7136\u540e\u7528\u8be5 model \u53bb\u5bf9 unlabelled data \u7b97\u51fa label\uff0c\u4e5f\u53eb\u505a pseudo label \u4ece unlabelled data \u4e2d\u9009\u51fa\u4e00\u4e9b data \u6dfb\u52a0\u5230 labelled data \u4e2d\uff0c\u5982\u4f55\u6311\u9009\u9700\u8981\u81ea\u5df1\u8bbe\u8ba1 \u56de\u5934\u518d\u53bb\u8bad\u7ec3 \u6ce8\uff1a\u8be5\u65b9\u6cd5\u5bf9 Regression \u662f\u4e0d\u9002\u7528\u7684\uff0c\u56e0\u4e3a Regression output \u662f\u4e00\u4e2a\u6570\u91cf \u5b9e\u9645\u4e0a\uff0c\u8be5\u65b9\u6cd5\u4e0e\u4e4b\u524d\u63d0\u5230\u7684 generative model \u8fd8\u662f\u633a\u50cf\u7684\uff0c\u533a\u522b\u5728\u4e8e\uff1a Self Training\u4f7f\u7528\u7684\u662f hard label\uff1a\u5047\u8bbe\u4e00\u7b14data\u5f3a\u5236\u5c5e\u4e8e\u67d0\u4e2a class Generative Model\u4f7f\u7528\u7684\u662f soft label\uff1a\u5047\u8bbe\u4e00\u7b14 data \u53ef\u4ee5\u6309\u7167\u6982\u7387\u5212\u5206\uff0c\u4e0d\u540c\u90e8\u5206\u5c5e\u4e8e\u4e0d\u540c class \u5728 neural network \u91cc\u4f7f\u7528 soft label \u662f\u6ca1\u6709\u7528\u7684\uff0c\u4e22\u8fdb\u53bb\u91cd\u65b0\u8bad\u7ec3\u540e\u4f9d\u65e7\u662f\u540c\u6837\u7684\u53c2\u6570\uff0c\u6240\u4ee5 low density separation \u5c31\u662f\u901a\u8fc7\u5f3a\u5236\u5206\u7c7b\u6765\u63d0\u5347\u5206\u7c7b\u6548\u679c\u7684\u65b9\u6cd5","title":"Self Training"},{"location":"ML/7_Semi-supervised%20Learning/#entropy-based-regularization","text":"hard label \u7684\u65b9\u5f0f\u6709\u4e9b\u592a\u6b66\u65ad\u4e86\uff0c\u800c entropy-based regularization \u5219\u505a\u4e86\u76f8\u5e94\u7684\u6539\u8fdb\uff1a \\(y^u=f^*_{\\theta^*}(x^u)\\) \uff0c\u5176\u4e2d \\(y^u\\) \u200b\u200b \u662f\u4e00\u4e2a \u6982\u7387\u5206\u5e03 (distribution) \uff0c\u5982\u679c\u901a\u8fc7 entropy-based regularization \u5f97\u5230\u7684\u5206\u5e03\u96c6\u4e2d\u5728\u67d0\u4e2a class \u4e0a\u7684\u8bdd\uff0c\u90a3\u8fd9\u4e2a model \u5c31\u662f\u597d\u7684\uff0c\u800c\u5982\u679c\u5206\u5e03\u662f\u6bd4\u8f83\u5206\u6563\u7684\uff0c\u90a3\u8fd9\u4e2a model \u5c31\u662f\u4e0d\u597d\u7684 \u5229\u7528\u4e00\u4e2a output \u7684 distribution \u7684 entropy \u6765\u544a\u8bc9\u4f60\u5b83\u7684\u96c6\u4e2d\u7a0b\u5ea6\uff1a $$ E(y^u)=-\\sum\\limits_{m=1}^5 y_m^u ln(y_m^u) $$ entropy \u8d8a\u5927\uff0cdistribution \u5c31\u8d8a\u5206\u6563\uff0centropy \u8d8a\u5c0f\uff0cdistribution \u5c31\u8d8a\u96c6\u4e2d \u6211\u4eec\u7684\u76ee\u6807\u662f\u5728 labeled data \u4e0a\u5206\u7c7b\u8981\u6b63\u786e\uff0c\u5728 unlabeled data \u4e0a\uff0coutput \u7684 entropy \u8981\u8d8a\u5c0f\u8d8a\u597d\uff0c\u6b64\u65f6\u5c31\u8981\u4fee\u6539 loss function $$ min:L=\\sum\\limits_{x^r} C(y^r,\\hat y^r) + \\lambda \\sum\\limits_{x^u} E(y^u) $$ labeled data \u7684 Cross Entropy \u548c unlabeled data \u7684 entropy \u52a0\u6743\u76f8\u52a0\uff08\u6743\u503c\u9700\u8981\u81ea\u5df1\u5b9a\uff09 \u53ef\u4ee5\u53d1\u73b0\u8be5\u5f0f\u957f\u5f97\u5f88\u50cf regularization\uff0c\u8fd9\u4e5f\u5c31\u662f entropy regularization \u7684\u540d\u79f0\u7531\u6765","title":"Entropy-based Regularization"},{"location":"ML/7_Semi-supervised%20Learning/#semi-supervised-svm","text":"SVM \u8981\u505a\u7684\u662f\uff0c\u7ed9\u4f60\u4e24\u4e2a class \u7684 data\uff0c\u53bb\u627e\u4e00\u4e2a boundary\uff1a \u8981\u6709\u6700\u5927\u7684 margin\uff0c\u8ba9\u8fd9\u4e24\u4e2a class \u5206\u7684\u8d8a\u5f00\u8d8a\u597d \u8981\u6709\u6700\u5c0f\u7684\u5206\u7c7b\u9519\u8bef \u5bf9\u4e8e unlabelled data \u5219\u7a77\u5c3d\u6240\u6709\u53ef\u80fd\u7684 label\uff0c\u7136\u540e\u5bf9\u6bcf\u4e00\u79cd\u53ef\u80fd\u7684\u7ed3\u679c\u90fd\u53bb\u7b97 SVM\uff0c\u518d\u627e\u51fa\u53ef\u4ee5\u8ba9 margin \u6700\u5927\uff0c\u540c\u65f6\u53c8 minimize error \u7684\u90a3\u79cd\u60c5\u51b5 SVM paper\uff1aThorsten Joachims, \u201d Transductive Inference for Text Classification using Support Vector Machines\u201d, ICML, 1999 paper \u4e2d\u7ed9\u51fa\u4e86 n \u5f88\u5927\u7684\u65f6\u5019\u7684\u89e3\u51b3\u65b9\u6cd5\uff0c\u601d\u60f3\u662f\uff1a\u4e00\u5f00\u59cb\u4f60\u5148\u5f97\u5230\u4e00\u4e9b label\uff0c\u7136\u540e\u6bcf\u6b21\u6539\u4e00\u7b14 unlabeled data \u7684 label\uff0c\u770b\u770b\u53ef\u4e0d\u53ef\u4ee5\u8ba9\u4f60\u7684 objective function \u53d8\u5927\uff0c\u5982\u679c\u53d8\u5927\u5c31\u53bb\u6539\u53d8\u8be5 label","title":"Semi-supervised SVM"},{"location":"ML/7_Semi-supervised%20Learning/#smoothness-assumption","text":"","title":"Smoothness Assumption"},{"location":"ML/7_Semi-supervised%20Learning/#concepts","text":"smoothness assumption \u7684\u57fa\u672c\u7cbe\u795e\u662f\uff1a\u8fd1\u6731\u8005\u8d64\uff0c\u8fd1\u58a8\u8005\u9ed1 \u7c97\u7cd9\u7684\u5b9a\u4e49\u662f\u76f8\u4f3c\u7684 x \u5177\u6709\u76f8\u540c\u7684 \\(\\hat y\\) \uff0c\u7cbe\u786e\u7684\u5b9a\u4e49\u662f\uff1a x\u7684\u5206\u5e03\u662f\u4e0d\u5e73\u5747\u7684 \u5982\u679c \\(x^1\\) \u200b \u548c \\(x^2\\) \u200b \u5728\u4e00\u4e2a high density region \u4e0a\u5f88\u63a5\u8fd1\u7684\u8bdd\uff0c\u90a3\u4e48 \\(\\hat y^1\\) \u200b\u548c \\(\\hat y^2\\) \u200b\u5c31\u662f\u76f8\u540c\u7684 \u4e5f\u5c31\u662f\u8fd9\u4e24\u4e2a\u70b9\u53ef\u4ee5\u5728\u6837\u672c\u70b9\u9ad8\u5bc6\u5ea6\u96c6\u4e2d\u5206\u5e03\u7684\u533a\u57df\u5757\u4e2d\u6709\u4e00\u6761\u53ef\u8fde\u63a5\u7684\u8def\u5f84\uff0c\u5373 connected by a high density path","title":"Concepts"},{"location":"ML/7_Semi-supervised%20Learning/#digits-detection","text":"\u624b\u5199\u6570\u5b57\u8fa8\u8bc6\u4e3a\u4f8b\uff0c\u663e\u7136\u6700\u53f3\u4fa7\u7684 2 \u548c 3 \u5728 pixel \u4e0a\u4f1a\u66f4\u63a5\u8fd1\u4e00\u4e9b\uff1b\u4f46\u5982\u679c\u628a\u6240\u6709\u8fde\u7eed\u53d8\u5316\u7684 2 \u653e\u8fdb\u6765\uff0c\u90a3\u5b83\u4eec\u5176\u5b9e\u90fd\u662f 2 \u4eba\u8138\u7684\u8fc7\u6e21\u6570\u636e\u4e5f\u540c\u7406","title":"digits detection"},{"location":"ML/7_Semi-supervised%20Learning/#file-classification","text":"Smoothness Assumption \u5728\u6587\u4ef6\u5206\u7c7b\u4e0a\u662f\u975e\u5e38\u6709\u7528\u7684 \u5047\u8bbe\u5bf9\u5929\u6587\u5b66 (astronomy) \u548c\u65c5\u884c (travel) \u7684\u6587\u7ae0\u8fdb\u884c\u5206\u7c7b\uff0c\u5b83\u4eec\u5404\u81ea\u6709\u4e13\u5c5e\u7684\u8bcd\u6c47\uff0c\u6b64\u65f6\u5982\u679c unlabeled data \u4e0e label data \u7684\u8bcd\u6c47\u662f\u76f8\u540c\u6216\u91cd\u5408 (overlap) \u7684\uff0c\u90a3\u4e48\u5c31\u5f88\u5bb9\u6613\u5206\u7c7b\uff1b\u4f46\u5728\u771f\u5b9e\u7684\u60c5\u51b5\u4e0b\uff0cunlabeled data \u548c labeled data \u4e4b\u95f4\u53ef\u80fd\u6ca1\u6709\u4efb\u4f55\u91cd\u590d\u7684 words\uff0c\u56e0\u4e3a\u4e16\u754c\u4e0a\u7684\u8bcd\u6c47\u592a\u591a\u4e86\uff0csparse \u7684\u5206\u5e03\u5f88\u96be\u4f1a\u4f7f overlap \u53d1\u751f \u4f46\u5982\u679cunlabeled data\u8db3\u591f\u591a\uff0c\u5c31\u4f1a\u4ee5\u4e00\u79cd\u76f8\u4f3c\u4f20\u9012\u7684\u5f62\u5f0f\uff0c\u5efa\u7acb\u8d77\u6587\u6863\u4e4b\u95f4\u76f8\u4f3c\u7684\u6865\u6881","title":"file classification"},{"location":"ML/7_Semi-supervised%20Learning/#cluster-and-then-label","text":"\u5728\u5177\u4f53\u5b9e\u73b0\u4e0a\uff0c\u6709\u4e00\u79cd\u7b80\u5355\u7684\u65b9\u6cd5\u662fcluster and then label\uff0c\u4e5f\u5c31\u662f\u5148\u628a data \u5206\u6210\u51e0\u4e2a cluster \u540e\u518d\u53bb train\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u4e00\u5b9a\u4f1a\u5f97\u5230\u597d\u7684\u7ed3\u679c\uff0c\u56e0\u4e3a\u5b83\u7684\u5047\u8bbe\u662f\u4f60\u53ef\u4ee5\u628a\u540c\u4e00\u4e2a class \u7684\u6837\u672c\u70b9 cluster \u5728\u4e00\u8d77\uff0c\u800c\u8fd9\u5176\u5b9e\u662f\u6ca1\u90a3\u4e48\u5bb9\u6613\u7684\uff0c\u6bd4\u5982 \u5bf9\u56fe\u50cf\u7684\u5212\u5206","title":"cluster and then label"},{"location":"ML/7_Semi-supervised%20Learning/#graph-based-approach","text":"\u4e4b\u524d\u8bb2\u7684\u662f\u6bd4\u8f83\u76f4\u89c9\u7684\u505a\u6cd5\uff0c\u63a5\u4e0b\u6765\u5f15\u5165 Graph Structure \u6765\u8868\u8fbe connected by a high density path \u8fd9\u4ef6\u4e8b \u628a\u6240\u6709\u7684 data points \u90fd\u5efa\u6210\u4e00\u4e2a graph\uff0c\u6709\u65f6\u5019\u5efa\u7acb vertex \u4e4b\u95f4\u7684\u5173\u7cfb\u662f\u6bd4\u8f83\u5bb9\u6613\u7684\uff0c\u6bd4\u5982\u7f51\u9875\u4e4b\u95f4\u7684\u94fe\u63a5\u5173\u7cfb\u3001\u8bba\u6587\u4e4b\u95f4\u7684\u5f15\u7528\u5173\u7cfb\uff1b\u4f46\u6709\u65f6\u5019\u9700\u8981\u4f60\u81ea\u5df1\u53bb\u5bfb\u627e vertex \u4e4b\u95f4\u7684\u5173\u7cfb graph \u7684\u597d\u574f\uff0c\u5bf9\u7ed3\u679c\u8d77\u7740\u81f3\u5173\u91cd\u8981\u7684\u5f71\u54cd\uff0c\u800c\u5982\u4f55 build graph \u5374\u662f\u4e00\u4ef6 heuristic \u7684\u4e8b\u60c5\uff0c\u9700\u8981\u51ed\u7740\u7ecf\u9a8c\u548c\u76f4\u89c9\u6765\u505a \u9996\u5148\u5b9a\u4e49\u4e24\u4e2aobject \\(x^i,x^j\\) \u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6 \\(s(x^i, x^j)\\) \u7b97\u5b8c\u76f8\u4f3c\u5ea6\u540e\uff0c\u5c31\u53ef\u4ee5\u5efagraph\u4e86\uff0c\u65b9\u5f0f\u6709\u5f88\u591a\u79cd\uff1a k nearest neighbor\uff1ak \u90bb\u8fd1\u6cd5\uff0c\u4e0e\u5468\u56f4\u6700\u63a5\u8fd1\u7684 k \u4e2a\u70b9\u8fde\u63a5 e-neighborhood\uff1a\u6bcf\u4e2a point \u4e0e\u76f8\u4f3c\u5ea6\u8d85\u8fc7\u67d0\u4e2a\u7279\u5b9a threshold e \u7684\u70b9\u76f8\u8fde \u9664\u6b64\u4e4b\u5916\uff0c\u8fd8\u53ef\u4ee5\u7ed9 Edge \u7279\u5b9a\u7684 weight\uff0c\u8ba9\u5b83\u4e0e\u76f8\u4f3c\u5ea6 \\(s(x^i,x^j)\\) \u200b \u6210\u6b63\u6bd4 \u5efa\u8bae\u7528 RBM function \u6765\u786e\u5b9a\u76f8\u4f3c\u5ea6\uff1a \\(s(x^i,x^j)=e^{-\\gamma||x^i-x^j||^2 }\\) \u200b \u8fd9\u91cc \\(x^i,x^j\\) \u200b\u5747\u4e3avector\uff0c\u8ba1\u7b97\u5b83\u4eec\u7684 Euclidean Distance (\u6b27\u51e0\u91cc\u5f97\u8ddd\u79bb)\uff0c\u52a0\u4e0a\u53c2\u6570\u540e\u518d\u53bb exponential \u81f3\u4e8e\u52a0exponential\uff0c\u7ecf\u9a8c\u4e0a\u6765\u8bf4\u901a\u5e38\u662f\u53ef\u4ee5\u5e2e\u52a9\u63d0\u5347 performance\u7684\uff0c\u5728\u8fd9\u91cc\u53ea\u6709\u5f53 \\(x^i,x^j\\) \u200b \u975e\u5e38\u63a5\u8fd1\u7684\u65f6\u5019\uff0csingularity \u624d\u4f1a\u5927\uff1b\u53ea\u8981\u8ddd\u79bb\u7a0d\u5fae\u8fdc\u4e00\u70b9\uff0csingularity \u5c31\u4f1a\u4e0b\u964d\u5f97\u5f88\u5feb\uff0c\u53d8\u5f97\u5f88\u5c0f \u4f7f\u7528 exponential \u7684 RBM function \u53ef\u4ee5\u505a\u5230\u53ea\u6709\u975e\u5e38\u8fd1\u7684\u4e24\u4e2a\u70b9\u624d\u80fd\u76f8\u8fde\uff0c\u7a0d\u5fae\u8fdc\u4e00\u70b9\u5c31\u65e0\u6cd5\u76f8\u8fde\u7684\u6548\u679c graph-based approach \u9700\u8981\u6536\u96c6\u5230\u7684 data \u8db3\u591f\u591a\uff0c\u5426\u5219\u53ef\u80fd\u4f20\u9012\u5230\u4e00\u534a\uff0cgraph \u5c31\u65ad\u6389\u4e86\uff0cinformation \u7684\u4f20\u9012\u5c31\u5931\u6548\u4e86 \u4ecb\u7ecd\u5b8c\u4e86\u5982\u4f55\u5b9a\u6027\u4f7f\u7528 graph\uff0c\u63a5\u4e0b\u6765\u4ecb\u7ecd\u4e00\u4e0b\u5982\u4f55\u5b9a\u91cf\u4f7f\u7528 graph \u5b9a\u91cf\u7684\u4f7f\u7528\u65b9\u5f0f\u662f\u5b9a\u4e49 label \u7684 smoothness\uff0c\u4e0b\u56fe\u4e2d\uff0cedge \u4e0a\u7684\u6570\u5b57\u662f weight\uff0c \\(x^i\\) \u662fdata\uff0c \\(y^i\\) \u662f label\uff0c\u8ba1\u7b97 smoothness \u7684\u65b9\u5f0f\u4e3a\uff1a $$ S=\\frac{1}{2}\\sum\\limits_{i,j} w_{i,j}(y^i-y^j)^2 $$ \u6211\u4eec\u671f\u671b smooth \u7684\u503c \u8d8a\u5c0f\u8d8a\u597d \u5982\u679c\u628a labeled data \u548c unlabeled data \u7684 y \u7ec4\u6210\u4e00\u4e2a( R+U) dim vector\uff0c\u5373 $$ y=\\left [\\begin{matrix} ...y^i...y^j \\end{matrix} \\right ]^T $$ \u4e8e\u662f smooth \u53ef\u4ee5\u6539\u5199\u4e3a\uff1a $$ S=\\frac{1}{2}\\sum\\limits_{i,j} w_{i,j}(y^i-y^j)^2=y^TLy $$ \u5176\u4e2d L \u4e3a (R+U)\u00d7(R+U) matrix\uff0c\u79f0\u4e3a Graph Laplacian \uff0c \u5b9a\u4e49\u4e3a \\(L=D-W\\) W\uff1a\u628a data point \u4e24\u4e24\u4e4b\u95f4 weight \u7684\u5173\u7cfb\u5efa\u6210 matrix\uff0c\u4ee3\u8868\u4e86 \\(x^i\\) \u4e0e \\(x^j\\) \u4e4b\u95f4\u7684weight\u503c D\uff1a\u628a W \u7684\u6bcf\u4e00\u4e2a row \u4e0a\u7684\u503c\u52a0\u8d77\u6765\u653e\u5728\u8be5\u884c\u5bf9\u5e94\u7684 diagonal \u4e0a\u5373\u53ef \u5bf9 \\(S=y^TLy\\) \u6765\u8bf4\uff0cy \u662f label\uff0c\u662f neural network \u7684 output\uff0c\u53d6\u51b3\u4e8e neural network \u7684parameters\uff0c\u56e0\u6b64\u8981\u5728\u539f\u6765\u4ec5\u9488\u5bf9 labeled data \u7684 loss function \u4e2d\u52a0\u4e0a\u8fd9\u4e00\u9879\uff0c\u5f97\u5230\uff1a $$ L=\\sum\\limits_{x^r}C(y^r,\\hat y^r) + \\lambda S $$ \\(\\lambda S\\) \u200b\u200b \u5b9e\u9645\u4e0a\u4e5f\u662f\u4e00\u4e2a regularization \u8bad\u7ec3\u76ee\u6807\uff1a labeled data \u7684 cross entropy \u8d8a\u5c0f\u8d8a\u597d (neural network \u7684 output \u8ddf\u771f\u6b63\u7684 label \u8d8a\u63a5\u8fd1\u8d8a\u597d) smooth S \u8d8a\u5c0f\u8d8a\u597d (neural network \u7684 output\uff0c\u4e0d\u7ba1\u662f labeled \u8fd8\u662f unlabeled\uff0c\u90fd\u8981\u7b26\u5408 Smoothness Assumption \u7684\u5047\u8bbe) \u5177\u4f53\u8bad\u7ec3\u7684\u65f6\u5019\uff0c\u4e0d\u4e00\u5b9a\u53ea\u5c40\u9650\u4e8e neural network \u7684 output \u8981 smooth\uff0c\u53ef\u4ee5\u5bf9\u4e2d\u95f4\u4efb\u610f\u4e00\u4e2a hidden layer \u52a0\u4e0a smooth \u7684\u9650\u5236","title":"Graph-based Approach"},{"location":"ML/7_Semi-supervised%20Learning/#better-representation","text":"Better Representation \u7684\u7cbe\u795e\u662f\uff0c\u53bb\u829c\u5b58\u83c1\uff0c\u5316\u7e41\u4e3a\u7b80 \u5c31\u662f\u627e\u5230\u4e00\u4e2a data \u7684 feature \u6838\u5fc3 \u7b97\u6cd5\u5177\u4f53\u601d\u8def\u548c\u5185\u5bb9\u5230 unsupervised learning \u7684\u65f6\u5019\u518d\u4ecb\u7ecd","title":"Better Representation"},{"location":"ML/8_Unsupervised%20Learning%20Word%20Embedding/","text":"Unsupervised Learning: Word Embedding \u00b6 Word Embedding\uff1a\u8bcd\u5d4c\u5165 \u57fa\u4e8e\u964d\u7ef4\u601d\u60f3\u63d0\u4f9b\u4e86 count-based \u548c prediction-based \u4e24\u79cd\u65b9\u6cd5\uff0c\u5e76\u4ecb\u7ecd\u4e86\u8be5\u601d\u60f3\u5728\u673a\u5668\u95ee\u7b54\u3001\u673a\u5668\u7ffb\u8bd1\u3001\u56fe\u50cf\u5206\u7c7b\u3001\u6587\u6863\u5d4c\u5165\u7b49\u65b9\u9762\u7684\u5e94\u7528 Introduction \u00b6 \u8bcd\u5d4c\u5165 (word embedding) \u662f\u964d\u7ef4\u7b97\u6cd5 (Dimension Reduction) \u7684\u5178\u578b\u5e94\u7528 \u90a3\u5982\u4f55\u7528 vector \u6765\u8868\u793a\u4e00\u4e2a word \u5462\uff1f 1-of-N Encoding \u00b6 \u6709 n \u4e2a\u5355\u8bcd\u5c31\u6709 n \u7ef4\uff0c\u6bcf\u4e2a\u5355\u8bcd\u90fd\u662f\u4e00\u4e2a\u5355\u4f4d\u5411\u91cf \u7f3a\u70b9\uff1a\u65e0\u6cd5\u5efa\u7acb\u8d77\u540c\u7c7b word \u7684\u8054\u7cfb Word Class \u00b6 \u5bf9\u540c\u6837\u6027\u8d28\u7684 word \u8fdb\u884c\u805a\u7c7b (clustering)\uff0c\u5212\u5206\u4e3a\u591a\u4e2a class\uff0c\u7528 word \u6240\u5c5e\u7684 class \u6765\u8868\u793a word \u7f3a\u70b9\uff1a\u4e0d\u540c class \u4e4b\u95f4\u7684\u8054\u7cfb\u65e0\u6cd5\u6709\u6548\u7684\u88ab\u8868\u8fbe Word Embedding \u00b6 \u5c06\u6240\u6709 word \u6295\u5f71\u5230\u9ad8\u7ef4\u7a7a\u95f4\uff0c\u8fd9\u4e2a\u7a7a\u95f4\u7684\u7ef4\u6570\u8fdc\u4f4e\u4e8e word \u7684\u4e2a\u6570 n \u7c7b\u4f3c\u8bed\u4e49(semantic)\u7684\u8bcd\u6c47\uff0c\u5728\u8fd9\u4e2aword embedding\u7684\u6295\u5f71\u7a7a\u95f4\u4e0a\u662f\u6bd4\u8f83\u63a5\u8fd1\u7684\uff0c\u800c\u4e14\u8be5\u7a7a\u95f4\u91cc\u7684\u6bcf\u4e00\u7ef4\u90fd\u53ef\u80fd\u6709\u7279\u6b8a\u7684\u542b\u4e49 \u5047\u8bbe\u8bcd\u5d4c\u5165\u7684\u6295\u5f71\u7a7a\u95f4\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u5219\u6a2a\u8f74\u4ee3\u8868\u4e86\u751f\u7269\u4e0e\u5176\u5b83\u4e1c\u897f\u4e4b\u95f4\u7684\u533a\u522b\uff0c\u800c\u7eb5\u8f74\u5219\u4ee3\u8868\u4e86\u4f1a\u52a8\u7684\u4e1c\u897f\u4e0e\u9759\u6b62\u7684\u4e1c\u897f\u4e4b\u95f4\u7684\u5dee\u522b word embedding \u662f\u4e00\u4e2a\u65e0\u76d1\u7763\u7684\u65b9\u6cd5 (unsupervised approach)\uff0c\u53ea\u8981\u8ba9\u673a\u5668\u9605\u8bfb\u5927\u91cf\u7684\u6587\u7ae0\uff0c\u5b83\u5c31\u53ef\u4ee5\u77e5\u9053\u6bcf\u4e00\u4e2a\u8bcd\u6c47 embedding \u4e4b\u540e\u7684\u7279\u5f81\u5411\u91cf\u5e94\u8be5\u957f\u4ec0\u4e48\u6837\u5b50 \u6211\u4eec\u7684\u4efb\u52a1\u5c31\u662f\u8bad\u7ec3\u4e00\u4e2a neural network\uff0cinput \u662f\u8bcd\u6c47\uff0coutput \u5219\u662f\u5b83\u6240\u5bf9\u5e94\u7684 word embedding vector\uff0c\u5b9e\u9645\u8bad\u7ec3\u7684\u65f6\u5019\u6211\u4eec\u53ea\u6709 data\u7684 input\uff0c\u8be5\u5982\u4f55\u89e3\u8fd9\u7c7b\u95ee\u9898\u5462\uff1f \u4e4b\u524d\u63d0\u5230\u8fc7\u4e00\u79cd\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u964d\u7ef4\u65b9\u6cd5\uff0cAuto-encoder\uff0c\u5c31\u662f\u8bad\u7ec3\u4e00\u4e2a model\uff0c\u8ba9\u5b83\u7684\u8f93\u5165\u7b49\u4e8e\u8f93\u51fa\uff0c\u53d6\u51fa\u4e2d\u95f4\u7684\u67d0\u4e2a\u9690\u85cf\u5c42\u5c31\u662f\u964d\u7ef4\u7684\u7ed3\u679c\uff0c\u81ea\u7f16\u7801\u7684\u672c\u8d28\u5c31\u662f\u901a\u8fc7\u81ea\u6211\u538b\u7f29\u548c\u89e3\u538b\u7684\u8fc7\u7a0b\u6765\u5bfb\u627e\u5404\u4e2a\u7ef4\u5ea6\u4e4b\u95f4\u7684\u76f8\u5173\u4fe1\u606f\uff1b\u4f46 word embedding \u8fd9\u4e2a\u95ee\u9898\u662f\u4e0d\u80fd\u7528 Auto-encoder \u6765\u89e3\u7684\uff0c\u56e0\u4e3a\u8f93\u5165\u7684\u5411\u91cf\u901a\u5e38\u662f 1-of-N \u7f16\u7801\uff0c\u5404\u7ef4\u65e0\u5173\uff0c\u5f88\u96be\u901a\u8fc7\u81ea\u7f16\u7801\u7684\u8fc7\u7a0b\u63d0\u53d6\u51fa\u4ec0\u4e48\u6709\u7528\u4fe1\u606f Word Embedding \u00b6 Basic idea \u00b6 \u601d\u60f3\u662f\u901a\u8fc7\u6bcf\u4e00\u4e2a\u8bcd\u6c47\u7684\u4e0a\u4e0b\u6587\u6765\u5f97\u5230\u5b83\u7684\u542b\u4e49 \u6bd4\u5982\uff1a\u201c\u9a6c\u82f1\u4e5d520\u5ba3\u8a93\u5c31\u804c\u201d\u3001\u201c\u8521\u82f1\u6587520\u5ba3\u8a93\u5c31\u804c\u201d\uff0c\u673a\u5668\u5c31\u53ef\u4ee5\u63a8\u6d4b\u9a6c\u82f1\u4e5d\u548c\u8521\u82f1\u6587\u4ee3\u8868\u7684\u540c\u6837\u7684\u4e1c\u897f \u600e\u4e48\u7528\u8fd9\u4e2a\u601d\u60f3\u6765\u627e\u51faword embedding\u7684vector\u5462\uff1f\u6709\u4e24\u79cd\u505a\u6cd5\uff1a Count based Prediction based Count based \u00b6 \u5047\u5982 \\(w_i\\) \u200b\u200b\u200b\u200b \u548c \\(w_j\\) \u200b\u200b\u200b \u200b\u8fd9\u4e24\u4e2a\u8bcd\u6c47\u5e38\u5e38\u5728\u540c\u4e00\u7bc7\u6587\u7ae0\u4e2d\u51fa\u73b0 (co-occur)\uff0c\u5b83\u4eec\u7684 word vector \u5206\u522b\u7528 \\(V(w_i)\\) \u200b\u200b\u200b\u200b \u548c \\(V(w_j)\\) \u200b\u200b\u200b\u200b \u6765\u8868\u793a\uff0c\u5219 \\(V(w_i)\\) \u200b\u200b\u200b\u200b \u548c \\(V(w_j)\\) \u200b\u200b\u200b\u200b\u4f1a\u6bd4\u8f83\u63a5\u8fd1 \u5047\u8bbe \\(N_{i,j}\\) \u662f \\(w_i\\) \u548c \\(w_j\\) \u8fd9\u4e24\u4e2a\u8bcd\u6c47\u5728\u76f8\u540c\u6587\u7ae0\u91cc\u540c\u65f6\u51fa\u73b0\u7684\u6b21\u6570\uff0c\u6211\u4eec\u5e0c\u671b\u5b83\u4e0e \\(V(w_i)\\cdot V(w_j)\\) \u7684\u5185\u79ef\u8d8a\u63a5\u8fd1\u8d8a\u597d\uff0c\u8fd9\u4e2a\u601d\u60f3\u548c\u4e4b\u524d\u7684\u6587\u7ae0\u4e2d\u63d0\u5230\u7684\u77e9\u9635\u5206\u89e3 (matrix factorization) \u7684\u601d\u60f3\u5176\u5b9e\u662f\u4e00\u6837\u7684\uff08matrix factorization \u572820\u5e74\u7684\u8bfe\u7a0b\u91cc\u6ca1\u6709\uff09 \u8fd9\u79cd\u65b9\u6cd5\u6709\u4e00\u4e2a\u5f88\u4ee3\u8868\u6027\u7684\u4f8b\u5b50\u662f Glove Vector Prediction based \u00b6 how to do perdition \u00b6 \u7ed9\u5b9a\u4e00\u4e2a sentence\uff0c\u6211\u4eec\u8981\u8bad\u7ec3\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\uff0c\u6839\u636e\u5f53\u524d\u7684 word \\(w_{i-1}\\) \uff0c\u6765\u9884\u6d4b\u4e0b\u4e00\u4e2a\u53ef\u80fd\u51fa\u73b0\u7684 word \\(w_i\\) \u200b \u662f\u4ec0\u4e48 \u4f7f\u7528 1-of-N encoding \u628a \\(w_{i-1}\\) \u200b \u8868\u793a\u6210 feature vector \u4f5c\u4e3a input\uff0c\u7136\u540e\u8f93\u51fa output \u4e5f\u662f n \u7ef4\u7684 vector\uff0c\u8868\u793a\u6bcf\u4e00\u4e2a\u5355\u8bcd\u7684\u53ef\u80fd\u6027 \u628a\u7b2c\u4e00\u4e2a hidden layer \u7684 input \\(z_1,z_2,...\\) \u200b\u200b \u200b\u62ff\u51fa\u6765\uff0c\u5b83\u4eec\u6240\u7ec4\u6210\u7684 \\(Z\\) \u200b\u200b \u200b\u5c31\u662f word \u7684\u53e6\u4e00\u79cd\u8868\u793a\u65b9\u5f0f\uff0c\u5f53\u6211\u4eec input \u4e0d\u540c\u7684\u8bcd\u6c47\uff0c\u5411\u91cf \\(Z\\) \u200b\u200b\u200b\u200b \u5c31\u4f1a\u53d1\u751f\u53d8\u5316\uff0c\u800c\u4e14 \\(Z\\) \u7684\u7ef4\u6570\u662f\u53ef\u4ee5\u81ea\u5df1\u51b3\u5b9a\u7684\uff0c\u56e0\u6b64\u63d0\u53d6\u51fa\u7b2c\u4e00\u5c42 hidden layer \u7684 input\uff0c\u5b9e\u9645\u4e0a\u5c31\u5f97\u5230\u4e86\u4e00\u7ec4\u53ef\u4ee5\u81ea\u5b9a\u4e49\u7ef4\u6570\u7684Word Embedding \u7684\u5411\u91cf Why prediction works \u00b6 2 \u4e2a \u76f8\u4f3c\u7684 word \u7684 input vector \u7684 1-of-N \u7f16\u7801\u7ecf\u8fc7\u964d\u7ef4\u5230 \\(Z\\) \u200b\u200b \u7684 input \u540e\u7684 vector \u662f\u975e\u5e38\u63a5\u8fd1\u7684 Sharing Parameters \u00b6 \u901a\u8fc7\u5f53\u524d\u8bcd\u6c47\u9884\u6d4b\u4e0b\u4e00\u4e2a\u8bcd\u6c47\u8fd9\u4e2a\u7ea6\u675f\u592a\u5f31\u4e86\uff0c\u56e0\u4e3a\u8bcd\u6c47\u7684\u642d\u914d\u592a\u591a\u4e86 \u53ef\u4ee5\u6269\u5c55\u8fd9\u4e2a\u95ee\u9898\uff0c\u4f7f\u7528 10 \u4e2a\u53ca\u4ee5\u4e0a\u7684\u8bcd\u6c47\u53bb\u9884\u6d4b\u4e0b\u4e00\u4e2a\u8bcd\u6c47 \u4e3e 2 \u4e2a\u8bcd\u6c47\u7684\u4f8b\u5b50\u662f\u76f4\u63a5\u628a \\(w_{i-2}\\) \u548c \\(w_{i-1}\\) \u8fd9\u4e24\u4e2a vector \u62fc\u63a5\u6210\u4e00\u4e2a\u66f4\u957f\u7684 vector \u4f5c\u4e3a input \u5373\u53ef\uff0c\u800c\u4e14\u6211\u4eec\u5e0c\u671b \\(w_{i-2}\\) \u548c \\(w_{i-1}\\) \u7684 weight \u662f tight \u5728\u4e00\u8d77\u7684\uff0c\u5373\u4ed6\u4eec\u6709\u76f8\u540c\u7684 weight\uff0c\u56e0\u4e3a\u4e0d\u8fd9\u6837\u505a\u5982\u679c \\(w_{i-2}\\) \u548c \\(w_{i-1}\\) \u200b \u662f\u76f8\u540c\u7684\u90a3\u4ed6\u4eec\u7684 embedding \u7ed3\u679c\u4f1a\u4e0d\u4e00\u6837\uff0c\u540c\u65f6\u4e5f\u53ef\u4ee5\u51cf\u5c11\u53c2\u6570\uff0c\u4e0d\u4f1a\u56e0\u4e3a input word \u7684\u6570\u91cf\u7684\u589e\u52a0\u800c\u5bfc\u81f4\u53c2\u6570\u7684\u66b4\u589e $$ z=W_1 x_{i-2}+W_2 x_{i-1}=W(x_{i-2}+x_{i-1}) $$ \u5728\u5b9e\u9645\u64cd\u4f5c\u65f6\u5982\u4f55\u4fdd\u8bc1 \\(W_1\\) \u548c \\(W_2\\) \u200b \u4e00\u6837\u5462\uff1f \u539f\u672c\u7684 update \u7684\u53c2\u6570\uff1a $$ \\begin{align} w_i=w_i-\\eta \\frac{\\partial C}{\\partial w_i}\\ w_j=w_j-\\eta \\frac{\\partial C}{\\partial w_j} \\end{align} $$ \u4e3a\u4e86\u4fdd\u8bc1 \\(w_i=w_j\\) \uff1a $$ \\begin{align} w_i=w_i-\\eta \\frac{\\partial C}{\\partial w_i}-\\eta \\frac{\\partial C}{\\partial w_j}\\ w_j=w_j-\\eta \\frac{\\partial C}{\\partial w_j}-\\eta \\frac{\\partial C}{\\partial w_i} \\end{align} $$ Training \u00b6 \u8bad\u7ec3\u53ea\u8981\u4e0a\u7f51\u722c\u4e00\u4e0b\u6587\u7ae0\u6570\u636e\u5c31\u884c \u901a\u8fc7\u5e0c\u671b output \u548c target \u7684 cross entropy \u6700\u5c0f\uff0c\u4e5f\u5c31\u662f\u4f7f\u5f97\u8f93\u51fa\u7684\u90a3\u4e2a vector \u5728 target \u6240\u5bf9\u5e94\u7684\u90a3\u4e00\u7ef4\u4e0a\u6982\u7387\u6700\u9ad8 Various Architectures \u00b6 \u9664\u4e86\u4e0a\u9762\u7684\u57fa\u672c\u5f62\u6001\uff0cPrediction-based \u65b9\u6cd5\u8fd8\u53ef\u4ee5\u6709\u591a\u79cd\u53d8\u5f62 CBOW (Continuous bag of word model) \u62ff\u524d\u540e\u7684\u8bcd\u6c47\u53bb\u9884\u6d4b\u4e2d\u95f4\u7684\u8bcd\u6c47 Skip-gram \u62ff\u4e2d\u95f4\u7684\u8bcd\u6c47\u53bb\u9884\u6d4b\u524d\u540e\u7684\u8bcd\u6c47 Others \u00b6 \u5c3d\u7ba1 word vector \u662f deep learning \u7684\u4e00\u4e2a\u5e94\u7528\uff0c\u4f46\u8fd9\u4e2a neural network \u5176\u5b9e\u5e76\u4e0d\u662f deep\u7684\uff0c\u5b83\u5c31\u53ea\u6709\u4e00\u4e2a linear \u7684 hidden layer \u6211\u4eec\u628a 1-of-N \u7f16\u7801\u8f93\u5165\u7ed9\u795e\u7ecf\u7f51\u7edc\uff0c\u7ecf\u8fc7 weight \u7684\u8f6c\u6362\u5f97\u5230 Word Embedding\uff0c\u518d\u901a\u8fc7\u7b2c\u4e00\u5c42 hidden layer \u5c31\u53ef\u4ee5\u76f4\u63a5\u5f97\u5230\u8f93\u51fa\uff0c\u51cf\u5c0f\u8fd0\u7b97\u91cf Application \u00b6 Subtraction \u00b6 \u673a\u5668\u95ee\u7b54 \u4ece\u5f97\u5230\u7684 word vector \u91cc\uff0c\u6211\u4eec\u53ef\u4ee5\u53d1\u73b0\u4e00\u4e9b\u539f\u672c\u5e76\u4e0d\u77e5\u9053\u7684 word \u4e0e word \u4e4b\u95f4\u7684\u5173\u7cfb \u628a word vector \u4e24\u4e24\u76f8\u51cf\uff0c\u518d\u6295\u5f71\u5230\u4e0b\u56fe\u4e2d\u7684\u4e8c\u7ef4\u5e73\u9762\u4e0a\uff0c\u5982\u679c\u67d0\u4e24\u4e2a word \u4e4b\u95f4\u6709\u7c7b\u4f3c\u5305\u542b\u4e8e\u7684\u76f8\u540c\u5173\u7cfb\uff0c\u5b83\u4eec\u5c31\u4f1a\u88ab\u6295\u5f71\u5230\u540c\u4e00\u5757\u533a\u57df \u5229\u7528\u8fd9\u4e2a\u6982\u5ff5\uff0c\u6211\u4eec\u53ef\u4ee5\u505a\u4e00\u4e9b\u7b80\u5355\u7684\u63a8\u8bba\uff1a \u5728 word vector \u7684\u7279\u5f81\u4e0a\uff0c \\(V(Rome)-V(Italy)\u2248V(Berlin)-V(Germany)\\) \u6b64\u65f6\u5982\u679c\u6709\u4eba\u95ee \u201c\u7f57\u9a6c\u4e4b\u4e8e\u610f\u5927\u5229\u7b49\u4e8e\u67cf\u6797\u4e4b\u4e8e\uff1f\u201d\uff0c\u90a3\u673a\u5668\u5c31\u53ef\u4ee5\u56de\u7b54\u8fd9\u4e2a\u95ee\u9898 \u56e0\u4e3a\u5fb7\u56fd\u7684 vector \u4f1a\u5f88\u63a5\u8fd1\u4e8e \u201c\u67cf\u6797\u7684vector-\u7f57\u9a6c\u7684vector+\u610f\u5927\u5229\u7684vector\u201d\uff0c\u56e0\u6b64\u673a\u5668\u53ea\u9700\u8981\u8ba1\u7b97 \\(V(Berlin)-V(Rome)+V(Italy)\\) \u200b\uff0c\u7136\u540e\u9009\u53d6\u4e0e\u8fd9\u4e2a\u7ed3\u679c\u6700\u63a5\u8fd1\u7684 vector \u5373\u53ef Multi-lingual Embedding \u00b6 \u673a\u5668\u7ffb\u8bd1 \u6b64\u5916\uff0cword vector \u8fd8\u53ef\u4ee5\u5efa\u7acb\u8d77\u4e0d\u540c\u8bed\u8a00\u4e4b\u95f4\u7684\u8054\u7cfb \u5982\u679c\u4f60\u8981\u7528\u4e0a\u8ff0\u65b9\u6cd5\u5206\u522b\u8bad\u7ec3\u4e00\u4e2a\u82f1\u6587\u7684\u8bed\u6599\u5e93 (corpus) \u548c\u4e2d\u6587\u7684\u8bed\u6599\u5e93\uff0c\u4f60\u4f1a\u53d1\u73b0\u4e24\u8005\u7684 word vector \u4e4b\u95f4\u662f\u6ca1\u6709\u4efb\u4f55\u5173\u7cfb\u7684\uff0c\u56e0\u4e3a Word Embedding \u53ea\u4f53\u73b0\u4e86\u4e0a\u4e0b\u6587\u7684\u5173\u7cfb\uff0c\u5982\u679c\u4f60\u7684\u6587\u7ae0\u6ca1\u6709\u628a\u4e2d\u82f1\u6587\u6df7\u5408\u5728\u4e00\u8d77\u4f7f\u7528\uff0c\u673a\u5668\u5c31\u6ca1\u6709\u529e\u6cd5\u5224\u65ad\u4e2d\u82f1\u6587\u8bcd\u6c47\u4e4b\u95f4\u7684\u5173\u7cfb \u4f46\u662f\uff0c\u5982\u679c\u4f60\u77e5\u9053\u67d0\u4e9b\u4e2d\u6587\u8bcd\u6c47\u548c\u82f1\u6587\u8bcd\u6c47\u7684\u5bf9\u5e94\u5173\u7cfb\uff0c\u4f60\u53ef\u4ee5\u5148\u5206\u522b\u83b7\u53d6\u5b83\u4eec\u7684 word vector\uff0c\u7136\u540e\u518d\u53bb\u8bad\u7ec3\u4e00\u4e2a\u6a21\u578b\uff0c\u628a\u5177\u6709\u76f8\u540c\u542b\u4e49\u7684\u4e2d\u82f1\u6587\u8bcd\u6c47\u6295\u5f71\u5230\u65b0\u7a7a\u95f4\u4e0a\u7684\u540c\u4e00\u4e2a\u70b9 \u63a5\u4e0b\u6765\u9047\u5230\u672a\u77e5\u7684\u65b0\u8bcd\u6c47\uff0c\u65e0\u8bba\u662f\u4e2d\u6587\u8fd8\u662f\u82f1\u6587\uff0c\u4f60\u90fd\u53ef\u4ee5\u91c7\u7528\u540c\u6837\u7684\u65b9\u5f0f\u5c06\u5176\u6295\u5f71\u5230\u65b0\u7a7a\u95f4\uff0c\u5c31\u53ef\u4ee5\u81ea\u52a8\u505a\u5230\u7c7b\u4f3c\u7ffb\u8bd1\u7684\u6548\u679c \u53c2\u8003\u6587\u732e\uff1a Bilingual Word Embeddings for Phrase-Based Machine Translation, Will Zou, Richard Socher, Daniel Cer and Christopher Manning, EMNLP, 2013 Multi-domain Embedding \u00b6 \u56fe\u50cf\u5206\u7c7b \u8fd9\u4e2a\u505a\u6cd5\u4e0d\u53ea\u5c40\u9650\u4e8e\u6587\u5b57\u7684\u5e94\u7528\uff0c\u4e5f\u53ef\u4ee5\u5bf9\u6587\u5b57+\u56fe\u50cf\u505a Embedding \u5047\u8bbe\u4f60\u5df2\u7ecf\u5f97\u5230 horse\u3001cat \u548c dog \u8fd9\u4e9b \u8bcd\u6c47 \u7684 vector \u5728\u7a7a\u95f4\u4e0a\u7684\u5206\u5e03\u60c5\u51b5\uff0c\u4f60\u5c31\u53ef\u4ee5\u53bb\u8bad\u7ec3\u4e00\u4e2a\u6a21\u578b\uff0c\u628a\u4e00\u4e9b\u5df2\u77e5\u7684 horse\u3001cat \u548c dog \u56fe\u7247 \u53bb\u6295\u5f71\u5230\u548c\u5bf9\u5e94\u8bcd\u6c47\u76f8\u540c\u7684\u7a7a\u95f4\u533a\u57df\u4e0a \u6bd4\u5982\u5bf9\u6a21\u578b\u8f93\u5165\u4e00\u5f20\u56fe\u50cf\uff0c\u4f7f\u4e4b\u8f93\u51fa\u4e00\u4e2a\u8ddf word vector \u5177\u6709\u76f8\u540c\u7ef4\u6570\u7684 vector\uff0c\u4f7f dog \u56fe\u50cf\u7684\u6620\u5c04\u5411\u91cf\u5c31\u6563\u5e03\u5728 dog \u8bcd\u6c47\u5411\u91cf\u7684\u5468\u56f4\uff0chorse \u56fe\u50cf\u7684\u6620\u5c04\u5411\u91cf\u5c31\u6563\u5e03\u5728 horse \u8bcd\u6c47\u5411\u91cf\u7684\u5468\u56f4... \u8bad\u7ec3\u597d\u8fd9\u4e2a\u6a21\u578b\u4e4b\u540e\uff0c\u8f93\u5165\u65b0\u7684\u672a\u77e5\u56fe\u50cf\uff0c\u6839\u636e\u6295\u5f71\u4e4b\u540e\u7684\u4f4d\u7f6e\u6240\u5bf9\u5e94\u7684 word vector\uff0c\u5c31\u53ef\u4ee5\u5224\u65ad\u5b83\u6240\u5c5e\u7684\u7c7b\u522b \u6211\u4eec\u77e5\u9053\u5728\u505a\u56fe\u50cf\u5206\u7c7b\u7684\u65f6\u5019\uff0c\u5f88\u591a\u60c5\u51b5\u4e0b\u90fd\u662f\u4e8b\u5148\u5b9a\u597d\u8981\u5206\u4e3a\u54ea\u51e0\u4e2a\u5177\u4f53\u7684\u7c7b\u522b\uff0c\u518d\u7528\u8fd9\u51e0\u4e2a\u7c7b\u522b\u7684\u56fe\u50cf\u53bb\u8bad\u7ec3\u6a21\u578b\uff0c\u7531\u4e8e\u6211\u4eec\u65e0\u6cd5\u5728\u8bad\u7ec3\u7684\u65f6\u5019\u7a77\u5c3d\u6240\u6709\u7c7b\u522b\u7684\u56fe\u50cf\uff0c\u56e0\u6b64\u5728\u5b9e\u9645\u5e94\u7528\u7684\u65f6\u5019\u4e00\u65e6\u9047\u5230\u5c5e\u4e8e\u672a\u77e5\u7c7b\u522b\u7684\u56fe\u50cf\uff0c\u8fd9\u4e2a\u6a21\u578b\u5c31\u65e0\u80fd\u4e3a\u529b\u4e86 \u800c\u4f7f\u7528 image+word Embedding \u7684\u65b9\u6cd5\uff0c\u5c31\u7b97\u8f93\u5165\u7684\u56fe\u50cf\u7c7b\u522b\u5728\u8bad\u7ec3\u65f6\u6ca1\u6709\u88ab\u9047\u5230\u8fc7\uff0c\u6bd4\u5982\u4e0a\u56fe\u4e2d\u7684 cat\uff0c\u4f46\u5982\u679c\u8fd9\u5f20\u56fe\u50cf\u80fd\u591f\u6295\u5f71\u5230 cat \u7684 word vector \u7684\u9644\u8fd1\uff0c\u6839\u636e\u8bcd\u6c47\u5411\u91cf\u4e0e\u56fe\u50cf\u5411\u91cf\u7684\u5bf9\u5e94\u5173\u7cfb\uff0c\u4f60\u81ea\u7136\u5c31\u53ef\u4ee5\u77e5\u9053\u8fd9\u5f20\u56fe\u50cf\u53eb\u505a cat Document Embedding \u00b6 \u6587\u6863\u5d4c\u5165 \u5bf9 Document \u505a Embedding \u6700\u7b80\u5355\u7684\u65b9\u6cd5\u662f\u628a document \u53d8\u6210 bag-of-word\uff0c\u7136\u540e\u7528 Auto-encoder \u5c31\u53ef\u4ee5\u5f97\u5230\u8be5\u6587\u6863\u7684\u8bed\u4e49\u5d4c\u5165 (Semantic Embedding)\uff0c\u4f46\u5149\u8fd9\u4e48\u505a\u662f\u4e0d\u591f\u7684 \u8bcd\u6c47\u7684\u987a\u5e8f\u4ee3\u8868\u4e86\u5f88\u91cd\u8981\u7684\u542b\u4e49\uff0c\u4e24\u53e5\u8bcd\u6c47\u76f8\u540c\u4f46\u8bed\u5e8f\u4e0d\u540c\u7684\u8bdd\u53ef\u80fd\u4f1a\u6709\u5b8c\u5168\u4e0d\u540c\u7684\u542b\u4e49\uff0c\u6bd4\u5982 \u767d\u8840\u7403\u6d88\u706d\u4e86\u4f20\u67d3\u75c5\u2014\u2014\u6b63\u9762\u8bed\u4e49 \u4f20\u67d3\u75c5\u6d88\u706d\u4e86\u767d\u8840\u7403\u2014\u2014\u8d1f\u9762\u8bed\u4e49 \u60f3\u8981\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u5177\u4f53\u53ef\u4ee5\u53c2\u8003\u4e0b\u9762\u7684\u51e0\u79cd\u5904\u7406\u65b9\u6cd5\uff1a Paragraph Vector : Le, Quoc, and Tomas Mikolov. \"Distributed Representations of Sentences and Documents.\u201c ICML, 2014 Seq2seq Auto-encoder : Li, Jiwei, Minh-Thang Luong, and Dan Jurafsky. \"A hierarchical neural autoencoder for paragraphs and documents.\" arXiv preprint, 2015 Skip Thought : Ryan Kiros, Yukun Zhu, Ruslan Salakhutdinov, Richard S. Zemel, Antonio Torralba, Raquel Urtasun, Sanja Fidler, \u201cSkip-Thought Vectors\u201d arXiv preprint, 2015. \u5173\u4e8e word2vec \uff0c\u53ef\u4ee5\u53c2\u8003\u535a\u5ba2\uff1ahttp://blog.csdn.net/itplus/article/details/37969519","title":"Unsupervised Learning Word Embedding"},{"location":"ML/8_Unsupervised%20Learning%20Word%20Embedding/#unsupervised-learning-word-embedding","text":"Word Embedding\uff1a\u8bcd\u5d4c\u5165 \u57fa\u4e8e\u964d\u7ef4\u601d\u60f3\u63d0\u4f9b\u4e86 count-based \u548c prediction-based \u4e24\u79cd\u65b9\u6cd5\uff0c\u5e76\u4ecb\u7ecd\u4e86\u8be5\u601d\u60f3\u5728\u673a\u5668\u95ee\u7b54\u3001\u673a\u5668\u7ffb\u8bd1\u3001\u56fe\u50cf\u5206\u7c7b\u3001\u6587\u6863\u5d4c\u5165\u7b49\u65b9\u9762\u7684\u5e94\u7528","title":"Unsupervised Learning: Word Embedding"},{"location":"ML/8_Unsupervised%20Learning%20Word%20Embedding/#introduction","text":"\u8bcd\u5d4c\u5165 (word embedding) \u662f\u964d\u7ef4\u7b97\u6cd5 (Dimension Reduction) \u7684\u5178\u578b\u5e94\u7528 \u90a3\u5982\u4f55\u7528 vector \u6765\u8868\u793a\u4e00\u4e2a word \u5462\uff1f","title":"Introduction"},{"location":"ML/8_Unsupervised%20Learning%20Word%20Embedding/#1-of-n-encoding","text":"\u6709 n \u4e2a\u5355\u8bcd\u5c31\u6709 n \u7ef4\uff0c\u6bcf\u4e2a\u5355\u8bcd\u90fd\u662f\u4e00\u4e2a\u5355\u4f4d\u5411\u91cf \u7f3a\u70b9\uff1a\u65e0\u6cd5\u5efa\u7acb\u8d77\u540c\u7c7b word \u7684\u8054\u7cfb","title":"1-of-N Encoding"},{"location":"ML/8_Unsupervised%20Learning%20Word%20Embedding/#word-class","text":"\u5bf9\u540c\u6837\u6027\u8d28\u7684 word \u8fdb\u884c\u805a\u7c7b (clustering)\uff0c\u5212\u5206\u4e3a\u591a\u4e2a class\uff0c\u7528 word \u6240\u5c5e\u7684 class \u6765\u8868\u793a word \u7f3a\u70b9\uff1a\u4e0d\u540c class \u4e4b\u95f4\u7684\u8054\u7cfb\u65e0\u6cd5\u6709\u6548\u7684\u88ab\u8868\u8fbe","title":"Word Class"},{"location":"ML/8_Unsupervised%20Learning%20Word%20Embedding/#word-embedding","text":"\u5c06\u6240\u6709 word \u6295\u5f71\u5230\u9ad8\u7ef4\u7a7a\u95f4\uff0c\u8fd9\u4e2a\u7a7a\u95f4\u7684\u7ef4\u6570\u8fdc\u4f4e\u4e8e word \u7684\u4e2a\u6570 n \u7c7b\u4f3c\u8bed\u4e49(semantic)\u7684\u8bcd\u6c47\uff0c\u5728\u8fd9\u4e2aword embedding\u7684\u6295\u5f71\u7a7a\u95f4\u4e0a\u662f\u6bd4\u8f83\u63a5\u8fd1\u7684\uff0c\u800c\u4e14\u8be5\u7a7a\u95f4\u91cc\u7684\u6bcf\u4e00\u7ef4\u90fd\u53ef\u80fd\u6709\u7279\u6b8a\u7684\u542b\u4e49 \u5047\u8bbe\u8bcd\u5d4c\u5165\u7684\u6295\u5f71\u7a7a\u95f4\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u5219\u6a2a\u8f74\u4ee3\u8868\u4e86\u751f\u7269\u4e0e\u5176\u5b83\u4e1c\u897f\u4e4b\u95f4\u7684\u533a\u522b\uff0c\u800c\u7eb5\u8f74\u5219\u4ee3\u8868\u4e86\u4f1a\u52a8\u7684\u4e1c\u897f\u4e0e\u9759\u6b62\u7684\u4e1c\u897f\u4e4b\u95f4\u7684\u5dee\u522b word embedding \u662f\u4e00\u4e2a\u65e0\u76d1\u7763\u7684\u65b9\u6cd5 (unsupervised approach)\uff0c\u53ea\u8981\u8ba9\u673a\u5668\u9605\u8bfb\u5927\u91cf\u7684\u6587\u7ae0\uff0c\u5b83\u5c31\u53ef\u4ee5\u77e5\u9053\u6bcf\u4e00\u4e2a\u8bcd\u6c47 embedding \u4e4b\u540e\u7684\u7279\u5f81\u5411\u91cf\u5e94\u8be5\u957f\u4ec0\u4e48\u6837\u5b50 \u6211\u4eec\u7684\u4efb\u52a1\u5c31\u662f\u8bad\u7ec3\u4e00\u4e2a neural network\uff0cinput \u662f\u8bcd\u6c47\uff0coutput \u5219\u662f\u5b83\u6240\u5bf9\u5e94\u7684 word embedding vector\uff0c\u5b9e\u9645\u8bad\u7ec3\u7684\u65f6\u5019\u6211\u4eec\u53ea\u6709 data\u7684 input\uff0c\u8be5\u5982\u4f55\u89e3\u8fd9\u7c7b\u95ee\u9898\u5462\uff1f \u4e4b\u524d\u63d0\u5230\u8fc7\u4e00\u79cd\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u964d\u7ef4\u65b9\u6cd5\uff0cAuto-encoder\uff0c\u5c31\u662f\u8bad\u7ec3\u4e00\u4e2a model\uff0c\u8ba9\u5b83\u7684\u8f93\u5165\u7b49\u4e8e\u8f93\u51fa\uff0c\u53d6\u51fa\u4e2d\u95f4\u7684\u67d0\u4e2a\u9690\u85cf\u5c42\u5c31\u662f\u964d\u7ef4\u7684\u7ed3\u679c\uff0c\u81ea\u7f16\u7801\u7684\u672c\u8d28\u5c31\u662f\u901a\u8fc7\u81ea\u6211\u538b\u7f29\u548c\u89e3\u538b\u7684\u8fc7\u7a0b\u6765\u5bfb\u627e\u5404\u4e2a\u7ef4\u5ea6\u4e4b\u95f4\u7684\u76f8\u5173\u4fe1\u606f\uff1b\u4f46 word embedding \u8fd9\u4e2a\u95ee\u9898\u662f\u4e0d\u80fd\u7528 Auto-encoder \u6765\u89e3\u7684\uff0c\u56e0\u4e3a\u8f93\u5165\u7684\u5411\u91cf\u901a\u5e38\u662f 1-of-N \u7f16\u7801\uff0c\u5404\u7ef4\u65e0\u5173\uff0c\u5f88\u96be\u901a\u8fc7\u81ea\u7f16\u7801\u7684\u8fc7\u7a0b\u63d0\u53d6\u51fa\u4ec0\u4e48\u6709\u7528\u4fe1\u606f","title":"Word Embedding"},{"location":"ML/8_Unsupervised%20Learning%20Word%20Embedding/#word-embedding_1","text":"","title":"Word Embedding"},{"location":"ML/8_Unsupervised%20Learning%20Word%20Embedding/#basic-idea","text":"\u601d\u60f3\u662f\u901a\u8fc7\u6bcf\u4e00\u4e2a\u8bcd\u6c47\u7684\u4e0a\u4e0b\u6587\u6765\u5f97\u5230\u5b83\u7684\u542b\u4e49 \u6bd4\u5982\uff1a\u201c\u9a6c\u82f1\u4e5d520\u5ba3\u8a93\u5c31\u804c\u201d\u3001\u201c\u8521\u82f1\u6587520\u5ba3\u8a93\u5c31\u804c\u201d\uff0c\u673a\u5668\u5c31\u53ef\u4ee5\u63a8\u6d4b\u9a6c\u82f1\u4e5d\u548c\u8521\u82f1\u6587\u4ee3\u8868\u7684\u540c\u6837\u7684\u4e1c\u897f \u600e\u4e48\u7528\u8fd9\u4e2a\u601d\u60f3\u6765\u627e\u51faword embedding\u7684vector\u5462\uff1f\u6709\u4e24\u79cd\u505a\u6cd5\uff1a Count based Prediction based","title":"Basic idea"},{"location":"ML/8_Unsupervised%20Learning%20Word%20Embedding/#count-based","text":"\u5047\u5982 \\(w_i\\) \u200b\u200b\u200b\u200b \u548c \\(w_j\\) \u200b\u200b\u200b \u200b\u8fd9\u4e24\u4e2a\u8bcd\u6c47\u5e38\u5e38\u5728\u540c\u4e00\u7bc7\u6587\u7ae0\u4e2d\u51fa\u73b0 (co-occur)\uff0c\u5b83\u4eec\u7684 word vector \u5206\u522b\u7528 \\(V(w_i)\\) \u200b\u200b\u200b\u200b \u548c \\(V(w_j)\\) \u200b\u200b\u200b\u200b \u6765\u8868\u793a\uff0c\u5219 \\(V(w_i)\\) \u200b\u200b\u200b\u200b \u548c \\(V(w_j)\\) \u200b\u200b\u200b\u200b\u4f1a\u6bd4\u8f83\u63a5\u8fd1 \u5047\u8bbe \\(N_{i,j}\\) \u662f \\(w_i\\) \u548c \\(w_j\\) \u8fd9\u4e24\u4e2a\u8bcd\u6c47\u5728\u76f8\u540c\u6587\u7ae0\u91cc\u540c\u65f6\u51fa\u73b0\u7684\u6b21\u6570\uff0c\u6211\u4eec\u5e0c\u671b\u5b83\u4e0e \\(V(w_i)\\cdot V(w_j)\\) \u7684\u5185\u79ef\u8d8a\u63a5\u8fd1\u8d8a\u597d\uff0c\u8fd9\u4e2a\u601d\u60f3\u548c\u4e4b\u524d\u7684\u6587\u7ae0\u4e2d\u63d0\u5230\u7684\u77e9\u9635\u5206\u89e3 (matrix factorization) \u7684\u601d\u60f3\u5176\u5b9e\u662f\u4e00\u6837\u7684\uff08matrix factorization \u572820\u5e74\u7684\u8bfe\u7a0b\u91cc\u6ca1\u6709\uff09 \u8fd9\u79cd\u65b9\u6cd5\u6709\u4e00\u4e2a\u5f88\u4ee3\u8868\u6027\u7684\u4f8b\u5b50\u662f Glove Vector","title":"Count based"},{"location":"ML/8_Unsupervised%20Learning%20Word%20Embedding/#prediction-based","text":"","title":"Prediction based"},{"location":"ML/8_Unsupervised%20Learning%20Word%20Embedding/#how-to-do-perdition","text":"\u7ed9\u5b9a\u4e00\u4e2a sentence\uff0c\u6211\u4eec\u8981\u8bad\u7ec3\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\uff0c\u6839\u636e\u5f53\u524d\u7684 word \\(w_{i-1}\\) \uff0c\u6765\u9884\u6d4b\u4e0b\u4e00\u4e2a\u53ef\u80fd\u51fa\u73b0\u7684 word \\(w_i\\) \u200b \u662f\u4ec0\u4e48 \u4f7f\u7528 1-of-N encoding \u628a \\(w_{i-1}\\) \u200b \u8868\u793a\u6210 feature vector \u4f5c\u4e3a input\uff0c\u7136\u540e\u8f93\u51fa output \u4e5f\u662f n \u7ef4\u7684 vector\uff0c\u8868\u793a\u6bcf\u4e00\u4e2a\u5355\u8bcd\u7684\u53ef\u80fd\u6027 \u628a\u7b2c\u4e00\u4e2a hidden layer \u7684 input \\(z_1,z_2,...\\) \u200b\u200b \u200b\u62ff\u51fa\u6765\uff0c\u5b83\u4eec\u6240\u7ec4\u6210\u7684 \\(Z\\) \u200b\u200b \u200b\u5c31\u662f word \u7684\u53e6\u4e00\u79cd\u8868\u793a\u65b9\u5f0f\uff0c\u5f53\u6211\u4eec input \u4e0d\u540c\u7684\u8bcd\u6c47\uff0c\u5411\u91cf \\(Z\\) \u200b\u200b\u200b\u200b \u5c31\u4f1a\u53d1\u751f\u53d8\u5316\uff0c\u800c\u4e14 \\(Z\\) \u7684\u7ef4\u6570\u662f\u53ef\u4ee5\u81ea\u5df1\u51b3\u5b9a\u7684\uff0c\u56e0\u6b64\u63d0\u53d6\u51fa\u7b2c\u4e00\u5c42 hidden layer \u7684 input\uff0c\u5b9e\u9645\u4e0a\u5c31\u5f97\u5230\u4e86\u4e00\u7ec4\u53ef\u4ee5\u81ea\u5b9a\u4e49\u7ef4\u6570\u7684Word Embedding \u7684\u5411\u91cf","title":"how to do perdition"},{"location":"ML/8_Unsupervised%20Learning%20Word%20Embedding/#why-prediction-works","text":"2 \u4e2a \u76f8\u4f3c\u7684 word \u7684 input vector \u7684 1-of-N \u7f16\u7801\u7ecf\u8fc7\u964d\u7ef4\u5230 \\(Z\\) \u200b\u200b \u7684 input \u540e\u7684 vector \u662f\u975e\u5e38\u63a5\u8fd1\u7684","title":"Why prediction works"},{"location":"ML/8_Unsupervised%20Learning%20Word%20Embedding/#sharing-parameters","text":"\u901a\u8fc7\u5f53\u524d\u8bcd\u6c47\u9884\u6d4b\u4e0b\u4e00\u4e2a\u8bcd\u6c47\u8fd9\u4e2a\u7ea6\u675f\u592a\u5f31\u4e86\uff0c\u56e0\u4e3a\u8bcd\u6c47\u7684\u642d\u914d\u592a\u591a\u4e86 \u53ef\u4ee5\u6269\u5c55\u8fd9\u4e2a\u95ee\u9898\uff0c\u4f7f\u7528 10 \u4e2a\u53ca\u4ee5\u4e0a\u7684\u8bcd\u6c47\u53bb\u9884\u6d4b\u4e0b\u4e00\u4e2a\u8bcd\u6c47 \u4e3e 2 \u4e2a\u8bcd\u6c47\u7684\u4f8b\u5b50\u662f\u76f4\u63a5\u628a \\(w_{i-2}\\) \u548c \\(w_{i-1}\\) \u8fd9\u4e24\u4e2a vector \u62fc\u63a5\u6210\u4e00\u4e2a\u66f4\u957f\u7684 vector \u4f5c\u4e3a input \u5373\u53ef\uff0c\u800c\u4e14\u6211\u4eec\u5e0c\u671b \\(w_{i-2}\\) \u548c \\(w_{i-1}\\) \u7684 weight \u662f tight \u5728\u4e00\u8d77\u7684\uff0c\u5373\u4ed6\u4eec\u6709\u76f8\u540c\u7684 weight\uff0c\u56e0\u4e3a\u4e0d\u8fd9\u6837\u505a\u5982\u679c \\(w_{i-2}\\) \u548c \\(w_{i-1}\\) \u200b \u662f\u76f8\u540c\u7684\u90a3\u4ed6\u4eec\u7684 embedding \u7ed3\u679c\u4f1a\u4e0d\u4e00\u6837\uff0c\u540c\u65f6\u4e5f\u53ef\u4ee5\u51cf\u5c11\u53c2\u6570\uff0c\u4e0d\u4f1a\u56e0\u4e3a input word \u7684\u6570\u91cf\u7684\u589e\u52a0\u800c\u5bfc\u81f4\u53c2\u6570\u7684\u66b4\u589e $$ z=W_1 x_{i-2}+W_2 x_{i-1}=W(x_{i-2}+x_{i-1}) $$ \u5728\u5b9e\u9645\u64cd\u4f5c\u65f6\u5982\u4f55\u4fdd\u8bc1 \\(W_1\\) \u548c \\(W_2\\) \u200b \u4e00\u6837\u5462\uff1f \u539f\u672c\u7684 update \u7684\u53c2\u6570\uff1a $$ \\begin{align} w_i=w_i-\\eta \\frac{\\partial C}{\\partial w_i}\\ w_j=w_j-\\eta \\frac{\\partial C}{\\partial w_j} \\end{align} $$ \u4e3a\u4e86\u4fdd\u8bc1 \\(w_i=w_j\\) \uff1a $$ \\begin{align} w_i=w_i-\\eta \\frac{\\partial C}{\\partial w_i}-\\eta \\frac{\\partial C}{\\partial w_j}\\ w_j=w_j-\\eta \\frac{\\partial C}{\\partial w_j}-\\eta \\frac{\\partial C}{\\partial w_i} \\end{align} $$","title":"Sharing Parameters"},{"location":"ML/8_Unsupervised%20Learning%20Word%20Embedding/#training","text":"\u8bad\u7ec3\u53ea\u8981\u4e0a\u7f51\u722c\u4e00\u4e0b\u6587\u7ae0\u6570\u636e\u5c31\u884c \u901a\u8fc7\u5e0c\u671b output \u548c target \u7684 cross entropy \u6700\u5c0f\uff0c\u4e5f\u5c31\u662f\u4f7f\u5f97\u8f93\u51fa\u7684\u90a3\u4e2a vector \u5728 target \u6240\u5bf9\u5e94\u7684\u90a3\u4e00\u7ef4\u4e0a\u6982\u7387\u6700\u9ad8","title":"Training"},{"location":"ML/8_Unsupervised%20Learning%20Word%20Embedding/#various-architectures","text":"\u9664\u4e86\u4e0a\u9762\u7684\u57fa\u672c\u5f62\u6001\uff0cPrediction-based \u65b9\u6cd5\u8fd8\u53ef\u4ee5\u6709\u591a\u79cd\u53d8\u5f62 CBOW (Continuous bag of word model) \u62ff\u524d\u540e\u7684\u8bcd\u6c47\u53bb\u9884\u6d4b\u4e2d\u95f4\u7684\u8bcd\u6c47 Skip-gram \u62ff\u4e2d\u95f4\u7684\u8bcd\u6c47\u53bb\u9884\u6d4b\u524d\u540e\u7684\u8bcd\u6c47","title":"Various Architectures"},{"location":"ML/8_Unsupervised%20Learning%20Word%20Embedding/#others","text":"\u5c3d\u7ba1 word vector \u662f deep learning \u7684\u4e00\u4e2a\u5e94\u7528\uff0c\u4f46\u8fd9\u4e2a neural network \u5176\u5b9e\u5e76\u4e0d\u662f deep\u7684\uff0c\u5b83\u5c31\u53ea\u6709\u4e00\u4e2a linear \u7684 hidden layer \u6211\u4eec\u628a 1-of-N \u7f16\u7801\u8f93\u5165\u7ed9\u795e\u7ecf\u7f51\u7edc\uff0c\u7ecf\u8fc7 weight \u7684\u8f6c\u6362\u5f97\u5230 Word Embedding\uff0c\u518d\u901a\u8fc7\u7b2c\u4e00\u5c42 hidden layer \u5c31\u53ef\u4ee5\u76f4\u63a5\u5f97\u5230\u8f93\u51fa\uff0c\u51cf\u5c0f\u8fd0\u7b97\u91cf","title":"Others"},{"location":"ML/8_Unsupervised%20Learning%20Word%20Embedding/#application","text":"","title":"Application"},{"location":"ML/8_Unsupervised%20Learning%20Word%20Embedding/#subtraction","text":"\u673a\u5668\u95ee\u7b54 \u4ece\u5f97\u5230\u7684 word vector \u91cc\uff0c\u6211\u4eec\u53ef\u4ee5\u53d1\u73b0\u4e00\u4e9b\u539f\u672c\u5e76\u4e0d\u77e5\u9053\u7684 word \u4e0e word \u4e4b\u95f4\u7684\u5173\u7cfb \u628a word vector \u4e24\u4e24\u76f8\u51cf\uff0c\u518d\u6295\u5f71\u5230\u4e0b\u56fe\u4e2d\u7684\u4e8c\u7ef4\u5e73\u9762\u4e0a\uff0c\u5982\u679c\u67d0\u4e24\u4e2a word \u4e4b\u95f4\u6709\u7c7b\u4f3c\u5305\u542b\u4e8e\u7684\u76f8\u540c\u5173\u7cfb\uff0c\u5b83\u4eec\u5c31\u4f1a\u88ab\u6295\u5f71\u5230\u540c\u4e00\u5757\u533a\u57df \u5229\u7528\u8fd9\u4e2a\u6982\u5ff5\uff0c\u6211\u4eec\u53ef\u4ee5\u505a\u4e00\u4e9b\u7b80\u5355\u7684\u63a8\u8bba\uff1a \u5728 word vector \u7684\u7279\u5f81\u4e0a\uff0c \\(V(Rome)-V(Italy)\u2248V(Berlin)-V(Germany)\\) \u6b64\u65f6\u5982\u679c\u6709\u4eba\u95ee \u201c\u7f57\u9a6c\u4e4b\u4e8e\u610f\u5927\u5229\u7b49\u4e8e\u67cf\u6797\u4e4b\u4e8e\uff1f\u201d\uff0c\u90a3\u673a\u5668\u5c31\u53ef\u4ee5\u56de\u7b54\u8fd9\u4e2a\u95ee\u9898 \u56e0\u4e3a\u5fb7\u56fd\u7684 vector \u4f1a\u5f88\u63a5\u8fd1\u4e8e \u201c\u67cf\u6797\u7684vector-\u7f57\u9a6c\u7684vector+\u610f\u5927\u5229\u7684vector\u201d\uff0c\u56e0\u6b64\u673a\u5668\u53ea\u9700\u8981\u8ba1\u7b97 \\(V(Berlin)-V(Rome)+V(Italy)\\) \u200b\uff0c\u7136\u540e\u9009\u53d6\u4e0e\u8fd9\u4e2a\u7ed3\u679c\u6700\u63a5\u8fd1\u7684 vector \u5373\u53ef","title":"Subtraction"},{"location":"ML/8_Unsupervised%20Learning%20Word%20Embedding/#multi-lingual-embedding","text":"\u673a\u5668\u7ffb\u8bd1 \u6b64\u5916\uff0cword vector \u8fd8\u53ef\u4ee5\u5efa\u7acb\u8d77\u4e0d\u540c\u8bed\u8a00\u4e4b\u95f4\u7684\u8054\u7cfb \u5982\u679c\u4f60\u8981\u7528\u4e0a\u8ff0\u65b9\u6cd5\u5206\u522b\u8bad\u7ec3\u4e00\u4e2a\u82f1\u6587\u7684\u8bed\u6599\u5e93 (corpus) \u548c\u4e2d\u6587\u7684\u8bed\u6599\u5e93\uff0c\u4f60\u4f1a\u53d1\u73b0\u4e24\u8005\u7684 word vector \u4e4b\u95f4\u662f\u6ca1\u6709\u4efb\u4f55\u5173\u7cfb\u7684\uff0c\u56e0\u4e3a Word Embedding \u53ea\u4f53\u73b0\u4e86\u4e0a\u4e0b\u6587\u7684\u5173\u7cfb\uff0c\u5982\u679c\u4f60\u7684\u6587\u7ae0\u6ca1\u6709\u628a\u4e2d\u82f1\u6587\u6df7\u5408\u5728\u4e00\u8d77\u4f7f\u7528\uff0c\u673a\u5668\u5c31\u6ca1\u6709\u529e\u6cd5\u5224\u65ad\u4e2d\u82f1\u6587\u8bcd\u6c47\u4e4b\u95f4\u7684\u5173\u7cfb \u4f46\u662f\uff0c\u5982\u679c\u4f60\u77e5\u9053\u67d0\u4e9b\u4e2d\u6587\u8bcd\u6c47\u548c\u82f1\u6587\u8bcd\u6c47\u7684\u5bf9\u5e94\u5173\u7cfb\uff0c\u4f60\u53ef\u4ee5\u5148\u5206\u522b\u83b7\u53d6\u5b83\u4eec\u7684 word vector\uff0c\u7136\u540e\u518d\u53bb\u8bad\u7ec3\u4e00\u4e2a\u6a21\u578b\uff0c\u628a\u5177\u6709\u76f8\u540c\u542b\u4e49\u7684\u4e2d\u82f1\u6587\u8bcd\u6c47\u6295\u5f71\u5230\u65b0\u7a7a\u95f4\u4e0a\u7684\u540c\u4e00\u4e2a\u70b9 \u63a5\u4e0b\u6765\u9047\u5230\u672a\u77e5\u7684\u65b0\u8bcd\u6c47\uff0c\u65e0\u8bba\u662f\u4e2d\u6587\u8fd8\u662f\u82f1\u6587\uff0c\u4f60\u90fd\u53ef\u4ee5\u91c7\u7528\u540c\u6837\u7684\u65b9\u5f0f\u5c06\u5176\u6295\u5f71\u5230\u65b0\u7a7a\u95f4\uff0c\u5c31\u53ef\u4ee5\u81ea\u52a8\u505a\u5230\u7c7b\u4f3c\u7ffb\u8bd1\u7684\u6548\u679c \u53c2\u8003\u6587\u732e\uff1a Bilingual Word Embeddings for Phrase-Based Machine Translation, Will Zou, Richard Socher, Daniel Cer and Christopher Manning, EMNLP, 2013","title":"Multi-lingual Embedding"},{"location":"ML/8_Unsupervised%20Learning%20Word%20Embedding/#multi-domain-embedding","text":"\u56fe\u50cf\u5206\u7c7b \u8fd9\u4e2a\u505a\u6cd5\u4e0d\u53ea\u5c40\u9650\u4e8e\u6587\u5b57\u7684\u5e94\u7528\uff0c\u4e5f\u53ef\u4ee5\u5bf9\u6587\u5b57+\u56fe\u50cf\u505a Embedding \u5047\u8bbe\u4f60\u5df2\u7ecf\u5f97\u5230 horse\u3001cat \u548c dog \u8fd9\u4e9b \u8bcd\u6c47 \u7684 vector \u5728\u7a7a\u95f4\u4e0a\u7684\u5206\u5e03\u60c5\u51b5\uff0c\u4f60\u5c31\u53ef\u4ee5\u53bb\u8bad\u7ec3\u4e00\u4e2a\u6a21\u578b\uff0c\u628a\u4e00\u4e9b\u5df2\u77e5\u7684 horse\u3001cat \u548c dog \u56fe\u7247 \u53bb\u6295\u5f71\u5230\u548c\u5bf9\u5e94\u8bcd\u6c47\u76f8\u540c\u7684\u7a7a\u95f4\u533a\u57df\u4e0a \u6bd4\u5982\u5bf9\u6a21\u578b\u8f93\u5165\u4e00\u5f20\u56fe\u50cf\uff0c\u4f7f\u4e4b\u8f93\u51fa\u4e00\u4e2a\u8ddf word vector \u5177\u6709\u76f8\u540c\u7ef4\u6570\u7684 vector\uff0c\u4f7f dog \u56fe\u50cf\u7684\u6620\u5c04\u5411\u91cf\u5c31\u6563\u5e03\u5728 dog \u8bcd\u6c47\u5411\u91cf\u7684\u5468\u56f4\uff0chorse \u56fe\u50cf\u7684\u6620\u5c04\u5411\u91cf\u5c31\u6563\u5e03\u5728 horse \u8bcd\u6c47\u5411\u91cf\u7684\u5468\u56f4... \u8bad\u7ec3\u597d\u8fd9\u4e2a\u6a21\u578b\u4e4b\u540e\uff0c\u8f93\u5165\u65b0\u7684\u672a\u77e5\u56fe\u50cf\uff0c\u6839\u636e\u6295\u5f71\u4e4b\u540e\u7684\u4f4d\u7f6e\u6240\u5bf9\u5e94\u7684 word vector\uff0c\u5c31\u53ef\u4ee5\u5224\u65ad\u5b83\u6240\u5c5e\u7684\u7c7b\u522b \u6211\u4eec\u77e5\u9053\u5728\u505a\u56fe\u50cf\u5206\u7c7b\u7684\u65f6\u5019\uff0c\u5f88\u591a\u60c5\u51b5\u4e0b\u90fd\u662f\u4e8b\u5148\u5b9a\u597d\u8981\u5206\u4e3a\u54ea\u51e0\u4e2a\u5177\u4f53\u7684\u7c7b\u522b\uff0c\u518d\u7528\u8fd9\u51e0\u4e2a\u7c7b\u522b\u7684\u56fe\u50cf\u53bb\u8bad\u7ec3\u6a21\u578b\uff0c\u7531\u4e8e\u6211\u4eec\u65e0\u6cd5\u5728\u8bad\u7ec3\u7684\u65f6\u5019\u7a77\u5c3d\u6240\u6709\u7c7b\u522b\u7684\u56fe\u50cf\uff0c\u56e0\u6b64\u5728\u5b9e\u9645\u5e94\u7528\u7684\u65f6\u5019\u4e00\u65e6\u9047\u5230\u5c5e\u4e8e\u672a\u77e5\u7c7b\u522b\u7684\u56fe\u50cf\uff0c\u8fd9\u4e2a\u6a21\u578b\u5c31\u65e0\u80fd\u4e3a\u529b\u4e86 \u800c\u4f7f\u7528 image+word Embedding \u7684\u65b9\u6cd5\uff0c\u5c31\u7b97\u8f93\u5165\u7684\u56fe\u50cf\u7c7b\u522b\u5728\u8bad\u7ec3\u65f6\u6ca1\u6709\u88ab\u9047\u5230\u8fc7\uff0c\u6bd4\u5982\u4e0a\u56fe\u4e2d\u7684 cat\uff0c\u4f46\u5982\u679c\u8fd9\u5f20\u56fe\u50cf\u80fd\u591f\u6295\u5f71\u5230 cat \u7684 word vector \u7684\u9644\u8fd1\uff0c\u6839\u636e\u8bcd\u6c47\u5411\u91cf\u4e0e\u56fe\u50cf\u5411\u91cf\u7684\u5bf9\u5e94\u5173\u7cfb\uff0c\u4f60\u81ea\u7136\u5c31\u53ef\u4ee5\u77e5\u9053\u8fd9\u5f20\u56fe\u50cf\u53eb\u505a cat","title":"Multi-domain Embedding"},{"location":"ML/8_Unsupervised%20Learning%20Word%20Embedding/#document-embedding","text":"\u6587\u6863\u5d4c\u5165 \u5bf9 Document \u505a Embedding \u6700\u7b80\u5355\u7684\u65b9\u6cd5\u662f\u628a document \u53d8\u6210 bag-of-word\uff0c\u7136\u540e\u7528 Auto-encoder \u5c31\u53ef\u4ee5\u5f97\u5230\u8be5\u6587\u6863\u7684\u8bed\u4e49\u5d4c\u5165 (Semantic Embedding)\uff0c\u4f46\u5149\u8fd9\u4e48\u505a\u662f\u4e0d\u591f\u7684 \u8bcd\u6c47\u7684\u987a\u5e8f\u4ee3\u8868\u4e86\u5f88\u91cd\u8981\u7684\u542b\u4e49\uff0c\u4e24\u53e5\u8bcd\u6c47\u76f8\u540c\u4f46\u8bed\u5e8f\u4e0d\u540c\u7684\u8bdd\u53ef\u80fd\u4f1a\u6709\u5b8c\u5168\u4e0d\u540c\u7684\u542b\u4e49\uff0c\u6bd4\u5982 \u767d\u8840\u7403\u6d88\u706d\u4e86\u4f20\u67d3\u75c5\u2014\u2014\u6b63\u9762\u8bed\u4e49 \u4f20\u67d3\u75c5\u6d88\u706d\u4e86\u767d\u8840\u7403\u2014\u2014\u8d1f\u9762\u8bed\u4e49 \u60f3\u8981\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u5177\u4f53\u53ef\u4ee5\u53c2\u8003\u4e0b\u9762\u7684\u51e0\u79cd\u5904\u7406\u65b9\u6cd5\uff1a Paragraph Vector : Le, Quoc, and Tomas Mikolov. \"Distributed Representations of Sentences and Documents.\u201c ICML, 2014 Seq2seq Auto-encoder : Li, Jiwei, Minh-Thang Luong, and Dan Jurafsky. \"A hierarchical neural autoencoder for paragraphs and documents.\" arXiv preprint, 2015 Skip Thought : Ryan Kiros, Yukun Zhu, Ruslan Salakhutdinov, Richard S. Zemel, Antonio Torralba, Raquel Urtasun, Sanja Fidler, \u201cSkip-Thought Vectors\u201d arXiv preprint, 2015. \u5173\u4e8e word2vec \uff0c\u53ef\u4ee5\u53c2\u8003\u535a\u5ba2\uff1ahttp://blog.csdn.net/itplus/article/details/37969519","title":"Document Embedding"},{"location":"ML/9_Explainable%20Machine%20Learning/","text":"Explainable Machine Learning \u00b6 \u7b80\u5355\u6765\u8bf4\u5c31\u662f\u6211\u4eec\u9700\u8981\u77e5\u9053 Machine \u5b66\u5230\u4e86\u4ec0\u4e48\uff0c\u5c06 Machine \u5b66\u5230\u7684\u4e1c\u897f\u53ef\u89c6\u5316\u51fa\u6765 Why\uff1f\u8fdb\u884c\u6a21\u578b\u8bca\u65ad\uff0c\u6709\u7684\u6a21\u578b\u51c6\u786e\u7387\u5f88\u9ad8\u4f46\u662f\u5176\u5b9e\u4ec0\u4e48\u90fd\u6ca1\u5b66\u5230\uff1b\u6a21\u578b\u8bca\u65ad\u540e\u5c31\u53ef\u4ee5\u6839\u636e\u7ed3\u679c\u6765\u8c03\u6574 Local Explanation \u00b6 Global Explanation \u00b6","title":"Explainable Machine Learning"},{"location":"ML/9_Explainable%20Machine%20Learning/#explainable-machine-learning","text":"\u7b80\u5355\u6765\u8bf4\u5c31\u662f\u6211\u4eec\u9700\u8981\u77e5\u9053 Machine \u5b66\u5230\u4e86\u4ec0\u4e48\uff0c\u5c06 Machine \u5b66\u5230\u7684\u4e1c\u897f\u53ef\u89c6\u5316\u51fa\u6765 Why\uff1f\u8fdb\u884c\u6a21\u578b\u8bca\u65ad\uff0c\u6709\u7684\u6a21\u578b\u51c6\u786e\u7387\u5f88\u9ad8\u4f46\u662f\u5176\u5b9e\u4ec0\u4e48\u90fd\u6ca1\u5b66\u5230\uff1b\u6a21\u578b\u8bca\u65ad\u540e\u5c31\u53ef\u4ee5\u6839\u636e\u7ed3\u679c\u6765\u8c03\u6574","title":"Explainable Machine Learning"},{"location":"ML/9_Explainable%20Machine%20Learning/#local-explanation","text":"","title":"Local Explanation"},{"location":"ML/9_Explainable%20Machine%20Learning/#global-explanation","text":"","title":"Global Explanation"},{"location":"ML/Keras/","text":"Keras \u00b6 Why Keras \u00b6 tensorflow \u548c\u53e6\u5916\u4e00\u4e2a\u529f\u80fd\u76f8\u8fd1\u7684 toolkit theano \u5f88\u96be\u5728\u77ed\u65f6\u95f4\u5185\u7cbe\u901a Keras \u662f\u6bd4\u8f83\u5bb9\u6613\u53bb\u5b66\u4e60\u548c\u4f7f\u7528\u7684\uff0c\u5e76\u4e14\u5b83\u4e5f\u6709\u8db3\u591f\u7684\u5f39\u6027\uff0c\u9664\u975e\u4f60\u81ea\u5df1\u60f3\u8981\u505a deep learning \u7684\u7814\u7a76\uff0c\u53bb\u8bbe\u8ba1\u4e00\u4e2a\u81ea\u5df1\u7684 network\uff0c\u5426\u5219\u591a\u6570\u4f60\u53ef\u4ee5\u60f3\u5230\u7684 network\uff0c\u5728 Keras \u91cc\u90fd\u6709\u73b0\u6210\u7684 function \u53ef\u4ee5\u62ff\u6765\u4f7f\u7528\uff1b\u56e0\u4e3a\u5b83\u80cc\u540e\u5c31\u662f tensorflow or theano\uff0c\u6240\u4ee5\u5982\u679c\u4f60\u60f3\u8981\u7cbe\u8fdb\u81ea\u5df1\u7684\u80fd\u529b\u7684\u8bdd\uff0c\u4f60\u6c38\u8fdc\u53ef\u4ee5\u53bb\u6539 Keras \u80cc\u540e\u7684tensorflow \u7684 code\uff0c\u7136\u540e\u505a\u66f4\u5389\u5bb3\u7684\u4e8b\u60c5 \u800c\u4e14\uff0c\u73b0\u5728 Keras \u5df2\u7ecf\u6210\u4e3a\u4e86 Tensorflow \u5b98\u65b9\u7684 API\uff0c\u5b83\u50cf\u642d\u79ef\u6728\u4e00\u6837\u7b80\u5355 prepare data \u00b6 \u4f7f\u7528\u7684data\u662fMNIST\u7684Data\uff1ahttp://yann.lecun.com/exdb/mnist/ Keras\u63d0\u4f9b\u4e86\u81ea\u52a8\u4e0b\u8f7dMNIST data\u7684function\uff1ahttp://keras.io/datasets/ MNIST \u662f\u624b\u5199\u6570\u5b57\u7684\u6570\u636e\u96c6 process \u00b6 DOC\uff1a Keras API reference \u9996\u5148\u8981\u5148\u5bfc\u5165keras\u5305\uff1a from keras.models import Sequential step 1\uff1adefine a set of function\u2014\u2014neural network \u00b6 \u5148\u7528 Sequential() \u5ba3\u544a\u5efa\u7acb\u4e00\u4e2amodel model = Sequential () \u7136\u540e\u5f00\u59cb\u53e0 layer \u4ee5\u6784\u6210\u4e00\u4e2a neural network\uff0c\u8fd9\u91cc\u7684\u4f8b\u5b50\u4e00\u5171\u67092\u5c42\uff0c\u6bcf\u5c42 500 \u4e2a nuits\uff08units\uff09 model . add ( Dense ( input_dim = 28 * 28 , units = 500 , activation = 'sigmoid' )) model . add ( Dense ( units = 500 , activation = 'sigmoid' )) model . add ( Dense ( units = 10 , activation = 'softmax' )) add \uff1a\u52a0\u4e00\u5c42 hidden layer Dense \uff1a\u52a0\u4e00\u4e2a Fully connected \u7684 layer input_dim \uff1a\u53ea\u5728\u7b2c\u4e00\u5c42 layer \u524d\u9762\u52a0\u4e00\u4e2a input\uff0c\u8fd9\u91cc\u662f\u4e00\u4e2a 28*28=784 \u7684 vector\uff0c\u4ee3\u8868 img units \uff1a\u4e00\u5c42 layer \u4e2d units(neuron) \u7684\u6570\u91cf activation \uff1a\u6fc0\u6d3b\u51fd\u6570\uff0c\u4e00\u4e9b\u53ef\u9009\u7684\u4f8b\u5b50\uff1asoftplus, softsign, relu, tanh, hard_sigmoid, linear \u6700\u540e\u4e00\u5c42 output \u662f 10 \u7ef4\uff0c\u5206\u522b\u8868\u793a\u6570\u5b57 1~10\uff0c\u7528 softmax \u4f7f\u5f97\u51e0\u7387\u4e4b\u548c\u53d8\u6210\u4e00\u4e2a\u6982\u7387\u5206\u5e03 Step 2\uff1agoodness of function\u2014\u2014cross entropy \u00b6 \u5229\u7528 model.compile \u53bb\u5b9a\u4e49 loss function model . compile ( loss = 'categorical_crossentropy' , optimizer = 'adam' , metrics = [ 'accuracy' ]) loss : \u4f7f\u7528\u7684 loss function optimizer : \u7cfb\u6570\u7684\u66f4\u65b0\u65b9\u5f0f\uff0c\u4e00\u4e9b\u53ef\u9009\u7684\u4f8b\u5b50\uff1aAdagrad, Nadam Step 3\uff1apick the best function \u00b6 \u7528 model.fit \u53bb training model . fit ( x_train , y_train , batcha_size = 100 , nb_epoch = 20 ) x_train \uff1a\u524d 2 \u4e2a\u53c2\u6570\u662f train_data\uff0c\u4ee5\u624b\u5199\u6570\u5b57\u8fa8\u8bc6\u4e3a\u4f8b\uff0c\u4e00\u5f20\u56fe\u7247\u662f 28*28=784 \u7684 vector\uff0c\u6837\u672c\u91cf\u4e3a 10000\uff0c\u90a3\u4e48 x_train \u5c31\u4e00\u4e2a 10000*784 \u7684 numpy array\uff1by_train \u662f\u4e00\u4e2a 10000*10 \u7684 numpy array batch_size \uff1abatch \u7684\u5927\u5c0f\uff0c\u5373\u6bcf\u4e2a\u968f\u673a\u9009\u62e9\u591a\u5c11\u4e2a\u6837\u672c\u6765 update \u53c2\u6570 nb_epoch \uff1a\u5bf9\u6bcf\u4e2a batch update \u53c2\u6570\u7684\u6b21\u6570\uff0c\u4ee5\u4e0a\u9762\u7684\u53c2\u6570\u4e3a\u4f8b\uff0c10000 \u4e2a data\uff0c100 \u4e2a\u4e3a\u4e00\u4e2a batch\uff0c\u5219\u6709 100 \u4e2a batch\uff0c\u6240\u4ee5\u4e00\u5171 update 2000 \u6b21\uff08\u4e00\u4e2a epoch \u4e2d\u6bcf\u4e2a batch \u53ea update \u4e00\u6b21\u53c2\u6570\uff09 \u5982\u679c batch_size=0 \u5c31\u662f Stochastic Gradient Descent (\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u6cd5) \u8fd0\u7528\u4e86 GPU \u7684\u5e73\u884c\u8fd0\u7b97\u540e\uff0cbatch_size=10 \u548c batch_size=1 \u5728 update \u4e00\u6b21\u53c2\u6570\u4e0a\u7684\u901f\u5ea6\u57fa\u672c\u662f\u4e00\u6837\u7684\uff0c\u4f46 batch_size \u4e5f\u4e0d\u80fd\u5f00\u592a\u5927\uff0cGPU \u662f\u6709\u6781\u9650\u7684\u3002\u800c\u4e14\u5728 gradient descent \u7684\u65f6\u5019\u53ef\u80fd\u4f1a\u5361\u5728 local minima Save and Load Models \u00b6 Keras \u53ef\u4ee5\u628a train \u597d\u7684 model \u4fdd\u5b58\u8d77\u6765\u5e76\u76f4\u63a5\u4f7f\u7528\u4fdd\u5b58\u597d\u7684 model\uff0c\u53c2\u8003\uff1a Keras FAQ Testing and Predict \u00b6 \u7528 model.evaluate \u8ba1\u7b97\u6b63\u786e\u7387 score = model . evaluate ( x_test , y_test ) print ( 'Total loss on Testing Set:' , score [ 0 ]) print ( 'Accuracy of Testing Set:' , score [ 1 ]) \u7528 model.predict \u6765\u505a predict result = model . predict ( x_test ) Appendix\uff1a\u624b\u5199\u6570\u5b57\u8bc6\u522b\u5b8c\u6574\u4ee3\u7801 \u00b6 import numpy as np from keras.models import Sequential from keras.layers.core import Dense , Dropout , Activation from keras.layers import Conv2D , MaxPooling2D , Flatten from keras.optimizers import SGD , Adam from keras.utils import np_utils from keras.datasets import mnist # categorical_crossentropy def load_data (): ( x_train , y_train ), ( x_test , y_test ) = mnist . load_data () number = 10000 x_train = x_train [ 0 : number ] y_train = y_train [ 0 : number ] x_train = x_train . reshape ( number , 28 * 28 ) x_test = x_test . reshape ( x_test . shape [ 0 ], 28 * 28 ) x_train = x_train . astype ( 'float32' ) x_test = x_test . astype ( 'float32' ) # convert class vectors to binary class matrices y_train = np_utils . to_categorical ( y_train , 10 ) y_test = np_utils . to_categorical ( y_test , 10 ) x_train = x_train x_test = x_test # x_test=np.random.normal(x_test) x_train = x_train / 255 x_test = x_test / 255 return ( x_train , y_train ), ( x_test , y_test ) if __name__ == '__main__' : # load training data and testing data ( x_train , y_train ), ( x_test , y_test ) = load_data () # define network structure model = Sequential () model . add ( Dense ( input_dim = 28 * 28 , units = 500 , activation = 'sigmoid' )) model . add ( Dense ( units = 500 , activation = 'sigmoid' )) model . add ( Dense ( units = 10 , activation = 'softmax' )) # set configurations model . compile ( loss = 'categorical_crossentropy' , optimizer = 'adam' , metrics = [ 'accuracy' ]) # train model model . fit ( x_train , y_train , batch_size = 100 , epochs = 20 ) # evaluate the model and output the accuracy result = model . evaluate ( x_test , y_test ) print ( 'Test Acc:' , result [ 1 ]) Test Acc: 0.9439","title":"Keras"},{"location":"ML/Keras/#keras","text":"","title":"Keras"},{"location":"ML/Keras/#why-keras","text":"tensorflow \u548c\u53e6\u5916\u4e00\u4e2a\u529f\u80fd\u76f8\u8fd1\u7684 toolkit theano \u5f88\u96be\u5728\u77ed\u65f6\u95f4\u5185\u7cbe\u901a Keras \u662f\u6bd4\u8f83\u5bb9\u6613\u53bb\u5b66\u4e60\u548c\u4f7f\u7528\u7684\uff0c\u5e76\u4e14\u5b83\u4e5f\u6709\u8db3\u591f\u7684\u5f39\u6027\uff0c\u9664\u975e\u4f60\u81ea\u5df1\u60f3\u8981\u505a deep learning \u7684\u7814\u7a76\uff0c\u53bb\u8bbe\u8ba1\u4e00\u4e2a\u81ea\u5df1\u7684 network\uff0c\u5426\u5219\u591a\u6570\u4f60\u53ef\u4ee5\u60f3\u5230\u7684 network\uff0c\u5728 Keras \u91cc\u90fd\u6709\u73b0\u6210\u7684 function \u53ef\u4ee5\u62ff\u6765\u4f7f\u7528\uff1b\u56e0\u4e3a\u5b83\u80cc\u540e\u5c31\u662f tensorflow or theano\uff0c\u6240\u4ee5\u5982\u679c\u4f60\u60f3\u8981\u7cbe\u8fdb\u81ea\u5df1\u7684\u80fd\u529b\u7684\u8bdd\uff0c\u4f60\u6c38\u8fdc\u53ef\u4ee5\u53bb\u6539 Keras \u80cc\u540e\u7684tensorflow \u7684 code\uff0c\u7136\u540e\u505a\u66f4\u5389\u5bb3\u7684\u4e8b\u60c5 \u800c\u4e14\uff0c\u73b0\u5728 Keras \u5df2\u7ecf\u6210\u4e3a\u4e86 Tensorflow \u5b98\u65b9\u7684 API\uff0c\u5b83\u50cf\u642d\u79ef\u6728\u4e00\u6837\u7b80\u5355","title":"Why Keras"},{"location":"ML/Keras/#prepare-data","text":"\u4f7f\u7528\u7684data\u662fMNIST\u7684Data\uff1ahttp://yann.lecun.com/exdb/mnist/ Keras\u63d0\u4f9b\u4e86\u81ea\u52a8\u4e0b\u8f7dMNIST data\u7684function\uff1ahttp://keras.io/datasets/ MNIST \u662f\u624b\u5199\u6570\u5b57\u7684\u6570\u636e\u96c6","title":"prepare data"},{"location":"ML/Keras/#process","text":"DOC\uff1a Keras API reference \u9996\u5148\u8981\u5148\u5bfc\u5165keras\u5305\uff1a from keras.models import Sequential","title":"process"},{"location":"ML/Keras/#step-1define-a-set-of-functionneural-network","text":"\u5148\u7528 Sequential() \u5ba3\u544a\u5efa\u7acb\u4e00\u4e2amodel model = Sequential () \u7136\u540e\u5f00\u59cb\u53e0 layer \u4ee5\u6784\u6210\u4e00\u4e2a neural network\uff0c\u8fd9\u91cc\u7684\u4f8b\u5b50\u4e00\u5171\u67092\u5c42\uff0c\u6bcf\u5c42 500 \u4e2a nuits\uff08units\uff09 model . add ( Dense ( input_dim = 28 * 28 , units = 500 , activation = 'sigmoid' )) model . add ( Dense ( units = 500 , activation = 'sigmoid' )) model . add ( Dense ( units = 10 , activation = 'softmax' )) add \uff1a\u52a0\u4e00\u5c42 hidden layer Dense \uff1a\u52a0\u4e00\u4e2a Fully connected \u7684 layer input_dim \uff1a\u53ea\u5728\u7b2c\u4e00\u5c42 layer \u524d\u9762\u52a0\u4e00\u4e2a input\uff0c\u8fd9\u91cc\u662f\u4e00\u4e2a 28*28=784 \u7684 vector\uff0c\u4ee3\u8868 img units \uff1a\u4e00\u5c42 layer \u4e2d units(neuron) \u7684\u6570\u91cf activation \uff1a\u6fc0\u6d3b\u51fd\u6570\uff0c\u4e00\u4e9b\u53ef\u9009\u7684\u4f8b\u5b50\uff1asoftplus, softsign, relu, tanh, hard_sigmoid, linear \u6700\u540e\u4e00\u5c42 output \u662f 10 \u7ef4\uff0c\u5206\u522b\u8868\u793a\u6570\u5b57 1~10\uff0c\u7528 softmax \u4f7f\u5f97\u51e0\u7387\u4e4b\u548c\u53d8\u6210\u4e00\u4e2a\u6982\u7387\u5206\u5e03","title":"step 1\uff1adefine a set of function\u2014\u2014neural network"},{"location":"ML/Keras/#step-2goodness-of-functioncross-entropy","text":"\u5229\u7528 model.compile \u53bb\u5b9a\u4e49 loss function model . compile ( loss = 'categorical_crossentropy' , optimizer = 'adam' , metrics = [ 'accuracy' ]) loss : \u4f7f\u7528\u7684 loss function optimizer : \u7cfb\u6570\u7684\u66f4\u65b0\u65b9\u5f0f\uff0c\u4e00\u4e9b\u53ef\u9009\u7684\u4f8b\u5b50\uff1aAdagrad, Nadam","title":"Step 2\uff1agoodness of function\u2014\u2014cross entropy"},{"location":"ML/Keras/#step-3pick-the-best-function","text":"\u7528 model.fit \u53bb training model . fit ( x_train , y_train , batcha_size = 100 , nb_epoch = 20 ) x_train \uff1a\u524d 2 \u4e2a\u53c2\u6570\u662f train_data\uff0c\u4ee5\u624b\u5199\u6570\u5b57\u8fa8\u8bc6\u4e3a\u4f8b\uff0c\u4e00\u5f20\u56fe\u7247\u662f 28*28=784 \u7684 vector\uff0c\u6837\u672c\u91cf\u4e3a 10000\uff0c\u90a3\u4e48 x_train \u5c31\u4e00\u4e2a 10000*784 \u7684 numpy array\uff1by_train \u662f\u4e00\u4e2a 10000*10 \u7684 numpy array batch_size \uff1abatch \u7684\u5927\u5c0f\uff0c\u5373\u6bcf\u4e2a\u968f\u673a\u9009\u62e9\u591a\u5c11\u4e2a\u6837\u672c\u6765 update \u53c2\u6570 nb_epoch \uff1a\u5bf9\u6bcf\u4e2a batch update \u53c2\u6570\u7684\u6b21\u6570\uff0c\u4ee5\u4e0a\u9762\u7684\u53c2\u6570\u4e3a\u4f8b\uff0c10000 \u4e2a data\uff0c100 \u4e2a\u4e3a\u4e00\u4e2a batch\uff0c\u5219\u6709 100 \u4e2a batch\uff0c\u6240\u4ee5\u4e00\u5171 update 2000 \u6b21\uff08\u4e00\u4e2a epoch \u4e2d\u6bcf\u4e2a batch \u53ea update \u4e00\u6b21\u53c2\u6570\uff09 \u5982\u679c batch_size=0 \u5c31\u662f Stochastic Gradient Descent (\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u6cd5) \u8fd0\u7528\u4e86 GPU \u7684\u5e73\u884c\u8fd0\u7b97\u540e\uff0cbatch_size=10 \u548c batch_size=1 \u5728 update \u4e00\u6b21\u53c2\u6570\u4e0a\u7684\u901f\u5ea6\u57fa\u672c\u662f\u4e00\u6837\u7684\uff0c\u4f46 batch_size \u4e5f\u4e0d\u80fd\u5f00\u592a\u5927\uff0cGPU \u662f\u6709\u6781\u9650\u7684\u3002\u800c\u4e14\u5728 gradient descent \u7684\u65f6\u5019\u53ef\u80fd\u4f1a\u5361\u5728 local minima","title":"Step 3\uff1apick the best function"},{"location":"ML/Keras/#save-and-load-models","text":"Keras \u53ef\u4ee5\u628a train \u597d\u7684 model \u4fdd\u5b58\u8d77\u6765\u5e76\u76f4\u63a5\u4f7f\u7528\u4fdd\u5b58\u597d\u7684 model\uff0c\u53c2\u8003\uff1a Keras FAQ","title":"Save and Load Models"},{"location":"ML/Keras/#testing-and-predict","text":"\u7528 model.evaluate \u8ba1\u7b97\u6b63\u786e\u7387 score = model . evaluate ( x_test , y_test ) print ( 'Total loss on Testing Set:' , score [ 0 ]) print ( 'Accuracy of Testing Set:' , score [ 1 ]) \u7528 model.predict \u6765\u505a predict result = model . predict ( x_test )","title":"Testing and Predict"},{"location":"ML/Keras/#appendix","text":"import numpy as np from keras.models import Sequential from keras.layers.core import Dense , Dropout , Activation from keras.layers import Conv2D , MaxPooling2D , Flatten from keras.optimizers import SGD , Adam from keras.utils import np_utils from keras.datasets import mnist # categorical_crossentropy def load_data (): ( x_train , y_train ), ( x_test , y_test ) = mnist . load_data () number = 10000 x_train = x_train [ 0 : number ] y_train = y_train [ 0 : number ] x_train = x_train . reshape ( number , 28 * 28 ) x_test = x_test . reshape ( x_test . shape [ 0 ], 28 * 28 ) x_train = x_train . astype ( 'float32' ) x_test = x_test . astype ( 'float32' ) # convert class vectors to binary class matrices y_train = np_utils . to_categorical ( y_train , 10 ) y_test = np_utils . to_categorical ( y_test , 10 ) x_train = x_train x_test = x_test # x_test=np.random.normal(x_test) x_train = x_train / 255 x_test = x_test / 255 return ( x_train , y_train ), ( x_test , y_test ) if __name__ == '__main__' : # load training data and testing data ( x_train , y_train ), ( x_test , y_test ) = load_data () # define network structure model = Sequential () model . add ( Dense ( input_dim = 28 * 28 , units = 500 , activation = 'sigmoid' )) model . add ( Dense ( units = 500 , activation = 'sigmoid' )) model . add ( Dense ( units = 10 , activation = 'softmax' )) # set configurations model . compile ( loss = 'categorical_crossentropy' , optimizer = 'adam' , metrics = [ 'accuracy' ]) # train model model . fit ( x_train , y_train , batch_size = 100 , epochs = 20 ) # evaluate the model and output the accuracy result = model . evaluate ( x_test , y_test ) print ( 'Test Acc:' , result [ 1 ]) Test Acc: 0.9439","title":"Appendix\uff1a\u624b\u5199\u6570\u5b57\u8bc6\u522b\u5b8c\u6574\u4ee3\u7801"},{"location":"ML/Pytorch/","text":"Pytorch \u00b6 Pytorch Introduction \u00b6 \u674e\u5b8f\u6bc5\u8001\u5e0820\u5e74ML\u7684PyTorch Tutorial\uff1a PyTorch_Introduction.ipynb - Colaboratory (google.com) \u53c2\u8003\uff1a PyTorch\u7b80\u6613\u5165\u95e8 doc\uff1a PyTorch documentation \u2014 PyTorch master documentation \u5176\u4e2d\u52a0\u4e86\u4e00\u4e9b\u81ea\u5df1\u5b66\u4e60\u4e2d\u7684\u8865\u5145\u5185\u5bb9 import torch import torch.nn as nn import torch.nn.functional as F from mpl_toolkits.mplot3d import Axes3D import matplotlib.pyplot as plt import numpy as np torch . manual_seed ( 446 ) np . random . seed ( 446 ) Tensors && numpy \u00b6 the tensor is similar to numpy's ndarray # \u521d\u59cb\u5316 x_numpy = np . array ([ 0.1 , 0.2 , 0.3 ]) x_torch = torch . tensor ([ 0.1 , 0.2 , 0.3 ]) y_numpy = np . array ([ 3 , 4 , 5. ]) y_torch = torch . tensor ([ 3 , 4 , 5. ]) # tensor \u548c array \u7684\u8f6c\u6362 >>> torch . from_numpy ( x_numpy ) tensor ([ 0.1000 , 0.2000 , 0.3000 ], dtype = torch . float64 ) >>> x_torch . numpy () [ 0.1 0.2 0.3 ] # \u52a0\u51cf\u64cd\u4f5c >>> x_torch + y_torch tensor ([ 3.1000 , 4.2000 , 5.3000 ]) >>> x_torch - y_torch tensor ([ - 2.9000 , - 3.8000 , - 4.7000 ]) # \u6c42norm >>> np . linalg . norm ( x_numpy ) 0.37416573867739417 >>> torch . norm ( x_torch ) tensor ( 0.3742 ) # \u6c42\u5747\u503cmean >>> np . mean ( x_numpy ) 0.20000000000000004 >>> torch . mean ( x_torch ) tensor ( 0.2000 ) torch.view \u00b6 similarly to numpy.reshape() >>> N , C , W , H = 10000 , 3 , 28 , 28 >>> X = torch . randn (( N , C , W , H )) >>> X . shape torch . Size ([ 10000 , 3 , 28 , 28 ]) >>> X . view ( N , C , 784 ) . shape torch . Size ([ 10000 , 3 , 784 ]) >>> X . view ( - 1 , C , 784 ) . shape # -1\u7684\u53ef\u4ee5\u81ea\u52a8\u8ba1\u7b97X.shape\u4e2d\u5bf9\u5e94\u7ef4\u7684\u503c torch . Size ([ 10000 , 3 , 784 ]) broadcasting semantics \u00b6 \u5904\u7406\u7ef4\u6570\u4e0d\u540c\u7684 tensors \u65f6\u4f1a\u8fdb\u884c\u5e7f\u64ad\uff0c\u7c7b\u4f3c np.matmul() >>> x = torch . empty ( 5 , 1 , 4 , 1 ) >>> y = torch . empty ( 3 , 1 , 1 ) >>> ( x + y ) . size () torch . Size ([ 5 , 3 , 4 , 1 ]) \u6309\u7167\u5c3e\u90e8\u7ef4\u5ea6\u5bf9\u9f50\uff0c\u4e14\u5bf9\u5e94\u7ef4\u5ea6\u8981\u4e48\u76f8\u540c\uff0c\u8981\u4e48\u6709\u4e00\u4e2a\u4e3a 1 Computation graphs \u00b6 \u505a\u52a0\u51cf\u4e58\u9664\u8fd0\u7b97\u65f6\uff0c\u53ea\u8981\u5176\u4e2d\u4e00\u9879\u9700\u8981\u505a gradient \uff0c pytorch \u5c31\u4f1a\u81ea\u52a8\u5efa\u7acb\u4e00\u5f20\u8ba1\u7b97\u56fe # \u6211\u4eec\u9700\u8981\u8bbe\u7f6erequires_grad=True\u4f7fpytorch\u77e5\u9053\u8981\u4fdd\u5b58\u8ba1\u7b97\u56fe\u7684\u5b58\u5728 >>> a = torch . tensor ( 2.0 , requires_grad = True ) >>> b = torch . tensor ( 1.0 , requires_grad = True ) >>> c = a + b >>> d = b + 1 >>> e = c * d >>> c tensor ( 3. , grad_fn =< AddBackward0 > ) >>> d tensor ( 2. , grad_fn =< AddBackward0 > ) >>> e tensor ( 6. , grad_fn =< MulBackward0 > ) CUDA semantics \u00b6 \u4f7f\u7528 torch.device(\"cpu\") \u548c torch.device(\"cuda\") \uff0c\u5e76\u4f7f\u7528 data.to() \u5c06\u6570\u636e\u5728 cpu \u548c gpu \u4e0a\u5207\u6362 cpu = torch . device ( 'cpu' ) gpu = torch . device ( 'cuda' ) x = torch . rand ( 10 ) x = x . to ( gpu ) # x\u5207\u6362\u5230gpu\u4e0a x = x . to ( cpu ) # x\u5207\u6362\u5230cpu\u4e0a PyTorch as an auto grad framework \u00b6 y.backward() \u8ba1\u7b97\u51fa\u8ba1\u7b97\u56fe\u4e2d \\(y\\) \u5bf9\u4ee5 \\(y\\) \u4e3a\u7ec8\u70b9\u7684\u8def\u5f84\u4e0a\u6240\u6709\u53d8\u91cf \\(x^i\\) \u7684 gradient \\(\\frac{\\partial y}{\\partial x^i}\\) \u4f8b1\uff1a \\(f(x)=(x-2)^2,f'(x)=2(x-2)\\) >>> def f ( x ): ... return ( x - 2 ) ** 2 >>> x = torch . tensor ([ 1.0 ], requires_grad = True ) # \u9700\u8981\u5148\u5efa\u7acb\u8ba1\u7b97\u56fe\u540e\u7eed\u624d\u80fd\u5fae\u5206 >>> y = f ( x ) >>> y . backward () # \u8ba1\u7b97\u56fe\u4e0a\u4ee5y\u4e3a\u7ec8\u70b9\u7684\u8def\u5f84\u4e0a\u7684\u6240\u6709\u53d8\u91cf\u90fd\u81ea\u52a8\u5fae\u5206 >>> x . grad tensor ([ - 2. ]) \u4f8b2\uff1a \\(w=[w_1,w_2]^T,g(w)=2w_1w_2+w_2cos(w_1)\\) >>> def g ( w ): ... return 2 * w [ 0 ] * w [ 1 ] + w [ 1 ] * torch . cos ( w [ 0 ]) >>> w = torch . tensor ([ np . pi , 1 ], requires_grad = True ) >>> z = g ( w ) >>> z . backward () >>> w . grad tensor ([ 2.0000 , 5.2832 ]) # z\u5bf9w[0]\u548cw[1]\u7684\u5fae\u5206 Using the gradients \u00b6 \u4ee5 \\(f(x)=(x-2)^2,f'(x)=2(x-2)\\) \u4e3a\u4f8b\u505a gradient descent >>> def f ( x ): ... return ( x - 2 ) ** 2 >>> x = torch . tensor ([ 5.0 ], requires_grad = True ) # \u968f\u673a\u5b9a\u4e49x\u7684\u521d\u503c\u503c >>> lr = 0.25 # learning rate >>> for i in range ( 15 ): # \u505agd ... y = f ( x ) ... y . backward () ... print ( \"x= %f \\t f(x)= %f \\t f'(x)= %f \" % ( x . item (), y . item (), x . grad . item ())) ... x . data = x . data - lr * x . grad # \u4e0d\u7528x.data\u4f1a\u51fa\u95ee\u9898 ... x . grad . detach_ () # The detach_() is for efficiency. You do not need to worry too much about it. ... x . grad . zero_ () ... x = 5.000000 f ( x ) = 9.000000 f '(x)=6.000000 x = 3.500000 f ( x ) = 2.250000 f '(x)=3.000000 x = 2.750000 f ( x ) = 0.562500 f '(x)=1.500000 x = 2.375000 f ( x ) = 0.140625 f '(x)=0.750000 x = 2.187500 f ( x ) = 0.035156 f '(x)=0.375000 x = 2.093750 f ( x ) = 0.008789 f '(x)=0.187500 x = 2.046875 f ( x ) = 0.002197 f '(x)=0.093750 x = 2.023438 f ( x ) = 0.000549 f '(x)=0.046875 x = 2.011719 f ( x ) = 0.000137 f '(x)=0.023438 x = 2.005859 f ( x ) = 0.000034 f '(x)=0.011719 x = 2.002930 f ( x ) = 0.000009 f '(x)=0.005859 x = 2.001465 f ( x ) = 0.000002 f '(x)=0.002930 x = 2.000732 f ( x ) = 0.000001 f '(x)=0.001465 x = 2.000366 f ( x ) = 0.000000 f '(x)=0.000732 x = 2.000183 f ( x ) = 0.000000 f '(x)=0.000366 tensor.grad.zero_() \uff1agradient \u6e05\u96f6\uff0c\u5426\u5219\u4f1a\u7d2f\u52a0 tensor.item() \uff1a\u7528\u4e8e\u53d6\u51fa tensor \u4e2d\u7684\u7eaf\u6570\u503c\uff0c\u4e00\u822c\u9002\u7528\u4e8e tensor \u53ea\u5305\u542b\u4e00\u4e2a\u5143\u7d20\u7684\u60c5\u51b5\uff0c\u591a\u4e2a\u5143\u7d20\u53ef\u91c7\u7528 tensor.tolist() \u8f6c\u5316\u4e3a\u5217\u8868 tensor.detach_() \uff1a\u5207\u65ad\u8ba1\u7b97\u56fe\uff0c\u6bd4\u5982\u6211\u4eec\u5bf9 y \u8fdb\u884c detach_()\uff0c\u5c31\u628a x->y->z \u5207\u6210\u4e24\u90e8\u5206\uff1ax \u548c y->z\uff0cx \u5c31\u65e0\u6cd5\u63a5\u53d7\u5230\u540e\u9762\u4f20\u8fc7\u6765\u7684\u68af\u5ea6\uff0c\u5bf9 z \u8fdb\u884c backward() \u65f6\u4e5f\u4e0d\u4f1a\u5bf9\u6c42 y \u7684\u68af\u5ea6 tensor.detach() & tensor.data \uff1a\u83b7\u53d6 x \u8fd9\u4e2a tensor \u7684\u503c\uff08\u521b\u5efa x \u7684\u526f\u672c\uff09\uff0c\u4e14\u5185\u5b58\u90fd\u662f\u4e0e x \u5171\u4eab\uff0c\u5373\u4fee\u6539\u540e\u4e5f\u4f1a\u5f71\u54cd x \u7684\u503c\uff0c\u4f46\u4e0d\u4f1a\u81ea\u52a8\u5fae\u5206\uff0c require s_grad = False \uff1b\u4e24\u8005\u533a\u522b\u5728\u4e8e\u5728\u540e\u7eed\u7684\u53cd\u5411\u4f20\u64ad\u4e2d\uff0ctensor.data \u4e0d\u4f1a\u62a5\u9519\uff0c\u6240\u4ee5 detach() \u4f1a\u66f4\u52a0\u5b89\u5168 pytorch .detach() .detach_() \u548c .data\u7528\u4e8e\u5207\u65ad\u53cd\u5411\u4f20\u64ad - \u6162\u884c\u539a\u79ef Linear Regression \u00b6 Example \u00b6 \u635f\u5931\u51fd\u6570\uff1aRSS\uff0c\u6b8b\u5dee\u5e73\u65b9\u548c \u6570\u636e\u51c6\u5907 true_w \u662f\u771f\u5b9e\u53c2\u6570\uff0cy \u901a\u8fc7 \\(x@w\\) \u200b\u200b \u52a0\u4e0a\u4e00\u4e2a\u504f\u5dee\u83b7\u5f97 d = 2 n = 50 x = torch . randn ( n , d ) true_w = torch . tensor ([[ - 1.0 ],[ 2.0 ]]) y = x @true_w + torch . randn ( n , 1 ) * 0.1 \u521b\u5efa\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u548c\u635f\u5931\u51fd\u6570 def model ( x , w ): return x @w def rss ( y , h_hat ): return torch . norm ( y - h_hat ) ** 2 / n \u4f7f\u7528\u68af\u5ea6\u8fdb\u884c\u68af\u5ea6\u4e0b\u964d\u6cd5\u7ebf\u6027\u56de\u5f52 w = torch . tensor ([[ 1. ],[ 0 ]], requires_grad = True ) for i in range ( 20 ): y_hat = model ( x , w ) loss = rss ( y , y_hat ) loss . backward () print ( 'loss = %f ' % loss . item (), \\\\ \" \\t w =\" , w . tolist ()) w . data = w . data - lr * w . grad w . grad . detach_ () w . grad . zero_ () loss = 6.877078 w = [[ 1.0 ], [ 0.0 ]] loss = 4.700166 w = [[ 0.6123040914535522 ], [ 0.29769018292427063 ]] loss = 3.225300 w = [[ 0.3017166256904602 ], [ 0.5531282424926758 ]] loss = 2.221793 w = [[ 0.052597105503082275 ], [ 0.7719148397445679 ]] loss = 1.536276 w = [[ - 0.1474691480398178 ], [ 0.9590051174163818 ]] loss = 1.066256 w = [[ - 0.3083454966545105 ], [ 1.1187583208084106 ]] loss = 0.742897 w = [[ - 0.4378759264945984 ], [ 1.2549899816513062 ]] loss = 0.519751 w = [[ - 0.5423045754432678 ], [ 1.371025800704956 ]] loss = 0.365329 w = [[ - 0.6266074180603027 ], [ 1.4697538614273071 ]] loss = 0.258197 w = [[ - 0.694753885269165 ], [ 1.5536739826202393 ]] loss = 0.183704 w = [[ - 0.7499141693115234 ], [ 1.6249440908432007 ]] loss = 0.131802 w = [[ - 0.7946230173110962 ], [ 1.6854223012924194 ]] loss = 0.095576 w = [[ - 0.8309094309806824 ], [ 1.7367050647735596 ]] loss = 0.070251 w = [[ - 0.8603994846343994 ], [ 1.7801612615585327 ]] loss = 0.052521 w = [[ - 0.8843981027603149 ], [ 1.8169628381729126 ]] loss = 0.040094 w = [[ - 0.9039536118507385 ], [ 1.8481112718582153 ]] loss = 0.031374 w = [[ - 0.9199094772338867 ], [ 1.8744614124298096 ]] loss = 0.025249 w = [[ - 0.9329451322555542 ], [ 1.8967417478561401 ]] loss = 0.020944 w = [[ - 0.9436085224151611 ], [ 1.9155727624893188 ]] loss = 0.017916 w = [[ - 0.9523422122001648 ], [ 1.931482195854187 ]] torch.nn.Module \u00b6 Linear Module \u00b6 d_in = 3 d_out = 4 linear_module = nn . Linear ( d_in , d_out ) example_tensor = torch . tensor ([[ 1. , 2 , 3 ],[ 4 , 5 , 6 ]]) transformed = linear_module ( example_tensor ) print ( 'example_tensor' , example_tensor . shape ) print ( 'transormed' , transformed . shape ) print () print ( 'We can see that the weights exist in the background \\n ' ) print ( 'W:' , linear_module . weight ) print ( 'b:' , linear_module . bias ) ''' example_tensor torch.Size([2, 3]) transormed torch.Size([2, 4]) We can see that the weights exist in the background W: Parameter containing: tensor([[ 0.5260, 0.4925, -0.0887], [ 0.3944, 0.4080, 0.2182], [-0.1409, 0.0518, 0.3034], [ 0.0913, 0.2452, -0.2616]], requires_grad=True) b: Parameter containing: tensor([0.5021, 0.0118, 0.1383, 0.4757], requires_grad=True) ''' Activation functions \u00b6 activation_fn = nn . ReLU () # we instantiate an instance of the ReLU module example_tensor = torch . tensor ([ - 1.0 , 1.0 , 0.0 ]) activated = activation_fn ( example_tensor ) print ( 'example_tensor' , example_tensor ) print ( 'activated' , activated ) ''' example_tensor tensor([-1., 1., 0.]) activated tensor([0., 1., 0.]) ''' Sequential \u00b6 d_in = 3 d_hidden = 4 d_out = 1 model = torch . nn . Sequential ( nn . Linear ( d_in , d_hidden ), nn . Tanh (), nn . Linear ( d_hidden , d_out ), nn . Sigmoid () ) example_tensor = torch . tensor ([[ 1. , 2 , 3 ],[ 4 , 5 , 6 ]]) transformed = model ( example_tensor ) print ( 'transformed' , transformed . shape ) ''' transformed torch.Size([2, 1]) ''' \u4e0a\u9762\u7684\u5f0f\u5b50\u7b49\u4ef7\u4e8e d_in = 3 d_hidden = 4 d_out = 1 linear = nn . Linear ( d_in , d_hidden ) tanh = nn . Tanh () linear2 = nn . Linear ( d_hidden , d_out ) sigmoid = nn . Sigmoid () tensor_input = torch . tensor ([[ 1. , 2 , 3 ],[ 4 , 5 , 6 ]]) tensor_input = linear ( tensor_input ) tensor_input = tanh ( tensor_input ) tensor_input = linear2 ( tensor_input ) transformed = sigmoid ( tensor_input ) print ( transformed ) \u83b7\u53d6\u53c2\u6570 params = model . parameters () for param in params : print ( param ) ''' Parameter containing: tensor([[-0.5607, 0.4221, -0.0254], [-0.3630, 0.4541, 0.0275], [-0.0703, -0.1463, 0.3065], [ 0.0065, -0.2664, 0.0267]], requires_grad=True) Parameter containing: tensor([-0.3196, 0.2911, 0.1999, -0.3758], requires_grad=True) Parameter containing: tensor([[-0.0289, 0.1544, 0.3992, -0.3301]], requires_grad=True) Parameter containing: tensor([-0.1438], requires_grad=True) ''' Loss functions \u00b6 mse_loss_fn = nn . MSELoss () input = torch . tensor ([[ 0. , 0 , 0 ]]) target = torch . tensor ([[ 1. , 0 , - 1 ]]) loss = mse_loss_fn ( input , target ) print ( loss ) ''' tensor(0.6667) ''' torch.optim \u00b6 \u4f7f\u7528\u4f18\u5316\u5668 Optimizer \u642d\u5efa\u4e00\u4e2a\u5b8c\u6574\u7684\u795e\u7ecf\u7f51\u7edc \u4e0b\u9762\u7684\u4f8b\u5b50 GD \u4e86\u4e00\u6b21 # create a simple model model = nn . Linear ( 1 , 1 ) # create a simple dataset X_simple = torch . tensor ([[ 1. ]]) y_simple = torch . tensor ([[ 2. ]]) # create our optimizer # \u5fc5\u987b\u8981\u628amodel\u7684\u53c2\u6570\u5582\u7ed9optim\uff0clr\u53ef\u4ee5\u4e0d\u5199\uff0c\u4f1a\u6709\u9ed8\u8ba4\u53c2\u6570\u503c optim = torch . optim . SGD ( model . parameters (), lr = 1e-2 ) mse_loss_fn = nn . MSELoss () y_hat = model ( X_simple ) print ( 'model params before:' , model . weight ) loss = mse_loss_fn ( y_hat , y_simple ) # \u68af\u5ea6\u6e05\u96f6->\u8ba1\u7b97\u68af\u5ea6->\u68af\u5ea6\u4e0b\u964d # \u505aBackpropagation\u4e4b\u524d\u5148\u5c06\u68af\u5ea6\u6e05\u96f6\uff0c\u9632\u6b62\u4e0e\u65e7\u503c\u53e0\u52a0 optim . zero_grad () loss . backward () optim . step () print ( 'model params after:' , model . weight ) ''' model params before: Parameter containing: tensor([[-0.9604]], requires_grad=True) model params after: Parameter containing: tensor([[-0.9060]], requires_grad=True) ''' Linear regression using GD \u00b6 step_size = 0.1 linear_module = nn . Linear ( d , 1 , bias = False ) loss_func = nn . MSELoss () optim = torch . optim . SGD ( linear_module . parameters (), lr = step_size ) print ( 'iter, \\t loss, \\t w' ) for i in range ( 20 ): y_hat = linear_module ( X ) loss = loss_func ( y_hat , y ) optim . zero_grad () loss . backward () optim . step () print ( ' {} , \\t {:.2f} , \\t {} ' . format ( i , loss . item (), linear_module . weight . view ( 2 ) . detach () . numpy ())) print ( ' \\n true w \\t\\t ' , true_w . view ( 2 ) . numpy ()) print ( 'estimated w \\t ' , linear_module . weight . view ( 2 ) . detach () . numpy ()) ''' iter, loss, w 0, 6.14, [-0.4951109 -0.20055914] 1, 4.19, [-0.64017504 0.1509075 ] 2, 2.87, [-0.7496651 0.4441856] 3, 1.98, [-0.8317375 0.689143 ] 4, 1.37, [-0.8927491 0.89393103] 5, 0.95, [-0.93764454 1.0652909 ] 6, 0.67, [-0.9702622 1.208804 ] 7, 0.47, [-0.99357456 1.3290964 ] 8, 0.33, [-1.0098771 1.4300069] 9, 0.23, [-1.0209374 1.5147243] 10, 0.17, [-1.028112 1.5859002] 11, 0.12, [-1.0324373 1.6457422] 12, 0.09, [-1.0347017 1.6960896] 13, 0.06, [-1.035502 1.7384766] 14, 0.05, [-1.0352864 1.7741843] 15, 0.04, [-1.0343897 1.8042834] 16, 0.03, [-1.033059 1.829669] 17, 0.02, [-1.031475 1.8510911] 18, 0.02, [-1.0297676 1.8691778] 19, 0.01, [-1.0280287 1.8844559] true w [-1. 2.] estimated w [-1.0280287 1.8844559] ''' Linear regression using SGD \u00b6 step_size = 0.01 linear_module = nn . Linear ( d , 1 ) loss_func = nn . MSELoss () optim = torch . optim . SGD ( linear_module . parameters (), lr = step_size ) print ( 'iter, \\t loss, \\t w' ) for i in range ( 200 ): rand_idx = np . random . choice ( n ) # take a random point from the dataset x = X [ rand_idx ] y_hat = linear_module ( x ) loss = loss_func ( y_hat , y [ rand_idx ]) # only compute the loss on the single point optim . zero_grad () loss . backward () optim . step () if i % 20 == 0 : print ( ' {} , \\t {:.2f} , \\t {} ' . format ( i , loss . item (), linear_module . weight . view ( 2 ) . detach () . numpy ())) print ( ' \\n true w \\t\\t ' , true_w . view ( 2 ) . numpy ()) print ( 'estimated w \\t ' , linear_module . weight . view ( 2 ) . detach () . numpy ()) ''' iter, loss, w 0, 5.33, [-0.52818084 0.2690754 ] 20, 1.33, [-0.5849738 0.54701847] 40, 0.21, [-0.68336743 0.93094164] 60, 0.41, [-0.76554966 1.3865377 ] 80, 0.22, [-0.8548197 1.528812 ] 100, 0.45, [-0.9011376 1.679943 ] 120, 0.04, [-0.9418524 1.7858417] 140, 0.00, [-0.97288156 1.857902 ] 160, 0.00, [-0.98335326 1.893024 ] 180, 0.01, [-0.9927237 1.904962 ] true w [-1. 2.] estimated w [-0.99158174 1.9331173 ] ''' Neural Network Basics in PyTorch \u00b6 We will try and fit a simple neural network to the data. d = 1 n = 200 X = torch . rand ( n , d ) # rand \u751f\u6210\u7684\u968f\u673a\u6570\u5728 [0,1] # \u4e00\u4e2a\u7531 sin \u548c cos \u7684\u5408\u6210\u51fd\u6570 y = 4 * torch . sin ( np . pi * X ) * torch . cos ( 6 * np . pi * X ** 2 ) plt . scatter ( X . numpy (), y . numpy ()) plt . title ( 'plot of $f(x)$' ) plt . xlabel ( '$x$' ) plt . ylabel ( '$y$' ) plt . show () \u7528 pytorch \u642d\u5efa\u795e\u7ecf\u7f51\u7edc\u62df\u5408\u6570\u636e\u96c6\u7684\u66f2\u7ebf\uff0cactivation function \u7528 Tanh step_size = 0.05 n_epochs = 6000 n_hidden_1 = 32 n_hidden_2 = 32 d_out = 1 neural_network = nn . Sequential ( nn . Linear ( d , n_hidden_1 ), nn . Tanh (), nn . Linear ( n_hidden_1 , n_hidden_2 ), nn . Tanh (), nn . Linear ( n_hidden_2 , d_out ) ) loss_func = nn . MSELoss () optim = torch . optim . SGD ( neural_network . parameters (), lr = step_size ) print ( 'iter, \\t loss' ) for i in range ( n_epochs ): y_hat = neural_network ( X ) loss = loss_func ( y_hat , y ) optim . zero_grad () loss . backward () optim . step () if i % ( n_epochs // 10 ) == 0 : print ( ' {} , \\t {:.2f} ' . format ( i , loss . item ())) ''' iter, loss 0, 4.33 600, 4.27 1200, 3.87 1800, 1.54 2400, 0.71 3000, 0.78 3600, 0.24 4200, 0.10 4800, 0.08 5400, 0.08 ''' \u753b\u51fa\u62df\u5408\u540e\u7684\u66f2\u7ebf X_grid = torch . from_numpy ( np . linspace ( 0 , 1 , 50 )) . float () . view ( - 1 , d ) y_hat = neural_network ( X_grid ) plt . scatter ( X . numpy (), y . numpy ()) plt . plot ( X_grid . detach () . numpy (), y_hat . detach () . numpy (), 'r' ) plt . title ( 'plot of $f(x)$ and $\\hat {f} (x)$' ) plt . xlabel ( '$x$' ) plt . ylabel ( '$y$' ) plt . show () Things that may help \u00b6 Momentum \u00b6 doc\uff1a Why Momentum Really Works (distill.pub) optim = torch . optim . SGD ( neural_network . parameters (), lr = step_size , momentum = momentum ) CrossEntropyLoss \u00b6 loss = nn . CrossEntropyLoss () Learning rate schedulers \u00b6 doc\uff1a torch.optim \u2014 PyTorch 1.9.0 documentation ### Convolutions nn.Conv2d \u00b6 \u7528 CNN \u5904\u7406\u56fe\u50cf torch.nn.Conv2d doc\uff1a Conv2d \u2014 PyTorch 1.9.0 documentation torch.nn.Conv2d() \u7528\u6cd5\u8bb2\u89e3_\u5047\u88c5\u5f88\u574f\u7684\u8c26\u8c26\u541b torch . nn . Conv2d ( in_channels , out_channels , kernel_size , stride = 1 , padding = 0 , dilation = 1 , groups = 1 , bias = True , padding_mode = \u2018 zeros \u2019 ) in_channels \uff1a\u8f93\u5165\u7684\u901a\u9053\u6570\u76ee\uff0c\u6bd4\u5982 RGB \u5c31\u662f 3 \u901a\u9053 out_channels \uff1a\u8f93\u51fa\u7684\u901a\u9053\u6570\u76ee\uff0c\u5377\u79ef\u6838\u7684\u6570\u91cf kernel_size \uff1a\u5377\u79ef\u6838 (filter) \u5927\u5c0f\uff0cint \u6216\u8005 \u5143\u7ec4\uff0cint \u8868\u793a\u6b63\u65b9\u5f62\u7684\u5bbd\u5ea6 stride \uff1a\u6b65\u957f\uff0c\u9ed8\u8ba4 1 padding \uff1a\u5728\u8fb9\u754c\u589e\u52a0 \u503c\u4e3a0 \u7684\u8fb9\u8ddd\u7684\u957f\u5ea6\uff0c\u6216\u8005\u8bf4\u52a0\u51e0\u5708 0\uff0c\u9ed8\u8ba4\u4e3a 0 dilation \uff1a\u63a7\u5236\u5377\u79ef\u6838\u4e4b\u95f4\u7684\u95f4\u8ddd nn.BatchNorm2d \u00b6 \u5728\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u65f6\u901a\u5e38\u4e00\u6b21\u8bad\u7ec3\u4e00\u4e2a batch\uff0c\u4f46\u662f\u6bcf\u4e2a batch \u7684\u5206\u5e03\u4e0d\u540c\uff0c\u6240\u4ee5\u4f1a\u5bf9\u4e0b\u4e00\u5c42\u7f51\u7edc\u7684\u5b66\u4e60\u5e26\u6765\u56f0\u96be\uff0cBatchNorm \u5c31\u662f\u628a\u6570\u636e\u6807\u51c6\u5316\uff08\u5747\u503c\u4e3a 0\uff0c \u65b9\u5dee\u4e3a 1\uff09\uff0c\u907f\u514d\u68af\u5ea6\u6d88\u5931\u548c\u68af\u5ea6\u7206\u70b8 torch . nn . BatchNorm2d ( num_features , eps = 1e-05 , momentum = 0.1 , affine = True ) num_features \uff1achannel \u6570 eps \uff1a\u4e3a\u4fdd\u8bc1\u6570\u503c\u7a33\u5b9a\u6027\uff08\u5206\u6bcd\u4e0d\u80fd\u8d8b\u8fd1\u6216\u53d60\uff09,\u7ed9\u5206\u6bcd\u52a0\u4e0a\u7684\u503c\u3002\u9ed8\u8ba4\u4e3a 1e-5 momentum \uff1a\u52a8\u6001\u5747\u503c\u548c\u52a8\u6001\u65b9\u5dee\u6240\u4f7f\u7528\u7684\u52a8\u91cf affine \uff1a \u4e00\u4e2a\u5e03\u5c14\u503c\uff0c\u5f53\u8bbe\u4e3atrue\uff0c\u7ed9\u8be5\u5c42\u6dfb\u52a0\u53ef\u5b66\u4e60\u7684\u4eff\u5c04\u53d8\u6362\u53c2\u6570 nn.MaxPool2d \u00b6 torch . nn . MaxPool2d ( kernel_size , stride = None , padding = 0 , dilation = 1 , return_indices = False , ceil_mode = False ) kernel_size \uff1amax pooling \u7a97\u53e3\u5927\u5c0f stride \uff1a\u7a97\u53e3\u79fb\u52a8\u6b65\u957f\uff0c\u9ed8\u8ba4\u4e3a kernel_size padding \uff1a\u5728\u8fb9\u754c\u589e\u52a0 \u503c\u4e3a0 \u7684\u8fb9\u8ddd\u7684\u957f\u5ea6\uff0c\u6216\u8005\u8bf4\u52a0\u51e0\u5708 0\uff0c\u9ed8\u8ba4\u4e3a 0 Custom Datasets, DataLoaders \u00b6 torch.utils.data.Dataset \u662f\u8868\u793a\u6570\u636e\u96c6\u7684\u62bd\u8c61\u7c7b\uff0c\u4f60\u7684\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u5e94\u7ee7\u627f Dataset \u5e76\u8986\u76d6\u4ee5\u4e0b\u65b9\u6cd5\uff1a __len__ so that len(dataset) returns the size of the dataset. __getitem__ to support the indexing such that dataset[i] can be used to get i-th sample from torch.utils.data import Dataset , DataLoader class MyDataset ( Dataset ): def __init__ ( self ): # \u53ef\u4ee5\u5728\u8fd9\u91cc\u8bfb\u53d6\u6570\u636e x , y = ... self . x = x self . y = y def __len__ ( self ): return len ( self . x ) def __getitem__ ( self , idx ): return self . x [ idx ], self . y [ idx ] myDataset = MyDataset () torch.utils.data.DataLoader train_loader = DataLoader ( dataset = myDataset , # \u4f20\u9012\u6570\u636e\u96c6 batch_size = 32 , # \u5c0f\u6279\u91cf\u7684\u6570\u636e\u5927\u5c0f\uff0c\u6bcf\u6b21\u52a0\u8f7d\u4e00batch\u6570\u636e shuffle = True , # \u6253\u4e71\u6570\u636e\u4e4b\u95f4\u7684\u987a\u5e8f num_workers = 2 ) # \u4f7f\u7528\u591a\u5c11\u4e2a\u5b50\u8fdb\u7a0b\u6765\u52a0\u8f7d\u6570\u636e\uff0c\u9ed8\u8ba4\u4e3a0, \u4ee3\u8868\u4f7f\u7528\u4e3b\u7ebf\u7a0b\u52a0\u8f7dbatch\u6570\u636e Transforms \u00b6 \u53c2\u8003\uff1a PyTorch \u5b66\u4e60\u7b14\u8bb0:transforms\u7684\u4e8c\u5341\u4e8c\u4e2a\u65b9\u6cd5 \u521d\u8bc6-CV\u7684\u535a\u5ba2 \u56fe\u50cf\u53d8\u6362\uff0c\u53ef\u4ee5\u5229\u7528 Compose \u628a\u53d8\u6362\u8fde\u63a5\u8d77\u6765 eg\uff1a import torchvision.transforms as transforms train_transform = transforms . Compose ([ transforms . CenterCrop ( 10 ), transforms . ToTensor (), ]) \u88c1\u526a Crop \u00b6 \u968f\u673a\u88c1\u526a \u00b6 torchvision . transforms . RandomCrop \uff08 size \uff0c padding = None \uff0c pad_if_needed = False \uff0c fill = 0 \uff0c padding_mode = 'constant' \uff09 \u4e2d\u5fc3\u88c1\u526a \u00b6 torchvision . transforms . CenterCrop ( size ) \u968f\u673a\u957f\u5bbd\u6bd4\u88c1\u526a \u00b6 torchvision . transforms . RandomResizedCrop ( size , scale = ( 0.08 , 1.0 ), ratio = ( 0.75 , 1.3333333333333333 ), interpolation = 2 ) \u4e0a\u4e0b\u5de6\u53f3\u4e2d\u5fc3\u88c1\u526a \u00b6 torchvision . transforms . FiveCrop ( size ) \u4e0a\u4e0b\u5de6\u53f3\u4e2d\u5fc3\u88c1\u526a\u540e\u7ffb\u8f6c \u00b6 torchvision . transforms . TenCrop ( size , vertical_flip = False ) \u7ffb\u8f6c\u548c\u65cb\u8f6c Flip and Rotation \u00b6 \u4f9d\u6982\u7387 p \u6c34\u5e73\u7ffb\u8f6c \u00b6 torchvision . transforms . RandomHorizontalFlip ( p = 0.5 ) # p \u9ed8\u8ba4\u4e3a 0.5 \u4f9d\u6982\u7387 p \u5782\u76f4\u7ffb\u8f6c \u00b6 torchvision . transforms . RandomVerticalFlip ( p = 0.5 ) \u968f\u673a\u65cb\u8f6c \u00b6 torchvision . transforms . RandomRotation ( degrees , resample = False , expand = False , center = None ) degree \uff1a\u5982\u679c\u4e0d\u662f\u4e00\u4e2a\u8303\u56f4\u800c\u662f\u4e00\u4e2a\u6570\u5b57\uff0c\u90a3\u8303\u56f4\u662f \\((-degree,degree)\\) \u56fe\u50cf\u53d8\u6362 Resize \u00b6 Resize \u00b6 torchvision . transforms . Resize ( size , interpolation = 2 ) \u6807\u51c6\u5316 \u00b6 torchvision . transforms . Normalize ( mean , std ) \u8f6c\u4e3a Tensor \u00b6 \u5c06 PIL Image \u6216\u8005 ndarray \u8f6c\u6362\u4e3a tensor\uff0c\u5e76\u4e14\u5f52\u4e00\u5316\u81f3 [0-1] \u6ce8\u610f\u4e8b\u9879\uff1a\u5f52\u4e00\u5316\u81f3 [0, 1] \u662f\u76f4\u63a5\u9664\u4ee5255\uff0c\u82e5\u81ea\u5df1\u7684 ndarray \u6570\u636e\u5c3a\u5ea6\u6709\u53d8\u5316\uff0c\u5219\u9700\u8981\u81ea\u884c\u4fee\u6539 torchvision . transforms . ToTensor \u586b\u5145 \u00b6 torchvision . transforms . Pad ( padding , fill = 0 , padding_mode = 'constant' ) \u4fee\u6539\u4eae\u5ea6\u3001\u5bf9\u6bd4\u5ea6\u548c\u9971\u548c\u5ea6 \u00b6 torchvision . transforms . ColorJitter ( brightness = 0 , contrast = 0 , saturation = 0 , hue = 0 ) \u8f6c\u7070\u5ea6\u56fe \u00b6 torchvision . transforms . Grayscale ( num_output_channels = 1 ) \u7ebf\u6027\u53d8\u6362 \u00b6 torchvision . transforms . LinearTransformation ( transformation_matrix ) \u4eff\u5c04\u53d8\u6362 \u00b6 torchvision . transforms . RandomAffine ( degrees , translate = None , scale = None , shear = None , resample = False , fillcolor = 0 ) \u4f9d\u6982\u7387 p \u8f6c\u4e3a\u7070\u5ea6\u56fe \u00b6 torchvision . transforms . RandomGrayscale ( p = 0.1 ) \u8f6c\u6362\u4e3a PILImage \u00b6 \u5c06 tensor \u6216\u8005 ndarray \u7684\u6570\u636e\u8f6c\u6362\u4e3a PIL Image \u7c7b\u578b\u6570\u636e \u53c2\u6570\uff1a mode \u4e3a None \u65f6\uff0c\u4e3a1\u901a\u9053\uff0c mode=3 \u901a\u9053\u9ed8\u8ba4\u8f6c\u6362\u4e3a RGB\uff0c4 \u901a\u9053\u9ed8\u8ba4\u8f6c\u6362\u4e3aRGBA torchvision . transforms . ToPILImage ( mode = None ) Lambda \u00b6 torchvision . transforms . Lambda \uff08 lambd \uff09 \u5bf9 transforms \u64cd\u4f5c \u00b6 RandomChoice \u00b6 torchvision . transforms . RandomChoice ( transforms ) RandomApply \u00b6 torchvision . transforms . RandomApply ( transforms , p = 0.5 ) RandomOrder \u00b6 torchvision . transforms . RandomOrder ( transforms ) \u5176\u4ed6 \u00b6 model.train() && model.eval() && torch.no_grad() \u00b6 Pytorch\uff1amodel.train()\u548cmodel.eval()\u7528\u6cd5\u548c\u533a\u522b\uff0c\u4ee5\u53camodel.eval()\u548ctorch.no_grad()\u7684\u533a\u522b_\u521d\u8bc6-CV\u7684\u535a\u5ba2 model.train() \u542f\u7528 Batch Normalization \u548c Dropout model . train model.eval() \u5982\u679c model \u91cc\u9762\u6709 batch normalization \u6216\u8005 dropout \u65f6, \u5728 test \u524d\u9700\u8981\u5199 model.eval model . eval () torch.no_grad() with \u4e0b\u9762\u7684\u8bed\u53e5\u505c\u6b62 autograd \u6a21\u5757\u7684\u5de5\u4f5c\uff0c\u4ee5\u8d77\u5230\u52a0\u901f\u548c\u8282\u7701\u663e\u5b58\u7684\u4f5c\u7528 with torch . no_grad (): ...","title":"Pytorch"},{"location":"ML/Pytorch/#pytorch","text":"","title":"Pytorch"},{"location":"ML/Pytorch/#pytorch-introduction","text":"\u674e\u5b8f\u6bc5\u8001\u5e0820\u5e74ML\u7684PyTorch Tutorial\uff1a PyTorch_Introduction.ipynb - Colaboratory (google.com) \u53c2\u8003\uff1a PyTorch\u7b80\u6613\u5165\u95e8 doc\uff1a PyTorch documentation \u2014 PyTorch master documentation \u5176\u4e2d\u52a0\u4e86\u4e00\u4e9b\u81ea\u5df1\u5b66\u4e60\u4e2d\u7684\u8865\u5145\u5185\u5bb9 import torch import torch.nn as nn import torch.nn.functional as F from mpl_toolkits.mplot3d import Axes3D import matplotlib.pyplot as plt import numpy as np torch . manual_seed ( 446 ) np . random . seed ( 446 )","title":"Pytorch Introduction"},{"location":"ML/Pytorch/#tensors-numpy","text":"the tensor is similar to numpy's ndarray # \u521d\u59cb\u5316 x_numpy = np . array ([ 0.1 , 0.2 , 0.3 ]) x_torch = torch . tensor ([ 0.1 , 0.2 , 0.3 ]) y_numpy = np . array ([ 3 , 4 , 5. ]) y_torch = torch . tensor ([ 3 , 4 , 5. ]) # tensor \u548c array \u7684\u8f6c\u6362 >>> torch . from_numpy ( x_numpy ) tensor ([ 0.1000 , 0.2000 , 0.3000 ], dtype = torch . float64 ) >>> x_torch . numpy () [ 0.1 0.2 0.3 ] # \u52a0\u51cf\u64cd\u4f5c >>> x_torch + y_torch tensor ([ 3.1000 , 4.2000 , 5.3000 ]) >>> x_torch - y_torch tensor ([ - 2.9000 , - 3.8000 , - 4.7000 ]) # \u6c42norm >>> np . linalg . norm ( x_numpy ) 0.37416573867739417 >>> torch . norm ( x_torch ) tensor ( 0.3742 ) # \u6c42\u5747\u503cmean >>> np . mean ( x_numpy ) 0.20000000000000004 >>> torch . mean ( x_torch ) tensor ( 0.2000 )","title":"Tensors &amp;&amp; numpy"},{"location":"ML/Pytorch/#torchview","text":"similarly to numpy.reshape() >>> N , C , W , H = 10000 , 3 , 28 , 28 >>> X = torch . randn (( N , C , W , H )) >>> X . shape torch . Size ([ 10000 , 3 , 28 , 28 ]) >>> X . view ( N , C , 784 ) . shape torch . Size ([ 10000 , 3 , 784 ]) >>> X . view ( - 1 , C , 784 ) . shape # -1\u7684\u53ef\u4ee5\u81ea\u52a8\u8ba1\u7b97X.shape\u4e2d\u5bf9\u5e94\u7ef4\u7684\u503c torch . Size ([ 10000 , 3 , 784 ])","title":"torch.view"},{"location":"ML/Pytorch/#broadcasting-semantics","text":"\u5904\u7406\u7ef4\u6570\u4e0d\u540c\u7684 tensors \u65f6\u4f1a\u8fdb\u884c\u5e7f\u64ad\uff0c\u7c7b\u4f3c np.matmul() >>> x = torch . empty ( 5 , 1 , 4 , 1 ) >>> y = torch . empty ( 3 , 1 , 1 ) >>> ( x + y ) . size () torch . Size ([ 5 , 3 , 4 , 1 ]) \u6309\u7167\u5c3e\u90e8\u7ef4\u5ea6\u5bf9\u9f50\uff0c\u4e14\u5bf9\u5e94\u7ef4\u5ea6\u8981\u4e48\u76f8\u540c\uff0c\u8981\u4e48\u6709\u4e00\u4e2a\u4e3a 1","title":"broadcasting semantics"},{"location":"ML/Pytorch/#computation-graphs","text":"\u505a\u52a0\u51cf\u4e58\u9664\u8fd0\u7b97\u65f6\uff0c\u53ea\u8981\u5176\u4e2d\u4e00\u9879\u9700\u8981\u505a gradient \uff0c pytorch \u5c31\u4f1a\u81ea\u52a8\u5efa\u7acb\u4e00\u5f20\u8ba1\u7b97\u56fe # \u6211\u4eec\u9700\u8981\u8bbe\u7f6erequires_grad=True\u4f7fpytorch\u77e5\u9053\u8981\u4fdd\u5b58\u8ba1\u7b97\u56fe\u7684\u5b58\u5728 >>> a = torch . tensor ( 2.0 , requires_grad = True ) >>> b = torch . tensor ( 1.0 , requires_grad = True ) >>> c = a + b >>> d = b + 1 >>> e = c * d >>> c tensor ( 3. , grad_fn =< AddBackward0 > ) >>> d tensor ( 2. , grad_fn =< AddBackward0 > ) >>> e tensor ( 6. , grad_fn =< MulBackward0 > )","title":"Computation graphs"},{"location":"ML/Pytorch/#cuda-semantics","text":"\u4f7f\u7528 torch.device(\"cpu\") \u548c torch.device(\"cuda\") \uff0c\u5e76\u4f7f\u7528 data.to() \u5c06\u6570\u636e\u5728 cpu \u548c gpu \u4e0a\u5207\u6362 cpu = torch . device ( 'cpu' ) gpu = torch . device ( 'cuda' ) x = torch . rand ( 10 ) x = x . to ( gpu ) # x\u5207\u6362\u5230gpu\u4e0a x = x . to ( cpu ) # x\u5207\u6362\u5230cpu\u4e0a","title":"CUDA semantics"},{"location":"ML/Pytorch/#pytorch-as-an-auto-grad-framework","text":"y.backward() \u8ba1\u7b97\u51fa\u8ba1\u7b97\u56fe\u4e2d \\(y\\) \u5bf9\u4ee5 \\(y\\) \u4e3a\u7ec8\u70b9\u7684\u8def\u5f84\u4e0a\u6240\u6709\u53d8\u91cf \\(x^i\\) \u7684 gradient \\(\\frac{\\partial y}{\\partial x^i}\\) \u4f8b1\uff1a \\(f(x)=(x-2)^2,f'(x)=2(x-2)\\) >>> def f ( x ): ... return ( x - 2 ) ** 2 >>> x = torch . tensor ([ 1.0 ], requires_grad = True ) # \u9700\u8981\u5148\u5efa\u7acb\u8ba1\u7b97\u56fe\u540e\u7eed\u624d\u80fd\u5fae\u5206 >>> y = f ( x ) >>> y . backward () # \u8ba1\u7b97\u56fe\u4e0a\u4ee5y\u4e3a\u7ec8\u70b9\u7684\u8def\u5f84\u4e0a\u7684\u6240\u6709\u53d8\u91cf\u90fd\u81ea\u52a8\u5fae\u5206 >>> x . grad tensor ([ - 2. ]) \u4f8b2\uff1a \\(w=[w_1,w_2]^T,g(w)=2w_1w_2+w_2cos(w_1)\\) >>> def g ( w ): ... return 2 * w [ 0 ] * w [ 1 ] + w [ 1 ] * torch . cos ( w [ 0 ]) >>> w = torch . tensor ([ np . pi , 1 ], requires_grad = True ) >>> z = g ( w ) >>> z . backward () >>> w . grad tensor ([ 2.0000 , 5.2832 ]) # z\u5bf9w[0]\u548cw[1]\u7684\u5fae\u5206","title":"PyTorch as an auto grad framework"},{"location":"ML/Pytorch/#using-the-gradients","text":"\u4ee5 \\(f(x)=(x-2)^2,f'(x)=2(x-2)\\) \u4e3a\u4f8b\u505a gradient descent >>> def f ( x ): ... return ( x - 2 ) ** 2 >>> x = torch . tensor ([ 5.0 ], requires_grad = True ) # \u968f\u673a\u5b9a\u4e49x\u7684\u521d\u503c\u503c >>> lr = 0.25 # learning rate >>> for i in range ( 15 ): # \u505agd ... y = f ( x ) ... y . backward () ... print ( \"x= %f \\t f(x)= %f \\t f'(x)= %f \" % ( x . item (), y . item (), x . grad . item ())) ... x . data = x . data - lr * x . grad # \u4e0d\u7528x.data\u4f1a\u51fa\u95ee\u9898 ... x . grad . detach_ () # The detach_() is for efficiency. You do not need to worry too much about it. ... x . grad . zero_ () ... x = 5.000000 f ( x ) = 9.000000 f '(x)=6.000000 x = 3.500000 f ( x ) = 2.250000 f '(x)=3.000000 x = 2.750000 f ( x ) = 0.562500 f '(x)=1.500000 x = 2.375000 f ( x ) = 0.140625 f '(x)=0.750000 x = 2.187500 f ( x ) = 0.035156 f '(x)=0.375000 x = 2.093750 f ( x ) = 0.008789 f '(x)=0.187500 x = 2.046875 f ( x ) = 0.002197 f '(x)=0.093750 x = 2.023438 f ( x ) = 0.000549 f '(x)=0.046875 x = 2.011719 f ( x ) = 0.000137 f '(x)=0.023438 x = 2.005859 f ( x ) = 0.000034 f '(x)=0.011719 x = 2.002930 f ( x ) = 0.000009 f '(x)=0.005859 x = 2.001465 f ( x ) = 0.000002 f '(x)=0.002930 x = 2.000732 f ( x ) = 0.000001 f '(x)=0.001465 x = 2.000366 f ( x ) = 0.000000 f '(x)=0.000732 x = 2.000183 f ( x ) = 0.000000 f '(x)=0.000366 tensor.grad.zero_() \uff1agradient \u6e05\u96f6\uff0c\u5426\u5219\u4f1a\u7d2f\u52a0 tensor.item() \uff1a\u7528\u4e8e\u53d6\u51fa tensor \u4e2d\u7684\u7eaf\u6570\u503c\uff0c\u4e00\u822c\u9002\u7528\u4e8e tensor \u53ea\u5305\u542b\u4e00\u4e2a\u5143\u7d20\u7684\u60c5\u51b5\uff0c\u591a\u4e2a\u5143\u7d20\u53ef\u91c7\u7528 tensor.tolist() \u8f6c\u5316\u4e3a\u5217\u8868 tensor.detach_() \uff1a\u5207\u65ad\u8ba1\u7b97\u56fe\uff0c\u6bd4\u5982\u6211\u4eec\u5bf9 y \u8fdb\u884c detach_()\uff0c\u5c31\u628a x->y->z \u5207\u6210\u4e24\u90e8\u5206\uff1ax \u548c y->z\uff0cx \u5c31\u65e0\u6cd5\u63a5\u53d7\u5230\u540e\u9762\u4f20\u8fc7\u6765\u7684\u68af\u5ea6\uff0c\u5bf9 z \u8fdb\u884c backward() \u65f6\u4e5f\u4e0d\u4f1a\u5bf9\u6c42 y \u7684\u68af\u5ea6 tensor.detach() & tensor.data \uff1a\u83b7\u53d6 x \u8fd9\u4e2a tensor \u7684\u503c\uff08\u521b\u5efa x \u7684\u526f\u672c\uff09\uff0c\u4e14\u5185\u5b58\u90fd\u662f\u4e0e x \u5171\u4eab\uff0c\u5373\u4fee\u6539\u540e\u4e5f\u4f1a\u5f71\u54cd x \u7684\u503c\uff0c\u4f46\u4e0d\u4f1a\u81ea\u52a8\u5fae\u5206\uff0c require s_grad = False \uff1b\u4e24\u8005\u533a\u522b\u5728\u4e8e\u5728\u540e\u7eed\u7684\u53cd\u5411\u4f20\u64ad\u4e2d\uff0ctensor.data \u4e0d\u4f1a\u62a5\u9519\uff0c\u6240\u4ee5 detach() \u4f1a\u66f4\u52a0\u5b89\u5168 pytorch .detach() .detach_() \u548c .data\u7528\u4e8e\u5207\u65ad\u53cd\u5411\u4f20\u64ad - \u6162\u884c\u539a\u79ef","title":"Using the gradients"},{"location":"ML/Pytorch/#linear-regression","text":"","title":"Linear Regression"},{"location":"ML/Pytorch/#example","text":"\u635f\u5931\u51fd\u6570\uff1aRSS\uff0c\u6b8b\u5dee\u5e73\u65b9\u548c \u6570\u636e\u51c6\u5907 true_w \u662f\u771f\u5b9e\u53c2\u6570\uff0cy \u901a\u8fc7 \\(x@w\\) \u200b\u200b \u52a0\u4e0a\u4e00\u4e2a\u504f\u5dee\u83b7\u5f97 d = 2 n = 50 x = torch . randn ( n , d ) true_w = torch . tensor ([[ - 1.0 ],[ 2.0 ]]) y = x @true_w + torch . randn ( n , 1 ) * 0.1 \u521b\u5efa\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u548c\u635f\u5931\u51fd\u6570 def model ( x , w ): return x @w def rss ( y , h_hat ): return torch . norm ( y - h_hat ) ** 2 / n \u4f7f\u7528\u68af\u5ea6\u8fdb\u884c\u68af\u5ea6\u4e0b\u964d\u6cd5\u7ebf\u6027\u56de\u5f52 w = torch . tensor ([[ 1. ],[ 0 ]], requires_grad = True ) for i in range ( 20 ): y_hat = model ( x , w ) loss = rss ( y , y_hat ) loss . backward () print ( 'loss = %f ' % loss . item (), \\\\ \" \\t w =\" , w . tolist ()) w . data = w . data - lr * w . grad w . grad . detach_ () w . grad . zero_ () loss = 6.877078 w = [[ 1.0 ], [ 0.0 ]] loss = 4.700166 w = [[ 0.6123040914535522 ], [ 0.29769018292427063 ]] loss = 3.225300 w = [[ 0.3017166256904602 ], [ 0.5531282424926758 ]] loss = 2.221793 w = [[ 0.052597105503082275 ], [ 0.7719148397445679 ]] loss = 1.536276 w = [[ - 0.1474691480398178 ], [ 0.9590051174163818 ]] loss = 1.066256 w = [[ - 0.3083454966545105 ], [ 1.1187583208084106 ]] loss = 0.742897 w = [[ - 0.4378759264945984 ], [ 1.2549899816513062 ]] loss = 0.519751 w = [[ - 0.5423045754432678 ], [ 1.371025800704956 ]] loss = 0.365329 w = [[ - 0.6266074180603027 ], [ 1.4697538614273071 ]] loss = 0.258197 w = [[ - 0.694753885269165 ], [ 1.5536739826202393 ]] loss = 0.183704 w = [[ - 0.7499141693115234 ], [ 1.6249440908432007 ]] loss = 0.131802 w = [[ - 0.7946230173110962 ], [ 1.6854223012924194 ]] loss = 0.095576 w = [[ - 0.8309094309806824 ], [ 1.7367050647735596 ]] loss = 0.070251 w = [[ - 0.8603994846343994 ], [ 1.7801612615585327 ]] loss = 0.052521 w = [[ - 0.8843981027603149 ], [ 1.8169628381729126 ]] loss = 0.040094 w = [[ - 0.9039536118507385 ], [ 1.8481112718582153 ]] loss = 0.031374 w = [[ - 0.9199094772338867 ], [ 1.8744614124298096 ]] loss = 0.025249 w = [[ - 0.9329451322555542 ], [ 1.8967417478561401 ]] loss = 0.020944 w = [[ - 0.9436085224151611 ], [ 1.9155727624893188 ]] loss = 0.017916 w = [[ - 0.9523422122001648 ], [ 1.931482195854187 ]]","title":"Example"},{"location":"ML/Pytorch/#torchnnmodule","text":"","title":"torch.nn.Module"},{"location":"ML/Pytorch/#linear-module","text":"d_in = 3 d_out = 4 linear_module = nn . Linear ( d_in , d_out ) example_tensor = torch . tensor ([[ 1. , 2 , 3 ],[ 4 , 5 , 6 ]]) transformed = linear_module ( example_tensor ) print ( 'example_tensor' , example_tensor . shape ) print ( 'transormed' , transformed . shape ) print () print ( 'We can see that the weights exist in the background \\n ' ) print ( 'W:' , linear_module . weight ) print ( 'b:' , linear_module . bias ) ''' example_tensor torch.Size([2, 3]) transormed torch.Size([2, 4]) We can see that the weights exist in the background W: Parameter containing: tensor([[ 0.5260, 0.4925, -0.0887], [ 0.3944, 0.4080, 0.2182], [-0.1409, 0.0518, 0.3034], [ 0.0913, 0.2452, -0.2616]], requires_grad=True) b: Parameter containing: tensor([0.5021, 0.0118, 0.1383, 0.4757], requires_grad=True) '''","title":"Linear Module"},{"location":"ML/Pytorch/#activation-functions","text":"activation_fn = nn . ReLU () # we instantiate an instance of the ReLU module example_tensor = torch . tensor ([ - 1.0 , 1.0 , 0.0 ]) activated = activation_fn ( example_tensor ) print ( 'example_tensor' , example_tensor ) print ( 'activated' , activated ) ''' example_tensor tensor([-1., 1., 0.]) activated tensor([0., 1., 0.]) '''","title":"Activation functions"},{"location":"ML/Pytorch/#sequential","text":"d_in = 3 d_hidden = 4 d_out = 1 model = torch . nn . Sequential ( nn . Linear ( d_in , d_hidden ), nn . Tanh (), nn . Linear ( d_hidden , d_out ), nn . Sigmoid () ) example_tensor = torch . tensor ([[ 1. , 2 , 3 ],[ 4 , 5 , 6 ]]) transformed = model ( example_tensor ) print ( 'transformed' , transformed . shape ) ''' transformed torch.Size([2, 1]) ''' \u4e0a\u9762\u7684\u5f0f\u5b50\u7b49\u4ef7\u4e8e d_in = 3 d_hidden = 4 d_out = 1 linear = nn . Linear ( d_in , d_hidden ) tanh = nn . Tanh () linear2 = nn . Linear ( d_hidden , d_out ) sigmoid = nn . Sigmoid () tensor_input = torch . tensor ([[ 1. , 2 , 3 ],[ 4 , 5 , 6 ]]) tensor_input = linear ( tensor_input ) tensor_input = tanh ( tensor_input ) tensor_input = linear2 ( tensor_input ) transformed = sigmoid ( tensor_input ) print ( transformed ) \u83b7\u53d6\u53c2\u6570 params = model . parameters () for param in params : print ( param ) ''' Parameter containing: tensor([[-0.5607, 0.4221, -0.0254], [-0.3630, 0.4541, 0.0275], [-0.0703, -0.1463, 0.3065], [ 0.0065, -0.2664, 0.0267]], requires_grad=True) Parameter containing: tensor([-0.3196, 0.2911, 0.1999, -0.3758], requires_grad=True) Parameter containing: tensor([[-0.0289, 0.1544, 0.3992, -0.3301]], requires_grad=True) Parameter containing: tensor([-0.1438], requires_grad=True) '''","title":"Sequential"},{"location":"ML/Pytorch/#loss-functions","text":"mse_loss_fn = nn . MSELoss () input = torch . tensor ([[ 0. , 0 , 0 ]]) target = torch . tensor ([[ 1. , 0 , - 1 ]]) loss = mse_loss_fn ( input , target ) print ( loss ) ''' tensor(0.6667) '''","title":"Loss functions"},{"location":"ML/Pytorch/#torchoptim","text":"\u4f7f\u7528\u4f18\u5316\u5668 Optimizer \u642d\u5efa\u4e00\u4e2a\u5b8c\u6574\u7684\u795e\u7ecf\u7f51\u7edc \u4e0b\u9762\u7684\u4f8b\u5b50 GD \u4e86\u4e00\u6b21 # create a simple model model = nn . Linear ( 1 , 1 ) # create a simple dataset X_simple = torch . tensor ([[ 1. ]]) y_simple = torch . tensor ([[ 2. ]]) # create our optimizer # \u5fc5\u987b\u8981\u628amodel\u7684\u53c2\u6570\u5582\u7ed9optim\uff0clr\u53ef\u4ee5\u4e0d\u5199\uff0c\u4f1a\u6709\u9ed8\u8ba4\u53c2\u6570\u503c optim = torch . optim . SGD ( model . parameters (), lr = 1e-2 ) mse_loss_fn = nn . MSELoss () y_hat = model ( X_simple ) print ( 'model params before:' , model . weight ) loss = mse_loss_fn ( y_hat , y_simple ) # \u68af\u5ea6\u6e05\u96f6->\u8ba1\u7b97\u68af\u5ea6->\u68af\u5ea6\u4e0b\u964d # \u505aBackpropagation\u4e4b\u524d\u5148\u5c06\u68af\u5ea6\u6e05\u96f6\uff0c\u9632\u6b62\u4e0e\u65e7\u503c\u53e0\u52a0 optim . zero_grad () loss . backward () optim . step () print ( 'model params after:' , model . weight ) ''' model params before: Parameter containing: tensor([[-0.9604]], requires_grad=True) model params after: Parameter containing: tensor([[-0.9060]], requires_grad=True) '''","title":"torch.optim"},{"location":"ML/Pytorch/#linear-regression-using-gd","text":"step_size = 0.1 linear_module = nn . Linear ( d , 1 , bias = False ) loss_func = nn . MSELoss () optim = torch . optim . SGD ( linear_module . parameters (), lr = step_size ) print ( 'iter, \\t loss, \\t w' ) for i in range ( 20 ): y_hat = linear_module ( X ) loss = loss_func ( y_hat , y ) optim . zero_grad () loss . backward () optim . step () print ( ' {} , \\t {:.2f} , \\t {} ' . format ( i , loss . item (), linear_module . weight . view ( 2 ) . detach () . numpy ())) print ( ' \\n true w \\t\\t ' , true_w . view ( 2 ) . numpy ()) print ( 'estimated w \\t ' , linear_module . weight . view ( 2 ) . detach () . numpy ()) ''' iter, loss, w 0, 6.14, [-0.4951109 -0.20055914] 1, 4.19, [-0.64017504 0.1509075 ] 2, 2.87, [-0.7496651 0.4441856] 3, 1.98, [-0.8317375 0.689143 ] 4, 1.37, [-0.8927491 0.89393103] 5, 0.95, [-0.93764454 1.0652909 ] 6, 0.67, [-0.9702622 1.208804 ] 7, 0.47, [-0.99357456 1.3290964 ] 8, 0.33, [-1.0098771 1.4300069] 9, 0.23, [-1.0209374 1.5147243] 10, 0.17, [-1.028112 1.5859002] 11, 0.12, [-1.0324373 1.6457422] 12, 0.09, [-1.0347017 1.6960896] 13, 0.06, [-1.035502 1.7384766] 14, 0.05, [-1.0352864 1.7741843] 15, 0.04, [-1.0343897 1.8042834] 16, 0.03, [-1.033059 1.829669] 17, 0.02, [-1.031475 1.8510911] 18, 0.02, [-1.0297676 1.8691778] 19, 0.01, [-1.0280287 1.8844559] true w [-1. 2.] estimated w [-1.0280287 1.8844559] '''","title":"Linear regression using GD"},{"location":"ML/Pytorch/#linear-regression-using-sgd","text":"step_size = 0.01 linear_module = nn . Linear ( d , 1 ) loss_func = nn . MSELoss () optim = torch . optim . SGD ( linear_module . parameters (), lr = step_size ) print ( 'iter, \\t loss, \\t w' ) for i in range ( 200 ): rand_idx = np . random . choice ( n ) # take a random point from the dataset x = X [ rand_idx ] y_hat = linear_module ( x ) loss = loss_func ( y_hat , y [ rand_idx ]) # only compute the loss on the single point optim . zero_grad () loss . backward () optim . step () if i % 20 == 0 : print ( ' {} , \\t {:.2f} , \\t {} ' . format ( i , loss . item (), linear_module . weight . view ( 2 ) . detach () . numpy ())) print ( ' \\n true w \\t\\t ' , true_w . view ( 2 ) . numpy ()) print ( 'estimated w \\t ' , linear_module . weight . view ( 2 ) . detach () . numpy ()) ''' iter, loss, w 0, 5.33, [-0.52818084 0.2690754 ] 20, 1.33, [-0.5849738 0.54701847] 40, 0.21, [-0.68336743 0.93094164] 60, 0.41, [-0.76554966 1.3865377 ] 80, 0.22, [-0.8548197 1.528812 ] 100, 0.45, [-0.9011376 1.679943 ] 120, 0.04, [-0.9418524 1.7858417] 140, 0.00, [-0.97288156 1.857902 ] 160, 0.00, [-0.98335326 1.893024 ] 180, 0.01, [-0.9927237 1.904962 ] true w [-1. 2.] estimated w [-0.99158174 1.9331173 ] '''","title":"Linear regression using SGD"},{"location":"ML/Pytorch/#neural-network-basics-in-pytorch","text":"We will try and fit a simple neural network to the data. d = 1 n = 200 X = torch . rand ( n , d ) # rand \u751f\u6210\u7684\u968f\u673a\u6570\u5728 [0,1] # \u4e00\u4e2a\u7531 sin \u548c cos \u7684\u5408\u6210\u51fd\u6570 y = 4 * torch . sin ( np . pi * X ) * torch . cos ( 6 * np . pi * X ** 2 ) plt . scatter ( X . numpy (), y . numpy ()) plt . title ( 'plot of $f(x)$' ) plt . xlabel ( '$x$' ) plt . ylabel ( '$y$' ) plt . show () \u7528 pytorch \u642d\u5efa\u795e\u7ecf\u7f51\u7edc\u62df\u5408\u6570\u636e\u96c6\u7684\u66f2\u7ebf\uff0cactivation function \u7528 Tanh step_size = 0.05 n_epochs = 6000 n_hidden_1 = 32 n_hidden_2 = 32 d_out = 1 neural_network = nn . Sequential ( nn . Linear ( d , n_hidden_1 ), nn . Tanh (), nn . Linear ( n_hidden_1 , n_hidden_2 ), nn . Tanh (), nn . Linear ( n_hidden_2 , d_out ) ) loss_func = nn . MSELoss () optim = torch . optim . SGD ( neural_network . parameters (), lr = step_size ) print ( 'iter, \\t loss' ) for i in range ( n_epochs ): y_hat = neural_network ( X ) loss = loss_func ( y_hat , y ) optim . zero_grad () loss . backward () optim . step () if i % ( n_epochs // 10 ) == 0 : print ( ' {} , \\t {:.2f} ' . format ( i , loss . item ())) ''' iter, loss 0, 4.33 600, 4.27 1200, 3.87 1800, 1.54 2400, 0.71 3000, 0.78 3600, 0.24 4200, 0.10 4800, 0.08 5400, 0.08 ''' \u753b\u51fa\u62df\u5408\u540e\u7684\u66f2\u7ebf X_grid = torch . from_numpy ( np . linspace ( 0 , 1 , 50 )) . float () . view ( - 1 , d ) y_hat = neural_network ( X_grid ) plt . scatter ( X . numpy (), y . numpy ()) plt . plot ( X_grid . detach () . numpy (), y_hat . detach () . numpy (), 'r' ) plt . title ( 'plot of $f(x)$ and $\\hat {f} (x)$' ) plt . xlabel ( '$x$' ) plt . ylabel ( '$y$' ) plt . show ()","title":"Neural Network Basics in PyTorch"},{"location":"ML/Pytorch/#things-that-may-help","text":"","title":"Things that may help"},{"location":"ML/Pytorch/#momentum","text":"doc\uff1a Why Momentum Really Works (distill.pub) optim = torch . optim . SGD ( neural_network . parameters (), lr = step_size , momentum = momentum )","title":"Momentum"},{"location":"ML/Pytorch/#crossentropyloss","text":"loss = nn . CrossEntropyLoss ()","title":"CrossEntropyLoss"},{"location":"ML/Pytorch/#learning-rate-schedulers","text":"doc\uff1a torch.optim \u2014 PyTorch 1.9.0 documentation ### Convolutions","title":"Learning rate schedulers"},{"location":"ML/Pytorch/#nnconv2d","text":"\u7528 CNN \u5904\u7406\u56fe\u50cf torch.nn.Conv2d doc\uff1a Conv2d \u2014 PyTorch 1.9.0 documentation torch.nn.Conv2d() \u7528\u6cd5\u8bb2\u89e3_\u5047\u88c5\u5f88\u574f\u7684\u8c26\u8c26\u541b torch . nn . Conv2d ( in_channels , out_channels , kernel_size , stride = 1 , padding = 0 , dilation = 1 , groups = 1 , bias = True , padding_mode = \u2018 zeros \u2019 ) in_channels \uff1a\u8f93\u5165\u7684\u901a\u9053\u6570\u76ee\uff0c\u6bd4\u5982 RGB \u5c31\u662f 3 \u901a\u9053 out_channels \uff1a\u8f93\u51fa\u7684\u901a\u9053\u6570\u76ee\uff0c\u5377\u79ef\u6838\u7684\u6570\u91cf kernel_size \uff1a\u5377\u79ef\u6838 (filter) \u5927\u5c0f\uff0cint \u6216\u8005 \u5143\u7ec4\uff0cint \u8868\u793a\u6b63\u65b9\u5f62\u7684\u5bbd\u5ea6 stride \uff1a\u6b65\u957f\uff0c\u9ed8\u8ba4 1 padding \uff1a\u5728\u8fb9\u754c\u589e\u52a0 \u503c\u4e3a0 \u7684\u8fb9\u8ddd\u7684\u957f\u5ea6\uff0c\u6216\u8005\u8bf4\u52a0\u51e0\u5708 0\uff0c\u9ed8\u8ba4\u4e3a 0 dilation \uff1a\u63a7\u5236\u5377\u79ef\u6838\u4e4b\u95f4\u7684\u95f4\u8ddd","title":"nn.Conv2d"},{"location":"ML/Pytorch/#nnbatchnorm2d","text":"\u5728\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u65f6\u901a\u5e38\u4e00\u6b21\u8bad\u7ec3\u4e00\u4e2a batch\uff0c\u4f46\u662f\u6bcf\u4e2a batch \u7684\u5206\u5e03\u4e0d\u540c\uff0c\u6240\u4ee5\u4f1a\u5bf9\u4e0b\u4e00\u5c42\u7f51\u7edc\u7684\u5b66\u4e60\u5e26\u6765\u56f0\u96be\uff0cBatchNorm \u5c31\u662f\u628a\u6570\u636e\u6807\u51c6\u5316\uff08\u5747\u503c\u4e3a 0\uff0c \u65b9\u5dee\u4e3a 1\uff09\uff0c\u907f\u514d\u68af\u5ea6\u6d88\u5931\u548c\u68af\u5ea6\u7206\u70b8 torch . nn . BatchNorm2d ( num_features , eps = 1e-05 , momentum = 0.1 , affine = True ) num_features \uff1achannel \u6570 eps \uff1a\u4e3a\u4fdd\u8bc1\u6570\u503c\u7a33\u5b9a\u6027\uff08\u5206\u6bcd\u4e0d\u80fd\u8d8b\u8fd1\u6216\u53d60\uff09,\u7ed9\u5206\u6bcd\u52a0\u4e0a\u7684\u503c\u3002\u9ed8\u8ba4\u4e3a 1e-5 momentum \uff1a\u52a8\u6001\u5747\u503c\u548c\u52a8\u6001\u65b9\u5dee\u6240\u4f7f\u7528\u7684\u52a8\u91cf affine \uff1a \u4e00\u4e2a\u5e03\u5c14\u503c\uff0c\u5f53\u8bbe\u4e3atrue\uff0c\u7ed9\u8be5\u5c42\u6dfb\u52a0\u53ef\u5b66\u4e60\u7684\u4eff\u5c04\u53d8\u6362\u53c2\u6570","title":"nn.BatchNorm2d"},{"location":"ML/Pytorch/#nnmaxpool2d","text":"torch . nn . MaxPool2d ( kernel_size , stride = None , padding = 0 , dilation = 1 , return_indices = False , ceil_mode = False ) kernel_size \uff1amax pooling \u7a97\u53e3\u5927\u5c0f stride \uff1a\u7a97\u53e3\u79fb\u52a8\u6b65\u957f\uff0c\u9ed8\u8ba4\u4e3a kernel_size padding \uff1a\u5728\u8fb9\u754c\u589e\u52a0 \u503c\u4e3a0 \u7684\u8fb9\u8ddd\u7684\u957f\u5ea6\uff0c\u6216\u8005\u8bf4\u52a0\u51e0\u5708 0\uff0c\u9ed8\u8ba4\u4e3a 0","title":"nn.MaxPool2d"},{"location":"ML/Pytorch/#custom-datasets-dataloaders","text":"torch.utils.data.Dataset \u662f\u8868\u793a\u6570\u636e\u96c6\u7684\u62bd\u8c61\u7c7b\uff0c\u4f60\u7684\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u5e94\u7ee7\u627f Dataset \u5e76\u8986\u76d6\u4ee5\u4e0b\u65b9\u6cd5\uff1a __len__ so that len(dataset) returns the size of the dataset. __getitem__ to support the indexing such that dataset[i] can be used to get i-th sample from torch.utils.data import Dataset , DataLoader class MyDataset ( Dataset ): def __init__ ( self ): # \u53ef\u4ee5\u5728\u8fd9\u91cc\u8bfb\u53d6\u6570\u636e x , y = ... self . x = x self . y = y def __len__ ( self ): return len ( self . x ) def __getitem__ ( self , idx ): return self . x [ idx ], self . y [ idx ] myDataset = MyDataset () torch.utils.data.DataLoader train_loader = DataLoader ( dataset = myDataset , # \u4f20\u9012\u6570\u636e\u96c6 batch_size = 32 , # \u5c0f\u6279\u91cf\u7684\u6570\u636e\u5927\u5c0f\uff0c\u6bcf\u6b21\u52a0\u8f7d\u4e00batch\u6570\u636e shuffle = True , # \u6253\u4e71\u6570\u636e\u4e4b\u95f4\u7684\u987a\u5e8f num_workers = 2 ) # \u4f7f\u7528\u591a\u5c11\u4e2a\u5b50\u8fdb\u7a0b\u6765\u52a0\u8f7d\u6570\u636e\uff0c\u9ed8\u8ba4\u4e3a0, \u4ee3\u8868\u4f7f\u7528\u4e3b\u7ebf\u7a0b\u52a0\u8f7dbatch\u6570\u636e","title":"Custom Datasets, DataLoaders"},{"location":"ML/Pytorch/#transforms","text":"\u53c2\u8003\uff1a PyTorch \u5b66\u4e60\u7b14\u8bb0:transforms\u7684\u4e8c\u5341\u4e8c\u4e2a\u65b9\u6cd5 \u521d\u8bc6-CV\u7684\u535a\u5ba2 \u56fe\u50cf\u53d8\u6362\uff0c\u53ef\u4ee5\u5229\u7528 Compose \u628a\u53d8\u6362\u8fde\u63a5\u8d77\u6765 eg\uff1a import torchvision.transforms as transforms train_transform = transforms . Compose ([ transforms . CenterCrop ( 10 ), transforms . ToTensor (), ])","title":"Transforms"},{"location":"ML/Pytorch/#crop","text":"","title":"\u88c1\u526a Crop"},{"location":"ML/Pytorch/#_1","text":"torchvision . transforms . RandomCrop \uff08 size \uff0c padding = None \uff0c pad_if_needed = False \uff0c fill = 0 \uff0c padding_mode = 'constant' \uff09","title":"\u968f\u673a\u88c1\u526a"},{"location":"ML/Pytorch/#_2","text":"torchvision . transforms . CenterCrop ( size )","title":"\u4e2d\u5fc3\u88c1\u526a"},{"location":"ML/Pytorch/#_3","text":"torchvision . transforms . RandomResizedCrop ( size , scale = ( 0.08 , 1.0 ), ratio = ( 0.75 , 1.3333333333333333 ), interpolation = 2 )","title":"\u968f\u673a\u957f\u5bbd\u6bd4\u88c1\u526a"},{"location":"ML/Pytorch/#_4","text":"torchvision . transforms . FiveCrop ( size )","title":"\u4e0a\u4e0b\u5de6\u53f3\u4e2d\u5fc3\u88c1\u526a"},{"location":"ML/Pytorch/#_5","text":"torchvision . transforms . TenCrop ( size , vertical_flip = False )","title":"\u4e0a\u4e0b\u5de6\u53f3\u4e2d\u5fc3\u88c1\u526a\u540e\u7ffb\u8f6c"},{"location":"ML/Pytorch/#flip-and-rotation","text":"","title":"\u7ffb\u8f6c\u548c\u65cb\u8f6c Flip and Rotation"},{"location":"ML/Pytorch/#p","text":"torchvision . transforms . RandomHorizontalFlip ( p = 0.5 ) # p \u9ed8\u8ba4\u4e3a 0.5","title":"\u4f9d\u6982\u7387 p \u6c34\u5e73\u7ffb\u8f6c"},{"location":"ML/Pytorch/#p_1","text":"torchvision . transforms . RandomVerticalFlip ( p = 0.5 )","title":"\u4f9d\u6982\u7387 p \u5782\u76f4\u7ffb\u8f6c"},{"location":"ML/Pytorch/#_6","text":"torchvision . transforms . RandomRotation ( degrees , resample = False , expand = False , center = None ) degree \uff1a\u5982\u679c\u4e0d\u662f\u4e00\u4e2a\u8303\u56f4\u800c\u662f\u4e00\u4e2a\u6570\u5b57\uff0c\u90a3\u8303\u56f4\u662f \\((-degree,degree)\\)","title":"\u968f\u673a\u65cb\u8f6c"},{"location":"ML/Pytorch/#resize","text":"","title":"\u56fe\u50cf\u53d8\u6362 Resize"},{"location":"ML/Pytorch/#resize_1","text":"torchvision . transforms . Resize ( size , interpolation = 2 )","title":"Resize"},{"location":"ML/Pytorch/#_7","text":"torchvision . transforms . Normalize ( mean , std )","title":"\u6807\u51c6\u5316"},{"location":"ML/Pytorch/#tensor","text":"\u5c06 PIL Image \u6216\u8005 ndarray \u8f6c\u6362\u4e3a tensor\uff0c\u5e76\u4e14\u5f52\u4e00\u5316\u81f3 [0-1] \u6ce8\u610f\u4e8b\u9879\uff1a\u5f52\u4e00\u5316\u81f3 [0, 1] \u662f\u76f4\u63a5\u9664\u4ee5255\uff0c\u82e5\u81ea\u5df1\u7684 ndarray \u6570\u636e\u5c3a\u5ea6\u6709\u53d8\u5316\uff0c\u5219\u9700\u8981\u81ea\u884c\u4fee\u6539 torchvision . transforms . ToTensor","title":"\u8f6c\u4e3a Tensor"},{"location":"ML/Pytorch/#_8","text":"torchvision . transforms . Pad ( padding , fill = 0 , padding_mode = 'constant' )","title":"\u586b\u5145"},{"location":"ML/Pytorch/#_9","text":"torchvision . transforms . ColorJitter ( brightness = 0 , contrast = 0 , saturation = 0 , hue = 0 )","title":"\u4fee\u6539\u4eae\u5ea6\u3001\u5bf9\u6bd4\u5ea6\u548c\u9971\u548c\u5ea6"},{"location":"ML/Pytorch/#_10","text":"torchvision . transforms . Grayscale ( num_output_channels = 1 )","title":"\u8f6c\u7070\u5ea6\u56fe"},{"location":"ML/Pytorch/#_11","text":"torchvision . transforms . LinearTransformation ( transformation_matrix )","title":"\u7ebf\u6027\u53d8\u6362"},{"location":"ML/Pytorch/#_12","text":"torchvision . transforms . RandomAffine ( degrees , translate = None , scale = None , shear = None , resample = False , fillcolor = 0 )","title":"\u4eff\u5c04\u53d8\u6362"},{"location":"ML/Pytorch/#p_2","text":"torchvision . transforms . RandomGrayscale ( p = 0.1 )","title":"\u4f9d\u6982\u7387 p \u8f6c\u4e3a\u7070\u5ea6\u56fe"},{"location":"ML/Pytorch/#pilimage","text":"\u5c06 tensor \u6216\u8005 ndarray \u7684\u6570\u636e\u8f6c\u6362\u4e3a PIL Image \u7c7b\u578b\u6570\u636e \u53c2\u6570\uff1a mode \u4e3a None \u65f6\uff0c\u4e3a1\u901a\u9053\uff0c mode=3 \u901a\u9053\u9ed8\u8ba4\u8f6c\u6362\u4e3a RGB\uff0c4 \u901a\u9053\u9ed8\u8ba4\u8f6c\u6362\u4e3aRGBA torchvision . transforms . ToPILImage ( mode = None )","title":"\u8f6c\u6362\u4e3a PILImage"},{"location":"ML/Pytorch/#lambda","text":"torchvision . transforms . Lambda \uff08 lambd \uff09","title":"Lambda"},{"location":"ML/Pytorch/#transforms_1","text":"","title":"\u5bf9 transforms \u64cd\u4f5c"},{"location":"ML/Pytorch/#randomchoice","text":"torchvision . transforms . RandomChoice ( transforms )","title":"RandomChoice"},{"location":"ML/Pytorch/#randomapply","text":"torchvision . transforms . RandomApply ( transforms , p = 0.5 )","title":"RandomApply"},{"location":"ML/Pytorch/#randomorder","text":"torchvision . transforms . RandomOrder ( transforms )","title":"RandomOrder"},{"location":"ML/Pytorch/#_13","text":"","title":"\u5176\u4ed6"},{"location":"ML/Pytorch/#modeltrain-modeleval-torchno_grad","text":"Pytorch\uff1amodel.train()\u548cmodel.eval()\u7528\u6cd5\u548c\u533a\u522b\uff0c\u4ee5\u53camodel.eval()\u548ctorch.no_grad()\u7684\u533a\u522b_\u521d\u8bc6-CV\u7684\u535a\u5ba2 model.train() \u542f\u7528 Batch Normalization \u548c Dropout model . train model.eval() \u5982\u679c model \u91cc\u9762\u6709 batch normalization \u6216\u8005 dropout \u65f6, \u5728 test \u524d\u9700\u8981\u5199 model.eval model . eval () torch.no_grad() with \u4e0b\u9762\u7684\u8bed\u53e5\u505c\u6b62 autograd \u6a21\u5757\u7684\u5de5\u4f5c\uff0c\u4ee5\u8d77\u5230\u52a0\u901f\u548c\u8282\u7701\u663e\u5b58\u7684\u4f5c\u7528 with torch . no_grad (): ...","title":"model.train() &amp;&amp; model.eval() &amp;&amp; torch.no_grad()"},{"location":"ML/%E8%AF%B4%E6%98%8E/","text":"\u8bf4\u660e \u00b6 \u674e\u5b8f\u6bc5\u8001\u5e08\u673a\u5668\u5b66\u4e60\u7684\u7b14\u8bb0 \u53c2\u8003\uff1a \u8bfe\u7a0b\u89c6\u9891\uff1a \u674e\u5b8f\u6bc5\u6559\u6388\u7684\u673a\u5668\u5b66\u4e60\u8bfe\u7a0b(2020\u7248\u5168\u96c6) \u54d4\u54e9\u54d4\u54e9 \u674e\u5b8f\u6bc5\u8001\u5e08\u7684\u4e2a\u4eba\u7f51\u7ad9\uff1a ML 2020 Spring (ntu.edu.tw) Youtube\uff1a Hung-yi Lee - YouTube \u7b14\u8bb0\u53c2\u8003\uff1a Sakura-gh/ML-notes: notes about machine learning (github.com) Scarleatt \u6211\u7684 homework \u8bb0\u5f55\uff1a \u5206\u7c7b: ML | hucorz","title":"\u8bf4\u660e"},{"location":"ML/%E8%AF%B4%E6%98%8E/#_1","text":"\u674e\u5b8f\u6bc5\u8001\u5e08\u673a\u5668\u5b66\u4e60\u7684\u7b14\u8bb0 \u53c2\u8003\uff1a \u8bfe\u7a0b\u89c6\u9891\uff1a \u674e\u5b8f\u6bc5\u6559\u6388\u7684\u673a\u5668\u5b66\u4e60\u8bfe\u7a0b(2020\u7248\u5168\u96c6) \u54d4\u54e9\u54d4\u54e9 \u674e\u5b8f\u6bc5\u8001\u5e08\u7684\u4e2a\u4eba\u7f51\u7ad9\uff1a ML 2020 Spring (ntu.edu.tw) Youtube\uff1a Hung-yi Lee - YouTube \u7b14\u8bb0\u53c2\u8003\uff1a Sakura-gh/ML-notes: notes about machine learning (github.com) Scarleatt \u6211\u7684 homework \u8bb0\u5f55\uff1a \u5206\u7c7b: ML | hucorz","title":"\u8bf4\u660e"},{"location":"OI/STL/","text":"STL \u00b6 string \u00b6 \u5b57\u7b26\u4e32 \u6784\u9020\u51fd\u6570 string s = \"\" s1 = s2 \u589e\u52a0\u5143\u7d20 s += s2 //\u76f4\u63a5\u7528 + \u5373\u53ef s += \"new string\" \u5220\u9664\u5143\u7d20 string & erase ( size_t pos = 0 , size_t n ) //\u5220\u9664\u4ecepos\u5f00\u59cb\u7684n\u4e2a\u5b57\u7b26 iterator erase ( iterator ) //\u5220\u9664\u4e00\u4e2a iterator erase ( iterator first , iterator last ) //\u5220\u9664\u8303\u56f4 iterator erase ( remove ( str . begin (), str . end (), 'a' ), str . end ()) //\u5220\u9664\u7279\u5b9a\u5b57\u7b26 \u8fed\u4ee3\u5668 iterator begin (); //\u5934\u8fed\u4ee3\u5668 iterator end (); //\u5c3e\u8fed\u4ee3\u5668 \u5176\u4ed6 sort ( string , iterator l , iterator r ) //\u6392\u5e8f [l, r) string substr ( int pos , int n ) //\u83b7\u53d6\u8fde\u7eed\u5b50\u4e32\uff0c\u4ece pos \u5f00\u59cb\u7684 n \u4e2a\u5b57\u7b26\uff0c-1\u8868\u793a\u5230\u6700\u540e bool empty () //\u5224\u65ad\u662f\u5426\u4e3a\u7a7a int size () //\u5b57\u7b26\u4e2a\u6570 bool isalnum ( char ) //\u5982\u679cc\u662f\u5b57\u6bcd\u6216\u6570\u5b57\uff0c\u8fd4\u56de true bool isalpha ( char ) //\u5982\u679cc\u662f\u5b57\u6bcd\uff0c\u8fd4\u56detrue bool iscntrl ( char ) //\u5982\u679cc\u662f\u63a7\u5236\u7b26\uff0c\u8fd4\u56detrue bool isdigit ( char ) //\u5982\u679cc\u662f\u6570\u5b57\uff0c\u8fd4\u56detrue bool isgraph ( char ) //\u5982\u679cc\u4e0d\u662f\u7a7a\u683c\uff0c\u8fd4\u56de\u4e3atrue bool islower ( char ) //\u5982\u679cc\u662f\u5c0f\u5199\u5b57\u6bcd\uff0c\u8fd4\u56de\u4e3atrue bool isupper ( char ) //\u5982\u679cc\u662f\u5927\u5199\u5b57\u7b26\uff0c\u8fd4\u56de\u4e3atrue bool isprint ( char ) //\u5982\u679cc\u662f\u53ef\u6253\u5370\u7684\u5b57\u7b26\uff0c\u8fd4\u56de\u4e3atrue bool ispunct ( char ) //\u5982\u679cc\u662f\u6807\u70b9\u7b26\u53f7\uff0c\u8fd4\u56de\u4e3atrue bool isspace ( char ) //\u5982\u679cc\u662f\u7a7a\u767d\u5b57\u7b26\uff0c\u8fd4\u56de\u4e3atrue bool isxdigit ( char ) //\u5982\u679cc\u662f\u5341\u516d\u8fdb\u5236\u6570\uff0c\u8fd4\u56de\u4e3atrue vector \u00b6 \\(include<vector>\\) \u6784\u9020\u51fd\u6570 vector () //\u521b\u5efa\u4e00\u4e2a\u7a7avector vector ( int nSize ) //\u521b\u5efa\u4e00\u4e2avector,\u5143\u7d20\u4e2a\u6570\u4e3anSize vector ( int nSize , const T & t ) //\u521b\u5efa\u4e00\u4e2avector\uff0c\u5143\u7d20\u4e2a\u6570\u4e3anSize,\u4e14\u503c\u5747\u4e3at vector ( const vector & ) //\u590d\u5236\u6784\u9020\u51fd\u6570 vector ( begin , end ) //\u590d\u5236[begin,end)\u533a\u95f4\u5185\u53e6\u4e00\u4e2a\u6570\u7ec4\u7684\u5143\u7d20\u5230vector\u4e2d \u589e\u52a0\u5143\u7d20 void push_back ( const T & x ) //\u5411\u91cf\u5c3e\u90e8\u589e\u52a0\u4e00\u4e2a\u5143\u7d20X iterator insert ( iterator it , const T & x ) //\u8fed\u4ee3\u5668\u6307\u5411\u5143\u7d20\u524d\u589e\u52a0\u4e00\u4e2a\u5143\u7d20x iterator insert ( iterator it , int n , const T & x ) //\u8fed\u4ee3\u5668\u6307\u5411\u5143\u7d20\u524d\u589e\u52a0n\u4e2a\u76f8\u540c\u7684\u5143\u7d20x iterator insert ( iterator it , iterator first , iterator last ) //\u8fed\u4ee3\u5668\u6307\u5411\u5143\u7d20\u524d\u63d2\u5165\u53e6\u4e00\u4e2a\u5411\u91cf\u7684[first,last)\u7684\u6570\u636e \u5220\u9664\u5143\u7d20 iterator erase ( iterator it ) //\u5220\u9664\u8fed\u4ee3\u5668\u6307\u5411\u5143\u7d20 iterator erase ( iterator first , iterator last ) //\u5220\u9664[first,last)\u4e2d\u5143\u7d20 void pop_back () //\u5220\u9664\u5411\u91cf\u4e2d\u6700\u540e\u4e00\u4e2a\u5143\u7d20 void clear () //\u6e05\u7a7a\u5411\u91cf\u4e2d\u6240\u6709\u5143\u7d20 \u8fed\u4ee3\u5668 reference at ( int pos ) //\u8fd4\u56depos\u4f4d\u7f6e\u5143\u7d20\u7684\u5f15\u7528 reference front () //\u8fd4\u56de\u9996\u5143\u7d20\u7684\u5f15\u7528 reference back () //\u8fd4\u56de\u5c3e\u5143\u7d20\u7684\u5f15\u7528 iterator begin () //\u8fd4\u56de\u5411\u91cf\u5934\u6307\u9488\uff0c\u6307\u5411\u7b2c\u4e00\u4e2a\u5143\u7d20 iterator end () //\u8fd4\u56de\u5411\u91cf\u5c3e\u6307\u9488\uff0c\u6307\u5411\u5411\u91cf\u6700\u540e\u4e00\u4e2a\u5143\u7d20\u7684\u4e0b\u4e00\u4e2a\u4f4d\u7f6e reverse_iterator rbegin () //\u53cd\u5411\u8fed\u4ee3\u5668\uff0c\u6307\u5411\u6700\u540e\u4e00\u4e2a\u5143\u7d20 reverse_iterator rend () //\u53cd\u5411\u8fed\u4ee3\u5668\uff0c\u6307\u5411\u7b2c\u4e00\u4e2a\u5143\u7d20\u4e4b\u524d\u7684\u4f4d\u7f6e \u5176\u4ed6 int size () const //\u8fd4\u56de\u5411\u91cf\u4e2d\u5143\u7d20\u7684\u4e2a\u6570 int capacity () const //\u8fd4\u56de\u5f53\u524d\u5411\u91cf\u6240\u80fd\u5bb9\u7eb3\u7684\u6700\u5927\u5143\u7d20\u503c int max_size () const //\u8fd4\u56de\u6700\u5927\u53ef\u5141\u8bb8\u7684vector\u5143\u7d20\u6570\u91cf\u503c bool empty () const //\u5224\u65ad\u5411\u91cf\u662f\u5426\u4e3a\u7a7a\uff0c\u82e5\u4e3a\u7a7a\uff0c\u5219\u5411\u91cf\u4e2d\u65e0\u5143\u7d20 void swap ( vector & ) //\u4ea4\u6362\u4e24\u4e2a\u540c\u7c7b\u578b\u5411\u91cf\u7684\u6570\u636e void assign ( int n , const T & x ) //\u8bbe\u7f6e\u5411\u91cf\u4e2d\u524dn\u4e2a\u5143\u7d20\u7684\u503c\u4e3ax void assign ( const_iterator first , const_iterator last ) //\u5411\u91cf\u4e2d[first,last)\u4e2d\u5143\u7d20\u8bbe\u7f6e\u6210\u5f53\u524d\u5411\u91cf\u5143\u7d20 stack \u00b6 \\(include<stack>\\) \u6784\u9020\u51fd\u6570 list < int > c0 //\u7a7a\u94fe\u8868 list < int > c1 ( 3 ) //\u5efa\u4e00\u4e2a\u542b3\u4e2a\u9ed8\u8ba4\u503c\u662f0\u7684\u5143\u7d20\u7684\u94fe\u8868 list < int > c2 ( 5 , 2 ) //\u5efa\u4e00\u4e2a\u542b5\u4e2a\u5143\u7d20\u7684\u94fe\u8868\uff0c\u503c\u90fd\u662f2 list < int > c4 ( c2 ) //\u590d\u5236 list < int > c5 ( iterator beg , iterator end ) //\u533a\u95f4[beg, end)\u505a\u4e3a\u5143\u7d20\u521d\u503c push ( const T & x ) //\u5165\u6808 T pop () //\u51fa\u6808 T top () //\u83b7\u53d6\u6808\u9876 bool empty () //\u5224\u65ad\u7a7a\u6808 int size () //\u8fd4\u56de\u6808\u5143\u7d20\u4e2a\u6570 list \u00b6 \\(include <list>\\) \u6784\u9020\u51fd\u6570 c1 = c2 //\u590d\u5236 assign ( n , elem ) //\u8d4b\u503cn\u4e2aelem assign ( beg , end ) //\u533a\u95f4[beg,end\uff09\u5185\u7684\u5143\u7d20\u8d4b\u503c\u7ed9c swap ( c1 , c2 ) //\u4ea4\u6362 \u589e\u52a0\u5143\u7d20 push_front () //\u9996\u52a0 push_back () //\u5c3e\u52a0 insert ( pos , num ) //\u5728pos\u4f4d\u7f6e\u63d2\u5165\u5143\u7d20num\uff0c\u8fd4\u56de\u65b0\u5143\u7d20\u4f4d\u7f6e insert ( pos , n , elem ) //\u5728pos\u4f4d\u7f6e\u4e0a\u63d2\u5165n\u4e2aelem\u526f\u672c\uff0c\u65e0\u8fd4\u56de\u503c insert ( pos , beg , end ) //\u5728pos\u4f4d\u7f6e\u4e0a\u63d2\u5165\u533a\u95f4[beg,end)\u5185\u7684\u6240\u6709\u5143\u7d20\u7684\u526f\u672c\uff0c\u6ca1\u6709\u8fd4\u56de\u503c \u5220\u9664\u5143\u7d20 pop_front () //\u9996\u5220 pop_back () //\u5c3e\u5220 erase ( pos ) \u3000\u3000\u3000\u3000 //\u5220\u9664pos\u4f4d\u7f6e\u7684\u5143\u7d20\uff0c\u8fd4\u56de\u4e0b\u4e00\u4e2a\u5143\u7d20\u7684\u4f4d\u7f6e erase ( beg , end ) //\u79fb\u9664[beg, end)\u533a\u95f4\u5185\u7684\u6240\u6709\u5143\u7d20\uff0c\u8fd4\u56de\u4e0b\u4e00\u4e2a\u5143\u7d20\u7684\u4f4d\u7f6e remove ( num ) //\u5220\u9664\u94fe\u8868\u4e2d\u5339\u914dnum\u7684\u5143\u7d20 remove_if ( cmp ) //\u5220\u9664\u6761\u4ef6\u6ee1\u8db3\u7684\u5143\u7d20,\u53c2\u6570\u4e3a\u81ea\u5b9a\u4e49\u7684\u56de\u8c03\u51fd\u6570 clear () //\u6e05\u7a7a \u8fed\u4ee3\u5668 list < T >:: iterator it c . begin () c . end () c . rbegin () //\u9006\u5411\u94fe\u8868\u7684\u7b2c\u4e00\u4e2a\u5143\u7d20,\u5373c\u94fe\u8868\u7684\u6700\u540e\u4e00\u4e2a\u6570\u636e\u3002 c . rend () //\u8fd4\u56de\u9006\u5411\u94fe\u8868\u7684\u6700\u540e\u4e00\u4e2a\u5143\u7d20\u7684\u4e0b\u4e00\u4e2a\u4f4d\u7f6e,\u5373c\u94fe\u8868\u7684\u7b2c\u4e00\u4e2a\u6570\u636e\u518d\u5f80\u524d\u7684\u4f4d\u7f6e\u3002it++ \u5176\u4ed6 T front () //\u9996\u5143\u7d20 T back () //\u5c3e\u5143 bool empty () //\u5224\u65ad\u662f\u5426\u4e3a\u7a7a int size () //\u6709\u6548\u5143\u7d20\u4e2a\u6570 int max_size () //\u8fd4\u56de\u5bb9\u5668\u6700\u5927\u7684\u53ef\u4ee5\u5b58\u50a8\u7684\u5143\u7d20 bool c1 == c2 //\u6bd4\u8f83 sort () //\u5355\u94fe\u8868\u6392\u5e8f unique () //\u53bb\u91cd\uff0c\u8981\u5148\u6392\u5e8f c1 . merge ( c2 ) //\u5408\u5e762\u4e2a\u6709\u5e8f\u7684\u94fe\u8868\u5e76\u4f7f\u4e4b\u6709\u5e8f,\u4ece\u65b0\u653e\u5230c1\u91cc,\u91ca\u653ec2 c1 . merge ( c2 , cmp ) //\u5408\u5e762\u4e2a\u6709\u5e8f\u7684\u94fe\u8868\u5e76\u4f7f\u4e4b\u6309\u7167\u81ea\u5b9a\u4e49\u89c4\u5219\u6392\u5e8f\u4e4b\u540e\u4ece\u65b0\u653e\u5230c1\u4e2d,\u91ca\u653ec2 reverse () //\u53cd\u8f6c resize ( int ) //\u91cd\u7f6e\u6709\u6548\u5143\u7d20\u4e2a\u6570 set \u00b6 \\(include<set>\\) \u5e73\u8861\u4e8c\u53c9\u641c\u7d22\u6811\uff0c\u4e0d\u4f1a\u5b58\u50a8\u91cd\u590d\u7684\u5143\u7d20 \u6784\u9020\u51fd\u6570 swap ( set , set ) // \u4ea4\u6362\u4e24\u4e2a\u96c6\u5408\u53d8\u91cf s1 = s2 \u589e\u52a0\u5143\u7d20 insert ( T ) // \u5728\u96c6\u5408\u4e2d\u63d2\u5165\u5143\u7d20 \u5220\u9664\u5143\u7d20 clear () // \u6e05\u9664\u6240\u6709\u5143\u7d20 erase ( T ) // \u5220\u9664\u96c6\u5408\u4e2d\u7684\u5143\u7d20 \u8fed\u4ee3\u5668 set < T >:: iterator it begin () // \u8fd4\u56de\u6307\u5411\u9996\u5143\u7d20\u7684\u8fed\u4ee3\u5668 end () // \u8fd4\u56de\u6307\u5411\u5c3e\u5143\u7d20\u7684\u540e\u4e00\u4f4d\u7684\u8fed\u4ee3\u5668 rbegin () // \u53cd\u5411\u8fed\u4ee3\u5668 rend () // \u5176\u4ed6 int count ( T ) // \u8fd4\u56de\u67d0\u4e2a\u5143\u7d20\u7684\u4e2a\u6570,0\u62161\uff0c\u53ea\u80fd\u5224\u65ad\u662f\u5426\u5b58\u5728 bool empty () // \u5224\u65ad\u96c6\u5408\u4e3a\u7a7a int size () // \u96c6\u5408\u4e2d\u5143\u7d20\u7684\u6570\u76ee max_size () // \u8fd4\u56de\u96c6\u5408\u80fd\u5bb9\u7eb3\u7684\u5143\u7d20\u7684\u6700\u5927\u9650\u503c iterator find ( T ) // \u8fd4\u56de\u4e00\u4e2a\u6307\u5411\u88ab\u67e5\u627e\u5230\u5143\u7d20\u7684\u8fed\u4ee3\u5668,\u65e0\u5219\u8fd4\u56deend() iterator lower_bound ( T ) // \u8fd4\u56de\u6307\u5411\u5927\u4e8e\u6216\u7b49\u4e8e\u67d0\u503c\u7684\u7b2c\u4e00\u4e2a\u5143\u7d20\u7684\u8fed\u4ee3\u5668 iterator upper_bound ( T ) // \u8fd4\u56de\u5927\u4e8e\u67d0\u4e2a\u503c\u5143\u7d20\u7684\u8fed\u4ee3\u5668 pair \u00b6 \\(include<utility>\\) \u4e24\u4efb\u610f\u7c7b\u578b\u5143\u7d20\u7684\u7ed3\u6784\u4f53 pair < int , double > p1 ; //\u9ed8\u8ba4\u6784\u9020\u51fd\u6570 pair < int , double > p1 ( 1 , 1.1 ); //\u542b\u53c2\u6784\u9020\u51fd\u6570 pair < int , double > p1 ( p2 ); //\u62f7\u8d1d\u6784\u9020\u51fd\u6570 p1 = p2 p1 . first //\u83b7\u53d6 \u7b2c\u4e00\u4e2a\u5143\u7d20 p1 . second //\u83b7\u53d6 \u7b2c\u4e8c\u4e2a\u5143\u7d20 p1 < p2 //\u53ef\u4ee5\u76f4\u63a5\u6bd4\u8f83,\u5148\u6bd4\u8f83first\uff0c\u518d\u6bd4\u8f83second map \u00b6 \\(include<map>\\) \u5efa\u7acbKey\uff0dvalue\u7684\u5bf9\u5e94\uff0ckey \u548c value \u53ef\u4ee5\u662f\u4efb\u610f\u7c7b\u578b\u3002 \u6784\u9020\u51fd\u6570 map < int , string > m1 ; //\u7d22\u5f15\u4e3a int\u578b map < string , int > m2 ; //\u7d22\u5f15\u4e3a string \u589e\u52a0\u5143\u7d20 insert ( pair < int , string > ( 1 , \"string1\" )) //\u8fd9\u91cc\u7684\u5143\u7d20\u53ef\u4ee5\u662f\u5143\u7d20\u7c7b\u578b\u4e0e\u58f0\u660e\u5339\u914d\u76842\u5143\u7d20\u7ed3\u6784\u4f53\u6216\u8005pair\uff0cinsert\u4e0d\u80fd\u8986\u76d6\u539f\u503c map < int , string > m1 //\u6570\u7ec4\u53ef\u4ee5\u8986\u76d6\u539f\u503c m1 [ 1 ] = \"string1\" //\u5982\u679c\u6ca1\u6709\u5bf9\u5e94 key \u503c\u4f1a\u81ea\u52a8\u6dfb\u52a0 m1 [ 2 ] = \"string2\" map < string , int > m2 m2 [ \"string1\" ] = 1 m2 [ \"string2\" ] = 2 \u5220\u9664\u5143\u7d20 erase ( iter ) erase ( iterator first , iterator second ) //\u5220\u9664\u8303\u56f4 clear ( \uff09 //\u5220\u9664\u6240\u6709\u5143\u7d20 \u8fed\u4ee3\u5668 iterator begin () iterator end () iterator rbegin () //\u8fd4\u56de\u4e00\u4e2a\u6307\u5411map\u5c3e\u90e8\u7684\u9006\u5411\u8fed\u4ee3\u5668 iterator rend () //\u8fd4\u56de\u4e00\u4e2a\u6307\u5411map\u5934\u90e8\u7684\u9006\u5411\u8fed\u4ee3\u5668 map < int , string >:: iterator iter ; for ( iter = m1 . begin (); iter != m1 . end (); iter ++ ) //\u904d\u5386 cout << iter -> first << ' ' << iter -> second << endl ; \u5176\u4ed6 int size () // \u83b7\u53d6\u5927\u5c0f iterator find ( T ) // T \u662f value \u7c7b\u578b\uff0c\u6ca1\u627e\u5230\u8fd4\u56de end() swap ( m1 [ key1 ], m1 [ key2 ]) //\u4ea4\u6362 value bool empty () //\u5982\u679cmap\u4e3a\u7a7a\u5219\u8fd4\u56detrue int count () //\u8fd4\u56de\u6307\u5b9a\u5143\u7d20\u51fa\u73b0\u7684\u6b21\u6570 queue \u00b6 \\(include<queue>\\) \u5148\u8fdb\u5148\u51fa\uff08FIFO\uff09\uff0c\u53ea\u80fd\u5c3e\u52a0\u548c\u9996\u5220\uff0c\u53ea\u80fd\u8bbf\u95ee\u961f\u9996\u548c\u961f\u5c3e\u5143\u7d20\uff0c bool empty () //\u961f\u5217\u4e3a\u7a7a\u8fd4\u56de\u771f T front () //\u8fd4\u56de\u7b2c\u4e00\u4e2a\u5143\u7d20 T back () //\u8fd4\u56de\u6700\u540e\u4e00\u4e2a\u5143\u7d20 int size () //\u8fd4\u56de\u5143\u7d20\u4e2a\u6570 push () //\u961f\u5c3e\u52a0\u5165\u5143\u7d20 pop () //\u5220\u9664\u961f\u9996\u5143\u7d20 swap () //\u4ea4\u6362\u5185\u5bb9 \u6e05\u7a7a\u961f\u5217\u7684\u4e09\u79cd\u65b9\u6cd5\uff08\u6ca1\u6709clear\u64cd\u4f5c\uff09 //\u7528\u7a7a\u961f\u5217\u8d4b\u503c q1 = queue < T > (); //\u4e0d\u65ad\u9996\u5220 while ( ! q . empty ()) q . pop (); //\u81ea\u5df1\u5b9a\u4e49clear void clear ( queue < T >& q ){ queue < T > empty ; swap ( empty , q ); } priority_queue \u00b6 \\(include<queue>\\) \u9ed8\u8ba4\u5927\u6839\u5806 priority_queue \u6570\u636e\u7c7b\u578b \u5bb9\u5668 \u6bd4\u8f83\u65b9\u5f0f \u5176\u4e2d Container\u9700\u8981\u7528\u6570\u7ec4\u5b9e\u73b0\u7684\u5bb9\u5668 \u58f0\u660e priority_queue < T > p ; priority_queue < int , vector < int > , greater < int > > p ; //\u5c0f\u6839\u5806 \u5728sort\u91ccgreater\u662f\u4ece\u5927\u5230\u5c0f priority_queue < int , vector < int > , less < int > > p ; //\u5927\u6839\u5806 /*\u81ea\u5b9a\u4e49\u4f18\u5148\u7ea7\u76842\u79cd\u65b9\u5f0f*/ // struct node { \u3000\u3000 int x ; \u3000\u3000 bool operator < ( const node & a ) const { \u3000\u3000\u3000\u3000 return a . x < x ; //\u5c0f\u6839\u5806 \u3000\u3000 } }; priority_queue < node > p ; // struct cmp { \u3000\u3000 bool operator ()( int x , int y ) { \u3000\u3000\u3000\u3000 return \u3000 x > y ; //\u5c0f\u6839\u5806 \u3000\u3000 } }; priority_queue < int , vector < int > , cmp > q ; \u6210\u5458\u51fd\u6570 top () //\u8bbf\u95ee\u961f\u5934\u5143\u7d20 empty () //\u961f\u5217\u662f\u5426\u4e3a\u7a7a size () //\u8fd4\u56de\u961f\u5217\u5185\u5143\u7d20\u4e2a\u6570 push () //\u961f\u5c3e\u52a0\u5165\u5143\u7d20\uff08\u5e76\u6392\u5e8f\uff09 pop () //\u5f39\u51fa\u961f\u9876\u5143\u7d20 swap () //\u4ea4\u6362\u5185\u5bb9 deque \u00b6 \\(include<queue>\\) \u6784\u9020\u51fd\u6570 deque < T > deq ; //\u7a7adeque deque ( n ) //\u5143\u7d20\u4e2a\u6570\u4e3an deque ( n , elem ) //\u5143\u7d20\u4e2a\u6570\u4e3an,\u4e14\u503c\u5747\u4e3aelem deque ( beg , end ) //[beg, end) deque ( const deque & deq ) //\u590d\u5236\u6784\u9020\u51fd\u6570 \u589e\u52a0\u51fd\u6570 void push_front ( elem ) //\u5934\u63d2 void push_back ( elem ) //\u5c3e\u63d2 ? insert ( pos , elem ) //\u67d0\u4e00\u5143\u7d20\u524d\u589e\u52a0\u4e00\u4e2a\u5143\u7d20x void insert ( pos , n , elem ) //\u67d0\u4e00\u5143\u7d20\u524d\u589e\u52a0n\u4e2a\u76f8\u540c\u7684\u5143\u7d20x void insert ( pos , beg , endt ) //\u67d0\u4e00\u5143\u7d20\u524d\u63d2\u5165\u53e6\u4e00\u4e2a\u76f8\u540c\u7c7b\u578b\u5411\u91cf\u7684[forst,last)\u95f4\u7684\u6570\u636e \u5220\u9664\u51fd\u6570 ? erase ( pos ) //\u5220\u9664\u67d0\u4e00\u4e2a\u5143\u7d20,\u8fd4\u56de\u4e0b\u4e00\u4e2a\u5143\u7d20\u4f4d\u7f6e ? erase ( beg , end ) //\u5220\u9664[first,last\uff09\u4e2d\u7684\u5143\u7d20,\u8fd4\u56de\u4e0b\u4e00\u4e2a\u5143\u7d20\u4f4d\u7f6e void pop_front () //\u5934\u5220 void pop_back () //\u5c3e\u5220 void clear () \u904d\u5386\u51fd\u6570 reference at ( pos ) //\u8fd4\u56depos\u4f4d\u7f6e\u5143\u7d20\u7684\u5f15\u7528 reference front () //\u8fd4\u56de\u9996\u5143\u7d20\u7684\u5f15\u7528 reference back () //\u8fd4\u56de\u5c3e\u5143\u7d20\u7684\u5f15\u7528 iterator begin () //\u8fd4\u56de\u5934\u8fed\u4ee3\u5668 iterator end () //\u8fd4\u56de\u5c3e\u8fed\u4ee3\u5668\uff08\u6700\u540e\u4e00\u4e2a\u5143\u7d20\u7684\u4e0b\u4e00\u4e2a reverse_iterator rbegin () //\u53cd\u5411\u8fed\u4ee3\u5668\uff0c\u6307\u5411\u6700\u540e\u4e00\u4e2a\u5143\u7d20 reverse_iterator rend () //\u53cd\u5411\u8fed\u4ee3\u5668\uff0c\u6307\u5411\u7b2c\u4e00\u4e2a\u5143\u7d20\u7684\u524d\u4e00\u4e2a\u5143\u7d20 \u5176\u4ed6\u51fd\u6570 bool empty () //\u5411\u91cf\u662f\u5426\u4e3a\u7a7a int size () //\u8fd4\u56de\u5143\u7d20\u7684\u4e2a\u6570 int max_size () //\u8fd4\u56de\u6700\u5927\u53ef\u5141\u8bb8\u7684\u5143\u7d20\u6570\u91cf void swap ( deque & ) //\u4ea4\u6362\u4e24\u4e2a\u540c\u7c7b\u578bdeque\u7684\u6570\u636e void assign ( beg , end ) //\u5c06[beg, end)\u533a\u95f4\u4e2d\u7684\u6570\u636e\u62f7\u8d1d\u8d4b\u503c\u7ed9\u672c\u8eab\u3002 void assign ( n , elem ) //\u5c06n\u4e2aelem\u62f7\u8d1d\u8d4b\u503c\u7ed9\u672c\u8eab\u3002 algorithm \u00b6 lower_bound() \u00b6 \u4e8c\u5206\u67e5\u627e \u5bf9\u4e8e\u5347\u5e8f\u6570\u7ec4\uff1a lower_bound( begin, end, num)\uff1a\u67e5\u627e\u7b2c\u4e00\u4e2a \u5927\u4e8e\u7b49\u4e8e num \u7684\u6570\u5e76\u8fd4\u56de\u5176\u5730\u5740\uff0c\u4e0d\u5b58\u5728\u8fd4\u56deend\u3002\u8fd4\u56de\u503c\u51cf\u53bbbegine\u5373\u7d22\u5f15\u4e0b\u6807 upper_bound( begin, end, num)\uff1a \u5927\u4e8e \u5bf9\u4e8e\u964d\u5e8f\u6570\u7ec4\uff1a\u9700\u8981\u91cd\u8f7d //\u5347\u5e8f a\u6570\u7ec4\u4e2d k \u7684\u4e2a\u6570 upper_bound ( a , a + n , k ) - lower_bound ( a , a + n , k ); next_permutation \u00b6 //\u6c42\u6309\u7167\u5b57\u5178\u5e8f\u7684\u5168\u6392\u5217 int a [ 4 ] = { 1 , 2 , 3 , 4 }; while ( next_permutation ( a , a + 4 )) { for ( int i = 0 ; i < 4 ; i ++ ) cout << a [ i ] << \" \" ; cout << endl ; } min_element/max_element \u00b6 int maxx = * max_element ( a , a + n );","title":"STL"},{"location":"OI/STL/#stl","text":"","title":"STL"},{"location":"OI/STL/#string","text":"\u5b57\u7b26\u4e32 \u6784\u9020\u51fd\u6570 string s = \"\" s1 = s2 \u589e\u52a0\u5143\u7d20 s += s2 //\u76f4\u63a5\u7528 + \u5373\u53ef s += \"new string\" \u5220\u9664\u5143\u7d20 string & erase ( size_t pos = 0 , size_t n ) //\u5220\u9664\u4ecepos\u5f00\u59cb\u7684n\u4e2a\u5b57\u7b26 iterator erase ( iterator ) //\u5220\u9664\u4e00\u4e2a iterator erase ( iterator first , iterator last ) //\u5220\u9664\u8303\u56f4 iterator erase ( remove ( str . begin (), str . end (), 'a' ), str . end ()) //\u5220\u9664\u7279\u5b9a\u5b57\u7b26 \u8fed\u4ee3\u5668 iterator begin (); //\u5934\u8fed\u4ee3\u5668 iterator end (); //\u5c3e\u8fed\u4ee3\u5668 \u5176\u4ed6 sort ( string , iterator l , iterator r ) //\u6392\u5e8f [l, r) string substr ( int pos , int n ) //\u83b7\u53d6\u8fde\u7eed\u5b50\u4e32\uff0c\u4ece pos \u5f00\u59cb\u7684 n \u4e2a\u5b57\u7b26\uff0c-1\u8868\u793a\u5230\u6700\u540e bool empty () //\u5224\u65ad\u662f\u5426\u4e3a\u7a7a int size () //\u5b57\u7b26\u4e2a\u6570 bool isalnum ( char ) //\u5982\u679cc\u662f\u5b57\u6bcd\u6216\u6570\u5b57\uff0c\u8fd4\u56de true bool isalpha ( char ) //\u5982\u679cc\u662f\u5b57\u6bcd\uff0c\u8fd4\u56detrue bool iscntrl ( char ) //\u5982\u679cc\u662f\u63a7\u5236\u7b26\uff0c\u8fd4\u56detrue bool isdigit ( char ) //\u5982\u679cc\u662f\u6570\u5b57\uff0c\u8fd4\u56detrue bool isgraph ( char ) //\u5982\u679cc\u4e0d\u662f\u7a7a\u683c\uff0c\u8fd4\u56de\u4e3atrue bool islower ( char ) //\u5982\u679cc\u662f\u5c0f\u5199\u5b57\u6bcd\uff0c\u8fd4\u56de\u4e3atrue bool isupper ( char ) //\u5982\u679cc\u662f\u5927\u5199\u5b57\u7b26\uff0c\u8fd4\u56de\u4e3atrue bool isprint ( char ) //\u5982\u679cc\u662f\u53ef\u6253\u5370\u7684\u5b57\u7b26\uff0c\u8fd4\u56de\u4e3atrue bool ispunct ( char ) //\u5982\u679cc\u662f\u6807\u70b9\u7b26\u53f7\uff0c\u8fd4\u56de\u4e3atrue bool isspace ( char ) //\u5982\u679cc\u662f\u7a7a\u767d\u5b57\u7b26\uff0c\u8fd4\u56de\u4e3atrue bool isxdigit ( char ) //\u5982\u679cc\u662f\u5341\u516d\u8fdb\u5236\u6570\uff0c\u8fd4\u56de\u4e3atrue","title":"string"},{"location":"OI/STL/#vector","text":"\\(include<vector>\\) \u6784\u9020\u51fd\u6570 vector () //\u521b\u5efa\u4e00\u4e2a\u7a7avector vector ( int nSize ) //\u521b\u5efa\u4e00\u4e2avector,\u5143\u7d20\u4e2a\u6570\u4e3anSize vector ( int nSize , const T & t ) //\u521b\u5efa\u4e00\u4e2avector\uff0c\u5143\u7d20\u4e2a\u6570\u4e3anSize,\u4e14\u503c\u5747\u4e3at vector ( const vector & ) //\u590d\u5236\u6784\u9020\u51fd\u6570 vector ( begin , end ) //\u590d\u5236[begin,end)\u533a\u95f4\u5185\u53e6\u4e00\u4e2a\u6570\u7ec4\u7684\u5143\u7d20\u5230vector\u4e2d \u589e\u52a0\u5143\u7d20 void push_back ( const T & x ) //\u5411\u91cf\u5c3e\u90e8\u589e\u52a0\u4e00\u4e2a\u5143\u7d20X iterator insert ( iterator it , const T & x ) //\u8fed\u4ee3\u5668\u6307\u5411\u5143\u7d20\u524d\u589e\u52a0\u4e00\u4e2a\u5143\u7d20x iterator insert ( iterator it , int n , const T & x ) //\u8fed\u4ee3\u5668\u6307\u5411\u5143\u7d20\u524d\u589e\u52a0n\u4e2a\u76f8\u540c\u7684\u5143\u7d20x iterator insert ( iterator it , iterator first , iterator last ) //\u8fed\u4ee3\u5668\u6307\u5411\u5143\u7d20\u524d\u63d2\u5165\u53e6\u4e00\u4e2a\u5411\u91cf\u7684[first,last)\u7684\u6570\u636e \u5220\u9664\u5143\u7d20 iterator erase ( iterator it ) //\u5220\u9664\u8fed\u4ee3\u5668\u6307\u5411\u5143\u7d20 iterator erase ( iterator first , iterator last ) //\u5220\u9664[first,last)\u4e2d\u5143\u7d20 void pop_back () //\u5220\u9664\u5411\u91cf\u4e2d\u6700\u540e\u4e00\u4e2a\u5143\u7d20 void clear () //\u6e05\u7a7a\u5411\u91cf\u4e2d\u6240\u6709\u5143\u7d20 \u8fed\u4ee3\u5668 reference at ( int pos ) //\u8fd4\u56depos\u4f4d\u7f6e\u5143\u7d20\u7684\u5f15\u7528 reference front () //\u8fd4\u56de\u9996\u5143\u7d20\u7684\u5f15\u7528 reference back () //\u8fd4\u56de\u5c3e\u5143\u7d20\u7684\u5f15\u7528 iterator begin () //\u8fd4\u56de\u5411\u91cf\u5934\u6307\u9488\uff0c\u6307\u5411\u7b2c\u4e00\u4e2a\u5143\u7d20 iterator end () //\u8fd4\u56de\u5411\u91cf\u5c3e\u6307\u9488\uff0c\u6307\u5411\u5411\u91cf\u6700\u540e\u4e00\u4e2a\u5143\u7d20\u7684\u4e0b\u4e00\u4e2a\u4f4d\u7f6e reverse_iterator rbegin () //\u53cd\u5411\u8fed\u4ee3\u5668\uff0c\u6307\u5411\u6700\u540e\u4e00\u4e2a\u5143\u7d20 reverse_iterator rend () //\u53cd\u5411\u8fed\u4ee3\u5668\uff0c\u6307\u5411\u7b2c\u4e00\u4e2a\u5143\u7d20\u4e4b\u524d\u7684\u4f4d\u7f6e \u5176\u4ed6 int size () const //\u8fd4\u56de\u5411\u91cf\u4e2d\u5143\u7d20\u7684\u4e2a\u6570 int capacity () const //\u8fd4\u56de\u5f53\u524d\u5411\u91cf\u6240\u80fd\u5bb9\u7eb3\u7684\u6700\u5927\u5143\u7d20\u503c int max_size () const //\u8fd4\u56de\u6700\u5927\u53ef\u5141\u8bb8\u7684vector\u5143\u7d20\u6570\u91cf\u503c bool empty () const //\u5224\u65ad\u5411\u91cf\u662f\u5426\u4e3a\u7a7a\uff0c\u82e5\u4e3a\u7a7a\uff0c\u5219\u5411\u91cf\u4e2d\u65e0\u5143\u7d20 void swap ( vector & ) //\u4ea4\u6362\u4e24\u4e2a\u540c\u7c7b\u578b\u5411\u91cf\u7684\u6570\u636e void assign ( int n , const T & x ) //\u8bbe\u7f6e\u5411\u91cf\u4e2d\u524dn\u4e2a\u5143\u7d20\u7684\u503c\u4e3ax void assign ( const_iterator first , const_iterator last ) //\u5411\u91cf\u4e2d[first,last)\u4e2d\u5143\u7d20\u8bbe\u7f6e\u6210\u5f53\u524d\u5411\u91cf\u5143\u7d20","title":"vector"},{"location":"OI/STL/#stack","text":"\\(include<stack>\\) \u6784\u9020\u51fd\u6570 list < int > c0 //\u7a7a\u94fe\u8868 list < int > c1 ( 3 ) //\u5efa\u4e00\u4e2a\u542b3\u4e2a\u9ed8\u8ba4\u503c\u662f0\u7684\u5143\u7d20\u7684\u94fe\u8868 list < int > c2 ( 5 , 2 ) //\u5efa\u4e00\u4e2a\u542b5\u4e2a\u5143\u7d20\u7684\u94fe\u8868\uff0c\u503c\u90fd\u662f2 list < int > c4 ( c2 ) //\u590d\u5236 list < int > c5 ( iterator beg , iterator end ) //\u533a\u95f4[beg, end)\u505a\u4e3a\u5143\u7d20\u521d\u503c push ( const T & x ) //\u5165\u6808 T pop () //\u51fa\u6808 T top () //\u83b7\u53d6\u6808\u9876 bool empty () //\u5224\u65ad\u7a7a\u6808 int size () //\u8fd4\u56de\u6808\u5143\u7d20\u4e2a\u6570","title":"stack"},{"location":"OI/STL/#list","text":"\\(include <list>\\) \u6784\u9020\u51fd\u6570 c1 = c2 //\u590d\u5236 assign ( n , elem ) //\u8d4b\u503cn\u4e2aelem assign ( beg , end ) //\u533a\u95f4[beg,end\uff09\u5185\u7684\u5143\u7d20\u8d4b\u503c\u7ed9c swap ( c1 , c2 ) //\u4ea4\u6362 \u589e\u52a0\u5143\u7d20 push_front () //\u9996\u52a0 push_back () //\u5c3e\u52a0 insert ( pos , num ) //\u5728pos\u4f4d\u7f6e\u63d2\u5165\u5143\u7d20num\uff0c\u8fd4\u56de\u65b0\u5143\u7d20\u4f4d\u7f6e insert ( pos , n , elem ) //\u5728pos\u4f4d\u7f6e\u4e0a\u63d2\u5165n\u4e2aelem\u526f\u672c\uff0c\u65e0\u8fd4\u56de\u503c insert ( pos , beg , end ) //\u5728pos\u4f4d\u7f6e\u4e0a\u63d2\u5165\u533a\u95f4[beg,end)\u5185\u7684\u6240\u6709\u5143\u7d20\u7684\u526f\u672c\uff0c\u6ca1\u6709\u8fd4\u56de\u503c \u5220\u9664\u5143\u7d20 pop_front () //\u9996\u5220 pop_back () //\u5c3e\u5220 erase ( pos ) \u3000\u3000\u3000\u3000 //\u5220\u9664pos\u4f4d\u7f6e\u7684\u5143\u7d20\uff0c\u8fd4\u56de\u4e0b\u4e00\u4e2a\u5143\u7d20\u7684\u4f4d\u7f6e erase ( beg , end ) //\u79fb\u9664[beg, end)\u533a\u95f4\u5185\u7684\u6240\u6709\u5143\u7d20\uff0c\u8fd4\u56de\u4e0b\u4e00\u4e2a\u5143\u7d20\u7684\u4f4d\u7f6e remove ( num ) //\u5220\u9664\u94fe\u8868\u4e2d\u5339\u914dnum\u7684\u5143\u7d20 remove_if ( cmp ) //\u5220\u9664\u6761\u4ef6\u6ee1\u8db3\u7684\u5143\u7d20,\u53c2\u6570\u4e3a\u81ea\u5b9a\u4e49\u7684\u56de\u8c03\u51fd\u6570 clear () //\u6e05\u7a7a \u8fed\u4ee3\u5668 list < T >:: iterator it c . begin () c . end () c . rbegin () //\u9006\u5411\u94fe\u8868\u7684\u7b2c\u4e00\u4e2a\u5143\u7d20,\u5373c\u94fe\u8868\u7684\u6700\u540e\u4e00\u4e2a\u6570\u636e\u3002 c . rend () //\u8fd4\u56de\u9006\u5411\u94fe\u8868\u7684\u6700\u540e\u4e00\u4e2a\u5143\u7d20\u7684\u4e0b\u4e00\u4e2a\u4f4d\u7f6e,\u5373c\u94fe\u8868\u7684\u7b2c\u4e00\u4e2a\u6570\u636e\u518d\u5f80\u524d\u7684\u4f4d\u7f6e\u3002it++ \u5176\u4ed6 T front () //\u9996\u5143\u7d20 T back () //\u5c3e\u5143 bool empty () //\u5224\u65ad\u662f\u5426\u4e3a\u7a7a int size () //\u6709\u6548\u5143\u7d20\u4e2a\u6570 int max_size () //\u8fd4\u56de\u5bb9\u5668\u6700\u5927\u7684\u53ef\u4ee5\u5b58\u50a8\u7684\u5143\u7d20 bool c1 == c2 //\u6bd4\u8f83 sort () //\u5355\u94fe\u8868\u6392\u5e8f unique () //\u53bb\u91cd\uff0c\u8981\u5148\u6392\u5e8f c1 . merge ( c2 ) //\u5408\u5e762\u4e2a\u6709\u5e8f\u7684\u94fe\u8868\u5e76\u4f7f\u4e4b\u6709\u5e8f,\u4ece\u65b0\u653e\u5230c1\u91cc,\u91ca\u653ec2 c1 . merge ( c2 , cmp ) //\u5408\u5e762\u4e2a\u6709\u5e8f\u7684\u94fe\u8868\u5e76\u4f7f\u4e4b\u6309\u7167\u81ea\u5b9a\u4e49\u89c4\u5219\u6392\u5e8f\u4e4b\u540e\u4ece\u65b0\u653e\u5230c1\u4e2d,\u91ca\u653ec2 reverse () //\u53cd\u8f6c resize ( int ) //\u91cd\u7f6e\u6709\u6548\u5143\u7d20\u4e2a\u6570","title":"list"},{"location":"OI/STL/#set","text":"\\(include<set>\\) \u5e73\u8861\u4e8c\u53c9\u641c\u7d22\u6811\uff0c\u4e0d\u4f1a\u5b58\u50a8\u91cd\u590d\u7684\u5143\u7d20 \u6784\u9020\u51fd\u6570 swap ( set , set ) // \u4ea4\u6362\u4e24\u4e2a\u96c6\u5408\u53d8\u91cf s1 = s2 \u589e\u52a0\u5143\u7d20 insert ( T ) // \u5728\u96c6\u5408\u4e2d\u63d2\u5165\u5143\u7d20 \u5220\u9664\u5143\u7d20 clear () // \u6e05\u9664\u6240\u6709\u5143\u7d20 erase ( T ) // \u5220\u9664\u96c6\u5408\u4e2d\u7684\u5143\u7d20 \u8fed\u4ee3\u5668 set < T >:: iterator it begin () // \u8fd4\u56de\u6307\u5411\u9996\u5143\u7d20\u7684\u8fed\u4ee3\u5668 end () // \u8fd4\u56de\u6307\u5411\u5c3e\u5143\u7d20\u7684\u540e\u4e00\u4f4d\u7684\u8fed\u4ee3\u5668 rbegin () // \u53cd\u5411\u8fed\u4ee3\u5668 rend () // \u5176\u4ed6 int count ( T ) // \u8fd4\u56de\u67d0\u4e2a\u5143\u7d20\u7684\u4e2a\u6570,0\u62161\uff0c\u53ea\u80fd\u5224\u65ad\u662f\u5426\u5b58\u5728 bool empty () // \u5224\u65ad\u96c6\u5408\u4e3a\u7a7a int size () // \u96c6\u5408\u4e2d\u5143\u7d20\u7684\u6570\u76ee max_size () // \u8fd4\u56de\u96c6\u5408\u80fd\u5bb9\u7eb3\u7684\u5143\u7d20\u7684\u6700\u5927\u9650\u503c iterator find ( T ) // \u8fd4\u56de\u4e00\u4e2a\u6307\u5411\u88ab\u67e5\u627e\u5230\u5143\u7d20\u7684\u8fed\u4ee3\u5668,\u65e0\u5219\u8fd4\u56deend() iterator lower_bound ( T ) // \u8fd4\u56de\u6307\u5411\u5927\u4e8e\u6216\u7b49\u4e8e\u67d0\u503c\u7684\u7b2c\u4e00\u4e2a\u5143\u7d20\u7684\u8fed\u4ee3\u5668 iterator upper_bound ( T ) // \u8fd4\u56de\u5927\u4e8e\u67d0\u4e2a\u503c\u5143\u7d20\u7684\u8fed\u4ee3\u5668","title":"set"},{"location":"OI/STL/#pair","text":"\\(include<utility>\\) \u4e24\u4efb\u610f\u7c7b\u578b\u5143\u7d20\u7684\u7ed3\u6784\u4f53 pair < int , double > p1 ; //\u9ed8\u8ba4\u6784\u9020\u51fd\u6570 pair < int , double > p1 ( 1 , 1.1 ); //\u542b\u53c2\u6784\u9020\u51fd\u6570 pair < int , double > p1 ( p2 ); //\u62f7\u8d1d\u6784\u9020\u51fd\u6570 p1 = p2 p1 . first //\u83b7\u53d6 \u7b2c\u4e00\u4e2a\u5143\u7d20 p1 . second //\u83b7\u53d6 \u7b2c\u4e8c\u4e2a\u5143\u7d20 p1 < p2 //\u53ef\u4ee5\u76f4\u63a5\u6bd4\u8f83,\u5148\u6bd4\u8f83first\uff0c\u518d\u6bd4\u8f83second","title":"pair"},{"location":"OI/STL/#map","text":"\\(include<map>\\) \u5efa\u7acbKey\uff0dvalue\u7684\u5bf9\u5e94\uff0ckey \u548c value \u53ef\u4ee5\u662f\u4efb\u610f\u7c7b\u578b\u3002 \u6784\u9020\u51fd\u6570 map < int , string > m1 ; //\u7d22\u5f15\u4e3a int\u578b map < string , int > m2 ; //\u7d22\u5f15\u4e3a string \u589e\u52a0\u5143\u7d20 insert ( pair < int , string > ( 1 , \"string1\" )) //\u8fd9\u91cc\u7684\u5143\u7d20\u53ef\u4ee5\u662f\u5143\u7d20\u7c7b\u578b\u4e0e\u58f0\u660e\u5339\u914d\u76842\u5143\u7d20\u7ed3\u6784\u4f53\u6216\u8005pair\uff0cinsert\u4e0d\u80fd\u8986\u76d6\u539f\u503c map < int , string > m1 //\u6570\u7ec4\u53ef\u4ee5\u8986\u76d6\u539f\u503c m1 [ 1 ] = \"string1\" //\u5982\u679c\u6ca1\u6709\u5bf9\u5e94 key \u503c\u4f1a\u81ea\u52a8\u6dfb\u52a0 m1 [ 2 ] = \"string2\" map < string , int > m2 m2 [ \"string1\" ] = 1 m2 [ \"string2\" ] = 2 \u5220\u9664\u5143\u7d20 erase ( iter ) erase ( iterator first , iterator second ) //\u5220\u9664\u8303\u56f4 clear ( \uff09 //\u5220\u9664\u6240\u6709\u5143\u7d20 \u8fed\u4ee3\u5668 iterator begin () iterator end () iterator rbegin () //\u8fd4\u56de\u4e00\u4e2a\u6307\u5411map\u5c3e\u90e8\u7684\u9006\u5411\u8fed\u4ee3\u5668 iterator rend () //\u8fd4\u56de\u4e00\u4e2a\u6307\u5411map\u5934\u90e8\u7684\u9006\u5411\u8fed\u4ee3\u5668 map < int , string >:: iterator iter ; for ( iter = m1 . begin (); iter != m1 . end (); iter ++ ) //\u904d\u5386 cout << iter -> first << ' ' << iter -> second << endl ; \u5176\u4ed6 int size () // \u83b7\u53d6\u5927\u5c0f iterator find ( T ) // T \u662f value \u7c7b\u578b\uff0c\u6ca1\u627e\u5230\u8fd4\u56de end() swap ( m1 [ key1 ], m1 [ key2 ]) //\u4ea4\u6362 value bool empty () //\u5982\u679cmap\u4e3a\u7a7a\u5219\u8fd4\u56detrue int count () //\u8fd4\u56de\u6307\u5b9a\u5143\u7d20\u51fa\u73b0\u7684\u6b21\u6570","title":"map"},{"location":"OI/STL/#queue","text":"\\(include<queue>\\) \u5148\u8fdb\u5148\u51fa\uff08FIFO\uff09\uff0c\u53ea\u80fd\u5c3e\u52a0\u548c\u9996\u5220\uff0c\u53ea\u80fd\u8bbf\u95ee\u961f\u9996\u548c\u961f\u5c3e\u5143\u7d20\uff0c bool empty () //\u961f\u5217\u4e3a\u7a7a\u8fd4\u56de\u771f T front () //\u8fd4\u56de\u7b2c\u4e00\u4e2a\u5143\u7d20 T back () //\u8fd4\u56de\u6700\u540e\u4e00\u4e2a\u5143\u7d20 int size () //\u8fd4\u56de\u5143\u7d20\u4e2a\u6570 push () //\u961f\u5c3e\u52a0\u5165\u5143\u7d20 pop () //\u5220\u9664\u961f\u9996\u5143\u7d20 swap () //\u4ea4\u6362\u5185\u5bb9 \u6e05\u7a7a\u961f\u5217\u7684\u4e09\u79cd\u65b9\u6cd5\uff08\u6ca1\u6709clear\u64cd\u4f5c\uff09 //\u7528\u7a7a\u961f\u5217\u8d4b\u503c q1 = queue < T > (); //\u4e0d\u65ad\u9996\u5220 while ( ! q . empty ()) q . pop (); //\u81ea\u5df1\u5b9a\u4e49clear void clear ( queue < T >& q ){ queue < T > empty ; swap ( empty , q ); }","title":"queue"},{"location":"OI/STL/#priority_queue","text":"\\(include<queue>\\) \u9ed8\u8ba4\u5927\u6839\u5806 priority_queue \u6570\u636e\u7c7b\u578b \u5bb9\u5668 \u6bd4\u8f83\u65b9\u5f0f \u5176\u4e2d Container\u9700\u8981\u7528\u6570\u7ec4\u5b9e\u73b0\u7684\u5bb9\u5668 \u58f0\u660e priority_queue < T > p ; priority_queue < int , vector < int > , greater < int > > p ; //\u5c0f\u6839\u5806 \u5728sort\u91ccgreater\u662f\u4ece\u5927\u5230\u5c0f priority_queue < int , vector < int > , less < int > > p ; //\u5927\u6839\u5806 /*\u81ea\u5b9a\u4e49\u4f18\u5148\u7ea7\u76842\u79cd\u65b9\u5f0f*/ // struct node { \u3000\u3000 int x ; \u3000\u3000 bool operator < ( const node & a ) const { \u3000\u3000\u3000\u3000 return a . x < x ; //\u5c0f\u6839\u5806 \u3000\u3000 } }; priority_queue < node > p ; // struct cmp { \u3000\u3000 bool operator ()( int x , int y ) { \u3000\u3000\u3000\u3000 return \u3000 x > y ; //\u5c0f\u6839\u5806 \u3000\u3000 } }; priority_queue < int , vector < int > , cmp > q ; \u6210\u5458\u51fd\u6570 top () //\u8bbf\u95ee\u961f\u5934\u5143\u7d20 empty () //\u961f\u5217\u662f\u5426\u4e3a\u7a7a size () //\u8fd4\u56de\u961f\u5217\u5185\u5143\u7d20\u4e2a\u6570 push () //\u961f\u5c3e\u52a0\u5165\u5143\u7d20\uff08\u5e76\u6392\u5e8f\uff09 pop () //\u5f39\u51fa\u961f\u9876\u5143\u7d20 swap () //\u4ea4\u6362\u5185\u5bb9","title":"priority_queue"},{"location":"OI/STL/#deque","text":"\\(include<queue>\\) \u6784\u9020\u51fd\u6570 deque < T > deq ; //\u7a7adeque deque ( n ) //\u5143\u7d20\u4e2a\u6570\u4e3an deque ( n , elem ) //\u5143\u7d20\u4e2a\u6570\u4e3an,\u4e14\u503c\u5747\u4e3aelem deque ( beg , end ) //[beg, end) deque ( const deque & deq ) //\u590d\u5236\u6784\u9020\u51fd\u6570 \u589e\u52a0\u51fd\u6570 void push_front ( elem ) //\u5934\u63d2 void push_back ( elem ) //\u5c3e\u63d2 ? insert ( pos , elem ) //\u67d0\u4e00\u5143\u7d20\u524d\u589e\u52a0\u4e00\u4e2a\u5143\u7d20x void insert ( pos , n , elem ) //\u67d0\u4e00\u5143\u7d20\u524d\u589e\u52a0n\u4e2a\u76f8\u540c\u7684\u5143\u7d20x void insert ( pos , beg , endt ) //\u67d0\u4e00\u5143\u7d20\u524d\u63d2\u5165\u53e6\u4e00\u4e2a\u76f8\u540c\u7c7b\u578b\u5411\u91cf\u7684[forst,last)\u95f4\u7684\u6570\u636e \u5220\u9664\u51fd\u6570 ? erase ( pos ) //\u5220\u9664\u67d0\u4e00\u4e2a\u5143\u7d20,\u8fd4\u56de\u4e0b\u4e00\u4e2a\u5143\u7d20\u4f4d\u7f6e ? erase ( beg , end ) //\u5220\u9664[first,last\uff09\u4e2d\u7684\u5143\u7d20,\u8fd4\u56de\u4e0b\u4e00\u4e2a\u5143\u7d20\u4f4d\u7f6e void pop_front () //\u5934\u5220 void pop_back () //\u5c3e\u5220 void clear () \u904d\u5386\u51fd\u6570 reference at ( pos ) //\u8fd4\u56depos\u4f4d\u7f6e\u5143\u7d20\u7684\u5f15\u7528 reference front () //\u8fd4\u56de\u9996\u5143\u7d20\u7684\u5f15\u7528 reference back () //\u8fd4\u56de\u5c3e\u5143\u7d20\u7684\u5f15\u7528 iterator begin () //\u8fd4\u56de\u5934\u8fed\u4ee3\u5668 iterator end () //\u8fd4\u56de\u5c3e\u8fed\u4ee3\u5668\uff08\u6700\u540e\u4e00\u4e2a\u5143\u7d20\u7684\u4e0b\u4e00\u4e2a reverse_iterator rbegin () //\u53cd\u5411\u8fed\u4ee3\u5668\uff0c\u6307\u5411\u6700\u540e\u4e00\u4e2a\u5143\u7d20 reverse_iterator rend () //\u53cd\u5411\u8fed\u4ee3\u5668\uff0c\u6307\u5411\u7b2c\u4e00\u4e2a\u5143\u7d20\u7684\u524d\u4e00\u4e2a\u5143\u7d20 \u5176\u4ed6\u51fd\u6570 bool empty () //\u5411\u91cf\u662f\u5426\u4e3a\u7a7a int size () //\u8fd4\u56de\u5143\u7d20\u7684\u4e2a\u6570 int max_size () //\u8fd4\u56de\u6700\u5927\u53ef\u5141\u8bb8\u7684\u5143\u7d20\u6570\u91cf void swap ( deque & ) //\u4ea4\u6362\u4e24\u4e2a\u540c\u7c7b\u578bdeque\u7684\u6570\u636e void assign ( beg , end ) //\u5c06[beg, end)\u533a\u95f4\u4e2d\u7684\u6570\u636e\u62f7\u8d1d\u8d4b\u503c\u7ed9\u672c\u8eab\u3002 void assign ( n , elem ) //\u5c06n\u4e2aelem\u62f7\u8d1d\u8d4b\u503c\u7ed9\u672c\u8eab\u3002","title":"deque"},{"location":"OI/STL/#algorithm","text":"","title":"algorithm"},{"location":"OI/STL/#lower_bound","text":"\u4e8c\u5206\u67e5\u627e \u5bf9\u4e8e\u5347\u5e8f\u6570\u7ec4\uff1a lower_bound( begin, end, num)\uff1a\u67e5\u627e\u7b2c\u4e00\u4e2a \u5927\u4e8e\u7b49\u4e8e num \u7684\u6570\u5e76\u8fd4\u56de\u5176\u5730\u5740\uff0c\u4e0d\u5b58\u5728\u8fd4\u56deend\u3002\u8fd4\u56de\u503c\u51cf\u53bbbegine\u5373\u7d22\u5f15\u4e0b\u6807 upper_bound( begin, end, num)\uff1a \u5927\u4e8e \u5bf9\u4e8e\u964d\u5e8f\u6570\u7ec4\uff1a\u9700\u8981\u91cd\u8f7d //\u5347\u5e8f a\u6570\u7ec4\u4e2d k \u7684\u4e2a\u6570 upper_bound ( a , a + n , k ) - lower_bound ( a , a + n , k );","title":"lower_bound()"},{"location":"OI/STL/#next_permutation","text":"//\u6c42\u6309\u7167\u5b57\u5178\u5e8f\u7684\u5168\u6392\u5217 int a [ 4 ] = { 1 , 2 , 3 , 4 }; while ( next_permutation ( a , a + 4 )) { for ( int i = 0 ; i < 4 ; i ++ ) cout << a [ i ] << \" \" ; cout << endl ; }","title":"next_permutation"},{"location":"OI/STL/#min_elementmax_element","text":"int maxx = * max_element ( a , a + n );","title":"min_element/max_element"},{"location":"OI/%E5%85%B6%E4%BB%96/","text":"\u5176\u4ed6 \u00b6 \u535a\u5f08\u8bba \u00b6 NIM \u00b6 \u5fc5\u80dc\u6001\uff1a \\( \\(a_1XORa_2XOR\\dots XORa_n \\neq 0\\) \\) \u5fc5\u8d25\u6001\uff1a \\( \\(a_1XORa_2XOR\\dots XORa_n = 0\\) \\) \u5176\u4ed6\uff1a Staircase Nim\uff1aPOJ 1704 Grundy\u503c \u00b6 void grundy () { grundy [ 0 ] = 0 ; //\u5fc5\u8d25\uff0c\u5176\u5b9e\u4e5f\u53ef\u4ee5\u4e0d\u5199\u8ba9j\u4ece0\u5f00\u59cb int maxa = * max_element ( a , a + n ); for ( int j = 1 ; j <= maxa ; j ++ ){ set < int > s ; for ( int i = 0 ; i < k ; i ++ ) if ( a [ i ] <= j ) s . insert ( grundy ( j - a [ i ])); int g = 0 ; while ( s . count ( g ) != 0 ) g ++ ; grundy [ j ] = g ; } } \u79bb\u6563\u5316 \u00b6 //\u767d\u4e66P164\uff0c\u4e8c\u7ef4\u5750\u6807\u79bb\u6563\u5316 typedef long long ll ; const int maxn = 600 ; int x1 [ maxn ], x2 [ maxn ], y1 [ maxn ], y2 [ maxn ]; int n ; int compress ( int * x1 , int * x2 , int w ) { vector < int > vec ; for ( int i = 0 ; i < n ; i ++ ) { for ( int d = -1 ; d <= 1 ; d ++ ) { int tx1 = x1 [ i ] + d , tx2 = x2 [ i ] + d ; if ( tx1 >= 1 && tx1 <= w ) vec . push_back ( tx1 ); if ( tx2 >= 1 && tx2 <= w ) vec . push_back ( tx2 ); } } sort ( vec . begin (), vec . end ()); vec . erase ( unique ( vec . begin (), vec . end ()), vec . end ()); for ( int i = 0 ; i < n ; i ++ ) { x1 [ i ] = find ( vec . begin (), vec . end (), x1 [ i ]) - vec . begin (); x2 [ i ] = find ( vec . begin (), vec . end (), x2 [ i ]) - vec . begin (); } return vec . size (); }","title":"\u5176\u4ed6"},{"location":"OI/%E5%85%B6%E4%BB%96/#_1","text":"","title":"\u5176\u4ed6"},{"location":"OI/%E5%85%B6%E4%BB%96/#_2","text":"","title":"\u535a\u5f08\u8bba"},{"location":"OI/%E5%85%B6%E4%BB%96/#nim","text":"\u5fc5\u80dc\u6001\uff1a \\( \\(a_1XORa_2XOR\\dots XORa_n \\neq 0\\) \\) \u5fc5\u8d25\u6001\uff1a \\( \\(a_1XORa_2XOR\\dots XORa_n = 0\\) \\) \u5176\u4ed6\uff1a Staircase Nim\uff1aPOJ 1704","title":"NIM"},{"location":"OI/%E5%85%B6%E4%BB%96/#grundy","text":"void grundy () { grundy [ 0 ] = 0 ; //\u5fc5\u8d25\uff0c\u5176\u5b9e\u4e5f\u53ef\u4ee5\u4e0d\u5199\u8ba9j\u4ece0\u5f00\u59cb int maxa = * max_element ( a , a + n ); for ( int j = 1 ; j <= maxa ; j ++ ){ set < int > s ; for ( int i = 0 ; i < k ; i ++ ) if ( a [ i ] <= j ) s . insert ( grundy ( j - a [ i ])); int g = 0 ; while ( s . count ( g ) != 0 ) g ++ ; grundy [ j ] = g ; } }","title":"Grundy\u503c"},{"location":"OI/%E5%85%B6%E4%BB%96/#_3","text":"//\u767d\u4e66P164\uff0c\u4e8c\u7ef4\u5750\u6807\u79bb\u6563\u5316 typedef long long ll ; const int maxn = 600 ; int x1 [ maxn ], x2 [ maxn ], y1 [ maxn ], y2 [ maxn ]; int n ; int compress ( int * x1 , int * x2 , int w ) { vector < int > vec ; for ( int i = 0 ; i < n ; i ++ ) { for ( int d = -1 ; d <= 1 ; d ++ ) { int tx1 = x1 [ i ] + d , tx2 = x2 [ i ] + d ; if ( tx1 >= 1 && tx1 <= w ) vec . push_back ( tx1 ); if ( tx2 >= 1 && tx2 <= w ) vec . push_back ( tx2 ); } } sort ( vec . begin (), vec . end ()); vec . erase ( unique ( vec . begin (), vec . end ()), vec . end ()); for ( int i = 0 ; i < n ; i ++ ) { x1 [ i ] = find ( vec . begin (), vec . end (), x1 [ i ]) - vec . begin (); x2 [ i ] = find ( vec . begin (), vec . end (), x2 [ i ]) - vec . begin (); } return vec . size (); }","title":"\u79bb\u6563\u5316"},{"location":"OI/%E5%8F%82%E8%80%83/","text":"\u53c2\u8003\uff1a OI Wiki (oi-wiki.org) \u6b64\u6587\u6863\u4ec5\u4f5c\u4e3a\u5b66\u4e60\u8bb0\u5f55","title":"\u53c2\u8003"},{"location":"OI/%E5%9B%BE%E8%AE%BA/","text":"\u56fe\u8bba \u00b6 \u56fe\u7684\u5b58\u50a8 \u00b6 \u90bb\u63a5\u77e9\u9635 \u00b6 \\(G[i][j]=1\\) \u8868\u793a\u6709\u4e00\u6761\u8fb9\u4ece \\(i\\) \u5230 \\(j\\) \u90bb\u63a5\u8868 \u00b6 vector < int > es [ MAXN ]; /* \u5e26\u6743\u8fb9 struct edge{ int to, w; }; vector<edge> es[MAXN]; */ \u94fe\u5f0f\u524d\u5411\u661f \u00b6 struct edge { int to , w , next ; } es [ MAX_E ]; int cnt = 0 ; void init () { memset ( head , -1 , sizeof head ); } void add_edge ( int u , int v , int w ) { //\u52a0\u8fb9 es [ cnt ]. to = v ; es [ cnt ]. w = w ; es [ cnt ]. next = head [ u ]; head [ u ] = cnt ++ ; } /*\u904d\u5386 for(int i = 1; i <= n; i++) for(int j = head[i]; i != -1; j = es[j].next) */ \u6700\u77ed\u8def \u00b6 Bellman-Ford \u00b6 \u5355\u6e90\u6700\u77ed\u8def\u95ee\u9898 \\(O(VE)\\) \u652f\u6301\u8d1f\u6743 struct edge { int from , to , w ; }; edge es [ MAX_E ]; int d [ MAX_V ]; int V , E ; void BF ( int s ){ memset ( d , INF , sizeof d ); d [ s ] = 0 ; for ( int k = 0 ; k < V ; k ++ ){ for ( int i = 0 ; i < E ; i ++ ){ edge e = es [ i ]; if ( d [ e . from ] != INF && d [ e . to ] > d [ e . from ] + e . w ){ d [ e . to ] = d [ e . from ] + w ; //\u677e\u5f1b\u64cd\u4f5c } } } } //\u5faa\u73af\u81f3\u591a\u6267\u884c V-1 \u6b21\uff0c\u4e00\u6b21\u677e\u5f1b\u64cd\u4f5c\u81f3\u5c11\u8ba9\u786e\u5b9a\u7684\u6700\u77ed\u8def+1\uff0c\u6240\u4ee5O(VE)\uff0c\u5982\u679c\u7b2c n \u6b21\u4efb\u7136\u66f4\u65b0\u4e86d\uff0c\u8868\u793a\u6709\u8d1f\u73af //\u628a\u6240\u6709d[i]\u521d\u59cb\u5316\u4e3a0\uff0c\u5c31\u53ef\u4ee5\u627e\u5230\u6240\u6709\u7684\u8d1f\u5708 bool find_negative_loop (){ memset ( d , 0 , sizeof d ); for ( int i = 0 ; i < V ; i ++ ){ for ( int j = 0 ; j < E ; j ++ ){ edge e = es [ j ]; if ( d [ e . to ] > d [ e . from ] + e . w ){ d [ e . to ] = d [ e . from ] + e . w ; if ( i == V -1 ) return true ; } } } return false ; } Dijkstra \u00b6 \u5355\u6e90\u6700\u77ed\u8def\u95ee\u9898 \u4e0d\u652f\u6301\u8d1f\u6743\u8fb9 \u68c0\u67e5\u5b58\u5728 \\(d[i][i]\\) \u4e3a\u8d1f\u6570\u6765\u5224\u65ad\u662f\u5426\u6709\u8d1f\u73af \\(O(ElogV)\\) \u7528\u4f18\u5148\u961f\u5217 typedef pair < int , int > P ; vector < P > es [ MAX_V ]; //\u90bb\u63a5\u8868\u4e2dfirst\u8868\u793a\u7aef\u70b9\uff0csecond\u8868\u793a\u6743\u503c int d [ MAX_V ]; void dijkstra ( int s ) { priority_queue < P , vector < P > , greater < P > > que ; //\u961f\u5217\u4e2dfirst\u8868\u793a\u6700\u77ed\u8def\uff0c second\u8868\u793a\u7aef\u70b9 memset ( d , INF , sizeof d ); d [ s ] = 0 ; que . push ( P ( 0 , s )); while ( ! que . empty ()) { P p = que . top (); que . pop (); int u = p . second ; if ( d [ u ] < p . first ) continue ; for ( int i = 0 ; i < es [ u ]. size (); i ++ ) { int v = es [ u ][ i ]. first , w = es [ u ][ i ]. second ; if ( d [ v ] > d [ u ] + w ) { //\u677e\u5f1b\u64cd\u4f5c d [ v ] = d [ u ] + w ; que . push ( P ( d [ v ], v )); } } } } Floyd-Warshall \u00b6 \\(O(V^3)\\) dp:\u72b6\u6001\u8f6c\u79fb\u65b9\u65b9\u7a0b \\(d[k][i][j]=min(d[k-1][i][j],d[k-1][i][k]+d[k-1][k][i])\\) , \u5373 \\(d[i][j] = min(dp[i][k], dp[k][j])\\) int d [ MAX_V [ MAX_V ]; void floyd () { for ( int k = 0 ; k < V ; k ++ ) for ( int i = 0 ; i < V ; i ++ ) for ( int j = 0 ; j < V ; j ++ ) d [ i ][ j ] = min ( d [ i ][ j ], d [ i ][ k ] + d [ k ][ j ]); } \u8def\u5f84\u8fd8\u539f \u00b6 \u5728\u677e\u5f1b\u64cd\u4f5c\u65f6\u8bb0\u5f55\u6bcf\u4e2a\u7ed3\u70b9\u7684\u524d\u8d8b\u7ed3\u70b9 \\(path[i]\\) \u5373\u53ef, \u67e5\u8be2\u65f6\u4ece\u540e\u5f80\u524d\u904d\u5386 \u6b21\u77ed\u8def \u00b6 //\u6bcf\u6b21\u66f4\u65b0\u6700\u77ed\u8def\u65f6\u770b\u770b\u88ab\u629b\u5f03\u7684\u503c\u80fd\u4e0d\u80fd\u66f4\u65b0\u6b21\u77ed\u8def typedef pair < int , int > P ; const int inf = 0x3f3f3f3f ; vector < P > es [ max_v ]; int n , r , a , b , c ; int d1 [ max_v ], d2 [ max_v ]; //d2 \u6b21\u77ed\u8def void dijkstra ( int s ){ memset ( d1 , inf , sizeof d1 ); memset ( d2 , inf , sizeof d2 ); priority_queue < P , vector < P > , greater < P > > que ; d1 [ s ] = 0 ; que . push ( P ( 0 , s )); while ( ! que . empty ()){ P p = que . top (); que . pop (); int u = p . second ; if ( d2 [ u ] < p . first ) continue ; for ( int i = 0 ; i < es [ u ]. size (); i ++ ){ int v = es [ u ][ i ]. first , w = es [ u ][ i ]. second ; int tmp = p . first + w ; if ( d1 [ v ] > tmp ){ swap ( tmp , d1 [ v ]); que . push ( P ( d1 [ v ], v )); } if ( tmp < d2 [ v ] && tmp > d1 [ v ]){ d2 [ v ] = tmp ; que . push ( P ( d2 [ v ], v )); } } } } \u6700\u5c0f\u751f\u6210\u6811 \u00b6 \u524d\u63d0\uff1a\u56fe\u662f\u8fde\u901a\u7684 Prim \u00b6 \\(O(V^2)\\) vector < edge > es [ max_v ]; int dis [ MAX_V ]; bool vis [ MAX_V ]; int prime (){ memset ( dis , inf , sizeof dis ); memset ( vis , false , vis ); dis [ 0 ] = 0 ; //s int res = 0 ; while ( true ){ int v = -1 , mn = inf ; for ( int i = 0 ; i < V ; i ++ ) if ( ! visited [ i ] && dis [ i ] < mn ) mn = dis [ i ], v = i ; if ( v == -1 ) break ; vis [ v ] = true ; res += mn ; for ( int i = 0 ; i < es [ v ]. size (); i ++ ){ edge e = es [ v ][ i ]; dis [ e . to ] = min ( dis [ e . to ], e . w ); } } return res ; } Kruskal \u00b6 \u6309\u7167\u8fb9\u7684\u6743\u503c\u4ece\u5c0f\u5230\u8fbe\uff0c\u5229\u7528\u5e76\u67e5\u96c6\u5224\u65ad\u662f\u5426\u4f1a\u4ea7\u51fa\u5708\uff0c\u4e0d\u4f1a\u5c31\u52a0\u5165 \\(O(ElogV)\\) struct edge { int from , to , w ; }; edge es [ MAX_E ]; bool cmp ( edge a , edge b ){ return a . w < b . w ; } int kruskal (){ sort ( es , es + E , cmp ); init ( MAX_V ); //\u5e76\u67e5\u96c6\u7684\u521d\u59cb\u5316 int res = 0 ; for ( int i = 0 ; i < E ; i ++ ){ edge e = es [ i ]; if ( ! same ( e . from , e . to )){ unite ( e . from , e . to ); res += e . w ; } } return res ; } \u7f51\u7edc\u6d41 \u00b6 \u6700\u5927\u6d41 Dinic \u00b6 struct edge { int to , cap , rev ; } //rev\u8bb0\u5f55\u53cd\u5411\u8fb9\u5728 es[to] \u4e2d\u7684\u7d22\u5f15 vector < edge > es [ max_v ]; //\u90bb\u63a5\u8868 int level [ max_v ]; //\u5206\u5c42\u56fe int iter [ max_v ]; //\u5f27\u4f18\u5316\uff0c\u8bb0\u5f55\u7ed3\u70b9\u589e\u5e7f\u8fc7\u54ea\u4e9b\u8fb9\u4e86\uff0c\u4e0b\u6b21\u5c31\u4e0d\u589e\u5e7f\u4e86 void add_edge ( int from , int to , int cap ) { //\u52a0\u8fb9 es [ from ]. push_back ( edge { to , cap , es [ to ]. size ()}); es [ to ]. push_back ( edge { from , 0 , es [ from ]. size () -1 }); } void bfs ( int s ) { //\u5206\u5c42\u56fe memset ( level , -1 , sizeof level ); queue < int > que ; level [ s ] = 0 ; que . push ( s ); while ( ! que . empty ()){ int v = que . front (), que . pop (); for ( int i = 0 ; i < es [ i ]. size (); i ++ ){ edge & e = es [ v ][ i ]; if ( e . cap > 0 && level [ e . to ] < 0 ){ level [ e . to ] = level [ v ] + 1 ; que . push ( e . to ); } } } } int dfs ( int cur , int t , int f ) { //\u589e\u5e7f\u8def if ( cur == t ) return f ; for ( int & i = iter [ cur ]; i < es [ cur ]. size (); i ++ ){ edge & e = es [ cur ][ i ]; if ( e . cap > 0 && level [ cur ] < level [ e . to ]){ int d = dfs ( e . to , t , min ( f , e . cap )); if ( d > 0 ) { e . cap -= d ; es [ e . to ][ e . rev ]. cap += d ; return d ; } } } return 0 ; } int max_flow ( int s , int t ){ int flow = 0 ; while ( 1 ){ bfs ( s ); if ( level [ t ] < 0 ) return flow ; memset ( iter , 0 , sizeof iter ); int f ; while ( f = dfs ( s , t , inf ) > 0 ) flow += f ; } } \u6700\u5c0f\u8d39\u7528\u6d41 \u00b6 \u8d1f\u6743\u8fb9\uff0c\u7528 BF \u7b97\u6cd5 const int inf = 0x3f3f3f3f ; struct edge { int to , cap , cost , rev ; } vector < edge > es [ max_v ]; int dist [ max_v ]; int pree [ max_e ], prev [ max_v ]; //\u524d\u5bfc\u9876\u70b9\u7684\u5bf9\u5e94\u7684\u8fb9\u7684\u7d22\u5f15 void add_edge ( int from , int to , int cap , int cost ){ es [ from ]. push_back ( edge { to , cap , cost , es [ to ]. size ()}); es [ to ]. push_back ( edge { from , 0 , - cost , es [ from ]. size () -1 }); } int min_cost_flow ( int s , int t , int f ) { //\u8d77\u70b9 \u7ec8\u70b9 \u6d41\u91cf int res = 0 ; while ( f > 0 ){ memset ( dist , inf , sizeof dist ); dist [ s ] = 0 ; while ( true ) bool update = false ; for ( int i = 0 ; i < V ; i ++ ) { if ( dist [ i ] == inf ) continue ; for ( int j = 0 ; j < es [ i ]. size (); j ++ ) { edge & e = es [ i ][ j ]; if ( e . cap > 0 && dist [ e . to ] > dist [ e . from ] + e . cost ) { dist [ to ] = dist [ from ] + e . cost ; prev [ e . to ] = i ; pree [ e . to ] = j ; update = true ; } } } if ( ! update ) break ; } if ( dist [ t ] == inf ) return -1 ; //\u6cbfs\u5230t\u7684\u6700\u77ed\u8def\u5c3d\u91cf\u589e\u5e7f int d = f ; for ( int i = t ; i != s ; i = prev [ i ]) d = min ( d , es [ prev [ i ]][ pree [ i ]]. cap ); f -= d ; res += d * dist [ t ]; for ( int i = t ; i != s ; i = prev [ i ]) { edge & e = es [ prev [ i ][ pree [ i ]]]; e . cap -= d ; es [ i ][ e . rev ]. cap += d ; } } return res ; } \u4e8c\u5206\u56fe\u5339\u914d \u00b6 \u6700\u5927\u6d41 \u00b6 \u6dfb\u52a0\u539f\u70b9\u548c\u6c47\u70b9\uff0c\u8ba1\u7b97\u6700\u5927\u6d41 //\u8ba1\u7b97\u673a\u5904\u7406\u4efb\u52a1 bool can [ max_n ][ max_m ]; // can[i][j] : \u8ba1\u7b97\u673a i \u80fd\u5904\u7406\u4efb\u52a1 j void MaxMatch (){ //\u8ba1\u7b97\u673a\u5bf9\u5e94\u7684\u9876\u70b9\uff1a0 ~ n-1 //\u4efb\u52a1\u5bf9\u5e94\u7684\u9876\u70b9\uff1an ~ n+m-1 int s = n + m , t = n + m + 1 ; for ( int i = 0 ; i < n ; i ++ ){ add_edge ( s , i , 1 ); } for ( int i = 0 ; i < m ; i ++ ){ add_edge ( n + i , t , 1 ); } for ( int i = 0 ; i < n ; i ++ ) for ( int j = 0 ; j < m ; j ++ ) add_edge ( i , n + j , 1 ); cout << max_flow ( s , t ) << endl ; } \u5308\u7259\u5229\u7b97\u6cd5 \u00b6 \\(O(VE)\\) bool vis [ max_v ]; int match [ max_v ]; vector < int > es [ max_v ]; void add_edge ( int u , int v ){ es [ u ]. push_back ( v ); es [ v ]. push_back ( u ); } bool dfs ( int cur ){ for ( int i = 0 ; i < es [ cur ]. size (); i ++ ){ int v = es [ cur ][ i ]; if ( vis [ v ]) continue ; vis [ v ] = true ; if ( ! match [ v ] || dfs ( match [ v ])){ match [ v ] = cur ; match [ cur ] = v ; return true ; } } return false ; } int MaxMatch (){ int res = 0 ; for ( int i = 1 ; i <= n ; i ++ ){ //\u5bfb\u627e\u589e\u5e7f\u8def\u5f84 memset ( vis , 0 , sizeof vis ); if ( ! match [ i ] && dfs ( i )) res ++ ; } return res ; } Hopcroft-Karp \u00b6 \\(O(E\\sqrt{V})\\) HDU 2389 int match [ max_v ], dep [ max_v ]; vector < int > es [ max_v ]; bool bfs () { memset ( dep , 0 , sizeof dep ); queue < int > q ; for ( int i = 1 ; i <= n ; i ++ ) if ( ! match [ i ]) q . push ( i ); bool flag = false ; while ( ! q . empty ()) { int u = q . front (); q . pop (); for ( int i = 0 ; i < es [ u ]. size (); i ++ ) { int v = es [ u ][ i ]; if ( dep [ v ]) continue ; dep [ v ] = dep [ u ] + 1 ; if ( ! match [ v ]) flag = true ; else dep [ match [ v ]] = dep [ v ] + 1 , q . push ( match [ v ]); } } return flag ; } bool dfs ( int u ) { for ( int i = 0 ; i < es [ u ]. size (); i ++ ) { int v = es [ u ][ i ]; if ( dep [ v ] != dep [ u ] + 1 ) continue ; dep [ v ] = 0 ; if ( ! match [ v ] || dfs ( match [ v ])) { match [ v ] = u ; match [ u ] = v ; return true ; } } return false ; } int MaxMatch () { int res = 0 ; while ( bfs ()) { for ( int i = 1 ; i <= n ; i ++ ) if ( ! match [ i ] && dfs ( i )) res ++ ; } return res ; } \u8fde\u901a\u6027\u76f8\u5173 \u00b6 \u5f3a\u8fde\u901a\u5206\u91cf\u5206\u89e3 \u00b6 \\(O(V+E)\\) \u4e24\u6b21DFS\uff0c\u7b2c\u4e00\u904d\u540e\u5e8f\u904d\u5386\u5e76\u7ed9\u9876\u70b9\u6807\u53f7\uff0c\u7b2c\u4e8c\u904d\u5bf9\u53cd\u5411\u56fe\u904d\u5386 vector < int > G [ max_v ]; vector < int > rG [ max_v ]; //\u53cd\u5411\u56fe vector < int > vs ; //vertex sequence bool vis [ max_v ]; int cmp [ max_v ]; //\u6240\u5c5e\u5f3a\u8fde\u901a\u56fe\u7684\u62d3\u6251\u5e8f void add_edge ( int u , int v ){ G [ u ]. push_back ( v ); rG [ v ]. push_back ( u ); } void dfs ( int v ){ vis [ v ] = true ; for ( int i = 0 ; i < G [ v ]. size (); i ++ ) if ( ! vis [ G [ v ][ i ]]) dfs ( G [ v ][ i ]); vs . push_back ( v ); } void rdfs ( int v , int k ){ vis [ v ] = true ; cmp [ v ] = k ; for ( int i = 0 ; i < rG [ v ]. size (); i ++ ) if ( ! vis [ rG [ v ][ i ]]) rdfs ( rG [ v ][ i ], k ); } int scc () { //strongly connected component memset ( vis , false , sizeof vis ); vs . clear (); for ( int v = 0 ; v < V ; v ++ ) if ( ! vis [ v ]) dfs ( v ); memset ( vis , false , sizeof vis ); int k = 0 ; for ( int i = vs . size () -1 ; i >= 0 ; i -- ) if ( ! vis [ vs [ i ]]) rdfs ( vs [ i ], k ++ ); return k ; } \u8fde\u901a\u5206\u652f\u4e2a\u6570 \u00b6 \u5e76\u67e5\u96c6 \u6811\u4e0a\u95ee\u9898 \u00b6 \u6700\u8fd1\u516c\u5171\u7956\u5148(LCA) \u00b6 \\(O(n)\\) vector < int > G [ maxn_v ]; int root , parent [ max_v ], depth [ max_v ]; void dfs ( int v , int p , int d ){ parent [ v ] = p , depth [ v ] = d ; for ( int i = 0 ; i < G [ v ]. size (); i ++ ) if ( G [ v ][ i ] != p ) dfs ( G [ v ][ i ], v , d + 1 ); } void init (){ dfs ( root , -1 , 0 ); } int lca ( int u , int v ){ //\u5148\u628au,v\u8d70\u5230\u540c\u4e00\u6df1\u5ea6 while ( depth [ u ] > depth [ v ]) u = parent [ u ]; while ( depth [ v ] > depth [ u ]) v = parent [ v ]; //\u4e00\u8d77\u5411\u4e0a\u8d70 while ( u != v ){ u = parent [ u ], v = parent [ v ]; } return u ; } \u57fa\u4e8e\u4e8c\u5206\u641c\u7d22\u7684\u7b97\u6cd5 \u5bf9\u4e8e\u4efb\u610f\u7ed3\u70b9v\uff0c\u53ef\u4ee5\u901a\u8fc7 parent2[v] = parent[parent[v]] parent4[v] = parent2[parent2[v]] ... \u5f97\u5230\u5176\u5411\u4e0a\u8d70 \\( \\(2^k\\) \\) \u6b65\u5230\u8fbe\u7684\u9876\u70b9 \u6bcf\u6b21\u641c\u7d22\u7684\u590d\u6742\u5ea6\uff1a \\(O(logn)\\) \uff0c\u9884\u5904\u7406\u7684\u590d\u6742\u5ea6\uff1a \\(O(nlogn)\\) vector < int > G [ max_v ]; int root , parent [ max_k ][ max_v ], depth [ max_v ]; void dfs ( int v , int p , int d ){ depth [ v ] = d , parent [ v ] = p ; for ( int i = 0 ; i < G [ v ]. size (); i ++ ) if ( G [ v ][ i ] != p ) dfs ( G [ v ][ i ], v , d + 1 ); } void init ( int V ){ //\u9884\u5904\u7406parent[0]\u548cdepth dfs ( root , -1 , 0 ); //\u9884\u5904\u7406parent for ( int k = 0 ; k + 1 < max_k ; k ++ ) for ( int i = 0 ; i < V ; i ++ ) { //parent[k][v] \u8868\u793a\u4ece v \u7ed3\u70b9\u5411\u4e0a\u8d70 2^k \u6b21\u7684\u7ed3\u70b9\uff0c \u8d85\u8fc7\u6839\u65f6\u8bb0\u4f5c-1 if ( parent [ k ][ i ] < 0 ) parent [ k + 1 ][ i ] = -1 ; else parent [ k + 1 ][ i ] = parent [ k ][ parent [ k ][ i ]]; } } int lca ( int u , int v ){ //\u8ba9u\u548cv\u8d70\u5230\u540c\u4e00\u6df1\u5ea6 if ( depth [ u ] > depth [ v ]) swap ( u , v ); //\u8ba9v\u7684\u6df1\u5ea6\u6df1\u4e00\u4e9b for ( int k = 0 ; k < max_k ; k ++ ) { if (( depth [ v ] - depth [ u ]) >> k & 1 ) v = parent [ k ][ v ]; } if ( u == v ) return u ; //\u4e8c\u5206\u641c\u7d22\u8ba1\u7b97LCA for ( int k = max_k -1 ; k >= 0 ; k -- ) { if ( parent [ k ][ v ] != parent [ k ][ u ]) { //\u5982\u679c\u8d85\u8fc7\u4e86\u4ed6\u4eec\u7684LCA\u4e5f\u4e00\u5b9a\u662f\u4e00\u6837\u7684,\u4e0d\u4e00\u6837\u4e00\u5b9a\u8fd8\u6ca1\u5230LCA v = parent [ k ][ v ], u = parent [ k ][ u ]; } } return parnet [ 0 ][ u ]; //?\u8fd9\u91cc\u597d\u50cf\u4e0d\u592a\u5bf9?// } \u70b9\u5206\u6cbb \u00b6 \u6d1b\u8c37 P3806 POJ 1741 \u5176\u4ed6 \u00b6 \u4e8c\u5206\u56fe\u76f8\u5173\u7ed3\u8bba \u00b6 \u5b9a\u4e49\uff1a \u5339\u914d\uff1a\u5728G\u4e2d\u4e24\u4e24\u6ca1\u6709\u516c\u5171\u70b9\u7684\u8fb9\u96c6\u5408M \u8fb9\u8986\u76d6\uff1aG\u4e2d\u4efb\u610f\u9876\u70b9\u90fd\u81f3\u5c11\u662fF\u4e2d\u67d0\u6761\u8fb9\u7684\u7aef\u70b9\u7684\u8fb9\u96c6\u5408F \u72ec\u7acb\u96c6\uff1a\u5728G\u4e2d\u4e24\u4e24\u4e92\u4e0d\u76f8\u8fde\u7684\u9876\u70b9\u96c6\u5408S \u9876\u70b9\u8986\u76d6\uff1aG\u4e2d\u7684\u4efb\u610f\u8fb9\u90fd\u81f3\u5c11\u6709\u4e00\u4e2a\u7aef\u70b9\u5c5e\u4e8eS\u7684\u9876\u70b9\u96c6\u5408S \u7ed3\u8bba\uff1a \u5bf9\u4e8e\u65e0\u5b64\u7acb\u70b9\u7684\u56fe\uff0c|\u6700\u5927\u5339\u914d|+|\u6700\u5c0f\u8fb9\u8986\u76d6| = |V| |\u6700\u5927\u72ec\u7acb\u96c6|+|\u6700\u5c0f\u9876\u70b9\u8986\u76d6| = |V| \u5bf9\u4e8e\u4e8c\u5206\u56fe\uff0c|\u6700\u5927\u5339\u914d| = |\u6700\u5c0f\u9876\u70b9\u8986\u76d6| \u7b80\u5355\u8bc1\u660e\uff1a\u6700\u5927\u5339\u914d\u65f6\u662f\u6bcf\u4e00\u5bf9\u5339\u914d\u4e2d\uff0c\u4e0d\u53ef\u80fd2\u4e2a\u70b9\u90fd\u8fde\u63a5\u7740\u672a\u5339\u914d\u7684\u70b9\uff08\u4e0d\u7136\u7684\u8bdd\u5c31\u4f1a\u6709\u589e\u5e7f\u8def\u5f84\uff0c\u6700\u5927\u5339\u914d\u8fd8\u53ef\u4ee5\u66f4\u5927), \u6240\u4ee52\u4e2a\u70b9\u4e2d\u6700\u591a\u4e00\u4e2a\u70b9\u8fde\u63a5\u7740\u672a\u5339\u914d\u7684\u70b9\uff0c\u9009\u62e9\u90a3\u4e2a\u70b9\u4f5c\u4e3a\u6700\u5c0f\u5b9a\u70b9\u8986\u76d6\u5373\u53ef 2-SAT \u00b6 \u5e03\u5c14\u65b9\u7a0b\u7684\u53ef\u6ee1\u8db3\u6027\u95ee\u9898 \u5408\u53d6\u8303\u5f0f\uff1a \\((a\\vee b\\vee\\dots)\\wedge(c\\vee d\\vee\\dots)\\) 2-SAT\u95ee\u9898\uff1a\u5408\u53d6\u8303\u5f0f\u7684\u6bcf\u4e2a\u5b50\u53e5\u7684\u6587\u5b57\u4e0d\u8d85\u8fc72\u7684\u5e03\u5c14\u65b9\u7a0b\u7684\u53ef\u6ee1\u8db3\u6027\u95ee\u9898 \u5c06\u6bcf\u4e2a \\( \\(a\\vee b\\) \\) \u6539\u5199\u6210 \\( \\((\\urcorner a \\Rightarrow b \\wedge \\urcorner b \\Rightarrow a)\\) \\) \uff0c\u4ee5 \\(\\Rightarrow\\) \u5173\u7cfb\u4e3a\u8fb9\u5efa\u6709\u5411\u56fe\uff0c\u5229\u7528\u5f3a\u8fde\u901a\u5206\u91cf\u5206\u89e3 \u5982\u679c\u5b58\u5728 x\u548c \\( \\(\\urcorner x\\) \\) \u5b58\u5728\u540c\u4e00\u4e2a\u5f3a\u8fde\u901a\u5206\u91cf\uff0c\u65e0\u89e3 \u5426\u5219\uff0c\u5bf9\u4e8e\u6bcf\u4e2a\u5e03\u5c14\u53d8\u91cfx\uff0c\u5982\u679cx\u6240\u5728\u7684\u5f3a\u8fde\u901a\u5206\u91cf\u7684\u62d3\u6251\u5e8f\u5728 \\(\\urcorner x\\) \u4e4b\u540e\uff0c \\(x\\) \u4e3atrue \u56e0\u4e3a\u62d3\u6251\u5e8f\u5728\u524d\u7684\u5f3a\u8fde\u901a\u5206\u91cf\u53ef\u80fd\u5b58\u5728\u901a\u8def\u5230\u8fbe\u5728\u540e\u7684\uff0c\u6240\u4ee5\u5728\u540e\u7684\u4e00\u5b9a\u4e3atrue DFS\u5e8f \u00b6 \u5f53\u524d\u7ed3\u70b9\u7684 in \u548c out \u5305\u542b\u4e86\u5b50\u6811\u7684\u6240\u6709\u7ed3\u70b9 int in [ N ], out [ N ], tot = 0 ; void dfs ( int x , int dep ) { in [ x ] = ++ tot ; for ( int i = 0 ; i < es [ x ]. size (); i ++ ) dfs ( es [ x ][ i ], dep + 1 ); out [ x ] = tot ; }","title":"\u56fe\u8bba"},{"location":"OI/%E5%9B%BE%E8%AE%BA/#_1","text":"","title":"\u56fe\u8bba"},{"location":"OI/%E5%9B%BE%E8%AE%BA/#_2","text":"","title":"\u56fe\u7684\u5b58\u50a8"},{"location":"OI/%E5%9B%BE%E8%AE%BA/#_3","text":"\\(G[i][j]=1\\) \u8868\u793a\u6709\u4e00\u6761\u8fb9\u4ece \\(i\\) \u5230 \\(j\\)","title":"\u90bb\u63a5\u77e9\u9635"},{"location":"OI/%E5%9B%BE%E8%AE%BA/#_4","text":"vector < int > es [ MAXN ]; /* \u5e26\u6743\u8fb9 struct edge{ int to, w; }; vector<edge> es[MAXN]; */","title":"\u90bb\u63a5\u8868"},{"location":"OI/%E5%9B%BE%E8%AE%BA/#_5","text":"struct edge { int to , w , next ; } es [ MAX_E ]; int cnt = 0 ; void init () { memset ( head , -1 , sizeof head ); } void add_edge ( int u , int v , int w ) { //\u52a0\u8fb9 es [ cnt ]. to = v ; es [ cnt ]. w = w ; es [ cnt ]. next = head [ u ]; head [ u ] = cnt ++ ; } /*\u904d\u5386 for(int i = 1; i <= n; i++) for(int j = head[i]; i != -1; j = es[j].next) */","title":"\u94fe\u5f0f\u524d\u5411\u661f"},{"location":"OI/%E5%9B%BE%E8%AE%BA/#_6","text":"","title":"\u6700\u77ed\u8def"},{"location":"OI/%E5%9B%BE%E8%AE%BA/#bellman-ford","text":"\u5355\u6e90\u6700\u77ed\u8def\u95ee\u9898 \\(O(VE)\\) \u652f\u6301\u8d1f\u6743 struct edge { int from , to , w ; }; edge es [ MAX_E ]; int d [ MAX_V ]; int V , E ; void BF ( int s ){ memset ( d , INF , sizeof d ); d [ s ] = 0 ; for ( int k = 0 ; k < V ; k ++ ){ for ( int i = 0 ; i < E ; i ++ ){ edge e = es [ i ]; if ( d [ e . from ] != INF && d [ e . to ] > d [ e . from ] + e . w ){ d [ e . to ] = d [ e . from ] + w ; //\u677e\u5f1b\u64cd\u4f5c } } } } //\u5faa\u73af\u81f3\u591a\u6267\u884c V-1 \u6b21\uff0c\u4e00\u6b21\u677e\u5f1b\u64cd\u4f5c\u81f3\u5c11\u8ba9\u786e\u5b9a\u7684\u6700\u77ed\u8def+1\uff0c\u6240\u4ee5O(VE)\uff0c\u5982\u679c\u7b2c n \u6b21\u4efb\u7136\u66f4\u65b0\u4e86d\uff0c\u8868\u793a\u6709\u8d1f\u73af //\u628a\u6240\u6709d[i]\u521d\u59cb\u5316\u4e3a0\uff0c\u5c31\u53ef\u4ee5\u627e\u5230\u6240\u6709\u7684\u8d1f\u5708 bool find_negative_loop (){ memset ( d , 0 , sizeof d ); for ( int i = 0 ; i < V ; i ++ ){ for ( int j = 0 ; j < E ; j ++ ){ edge e = es [ j ]; if ( d [ e . to ] > d [ e . from ] + e . w ){ d [ e . to ] = d [ e . from ] + e . w ; if ( i == V -1 ) return true ; } } } return false ; }","title":"Bellman-Ford"},{"location":"OI/%E5%9B%BE%E8%AE%BA/#dijkstra","text":"\u5355\u6e90\u6700\u77ed\u8def\u95ee\u9898 \u4e0d\u652f\u6301\u8d1f\u6743\u8fb9 \u68c0\u67e5\u5b58\u5728 \\(d[i][i]\\) \u4e3a\u8d1f\u6570\u6765\u5224\u65ad\u662f\u5426\u6709\u8d1f\u73af \\(O(ElogV)\\) \u7528\u4f18\u5148\u961f\u5217 typedef pair < int , int > P ; vector < P > es [ MAX_V ]; //\u90bb\u63a5\u8868\u4e2dfirst\u8868\u793a\u7aef\u70b9\uff0csecond\u8868\u793a\u6743\u503c int d [ MAX_V ]; void dijkstra ( int s ) { priority_queue < P , vector < P > , greater < P > > que ; //\u961f\u5217\u4e2dfirst\u8868\u793a\u6700\u77ed\u8def\uff0c second\u8868\u793a\u7aef\u70b9 memset ( d , INF , sizeof d ); d [ s ] = 0 ; que . push ( P ( 0 , s )); while ( ! que . empty ()) { P p = que . top (); que . pop (); int u = p . second ; if ( d [ u ] < p . first ) continue ; for ( int i = 0 ; i < es [ u ]. size (); i ++ ) { int v = es [ u ][ i ]. first , w = es [ u ][ i ]. second ; if ( d [ v ] > d [ u ] + w ) { //\u677e\u5f1b\u64cd\u4f5c d [ v ] = d [ u ] + w ; que . push ( P ( d [ v ], v )); } } } }","title":"Dijkstra"},{"location":"OI/%E5%9B%BE%E8%AE%BA/#floyd-warshall","text":"\\(O(V^3)\\) dp:\u72b6\u6001\u8f6c\u79fb\u65b9\u65b9\u7a0b \\(d[k][i][j]=min(d[k-1][i][j],d[k-1][i][k]+d[k-1][k][i])\\) , \u5373 \\(d[i][j] = min(dp[i][k], dp[k][j])\\) int d [ MAX_V [ MAX_V ]; void floyd () { for ( int k = 0 ; k < V ; k ++ ) for ( int i = 0 ; i < V ; i ++ ) for ( int j = 0 ; j < V ; j ++ ) d [ i ][ j ] = min ( d [ i ][ j ], d [ i ][ k ] + d [ k ][ j ]); }","title":"Floyd-Warshall"},{"location":"OI/%E5%9B%BE%E8%AE%BA/#_7","text":"\u5728\u677e\u5f1b\u64cd\u4f5c\u65f6\u8bb0\u5f55\u6bcf\u4e2a\u7ed3\u70b9\u7684\u524d\u8d8b\u7ed3\u70b9 \\(path[i]\\) \u5373\u53ef, \u67e5\u8be2\u65f6\u4ece\u540e\u5f80\u524d\u904d\u5386","title":"\u8def\u5f84\u8fd8\u539f"},{"location":"OI/%E5%9B%BE%E8%AE%BA/#_8","text":"//\u6bcf\u6b21\u66f4\u65b0\u6700\u77ed\u8def\u65f6\u770b\u770b\u88ab\u629b\u5f03\u7684\u503c\u80fd\u4e0d\u80fd\u66f4\u65b0\u6b21\u77ed\u8def typedef pair < int , int > P ; const int inf = 0x3f3f3f3f ; vector < P > es [ max_v ]; int n , r , a , b , c ; int d1 [ max_v ], d2 [ max_v ]; //d2 \u6b21\u77ed\u8def void dijkstra ( int s ){ memset ( d1 , inf , sizeof d1 ); memset ( d2 , inf , sizeof d2 ); priority_queue < P , vector < P > , greater < P > > que ; d1 [ s ] = 0 ; que . push ( P ( 0 , s )); while ( ! que . empty ()){ P p = que . top (); que . pop (); int u = p . second ; if ( d2 [ u ] < p . first ) continue ; for ( int i = 0 ; i < es [ u ]. size (); i ++ ){ int v = es [ u ][ i ]. first , w = es [ u ][ i ]. second ; int tmp = p . first + w ; if ( d1 [ v ] > tmp ){ swap ( tmp , d1 [ v ]); que . push ( P ( d1 [ v ], v )); } if ( tmp < d2 [ v ] && tmp > d1 [ v ]){ d2 [ v ] = tmp ; que . push ( P ( d2 [ v ], v )); } } } }","title":"\u6b21\u77ed\u8def"},{"location":"OI/%E5%9B%BE%E8%AE%BA/#_9","text":"\u524d\u63d0\uff1a\u56fe\u662f\u8fde\u901a\u7684","title":"\u6700\u5c0f\u751f\u6210\u6811"},{"location":"OI/%E5%9B%BE%E8%AE%BA/#prim","text":"\\(O(V^2)\\) vector < edge > es [ max_v ]; int dis [ MAX_V ]; bool vis [ MAX_V ]; int prime (){ memset ( dis , inf , sizeof dis ); memset ( vis , false , vis ); dis [ 0 ] = 0 ; //s int res = 0 ; while ( true ){ int v = -1 , mn = inf ; for ( int i = 0 ; i < V ; i ++ ) if ( ! visited [ i ] && dis [ i ] < mn ) mn = dis [ i ], v = i ; if ( v == -1 ) break ; vis [ v ] = true ; res += mn ; for ( int i = 0 ; i < es [ v ]. size (); i ++ ){ edge e = es [ v ][ i ]; dis [ e . to ] = min ( dis [ e . to ], e . w ); } } return res ; }","title":"Prim"},{"location":"OI/%E5%9B%BE%E8%AE%BA/#kruskal","text":"\u6309\u7167\u8fb9\u7684\u6743\u503c\u4ece\u5c0f\u5230\u8fbe\uff0c\u5229\u7528\u5e76\u67e5\u96c6\u5224\u65ad\u662f\u5426\u4f1a\u4ea7\u51fa\u5708\uff0c\u4e0d\u4f1a\u5c31\u52a0\u5165 \\(O(ElogV)\\) struct edge { int from , to , w ; }; edge es [ MAX_E ]; bool cmp ( edge a , edge b ){ return a . w < b . w ; } int kruskal (){ sort ( es , es + E , cmp ); init ( MAX_V ); //\u5e76\u67e5\u96c6\u7684\u521d\u59cb\u5316 int res = 0 ; for ( int i = 0 ; i < E ; i ++ ){ edge e = es [ i ]; if ( ! same ( e . from , e . to )){ unite ( e . from , e . to ); res += e . w ; } } return res ; }","title":"Kruskal"},{"location":"OI/%E5%9B%BE%E8%AE%BA/#_10","text":"","title":"\u7f51\u7edc\u6d41"},{"location":"OI/%E5%9B%BE%E8%AE%BA/#dinic","text":"struct edge { int to , cap , rev ; } //rev\u8bb0\u5f55\u53cd\u5411\u8fb9\u5728 es[to] \u4e2d\u7684\u7d22\u5f15 vector < edge > es [ max_v ]; //\u90bb\u63a5\u8868 int level [ max_v ]; //\u5206\u5c42\u56fe int iter [ max_v ]; //\u5f27\u4f18\u5316\uff0c\u8bb0\u5f55\u7ed3\u70b9\u589e\u5e7f\u8fc7\u54ea\u4e9b\u8fb9\u4e86\uff0c\u4e0b\u6b21\u5c31\u4e0d\u589e\u5e7f\u4e86 void add_edge ( int from , int to , int cap ) { //\u52a0\u8fb9 es [ from ]. push_back ( edge { to , cap , es [ to ]. size ()}); es [ to ]. push_back ( edge { from , 0 , es [ from ]. size () -1 }); } void bfs ( int s ) { //\u5206\u5c42\u56fe memset ( level , -1 , sizeof level ); queue < int > que ; level [ s ] = 0 ; que . push ( s ); while ( ! que . empty ()){ int v = que . front (), que . pop (); for ( int i = 0 ; i < es [ i ]. size (); i ++ ){ edge & e = es [ v ][ i ]; if ( e . cap > 0 && level [ e . to ] < 0 ){ level [ e . to ] = level [ v ] + 1 ; que . push ( e . to ); } } } } int dfs ( int cur , int t , int f ) { //\u589e\u5e7f\u8def if ( cur == t ) return f ; for ( int & i = iter [ cur ]; i < es [ cur ]. size (); i ++ ){ edge & e = es [ cur ][ i ]; if ( e . cap > 0 && level [ cur ] < level [ e . to ]){ int d = dfs ( e . to , t , min ( f , e . cap )); if ( d > 0 ) { e . cap -= d ; es [ e . to ][ e . rev ]. cap += d ; return d ; } } } return 0 ; } int max_flow ( int s , int t ){ int flow = 0 ; while ( 1 ){ bfs ( s ); if ( level [ t ] < 0 ) return flow ; memset ( iter , 0 , sizeof iter ); int f ; while ( f = dfs ( s , t , inf ) > 0 ) flow += f ; } }","title":"\u6700\u5927\u6d41 Dinic"},{"location":"OI/%E5%9B%BE%E8%AE%BA/#_11","text":"\u8d1f\u6743\u8fb9\uff0c\u7528 BF \u7b97\u6cd5 const int inf = 0x3f3f3f3f ; struct edge { int to , cap , cost , rev ; } vector < edge > es [ max_v ]; int dist [ max_v ]; int pree [ max_e ], prev [ max_v ]; //\u524d\u5bfc\u9876\u70b9\u7684\u5bf9\u5e94\u7684\u8fb9\u7684\u7d22\u5f15 void add_edge ( int from , int to , int cap , int cost ){ es [ from ]. push_back ( edge { to , cap , cost , es [ to ]. size ()}); es [ to ]. push_back ( edge { from , 0 , - cost , es [ from ]. size () -1 }); } int min_cost_flow ( int s , int t , int f ) { //\u8d77\u70b9 \u7ec8\u70b9 \u6d41\u91cf int res = 0 ; while ( f > 0 ){ memset ( dist , inf , sizeof dist ); dist [ s ] = 0 ; while ( true ) bool update = false ; for ( int i = 0 ; i < V ; i ++ ) { if ( dist [ i ] == inf ) continue ; for ( int j = 0 ; j < es [ i ]. size (); j ++ ) { edge & e = es [ i ][ j ]; if ( e . cap > 0 && dist [ e . to ] > dist [ e . from ] + e . cost ) { dist [ to ] = dist [ from ] + e . cost ; prev [ e . to ] = i ; pree [ e . to ] = j ; update = true ; } } } if ( ! update ) break ; } if ( dist [ t ] == inf ) return -1 ; //\u6cbfs\u5230t\u7684\u6700\u77ed\u8def\u5c3d\u91cf\u589e\u5e7f int d = f ; for ( int i = t ; i != s ; i = prev [ i ]) d = min ( d , es [ prev [ i ]][ pree [ i ]]. cap ); f -= d ; res += d * dist [ t ]; for ( int i = t ; i != s ; i = prev [ i ]) { edge & e = es [ prev [ i ][ pree [ i ]]]; e . cap -= d ; es [ i ][ e . rev ]. cap += d ; } } return res ; }","title":"\u6700\u5c0f\u8d39\u7528\u6d41"},{"location":"OI/%E5%9B%BE%E8%AE%BA/#_12","text":"","title":"\u4e8c\u5206\u56fe\u5339\u914d"},{"location":"OI/%E5%9B%BE%E8%AE%BA/#_13","text":"\u6dfb\u52a0\u539f\u70b9\u548c\u6c47\u70b9\uff0c\u8ba1\u7b97\u6700\u5927\u6d41 //\u8ba1\u7b97\u673a\u5904\u7406\u4efb\u52a1 bool can [ max_n ][ max_m ]; // can[i][j] : \u8ba1\u7b97\u673a i \u80fd\u5904\u7406\u4efb\u52a1 j void MaxMatch (){ //\u8ba1\u7b97\u673a\u5bf9\u5e94\u7684\u9876\u70b9\uff1a0 ~ n-1 //\u4efb\u52a1\u5bf9\u5e94\u7684\u9876\u70b9\uff1an ~ n+m-1 int s = n + m , t = n + m + 1 ; for ( int i = 0 ; i < n ; i ++ ){ add_edge ( s , i , 1 ); } for ( int i = 0 ; i < m ; i ++ ){ add_edge ( n + i , t , 1 ); } for ( int i = 0 ; i < n ; i ++ ) for ( int j = 0 ; j < m ; j ++ ) add_edge ( i , n + j , 1 ); cout << max_flow ( s , t ) << endl ; }","title":"\u6700\u5927\u6d41"},{"location":"OI/%E5%9B%BE%E8%AE%BA/#_14","text":"\\(O(VE)\\) bool vis [ max_v ]; int match [ max_v ]; vector < int > es [ max_v ]; void add_edge ( int u , int v ){ es [ u ]. push_back ( v ); es [ v ]. push_back ( u ); } bool dfs ( int cur ){ for ( int i = 0 ; i < es [ cur ]. size (); i ++ ){ int v = es [ cur ][ i ]; if ( vis [ v ]) continue ; vis [ v ] = true ; if ( ! match [ v ] || dfs ( match [ v ])){ match [ v ] = cur ; match [ cur ] = v ; return true ; } } return false ; } int MaxMatch (){ int res = 0 ; for ( int i = 1 ; i <= n ; i ++ ){ //\u5bfb\u627e\u589e\u5e7f\u8def\u5f84 memset ( vis , 0 , sizeof vis ); if ( ! match [ i ] && dfs ( i )) res ++ ; } return res ; }","title":"\u5308\u7259\u5229\u7b97\u6cd5"},{"location":"OI/%E5%9B%BE%E8%AE%BA/#hopcroft-karp","text":"\\(O(E\\sqrt{V})\\) HDU 2389 int match [ max_v ], dep [ max_v ]; vector < int > es [ max_v ]; bool bfs () { memset ( dep , 0 , sizeof dep ); queue < int > q ; for ( int i = 1 ; i <= n ; i ++ ) if ( ! match [ i ]) q . push ( i ); bool flag = false ; while ( ! q . empty ()) { int u = q . front (); q . pop (); for ( int i = 0 ; i < es [ u ]. size (); i ++ ) { int v = es [ u ][ i ]; if ( dep [ v ]) continue ; dep [ v ] = dep [ u ] + 1 ; if ( ! match [ v ]) flag = true ; else dep [ match [ v ]] = dep [ v ] + 1 , q . push ( match [ v ]); } } return flag ; } bool dfs ( int u ) { for ( int i = 0 ; i < es [ u ]. size (); i ++ ) { int v = es [ u ][ i ]; if ( dep [ v ] != dep [ u ] + 1 ) continue ; dep [ v ] = 0 ; if ( ! match [ v ] || dfs ( match [ v ])) { match [ v ] = u ; match [ u ] = v ; return true ; } } return false ; } int MaxMatch () { int res = 0 ; while ( bfs ()) { for ( int i = 1 ; i <= n ; i ++ ) if ( ! match [ i ] && dfs ( i )) res ++ ; } return res ; }","title":"Hopcroft-Karp"},{"location":"OI/%E5%9B%BE%E8%AE%BA/#_15","text":"","title":"\u8fde\u901a\u6027\u76f8\u5173"},{"location":"OI/%E5%9B%BE%E8%AE%BA/#_16","text":"\\(O(V+E)\\) \u4e24\u6b21DFS\uff0c\u7b2c\u4e00\u904d\u540e\u5e8f\u904d\u5386\u5e76\u7ed9\u9876\u70b9\u6807\u53f7\uff0c\u7b2c\u4e8c\u904d\u5bf9\u53cd\u5411\u56fe\u904d\u5386 vector < int > G [ max_v ]; vector < int > rG [ max_v ]; //\u53cd\u5411\u56fe vector < int > vs ; //vertex sequence bool vis [ max_v ]; int cmp [ max_v ]; //\u6240\u5c5e\u5f3a\u8fde\u901a\u56fe\u7684\u62d3\u6251\u5e8f void add_edge ( int u , int v ){ G [ u ]. push_back ( v ); rG [ v ]. push_back ( u ); } void dfs ( int v ){ vis [ v ] = true ; for ( int i = 0 ; i < G [ v ]. size (); i ++ ) if ( ! vis [ G [ v ][ i ]]) dfs ( G [ v ][ i ]); vs . push_back ( v ); } void rdfs ( int v , int k ){ vis [ v ] = true ; cmp [ v ] = k ; for ( int i = 0 ; i < rG [ v ]. size (); i ++ ) if ( ! vis [ rG [ v ][ i ]]) rdfs ( rG [ v ][ i ], k ); } int scc () { //strongly connected component memset ( vis , false , sizeof vis ); vs . clear (); for ( int v = 0 ; v < V ; v ++ ) if ( ! vis [ v ]) dfs ( v ); memset ( vis , false , sizeof vis ); int k = 0 ; for ( int i = vs . size () -1 ; i >= 0 ; i -- ) if ( ! vis [ vs [ i ]]) rdfs ( vs [ i ], k ++ ); return k ; }","title":"\u5f3a\u8fde\u901a\u5206\u91cf\u5206\u89e3"},{"location":"OI/%E5%9B%BE%E8%AE%BA/#_17","text":"\u5e76\u67e5\u96c6","title":"\u8fde\u901a\u5206\u652f\u4e2a\u6570"},{"location":"OI/%E5%9B%BE%E8%AE%BA/#_18","text":"","title":"\u6811\u4e0a\u95ee\u9898"},{"location":"OI/%E5%9B%BE%E8%AE%BA/#lca","text":"\\(O(n)\\) vector < int > G [ maxn_v ]; int root , parent [ max_v ], depth [ max_v ]; void dfs ( int v , int p , int d ){ parent [ v ] = p , depth [ v ] = d ; for ( int i = 0 ; i < G [ v ]. size (); i ++ ) if ( G [ v ][ i ] != p ) dfs ( G [ v ][ i ], v , d + 1 ); } void init (){ dfs ( root , -1 , 0 ); } int lca ( int u , int v ){ //\u5148\u628au,v\u8d70\u5230\u540c\u4e00\u6df1\u5ea6 while ( depth [ u ] > depth [ v ]) u = parent [ u ]; while ( depth [ v ] > depth [ u ]) v = parent [ v ]; //\u4e00\u8d77\u5411\u4e0a\u8d70 while ( u != v ){ u = parent [ u ], v = parent [ v ]; } return u ; } \u57fa\u4e8e\u4e8c\u5206\u641c\u7d22\u7684\u7b97\u6cd5 \u5bf9\u4e8e\u4efb\u610f\u7ed3\u70b9v\uff0c\u53ef\u4ee5\u901a\u8fc7 parent2[v] = parent[parent[v]] parent4[v] = parent2[parent2[v]] ... \u5f97\u5230\u5176\u5411\u4e0a\u8d70 \\( \\(2^k\\) \\) \u6b65\u5230\u8fbe\u7684\u9876\u70b9 \u6bcf\u6b21\u641c\u7d22\u7684\u590d\u6742\u5ea6\uff1a \\(O(logn)\\) \uff0c\u9884\u5904\u7406\u7684\u590d\u6742\u5ea6\uff1a \\(O(nlogn)\\) vector < int > G [ max_v ]; int root , parent [ max_k ][ max_v ], depth [ max_v ]; void dfs ( int v , int p , int d ){ depth [ v ] = d , parent [ v ] = p ; for ( int i = 0 ; i < G [ v ]. size (); i ++ ) if ( G [ v ][ i ] != p ) dfs ( G [ v ][ i ], v , d + 1 ); } void init ( int V ){ //\u9884\u5904\u7406parent[0]\u548cdepth dfs ( root , -1 , 0 ); //\u9884\u5904\u7406parent for ( int k = 0 ; k + 1 < max_k ; k ++ ) for ( int i = 0 ; i < V ; i ++ ) { //parent[k][v] \u8868\u793a\u4ece v \u7ed3\u70b9\u5411\u4e0a\u8d70 2^k \u6b21\u7684\u7ed3\u70b9\uff0c \u8d85\u8fc7\u6839\u65f6\u8bb0\u4f5c-1 if ( parent [ k ][ i ] < 0 ) parent [ k + 1 ][ i ] = -1 ; else parent [ k + 1 ][ i ] = parent [ k ][ parent [ k ][ i ]]; } } int lca ( int u , int v ){ //\u8ba9u\u548cv\u8d70\u5230\u540c\u4e00\u6df1\u5ea6 if ( depth [ u ] > depth [ v ]) swap ( u , v ); //\u8ba9v\u7684\u6df1\u5ea6\u6df1\u4e00\u4e9b for ( int k = 0 ; k < max_k ; k ++ ) { if (( depth [ v ] - depth [ u ]) >> k & 1 ) v = parent [ k ][ v ]; } if ( u == v ) return u ; //\u4e8c\u5206\u641c\u7d22\u8ba1\u7b97LCA for ( int k = max_k -1 ; k >= 0 ; k -- ) { if ( parent [ k ][ v ] != parent [ k ][ u ]) { //\u5982\u679c\u8d85\u8fc7\u4e86\u4ed6\u4eec\u7684LCA\u4e5f\u4e00\u5b9a\u662f\u4e00\u6837\u7684,\u4e0d\u4e00\u6837\u4e00\u5b9a\u8fd8\u6ca1\u5230LCA v = parent [ k ][ v ], u = parent [ k ][ u ]; } } return parnet [ 0 ][ u ]; //?\u8fd9\u91cc\u597d\u50cf\u4e0d\u592a\u5bf9?// }","title":"\u6700\u8fd1\u516c\u5171\u7956\u5148(LCA)"},{"location":"OI/%E5%9B%BE%E8%AE%BA/#_19","text":"\u6d1b\u8c37 P3806 POJ 1741","title":"\u70b9\u5206\u6cbb"},{"location":"OI/%E5%9B%BE%E8%AE%BA/#_20","text":"","title":"\u5176\u4ed6"},{"location":"OI/%E5%9B%BE%E8%AE%BA/#_21","text":"\u5b9a\u4e49\uff1a \u5339\u914d\uff1a\u5728G\u4e2d\u4e24\u4e24\u6ca1\u6709\u516c\u5171\u70b9\u7684\u8fb9\u96c6\u5408M \u8fb9\u8986\u76d6\uff1aG\u4e2d\u4efb\u610f\u9876\u70b9\u90fd\u81f3\u5c11\u662fF\u4e2d\u67d0\u6761\u8fb9\u7684\u7aef\u70b9\u7684\u8fb9\u96c6\u5408F \u72ec\u7acb\u96c6\uff1a\u5728G\u4e2d\u4e24\u4e24\u4e92\u4e0d\u76f8\u8fde\u7684\u9876\u70b9\u96c6\u5408S \u9876\u70b9\u8986\u76d6\uff1aG\u4e2d\u7684\u4efb\u610f\u8fb9\u90fd\u81f3\u5c11\u6709\u4e00\u4e2a\u7aef\u70b9\u5c5e\u4e8eS\u7684\u9876\u70b9\u96c6\u5408S \u7ed3\u8bba\uff1a \u5bf9\u4e8e\u65e0\u5b64\u7acb\u70b9\u7684\u56fe\uff0c|\u6700\u5927\u5339\u914d|+|\u6700\u5c0f\u8fb9\u8986\u76d6| = |V| |\u6700\u5927\u72ec\u7acb\u96c6|+|\u6700\u5c0f\u9876\u70b9\u8986\u76d6| = |V| \u5bf9\u4e8e\u4e8c\u5206\u56fe\uff0c|\u6700\u5927\u5339\u914d| = |\u6700\u5c0f\u9876\u70b9\u8986\u76d6| \u7b80\u5355\u8bc1\u660e\uff1a\u6700\u5927\u5339\u914d\u65f6\u662f\u6bcf\u4e00\u5bf9\u5339\u914d\u4e2d\uff0c\u4e0d\u53ef\u80fd2\u4e2a\u70b9\u90fd\u8fde\u63a5\u7740\u672a\u5339\u914d\u7684\u70b9\uff08\u4e0d\u7136\u7684\u8bdd\u5c31\u4f1a\u6709\u589e\u5e7f\u8def\u5f84\uff0c\u6700\u5927\u5339\u914d\u8fd8\u53ef\u4ee5\u66f4\u5927), \u6240\u4ee52\u4e2a\u70b9\u4e2d\u6700\u591a\u4e00\u4e2a\u70b9\u8fde\u63a5\u7740\u672a\u5339\u914d\u7684\u70b9\uff0c\u9009\u62e9\u90a3\u4e2a\u70b9\u4f5c\u4e3a\u6700\u5c0f\u5b9a\u70b9\u8986\u76d6\u5373\u53ef","title":"\u4e8c\u5206\u56fe\u76f8\u5173\u7ed3\u8bba"},{"location":"OI/%E5%9B%BE%E8%AE%BA/#2-sat","text":"\u5e03\u5c14\u65b9\u7a0b\u7684\u53ef\u6ee1\u8db3\u6027\u95ee\u9898 \u5408\u53d6\u8303\u5f0f\uff1a \\((a\\vee b\\vee\\dots)\\wedge(c\\vee d\\vee\\dots)\\) 2-SAT\u95ee\u9898\uff1a\u5408\u53d6\u8303\u5f0f\u7684\u6bcf\u4e2a\u5b50\u53e5\u7684\u6587\u5b57\u4e0d\u8d85\u8fc72\u7684\u5e03\u5c14\u65b9\u7a0b\u7684\u53ef\u6ee1\u8db3\u6027\u95ee\u9898 \u5c06\u6bcf\u4e2a \\( \\(a\\vee b\\) \\) \u6539\u5199\u6210 \\( \\((\\urcorner a \\Rightarrow b \\wedge \\urcorner b \\Rightarrow a)\\) \\) \uff0c\u4ee5 \\(\\Rightarrow\\) \u5173\u7cfb\u4e3a\u8fb9\u5efa\u6709\u5411\u56fe\uff0c\u5229\u7528\u5f3a\u8fde\u901a\u5206\u91cf\u5206\u89e3 \u5982\u679c\u5b58\u5728 x\u548c \\( \\(\\urcorner x\\) \\) \u5b58\u5728\u540c\u4e00\u4e2a\u5f3a\u8fde\u901a\u5206\u91cf\uff0c\u65e0\u89e3 \u5426\u5219\uff0c\u5bf9\u4e8e\u6bcf\u4e2a\u5e03\u5c14\u53d8\u91cfx\uff0c\u5982\u679cx\u6240\u5728\u7684\u5f3a\u8fde\u901a\u5206\u91cf\u7684\u62d3\u6251\u5e8f\u5728 \\(\\urcorner x\\) \u4e4b\u540e\uff0c \\(x\\) \u4e3atrue \u56e0\u4e3a\u62d3\u6251\u5e8f\u5728\u524d\u7684\u5f3a\u8fde\u901a\u5206\u91cf\u53ef\u80fd\u5b58\u5728\u901a\u8def\u5230\u8fbe\u5728\u540e\u7684\uff0c\u6240\u4ee5\u5728\u540e\u7684\u4e00\u5b9a\u4e3atrue","title":"2-SAT"},{"location":"OI/%E5%9B%BE%E8%AE%BA/#dfs","text":"\u5f53\u524d\u7ed3\u70b9\u7684 in \u548c out \u5305\u542b\u4e86\u5b50\u6811\u7684\u6240\u6709\u7ed3\u70b9 int in [ N ], out [ N ], tot = 0 ; void dfs ( int x , int dep ) { in [ x ] = ++ tot ; for ( int i = 0 ; i < es [ x ]. size (); i ++ ) dfs ( es [ x ][ i ], dep + 1 ); out [ x ] = tot ; }","title":"DFS\u5e8f"},{"location":"OI/%E5%AD%97%E7%AC%A6%E4%B8%B2/","text":"\u5b57\u7b26\u4e32 \u00b6 next\u6570\u7ec4 \u4e0e KMP \u00b6 \\(O(n+m)\\) //next void getNext ( char * p , int * next ) { next [ 0 ] = -1 ; int i = 0 , j = -1 ; while ( i < strlen ( p )) if ( j == -1 || p [ i ] == p [ j ]){ i ++ , j ++ ; next [ i ] = j ; } else j = next [ j ]; } //KMP //\u4e3b\u4f53\u5b57\u7b26\u4e32 \u5339\u914d\u5b57\u7b26\u4e32 int KMP ( char * s , char * p ){ int i = 0 ; int j = 0 ; while ( i < strlen ( s ) && j < strlen ( p )) if ( j == -1 || s [ i ] == p [ j ]) i ++ , j ++ ; else j = next [ j ]; //\u8fd4\u56de\u5b58\u5728\u4e0e p \u76f8\u540c\u7684\u5b57\u4e32\u7684\u4f4d\u7f6e if ( j == strlen ( p )) return i - j ; else return -1 ; } Manacher \u00b6 \\(O(n)\\) //Manacher int Manacher ( string s ){ if ( s . length () == 0 ) return 0 ; int len = ( int )( s . length () * 2-1 ); char * cArry = new char [ len ]; int * pArry = new int [ len ]; //\u9884\u5904\u7406\uff1a\u5168\u90fd\u53d8\u6210\u5947\u6570\u56de\u6587\u4e32 for ( int i = 0 ; i < len ; i ++ ) cArry [ i ] = i & 1 ? s [( i -1 ) / 2 ] : '#' ; //R:\u6700\u53f3\u53f3\u8fb9\u754c C\uff1a\u4e0eR\u5bf9\u5e94\u7684\u56de\u6587\u4e2d\u5fc3 maxn\uff1a\u6700\u5927\u56de\u6587\u534a\u5f84\uff0c\u8fd4\u56de\u503c\u4e3amaxn-1 //R\u5b9e\u9645\u4e0a\u662f\u6700\u53f3\u8fb9\u754c\u7684\u53f3\u8fb9\u4e00\u4f4d int R = -1 ; int C = -1 ; int maxn = 0 ; for ( int i = 0 ; i < len ; i ++ ){ pArry [ i ] = i >= R ? 1 : min ( R - i , pArry [ 2 * C - i ]); //\u53d6\u5f97\u53ef\u80fd\u7684\u6700\u77ed\u7684\u56de\u6587\u534a\u5f84 *R\u662f\u6700\u53f3\u8fb9\u754c\u7684\u53f3\u8fb9\u4e00\u4f4d //\u66b4\u529b\u8ba1\u7b97 while ( i + pArry [ i ] < len && i - pArry [ i ] > -1 ){ if ( cArry [ i + pArry [ i ]] == cArry [ i - pArry [ i ]]) pArry [ i ] ++ ; else break ; } //\u66f4\u65b0 if ( i + pArry [ i ] > R ){ R = i + pArry [ i ]; C = i ; } maxn = maxn ( pArry [ i ], maxn ); } //\u6e05\u7a7a\u52a8\u6001\u6570\u7ec4 delete [] cArry ; delete [] pArry ; return maxn -1 ; } \u6700\u5c0f\u8868\u793a\u6cd5 \u00b6 \\(O(n)\\) //\u6700\u5c0f\u8868\u793a\u6cd5 int min_ ( char * s ){ int k = 0 , i = 0 , j = 1 , len = strlen ( s ); // k:\u5339\u914d\u957f\u5ea6 while ( k < len && i < len && j < len ){ if ( s [( s + k ) % len ] == s [( j + k ) % len ]) k ++ ; else { s [( s + k ) % len ] > s [( j + k ) % len ] ? i = i + k + 1 : j = j + k + 1 ; //\u4e0d\u540c\u5219\u8df3\u8f6c if ( i == j ) i ++ ; //\u82e5\u8df3\u8f6c\u540e\u4e0d\u540c\uff0c\u8981\u4fdd\u8bc1\u6bd4\u8f83\u7684\u53cc\u65b9\u4e0d\u540c k = 0 ; } } return min ( i , j ); }","title":"\u5b57\u7b26\u4e32"},{"location":"OI/%E5%AD%97%E7%AC%A6%E4%B8%B2/#_1","text":"","title":"\u5b57\u7b26\u4e32"},{"location":"OI/%E5%AD%97%E7%AC%A6%E4%B8%B2/#next-kmp","text":"\\(O(n+m)\\) //next void getNext ( char * p , int * next ) { next [ 0 ] = -1 ; int i = 0 , j = -1 ; while ( i < strlen ( p )) if ( j == -1 || p [ i ] == p [ j ]){ i ++ , j ++ ; next [ i ] = j ; } else j = next [ j ]; } //KMP //\u4e3b\u4f53\u5b57\u7b26\u4e32 \u5339\u914d\u5b57\u7b26\u4e32 int KMP ( char * s , char * p ){ int i = 0 ; int j = 0 ; while ( i < strlen ( s ) && j < strlen ( p )) if ( j == -1 || s [ i ] == p [ j ]) i ++ , j ++ ; else j = next [ j ]; //\u8fd4\u56de\u5b58\u5728\u4e0e p \u76f8\u540c\u7684\u5b57\u4e32\u7684\u4f4d\u7f6e if ( j == strlen ( p )) return i - j ; else return -1 ; }","title":"next\u6570\u7ec4 \u4e0e KMP"},{"location":"OI/%E5%AD%97%E7%AC%A6%E4%B8%B2/#manacher","text":"\\(O(n)\\) //Manacher int Manacher ( string s ){ if ( s . length () == 0 ) return 0 ; int len = ( int )( s . length () * 2-1 ); char * cArry = new char [ len ]; int * pArry = new int [ len ]; //\u9884\u5904\u7406\uff1a\u5168\u90fd\u53d8\u6210\u5947\u6570\u56de\u6587\u4e32 for ( int i = 0 ; i < len ; i ++ ) cArry [ i ] = i & 1 ? s [( i -1 ) / 2 ] : '#' ; //R:\u6700\u53f3\u53f3\u8fb9\u754c C\uff1a\u4e0eR\u5bf9\u5e94\u7684\u56de\u6587\u4e2d\u5fc3 maxn\uff1a\u6700\u5927\u56de\u6587\u534a\u5f84\uff0c\u8fd4\u56de\u503c\u4e3amaxn-1 //R\u5b9e\u9645\u4e0a\u662f\u6700\u53f3\u8fb9\u754c\u7684\u53f3\u8fb9\u4e00\u4f4d int R = -1 ; int C = -1 ; int maxn = 0 ; for ( int i = 0 ; i < len ; i ++ ){ pArry [ i ] = i >= R ? 1 : min ( R - i , pArry [ 2 * C - i ]); //\u53d6\u5f97\u53ef\u80fd\u7684\u6700\u77ed\u7684\u56de\u6587\u534a\u5f84 *R\u662f\u6700\u53f3\u8fb9\u754c\u7684\u53f3\u8fb9\u4e00\u4f4d //\u66b4\u529b\u8ba1\u7b97 while ( i + pArry [ i ] < len && i - pArry [ i ] > -1 ){ if ( cArry [ i + pArry [ i ]] == cArry [ i - pArry [ i ]]) pArry [ i ] ++ ; else break ; } //\u66f4\u65b0 if ( i + pArry [ i ] > R ){ R = i + pArry [ i ]; C = i ; } maxn = maxn ( pArry [ i ], maxn ); } //\u6e05\u7a7a\u52a8\u6001\u6570\u7ec4 delete [] cArry ; delete [] pArry ; return maxn -1 ; }","title":"Manacher"},{"location":"OI/%E5%AD%97%E7%AC%A6%E4%B8%B2/#_2","text":"\\(O(n)\\) //\u6700\u5c0f\u8868\u793a\u6cd5 int min_ ( char * s ){ int k = 0 , i = 0 , j = 1 , len = strlen ( s ); // k:\u5339\u914d\u957f\u5ea6 while ( k < len && i < len && j < len ){ if ( s [( s + k ) % len ] == s [( j + k ) % len ]) k ++ ; else { s [( s + k ) % len ] > s [( j + k ) % len ] ? i = i + k + 1 : j = j + k + 1 ; //\u4e0d\u540c\u5219\u8df3\u8f6c if ( i == j ) i ++ ; //\u82e5\u8df3\u8f6c\u540e\u4e0d\u540c\uff0c\u8981\u4fdd\u8bc1\u6bd4\u8f83\u7684\u53cc\u65b9\u4e0d\u540c k = 0 ; } } return min ( i , j ); }","title":"\u6700\u5c0f\u8868\u793a\u6cd5"},{"location":"OI/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","text":"\u6570\u636e\u7ed3\u6784 \u00b6 \u6811\u72b6\u6570\u7ec4 \u00b6 \u5355\u70b9\u66f4\u65b0 \u533a\u95f4\u67e5\u8be2 int a [ maxn ], c [ maxn ]; //\u539f\u6570\u7ec4\u548c\u6811\u72b6\u6570\u7ec4 int lowbit ( int x ){ return x & ( - x ); } void updata ( int i , int k ) //\u7b2c i \u4e2a\u5143\u7d20\u52a0 k { while ( i <= n ) { c [ i ] += k ; i += lowbit ( i ); } } int getsum ( int i ) //\u524di\u4e2a\u548c { int res = 0 ; while ( i > 0 ) { res += c [ i ]; i -= lowbit ( i ); } return res ; } \u533a\u95f4\u66f4\u65b0 \u5355\u70b9\u67e5\u8be2 //\u5229\u7528\u539f\u6570\u7ec4\u7684\u5dee\u5206\u6570\u7ec4\u5efa\u6811 int a [ maxn ] = { 0 }, c [ maxn ]; //\u539f\u6570\u7ec4\u548c\u6811\u72b6\u6570\u7ec4 int lowbit ( int x ){ return x & ( - x ); } void updata ( int i , int k ) //\u7b2c i \u4e2a\u5143\u7d20\u52a0 k { while ( i <= n ) { c [ i ] += k ; i += lowbit ( i ); } } int getsum ( int i ) //\u524di\u4e2a { int res = 0 ; while ( i > 0 ) { res += c [ i ]; i -= lowbit ( i ); } return res ; } /* updata(i,a[i] - a[i-1]); //\u5dee\u5206\u5efa\u6811 //[x,y]\u533a\u95f4\u5185\u52a0\u4e0ak updata(x,k); //A[x] - A[x-1]\u589e\u52a0k updata(y+1,-k); //A[y+1] - A[y]\u51cf\u5c11k //\u5355\u70b9\u67e5\u8be2 \u5dee\u5206\u5efa\u6811\u6240\u4ee5\u5355\u70b9\u67e5\u8be2\u53d8\u6210\u4e86\u6c42\u548c int sum = getsum(i); */ \u533a\u95f4\u66f4\u65b0 \u533a\u95f4\u67e5\u8be2 d \u662f a \u7684\u5dee\u5206\u6570\u7ec4 \u6709 \\(a_i = \\sum_{j=1}^{i}{d_j}\\) $\\therefore\\sum_{i=1}^{r}{a_i} = \\sum_{i=1}^{r}{\\sum_{j=1}^{i}{d_j}} $ \u200b \\(= \\sum_{i=1}^{r}{d_i \\times(r-i+1)}\\) \u200b $ = \\sum_{i=1}^{r}{d_i \\times(r+1)}-\\sum_{i=1}^{r}{d_i \\times i}$ \u6240\u4ee5\u7ef4\u62a42\u4e2a\u6811\u72b6\u6570\u7ec4 sum1[i] = d[i]\uff0csum2[i] = d[i]*(i-1) \u7ebf\u6bb5\u6811 \u00b6 /*\u533a\u95f4\u548c\u7684\u7ebf\u6bb5\u6811*/ //\u5efa\u6811 void build ( ll x , ll l , ll r ) { if ( l == r ) { scanf ( \"%lld\" , & sum [ x ]); return ; } ll mid = ( l + r ) >> 1 ; build ( x << 1 , l , mid ); build ( x << 1 | 1 , mid + 1 , r ); sum [ x ] = sum [ x << 1 ] + sum [ x << 1 | 1 ]; } //\u4e0b\u653e\u61d2\u6807\u8bb0 void pushdown ( ll x , ll l , ll r ) { ll mid = ( l + r ) / 2 ; lz [ x << 1 ] += lz [ x ], lz [ x << 1 | 1 ] += lz [ x ]; sum [ x << 1 ] += lz [ x ] * ( mid - l + 1 ), sum [ x << 1 | 1 ] += lz [ x ] * ( r - mid ); lz [ x ] = 0 ; } //\u533a\u95f4\u66f4\u65b0 void update ( ll x , ll l , ll r , ll gl , ll gr , ll k ) { if ( l >= gl && r <= gr ) { lz [ x ] += k ; sum [ x ] += ( r - l + 1 ) * k ; return ; } pushdown ( x , l , r ); ll mid = ( l + r ) / 2 ; if ( gl <= mid ) update ( x << 1 , l , mid , gl , gr , k ); if ( gr > mid ) update ( x << 1 | 1 , mid + 1 , r , gl , gr , k ); sum [ x ] = sum [ x << 1 ] + sum [ x << 1 | 1 ]; } //\u533a\u95f4\u548c ll get_sum ( ll x , ll l , ll r , ll gl , ll gr ) { if ( l >= gl && r <= gr ) return sum [ x ]; pushdown ( x , l , r ); ll res = 0 ; ll mid = ( l + r ) / 2 ; if ( gl <= mid ) res += get_sum ( x << 1 , l , mid , gl , gr ); if ( gr > mid ) res += get_sum ( x << 1 | 1 , mid + 1 , r , gl , gr ); return res ; } \u5e76\u67e5\u96c6 \u00b6 int fa [ MAXN ]; //\u521d\u59cb\u5316 void init ( int n ){ for ( int i = 0 ; i < n ; i ++ ) fa [ i ] = i ; //\u7236\u7ed3\u70b9\u662f\u81ea\u5df1 } //\u67e5\u8be2\u5e76\u8def\u5f84\u538b\u7f29 int find ( int x ){ if ( fa [ x ] != x ) fa [ x ] = find ( fa [ x ]); return fa [ x ]; } //\u5408\u5e76 void unite ( int x , int y ){ int fx = find ( x ); int fy = find ( y ); fa [ fx ] = fy ; } //\u67e5\u8be2\u662f\u5426\u5c5e\u4e8e\u540c\u4e00\u96c6\u5408 bool same ( int x , int y ){ return find ( x ) == find ( y ); } \u5e26\u6743\u5e76\u67e5\u96c6 int fa [ MAXN ], value [ MAXN ]; //\u7236\u7ed3\u70b9 \u6743\u503c //\u67e5\u8be2 int find ( int x ){ if ( x != fa [ x ]){ int t = fa [ x ]; fa [ x ] = find ( fa [ x ]); value [ x ] += value [ t ]; //\u8fd9\u65f6\u7684\u7236\u4eb2\u7ed3\u70b9\u7684\u6743\u503c\u662f\u7236\u7ed3\u70b9\u5230\u6839\u7ed3\u70b9\u7684\u6743\u503c //\u6240\u4ee5\u52a0\u4e0a\u539f\u672c\u81ea\u5df1\u5230\u7236\u7ed3\u70b9\u7684\u6743\u503c\u5c31\u662f\u81ea\u5df1\u5230\u6839\u7ed3\u70b9\u7684\u6743\u503c } return fa [ x ]; } //\u5408\u5e76, s\u662fx->y\u7684\u6743\u503c void unite ( int x , int y , int s ){ int px = find ( x ); int py = find ( y ); if ( px != py ){ fa [ px ] = py ; value [ px ] = s + value [ y ] - value [ x ]; //x->y->py\u7684\u6743\u503c = x->px->py\u7684\u6743\u503c\uff0c\u6240\u4ee5\u5f97px->py\u7684\u6743\u503c\u4e3a\u4e0a\u5f0f } } \u6808 \u00b6 \u5355\u8c03\u6808 \u00b6 //\u6c42\u51fa\u6bcf\u4e2a\u5143\u7d20\u5de6\u53f3\u7b2c\u4e00\u4e2a\u5c0f\u4e8e\u5b83\u7684\u5143\u7d20\u7684\u4e0b\u6807 for ( int i = 1 ; i <= n ; i ++ ) { while ( ! st . empty () && num [ st . top ()] > num [ i ]) { r [ st . top ()] = i ; st . pop (); } if ( st . empty ()) l [ i ] = -1 ; else if ( num [ st . top ()] == num [ i ]) l [ i ] = l [ st . top ()]; else l [ i ] = st . top (); st . push ( i ); } while ( ! st . empty ()) { r [ st . top ()] = n + 1 ; st . pop (); } \u53ef\u6301\u4e45\u5316\u6570\u636e\u7ed3\u6784 \u00b6 \u53ef\u6301\u4e45\u5316\u7ebf\u6bb5\u6811(\u4e3b\u5e2d\u6811) \u00b6 \u6d1b\u8c37 P3834 //\u4e00\u822c\u5f0032\u500d\u7a7a\u95f4 const int maxn = 2e5 + 5 ; int a [ maxn ], b [ maxn ], n , m , tot , q ; int lc [ maxn << 5 ], rc [ maxn << 5 ], sum [ maxn << 5 ], rt [ maxn << 5 ]; void build ( int & rt , int l , int r ) { rt = ++ tot , sum [ rt ] = 0 ; if ( l == r ) return ; int mid = ( l + r ) >> 1 ; build ( lc [ rt ], l , mid ), build ( rc [ rt ], mid + 1 , r ); } int update ( int x , int l , int r , int t ) { int xx = ++ tot ; lc [ xx ] = lc [ x ], rc [ xx ] = rc [ x ], sum [ xx ] = sum [ x ] + 1 ; if ( l == r ) return xx ; int mid = ( l + r ) >> 1 ; if ( t <= mid ) lc [ xx ] = update ( lc [ xx ], l , mid , t ); else rc [ xx ] = update ( rc [ xx ], mid + 1 , r , t ); return xx ; } int query ( int u , int v , int l , int r , int k ) { int mid = ( l + r ) >> 1 , t = sum [ lc [ v ]] - sum [ lc [ u ]]; if ( l == r ) return l ; if ( k <= t ) return query ( lc [ u ], lc [ v ], l , mid , k ); else return query ( rc [ u ], rc [ v ], mid + 1 , r , k - t ); } int main () { cin >> n >> m ; for ( int i = 1 ; i <= m ; i ++ ) scanf ( \"%d\" , a + i ), b [ i ] = a [ i ]; sort ( b + 1 , b + 1 + n ); q = unique ( b + 1 , b + 1 + n ) - b - 1 ; build ( rt [ 0 ], 1 , q ); for ( int i = 1 ; i <= n ; i ++ ) { int t = lower_bound ( b + 1 , b + 1 + q , a [ i ]) - b ; rt [ i ] = update ( rt [ i - 1 ], 1 , q , t ); } int l , r , k ; for ( int i = 1 ; i <= m ; i ++ ) { scanf ( \"%d %d %d\" , & l , & r , & k ); printf ( \"%d \\n \" , b [ query ( rt [ l - 1 ], rt [ r ], 1 , q , k )]); } return 0 ; } \u4e8c\u4f4d\u524d\u7f00\u548c \u00b6 //\u9884\u5904\u7406 for ( int i = 1 ; i <= n ; i ++ ) for ( int j = 1 ; j <= m ; j ++ ) dp [ i ][ j ] = dp [ i -1 ][ j ] + dp [ i ][ j -1 ] - dp [ i -1 ][ j -1 ] + matrix [ i ][ j ]; //x1, y1, x2, y2 (\u67e5\u8be2\u533a\u95f4) int res = dp [ x2 ][ y2 ] - dp [ x2 ][ y1 -1 ] - dp [ x1 -1 ][ y2 ] + dp [ x1 -1 ][ y1 -1 ];","title":"\u6570\u636e\u7ed3\u6784"},{"location":"OI/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/#_1","text":"","title":"\u6570\u636e\u7ed3\u6784"},{"location":"OI/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/#_2","text":"\u5355\u70b9\u66f4\u65b0 \u533a\u95f4\u67e5\u8be2 int a [ maxn ], c [ maxn ]; //\u539f\u6570\u7ec4\u548c\u6811\u72b6\u6570\u7ec4 int lowbit ( int x ){ return x & ( - x ); } void updata ( int i , int k ) //\u7b2c i \u4e2a\u5143\u7d20\u52a0 k { while ( i <= n ) { c [ i ] += k ; i += lowbit ( i ); } } int getsum ( int i ) //\u524di\u4e2a\u548c { int res = 0 ; while ( i > 0 ) { res += c [ i ]; i -= lowbit ( i ); } return res ; } \u533a\u95f4\u66f4\u65b0 \u5355\u70b9\u67e5\u8be2 //\u5229\u7528\u539f\u6570\u7ec4\u7684\u5dee\u5206\u6570\u7ec4\u5efa\u6811 int a [ maxn ] = { 0 }, c [ maxn ]; //\u539f\u6570\u7ec4\u548c\u6811\u72b6\u6570\u7ec4 int lowbit ( int x ){ return x & ( - x ); } void updata ( int i , int k ) //\u7b2c i \u4e2a\u5143\u7d20\u52a0 k { while ( i <= n ) { c [ i ] += k ; i += lowbit ( i ); } } int getsum ( int i ) //\u524di\u4e2a { int res = 0 ; while ( i > 0 ) { res += c [ i ]; i -= lowbit ( i ); } return res ; } /* updata(i,a[i] - a[i-1]); //\u5dee\u5206\u5efa\u6811 //[x,y]\u533a\u95f4\u5185\u52a0\u4e0ak updata(x,k); //A[x] - A[x-1]\u589e\u52a0k updata(y+1,-k); //A[y+1] - A[y]\u51cf\u5c11k //\u5355\u70b9\u67e5\u8be2 \u5dee\u5206\u5efa\u6811\u6240\u4ee5\u5355\u70b9\u67e5\u8be2\u53d8\u6210\u4e86\u6c42\u548c int sum = getsum(i); */ \u533a\u95f4\u66f4\u65b0 \u533a\u95f4\u67e5\u8be2 d \u662f a \u7684\u5dee\u5206\u6570\u7ec4 \u6709 \\(a_i = \\sum_{j=1}^{i}{d_j}\\) $\\therefore\\sum_{i=1}^{r}{a_i} = \\sum_{i=1}^{r}{\\sum_{j=1}^{i}{d_j}} $ \u200b \\(= \\sum_{i=1}^{r}{d_i \\times(r-i+1)}\\) \u200b $ = \\sum_{i=1}^{r}{d_i \\times(r+1)}-\\sum_{i=1}^{r}{d_i \\times i}$ \u6240\u4ee5\u7ef4\u62a42\u4e2a\u6811\u72b6\u6570\u7ec4 sum1[i] = d[i]\uff0csum2[i] = d[i]*(i-1)","title":"\u6811\u72b6\u6570\u7ec4"},{"location":"OI/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/#_3","text":"/*\u533a\u95f4\u548c\u7684\u7ebf\u6bb5\u6811*/ //\u5efa\u6811 void build ( ll x , ll l , ll r ) { if ( l == r ) { scanf ( \"%lld\" , & sum [ x ]); return ; } ll mid = ( l + r ) >> 1 ; build ( x << 1 , l , mid ); build ( x << 1 | 1 , mid + 1 , r ); sum [ x ] = sum [ x << 1 ] + sum [ x << 1 | 1 ]; } //\u4e0b\u653e\u61d2\u6807\u8bb0 void pushdown ( ll x , ll l , ll r ) { ll mid = ( l + r ) / 2 ; lz [ x << 1 ] += lz [ x ], lz [ x << 1 | 1 ] += lz [ x ]; sum [ x << 1 ] += lz [ x ] * ( mid - l + 1 ), sum [ x << 1 | 1 ] += lz [ x ] * ( r - mid ); lz [ x ] = 0 ; } //\u533a\u95f4\u66f4\u65b0 void update ( ll x , ll l , ll r , ll gl , ll gr , ll k ) { if ( l >= gl && r <= gr ) { lz [ x ] += k ; sum [ x ] += ( r - l + 1 ) * k ; return ; } pushdown ( x , l , r ); ll mid = ( l + r ) / 2 ; if ( gl <= mid ) update ( x << 1 , l , mid , gl , gr , k ); if ( gr > mid ) update ( x << 1 | 1 , mid + 1 , r , gl , gr , k ); sum [ x ] = sum [ x << 1 ] + sum [ x << 1 | 1 ]; } //\u533a\u95f4\u548c ll get_sum ( ll x , ll l , ll r , ll gl , ll gr ) { if ( l >= gl && r <= gr ) return sum [ x ]; pushdown ( x , l , r ); ll res = 0 ; ll mid = ( l + r ) / 2 ; if ( gl <= mid ) res += get_sum ( x << 1 , l , mid , gl , gr ); if ( gr > mid ) res += get_sum ( x << 1 | 1 , mid + 1 , r , gl , gr ); return res ; }","title":"\u7ebf\u6bb5\u6811"},{"location":"OI/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/#_4","text":"int fa [ MAXN ]; //\u521d\u59cb\u5316 void init ( int n ){ for ( int i = 0 ; i < n ; i ++ ) fa [ i ] = i ; //\u7236\u7ed3\u70b9\u662f\u81ea\u5df1 } //\u67e5\u8be2\u5e76\u8def\u5f84\u538b\u7f29 int find ( int x ){ if ( fa [ x ] != x ) fa [ x ] = find ( fa [ x ]); return fa [ x ]; } //\u5408\u5e76 void unite ( int x , int y ){ int fx = find ( x ); int fy = find ( y ); fa [ fx ] = fy ; } //\u67e5\u8be2\u662f\u5426\u5c5e\u4e8e\u540c\u4e00\u96c6\u5408 bool same ( int x , int y ){ return find ( x ) == find ( y ); } \u5e26\u6743\u5e76\u67e5\u96c6 int fa [ MAXN ], value [ MAXN ]; //\u7236\u7ed3\u70b9 \u6743\u503c //\u67e5\u8be2 int find ( int x ){ if ( x != fa [ x ]){ int t = fa [ x ]; fa [ x ] = find ( fa [ x ]); value [ x ] += value [ t ]; //\u8fd9\u65f6\u7684\u7236\u4eb2\u7ed3\u70b9\u7684\u6743\u503c\u662f\u7236\u7ed3\u70b9\u5230\u6839\u7ed3\u70b9\u7684\u6743\u503c //\u6240\u4ee5\u52a0\u4e0a\u539f\u672c\u81ea\u5df1\u5230\u7236\u7ed3\u70b9\u7684\u6743\u503c\u5c31\u662f\u81ea\u5df1\u5230\u6839\u7ed3\u70b9\u7684\u6743\u503c } return fa [ x ]; } //\u5408\u5e76, s\u662fx->y\u7684\u6743\u503c void unite ( int x , int y , int s ){ int px = find ( x ); int py = find ( y ); if ( px != py ){ fa [ px ] = py ; value [ px ] = s + value [ y ] - value [ x ]; //x->y->py\u7684\u6743\u503c = x->px->py\u7684\u6743\u503c\uff0c\u6240\u4ee5\u5f97px->py\u7684\u6743\u503c\u4e3a\u4e0a\u5f0f } }","title":"\u5e76\u67e5\u96c6"},{"location":"OI/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/#_5","text":"","title":"\u6808"},{"location":"OI/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/#_6","text":"//\u6c42\u51fa\u6bcf\u4e2a\u5143\u7d20\u5de6\u53f3\u7b2c\u4e00\u4e2a\u5c0f\u4e8e\u5b83\u7684\u5143\u7d20\u7684\u4e0b\u6807 for ( int i = 1 ; i <= n ; i ++ ) { while ( ! st . empty () && num [ st . top ()] > num [ i ]) { r [ st . top ()] = i ; st . pop (); } if ( st . empty ()) l [ i ] = -1 ; else if ( num [ st . top ()] == num [ i ]) l [ i ] = l [ st . top ()]; else l [ i ] = st . top (); st . push ( i ); } while ( ! st . empty ()) { r [ st . top ()] = n + 1 ; st . pop (); }","title":"\u5355\u8c03\u6808"},{"location":"OI/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/#_7","text":"","title":"\u53ef\u6301\u4e45\u5316\u6570\u636e\u7ed3\u6784"},{"location":"OI/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/#_8","text":"\u6d1b\u8c37 P3834 //\u4e00\u822c\u5f0032\u500d\u7a7a\u95f4 const int maxn = 2e5 + 5 ; int a [ maxn ], b [ maxn ], n , m , tot , q ; int lc [ maxn << 5 ], rc [ maxn << 5 ], sum [ maxn << 5 ], rt [ maxn << 5 ]; void build ( int & rt , int l , int r ) { rt = ++ tot , sum [ rt ] = 0 ; if ( l == r ) return ; int mid = ( l + r ) >> 1 ; build ( lc [ rt ], l , mid ), build ( rc [ rt ], mid + 1 , r ); } int update ( int x , int l , int r , int t ) { int xx = ++ tot ; lc [ xx ] = lc [ x ], rc [ xx ] = rc [ x ], sum [ xx ] = sum [ x ] + 1 ; if ( l == r ) return xx ; int mid = ( l + r ) >> 1 ; if ( t <= mid ) lc [ xx ] = update ( lc [ xx ], l , mid , t ); else rc [ xx ] = update ( rc [ xx ], mid + 1 , r , t ); return xx ; } int query ( int u , int v , int l , int r , int k ) { int mid = ( l + r ) >> 1 , t = sum [ lc [ v ]] - sum [ lc [ u ]]; if ( l == r ) return l ; if ( k <= t ) return query ( lc [ u ], lc [ v ], l , mid , k ); else return query ( rc [ u ], rc [ v ], mid + 1 , r , k - t ); } int main () { cin >> n >> m ; for ( int i = 1 ; i <= m ; i ++ ) scanf ( \"%d\" , a + i ), b [ i ] = a [ i ]; sort ( b + 1 , b + 1 + n ); q = unique ( b + 1 , b + 1 + n ) - b - 1 ; build ( rt [ 0 ], 1 , q ); for ( int i = 1 ; i <= n ; i ++ ) { int t = lower_bound ( b + 1 , b + 1 + q , a [ i ]) - b ; rt [ i ] = update ( rt [ i - 1 ], 1 , q , t ); } int l , r , k ; for ( int i = 1 ; i <= m ; i ++ ) { scanf ( \"%d %d %d\" , & l , & r , & k ); printf ( \"%d \\n \" , b [ query ( rt [ l - 1 ], rt [ r ], 1 , q , k )]); } return 0 ; }","title":"\u53ef\u6301\u4e45\u5316\u7ebf\u6bb5\u6811(\u4e3b\u5e2d\u6811)"},{"location":"OI/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/#_9","text":"//\u9884\u5904\u7406 for ( int i = 1 ; i <= n ; i ++ ) for ( int j = 1 ; j <= m ; j ++ ) dp [ i ][ j ] = dp [ i -1 ][ j ] + dp [ i ][ j -1 ] - dp [ i -1 ][ j -1 ] + matrix [ i ][ j ]; //x1, y1, x2, y2 (\u67e5\u8be2\u533a\u95f4) int res = dp [ x2 ][ y2 ] - dp [ x2 ][ y1 -1 ] - dp [ x1 -1 ][ y2 ] + dp [ x1 -1 ][ y1 -1 ];","title":"\u4e8c\u4f4d\u524d\u7f00\u548c"},{"location":"OI/%E6%95%B0%E8%AE%BA/","text":"\u6570\u8bba \u00b6 \u57fa\u7840\u51fd\u6570 \u00b6 gcd \u00b6 \u8bbe \\(a/b=d, a\\%b=r\\) \u5373 \\(a=b\\times d+r\\) \uff0c\u6240\u4ee5 \\(gcd(b, r) | a\\) \uff0c\u53c8 \\(gcd(b, r) | b\\) \uff0c\u6240\u4ee5 \\(gcd(b, r) | gcd(a, b)\\) \u53c8 \\(r=a-b\\times d\\) \uff0c\u6240\u4ee5 \\(gcd(a, b) | r\\) \uff0c\u53c8 \\(gcd(a, b) | b\\) \uff0c\u6240\u4ee5 \\(gcd(a, b) | gcd(b, r)\\) \u6240\u4ee5 \\(gcd(a, b) = gcd(b, r)\\) , \u5373 \\(gcd(a, b) = gcd(b, a\\%b)\\) \u4e00\u4e9b\u6027\u8d28 \\(gcd(a,b)=gcd(a,a+b)=gcd(a,ka+b)\\) \\(gcd(ka,kb)=k*gcd(a,b)\\) \\(gcd(a,b,c)=gcd(gcd(a,b),c)\\) int gcd ( int a , int b ){ return b ? gcd ( b , a % b ) : a ; } lcm \u00b6 int lcm ( int a , int b ){ return a * b / gcd ( a , b ); } exgcd \u00b6 \u6c42 \\(ax + by = gcd(a, b)\\) \u7684\u4e00\u7ec4\u6574\u6570\u89e3 x\uff0cy b = 0\u65f6\uff0c \\(gcd(a, b) = a\\) , x=1\u200b, y=0 \u4e3a\u4e00\u7ec4\u89e3 b != 0 \u65f6 \u8bbe \\(ax_{1} + by_{1} = gcd(a, b)\\) \u200b \\(bx_{2}+ (a\\%b)y_{2} = gcd(b, a\\%b)\\) \u56e0\u4e3a \\(gcd(a, b) = gcd(b, a\\%b)\\) \u6240\u4ee5 \\(bx_{2} + (a\\%b)y_{2} = ax_{1} + by_{1}\\) \u200b \\(a\\%b = a-(a/b)*b\\) , \u4ee3\u5165\u4e0a\u5f0f\u5f97 \u200b \\(bx_{2}+ ( a - (a/b) * b)*y_{2} = ax_{1} + by_{1}\\) \u200b \\(ay_{2} + bx_{2~}- (a/b)*by_{2} = ax_{1} + by_{1}\\) \u200b \\(ay_{2} + b[x_{2}-(a/b)*y_{2}] = ax_{1} + by_{1}\\) \u6240\u4ee5 \\(x_{1} = y_{2}\\) \u200b \\(y_{1} = x_{2} - (a/b)*y_{2}\\) ll exgcd ( ll a , ll b , ll & x , ll & y ) { //\u8fd4\u56de gcd(a, b) if ( ! b ){ x = 1 , y = 0 ; return a ; } ll d = exgcd ( b , a % b , x , y ); ll t = x ; x = y ; y = t - ( a / b ) * y ; return d ; } \u5feb\u901f\u5e42 \u00b6 typedef long long ll ; ll pow ( ll a , ll b , ll p ) { // a^b (mod p) ll res = 1 ; while ( b ){ if ( b & 1 ) res = res * a % p ; a = a * a % p ; b >>= 1 ; } return res ; } \u5feb\u901f\u4e58 \u00b6 //\u9632\u6b62\u4e58\u6cd5\u7206ll ll mul ( ll a , ll b , ll p ){ ll res = 0 ; while ( b ){ if ( b & 1 ) res = ( res + a ) % p ; a = ( a + a ) % p ; b >>= 1 ; } return res ; } \u7d20\u6570 \u00b6 bool isprime ( int x ){ if ( x <= 1 ) return false ; for ( int i = 2 ; i <= x / i ; i ++ ) if ( x % i == 0 ) return false ; return true ; } \u57c3\u6c0f\u7b5b\u7d20\u6570 \u00b6 bool isprime [ N + 1 ]; //0 1 \u662f\u975e\u7d20\u6570 void getPrime (){ for ( int i = 2 , i <= N ; i ++ ) isprime [ i ] = true ; for ( int i = 2 ; i <= N / i ; i ++ ) //\u5982\u679c x>sqrt(N) \u662f\u5408\u6570\uff0c \u5728\u524d\u9762\u5c31\u4f1a\u88ab\u7b5b\u6389 if ( isprime [ i ]) for ( int j = i * i ; j <= N ; j += i ) //2i, 3i, 5i \u90fd\u5df2\u7ecf\u7b5b\u8fc7\uff0c\u53ef\u4ee5\u4ecei*i\u5f00\u59cb isprime [ i ] = false ; } \u6b27\u62c9\u7b5b\u7d20\u6570(\u7ebf\u6027\u7b5b) \u00b6 \\(O(n)\\) int cnt = 0 ; int prime [ N + 1 ]; //\u8bb0\u5f55\u7d20\u6570 bool isprime [ N + 1 ]; void euler (){ for ( int i = 2 ; i <= N ; i ++ ) isprime [ i ] = true ; for ( int i = 2 ; i <= N ; i ++ ){ if ( isprime [ i ]) prime [ cnt ++ ] = i ; //\u8bb0\u5f55 for ( int j = 0 ; j < cnt && i * prime [ j ] <= N ; j ++ ){ isprime [ i * prime [ j ]] = false ; if ( i % prime [ j ] == 0 ) break ; //\u4fdd\u8bc1\u5408\u6570\u88ab\u6700\u5c0f\u7684\u8d28\u56e0\u5b50\u7b5b\u53bb } } } \u7b5b\u533a\u95f4\u5185\u7d20\u6570 \u00b6 //\u7b5b[l, r)\u4e4b\u95f4\u7684\u7d20\u6570 //\u6ce8\u610f\u533a\u95f4\u5f00\u95ed //\u5982\u679cl==1,l++\uff0c\u5426\u5219\u4f1a\u8ba4\u4e3a1\u662f\u7d20\u6570 bool isprime_small [ MAXN ]; //\u8bb0\u5f55\u524d sqrt(r) \u7684\u7d20\u6570 bool isprime [ MAXN ]; //\u5982\u679ci\u662f\u7d20\u6570\uff0c\u8bb0isprime[i-l] = true void segement_prime ( ll l , ll r ){ for ( ll i = 0 ; i * i < r ; i ++ ) isprime_small [ i ] = true ; for ( ll i = 0 ; i < r - l ; i ++ ) isprime [ i ] = true ; for ( ll i = 2 ; i * i < r ; i ++ ) if ( isprime_small [ i ]) { //\u5982\u679c\u662f\u7d20\u6570 for ( ll j = i * i ; j * j < r ; j += i ) //\u7b5b[2, sqrt(b)] isprime_small [ j ] = false ; for ( ll j = max ( 2L L , ( l + i -1 ) / i ) * i ; j < r ; j += i ) //\u7b5b[a, b] isprime [ j - l ] = false ; } } Miller-Rabin \u7d20\u6027\u6d4b\u8bd5 \u00b6 bool check ( ll a , ll r , ll t , ll n ) { ll ret = pow ( a , r , n ), last = ret ; for ( int i = 0 ; i < t ; i ++ ) { ret = mul ( ret , ret , n ); if ( ret == 1 && last != 1 && last != n - 1 ) return true ; last = ret ; } return ret != 1 ; } bool Miller_Rabin ( ll n ) { if ( n == 2 ) return true ; if ( n < 2 || ! ( n & 1 )) return false ; ll r = n - 1 , t = 0 ; while ( ! ( r & 1 )) r >>= 1 , t ++ ; for ( int i = 1 , j ; i <= 8 ; i ++ ) { ll a = rand () % ( n - 2 ) + 2 ; if ( check ( a , r , t , n )) return false ; } return true ; } Pollard-Rho\u5927\u6570\u5206\u89e3 \u00b6 ll pollard ( ll n ) { if ( ! ( n & 1 )) return 2 ; ll c = rand () % ( n - 1 ) + 1 ; ll x = rand () % ( n - 1 ) + 1 , y = x , i = 1 , k = 2 ; while ( true ) { i ++ ; x = ( mul ( x , x , n ) + c ) % n ; ll d = gcd ( y - x + n , n ); if ( d != 1 && d != n ) return d ; if ( y == x ) return n ; if ( i == k ) { y = x ; k <<= 1 ; } } } /* \u500d\u589e\u4f18\u5316 ll pr(ll n) { ll x = 0, y = 0; ll c = 1ll * rand() % (n - 1) + 1; int step = 0, goal = 1; ll val = 1; for (goal = 1;; goal <<= 1, y = x, val = 1) { for (step = 1; step <= goal; ++step) { x = (mul(x, x, n) + c) % n; val = mul(val, abs(y - x), n); if ((step % 127) == 0) { ll d = gcd(val, n); if (d > 1) return d; } } ll d = gcd(val, n); if (d > 1) return d; } } */ ll fac [ 10000 ]; ll tot = 0 ; void find_fac ( ll n ) { if ( Miller_Rabin ( n )) { fac [ tot ++ ] = n ; return ; } ll p = n ; while ( p >= n ) p = pollard ( p ); find_fac ( p ), find_fac ( n / p ); } \u6b27\u62c9\u51fd\u6570 \u00b6 \u5b9a\u4e49: \\(\\varphi(n)\\) \u8868\u793a\u5c0f\u4e8e\u7b49\u4e8e \\(n\\) \u4e14\u4e0e \\(n\\) \u4e92\u8d28\u7684\u6570\u7684\u4e2a\u6570\uff0c\u6bd4\u5982 \\(\\varphi(1)=1\\) \u901a\u5f0f\uff1a \\(\\varphi(x)=x\\prod_{i=1}^n{(1-\\frac{1}{p_i})}\\) \uff0c\u5176\u4e2d \\(p_i\\) \u662f \\(x\\) \u7684\u6240\u6709\u8d28\u56e0\u6570 \u57fa\u672c\u6027\u8d28 \u00b6 \\(n\\) \u662f\u8d28\u6570\u65f6\uff0c \\(\\varphi(n)=n-1\\) \\(p\\) \u662f\u8d28\u6570\u65f6\uff0c \\(\\varphi(p^k)=(p-1)\\times p^{k-1}\\) \u79ef\u6027\u6027\u8d28\uff0c\u5982\u679c \\(gcd(a,b)=1\\) \uff0c\u5219 \\(\\varphi(a\\times b)=\\varphi(a)\\times \\varphi(b)\\) \u7279\u522b\u7684\uff0c \\(n\\) \u662f\u5947\u6570\u65f6\uff0c \\(\\varphi(2n)=\\varphi(n)\\) \\(n > 2\\) \u65f6\uff0c \\(\\varphi(n)\\) \u4e3a\u5076\u6570 \\(n=\\sum_{d|n}\\varphi(d)\\) \u6b27\u62c9\u5b9a\u7406\uff0c\u82e5 \\(gcd(a,m)=1\\) \uff0c\u5219 \\(a^{\\varphi(m)}\\equiv 1(mod \\quad m)\\) \u6269\u5c55\u6b27\u62c9\u5b9a\u7406 \\[ a^b\\equiv \\begin{cases} a^{b \\% \\varphi(p)}&gcd(a,p)=1 \\\\ a^b&gcd(a,p)\\neq1,b<\\varphi(p) \\\\ a^{b \\% \\varphi(p)+\\varphi(p)}&gcd(a,p)\\neq1,b\\geq\\varphi(p) \\end{cases} (mod\\ p) \\] \u6c42\u5355\u4e2a\u6570\u7684\u6b27\u62c9\u51fd\u6570 \u00b6 \\(O(\\sqrt{n})\\) ll phi ( ll n ){ ll res = n ; for ( ll i = 2 ; i * i <= n ; i ++ ){ if ( n % i == 0 ){ res -= res / i ; while ( n % i == 0 ) n /= i ; } } if ( n > 1 ) res -= res / n ; return res ; } \u57c3\u6c0f\u6c42\u6b27\u62c9\u51fd\u6570 \u00b6 \\(\\varphi(x)=x\\prod_{i=1}^n{(1-\\frac{1}{p_i})}\\) void euler ( int n ){ for ( int i = 1 ; i <= n ; i ++ ) phi [ i ] = i ; for ( int i = 2 ; i <= n ; i ++ ) if ( phi [ i ] == i ) //\u8fd9\u4ee3\u8868i\u662f\u8d28\u6570 for ( int j = i ; j <= n ; j += i ) phi [ j ] = phi [ j ] / i * ( i -1 ); //\u628ai\u7684\u500d\u6570\u66f4\u65b0\u6389 } \u6b27\u62c9\u7b5b\u6c42\u6b27\u62c9\u51fd\u6570 \u00b6 \\(if(i\\%prime[j] != 0)\\) \uff0c\u5219 \\(i\\) \u4e0e \\(prime[j]\\) \u4e92\u8d28 \u7531\u79ef\u6027\u6027\u8d28\u53ef\u5f97\uff0c \\(phi[i*prime[j]] = phi[i]*phi[prime[j]]\\) \\(if(i\\%prime[j] == 0)\\) \uff0c\u5219 \\(i\\) \u4e2d\u6709 \\(i*prime[j]\\) \u7684\u6240\u6709\u8d28\u56e0\u5b50\uff0c\u6709 \\(\\varphi(i*prime[j])=prime[j]*i*\\prod_{k=1}^n{(1-\\frac{1}{k_i})}=\\varphi(i)*prime[j]\\) int prime [ maxn ], cnt = 0 ; bool vis [ maxn ]; void euler ( int n ){ phi [ 1 ] = 1 ; //1\u8981\u7279\u5224 for ( int i = 2 ; i < = n ; i ++ ){ if ( vis [ i ] == 0 ){ //i\u662f\u8d28\u6570 prime [ cnt ++ ] = i ; phi [ i ] = i -1 ; } for ( int j = 1 ; j < cnt && prime [ j ] * i <= n ; j ++ ){ vis [ i * prime [ j ]] = 1 ; if ( i % prime [ j ] == 0 ){ phi [ i * prime [ j ]] = phi [ i ] * prime [ j ]; //\u82e5prime[j]\u662fi\u7684\u8d28\u56e0\u5b50\uff0c\u5219\u6839\u636e\u8ba1\u7b97\u516c\u5f0f\uff0ci\u5df2\u7ecf\u5305\u62eci*prime[j]\u7684\u6240\u6709\u8d28\u56e0\u5b50 break ; //\u4fdd\u8bc1\u6bcf\u4e2a\u6570\u53ea\u4f1a\u88ab\u81ea\u5df1\u6700\u5c0f\u7684\u56e0\u5b50\u7b5b\u6389\u4e00\u6b21 } else phi [ i * prime [ j ]] = phi [ i ] * phi [ prime [ j ]]; //\u79ef\u6027\u51fd\u6570\u7684\u6027\u8d28 } } } \u4e2d\u56fd\u5269\u4f59\u5b9a\u7406 \u00b6 CRT \u00b6 \u6d1b\u8c37 P3868 \\(X \u2261 r_{i} ( mod\\quad m_{i} )\\) \u8981\u6c42\uff1a \\(m_i\\) \u4e24\u4e24\u4e92\u8d28 ll CRT ( ll n , ll * r , ll * m ){ ll res = 0 , M = 1 ; for ( int i = 0 ; i < n ; i ++ ) M *= m [ i ]; for ( int i = 0 ; i < n ; i ++ ) { ll x , y ; ll tmp = M / m [ i ]; ll d = exgcd ( tmp , m [ i ], x , y ); //gcd(tmp, m[i]) = 1 x = ( x % m [ i ] + m [ i ]) % m [ i ]; res = ( res + tmp * x * r [ i ]) % M ; //\u53ef\u80fd\u9700\u8981\u7528\u5230\u5feb\u901f\u4e58\u9632\u6b62\u6ea2\u51fa } return ( res + M ) % M ; } EXCRT \u00b6 \u6d1b\u8c37 P4777 \\(X \u2261 r_{i} ( mod\\quad m_{i} )\\) \u4e0d\u8981\u6c42 \\(m_i\\) \u4e24\u4e24\u4e92\u8d28 \u6ee1\u8db3\u7b2c\u4e00\u4e2a\u6761\u4ef6\u7684\u89e3\u4e3a \\(r_1\\) \u5047\u8bbe\u6ee1\u8db3\u524d \\(k-1\\) \u4e2a\u6761\u4ef6\u7684\u4e00\u4e2a\u7279\u89e3\u4e3a \\(res\\) \uff0c \\(M_{k-1}\\) \u4e3a\u524d \\(k-1\\) \u4e2a \\(m\\) \u7684 lcm \u5219\u524d \\(k-1\\) \u4e2a\u65b9\u7a0b\u7684\u901a\u89e3\u4e3a $$ res+x\\times M_{k-1} $$ \u90a3\u4e48\u5bf9\u4e8e\u524d \\(k\\) \u4e2a\u65b9\u7a0b,\u5982\u679c\u6709\u89e3\uff0c\u5219 \u5b58\u5728\u6574\u6570 \\(x\\) \uff0c\u4f7f $$ res+x\\times M_{k-1}\\equiv r_k\\quad (mod\\quad m_k) $$ \u5373 $$ x\\times M_{k-1}\\equiv r_k-res\\quad (mod\\quad m_k) $$ \u5229\u7528\u62d3\u6b27\u6c42\u89e3\u5f97 \\(x\\) \uff0c\u5219\u524d \\(k\\) \u4e2a\u65b9\u7a0b\u7684\u4e00\u4e2a\u7279\u89e3\u4e3a $$ res+x\\times M_{k-1} $$ \u901a\u89e3\u4e3a \\(\u7279\u89e3 + x^{'}M_k\\) ll EXCRT ( ll n , ll * r , ll * m ){ ll res = r [ 0 ], M = m [ 0 ]; ll x , y ; for ( int i = 1 ; i < n ; i ++ ) { ll c = ( r [ i ] - res % m [ i ] + m [ i ]) % m [ i ]; ll d = exgcd ( M , m [ i ], x , y ), bg = m [ i ] / d ; x = ( x % bg + bg ) % bg ; if ( c % d != 0 ) return -1 ; //\u65e0\u89e3,\u56e0\u4e3a\u65e0\u6cd5\u8ba9\u4f59\u6570\u6269\u5927\u6210c x = mul ( x , c / d , bg ); //\u5feb\u901f\u4e58 res += x * M ; M *= bg ; //lcm res = ( res % M + M ) % M ; } return res ; } \u540c\u4f59\u95ee\u9898 \u00b6 \u9006\u5143 \u00b6 \u540c\u4f59\u4e0d\u6ee1\u8db3\u9664\u6cd5\uff0c \\(a/b\\quad mod \\quad p\\quad != (a\\quad mod\\quad p)/(b\\quad mod\\quad p)\\) \u5f15\u5165 \\(b\\) \u7684\u9006\u5143 \\(x\\) , \u5373 \\(b*x = 1 (mod\\quad p)\\) \uff0cb \u4e0e p \u4e92\u8d28 \u5047\u8bbe \\(a/b = k (mod\\quad p)\\) \u540c\u4e58 \\(bx\\) \u5f97 $ a/b * bx = k * 1\uff08mod\\quad p)$ \u200b \\(a*x = k (mod\\quad p)\\) \u6ce8\u610f\uff1a b \u548c p \u4e92\u8d28\uff0cb \u624d\u6709\u5173\u4e8e p \u7684\u9006\u5143 \u8d39\u9a6c\u5c0f\u5b9a\u7406\u6c42\u9006\u5143 \u00b6 \u8d39\u9a6c\u5c0f\u5b9a\u7406 \uff1a\u5982\u679c \\(p\\) \u4e3a\u8d28\u6570\uff0c\u4e14 \\(a\\) \u4e0e \\(p\\) \u4e92\u8d28(\u5373 \\(a\\) \u4e0d\u662f \\(p\\) \u7684\u500d\u6570)\uff0c\u5219 \\(a^{p-1} \\equiv 1 \uff08mod\\quad p)\\) \u6240\u4ee5\u6709 \\(a * a^{p-2} \\equiv 1 (mod\\quad p)\\) , \u5373 \\(a^{p-2} (mod\\quad p)\\) \u662f a \u7684\u9006\u5143 //\u7528\u5feb\u901f\u5e42 ll pow ( ll a , ll p ){ int res = 1 ; int d = p -2 ; while ( d ) { if ( d & 1 ) res = res * a % p ; a = a * a % p ; d >>= 1 ; } return res ; } \u62d3\u5c55\u6b27\u51e0\u91cc\u5f97\u6c42\u9006\u5143 \u00b6 \u5982\u679c \\(b\\) \u4e0e \\(p\\) \u4e92\u8d28\uff0c\u5373 \\(gcd(b, p) = 1\\) \u8981\u89e3 \\(b*x = 1 (mod\\quad p)\\) , \u5373\u6c42 \\(bx + yp = 1 = gcd(b, p)\\) \u7684\u89e3 \\(x\\) ll inv ( ll b , ll p ) { ll x , y ; ll d = exgcd ( b , p , x , y ); return d == 1 ? ( x + p ) % p : -1 ; //\u8fd4\u56de -1 \u8bf4\u660e b,p \u4e0d\u4e92\u8d28 } \u6b27\u62c9\u51fd\u6570\u6c42\u9006\u5143 \u00b6 \u6d1b\u8c37 P3811 \u662f\u8d39\u5c0f\u7684\u63a8\u5e7f\uff0c\u4e0d\u8981\u6c42 \\(p\\) \u4e3a\u8d28\u6570\uff0c\u4f46 \\(gcd(a,p)=1\\) \\(a^{\\varphi(p)}\\equiv1(mod\\quad p)\\) \uff0c\u6240\u4ee5\u5176\u9006\u5143\u4e3a \\(a^{\\varphi(n)-1}\\) ll phi ( ll n ){ ll res = n ; for ( ll i = 2 ; i * i <= n ; i ++ ) { if ( n % i == 0 ) { res -= res / i ; while ( n % i == 0 ) n /= i ; } } if ( n > 1 ) res -= res / n ; return res ; } ans = pow ( a , phi ( p ) -1 , p ); \u9636\u4e58\u9006\u5143 \u00b6 \u6c42\u9636\u4e58\u7684\u9006\u5143\uff0c\u5148\u7528\u8d39\u9a6c\u5c0f\u5b9a\u7406\u6c42\u51fa n! \u5728 p \u4e0b\u7684\u9006\u5143\uff0c\u518d\u5f80\u524d\u63a8 \u5047\u8bbe n! \u7684\u9006\u5143\u4e3a \\([n!]^{-1}\\) , \u8981\u6c42 \\((n-1)!\\) \u7684\u9006\u5143 $$ (n-1)! \\times n[n!]^{-1} \u2261 1 (mod\\quad p) $$ \u6240\u4ee5\uff0c \\((n-1)!\\) \u7684\u9006\u5143\u5c31\u662f \\(n[n!]^{-1}\\) void fa_inv ( ll n , ll p ){ fact [ 0 ] = 1 ; //factorial for ( int i = 1 ; i <= n ; i ++ ) fact [ i ] = fact [ i -1 ] * i % p ; finv [ N ] = pow ( fact [ n ], p -2 , p ); for ( int i = n -1 ; i >= 0 ; i -- ) finv [ i ] = ( i + 1 ) * finv [ i + 1 ] % p ; } \u7ebf\u6027\u6c42\u9006\u5143(\u6253\u8868) \u00b6 \u6d1b\u8c37 P3811 \u8981\u6c42\u51fa 1~n \u4e2d\u6240\u6709\u6570\u5bf9 \\(p\\) \u7684\u9006\u5143\uff0c\u9009\u62e9\u6253\u8868 \u200b \\(1^{\u22121} \u2261 1 (mod\\quad p)\\) \u8bbe \\(p = k * i + r\\) \u5176\u4e2d 1 < r < i < p, \u5373 \\(k = p/i, r = p\\quad mod\\quad i\\) \u6240\u4ee5\u6709 \\(k * i + r \u2261 0 ( mod\\quad p )\\) \u4e24\u8fb9\u540c\u65f6\u4e58\u4e0a \\(i^{\u22121} * r^{\u22121}\\) \u5f97 \\(k * r^{\u22121} + i^{\u22121} \u2261 0 ( mod\\quad p )\\) \u200b \\(i^{\u22121} \u2261 \u2212k * r^{\u22121} ( mod\\quad p )\\) \u5f97\u9012\u63a8\u516c\u5f0f \\(i^{-1} \u2261 -\uff08p/i) * (p\\quad mod\\quad i)^{-1} (mod\\quad p)\\) \u6574\u7406\u5f97 \\(inv[i] = (p - p/i) * inv[p\\%i] \\% p\\) \u5176\u4e2d p % i \u6bd4 i \u5c0f void inverse =- ( int n , int p ) { inv [ 1 ] = 1 ; for ( int i = 2 ; i <= n ; i ++ ) inv [ i ] = ( ll )( p - p / i ) * inv [ p % i ] % p ; } Lucas\u5b9a\u7406 \u00b6 \u6d1b\u8c37 P3807 HDU 3037 \u89e3\u51b3\u7ec4\u5408\u6570\u53d6\u4f59\u7684\u95ee\u9898\uff1a (p\u5fc5\u987b\u662f\u7d20\u6570,\u4e0d\u7136\u4e0d\u80fd\u7528\u8d39\u9a6c\u5c0f\u5b9a\u7406\u6c42\u9006\u5143) $$ C(n,m) = \\prod_{i=0}^{k}{C(n_i, m_i)}(mod\\quad p) $$ \\[ n = n_k p^k+n_{k-1} p^{k-1}+\\cdots+n_1p+n_0 \\] \\[ m=m_k p^k+m_{k-1} p^{k-1}+\\cdots+m_1p+m_0 \\] //\u9884\u5904\u7406\u9636\u4e58 void getFact ( ll p ) { fact [ 0 ] = 1 ; for ( ll i = 1 ; i <= p ; i ++ ) f [ i ] = f [ i -1 ] * i % p ; } //\u8ba1\u7b97\u7ec4\u5408\u6570 ll comb ( ll n , ll m , ll p ) { if ( m > n ) return 0 ; return fact [ n ] * pow ( f [ m ], p -2 , p ) % p * pow ( f [ n - m ], p -2 , p ) % p ; //\u8d39\u9a6c\u5c0f\u5b9a\u7406\u6c42\u9006\u5143 } ll lucas ( ll n , ll m , ll p ) { if ( ! m ) return 1 ; return lucas ( n / p , m / p , p ) % p * comb ( n % p , m % p , p ) % p ; } BSGS \u00b6 \u6c42 \\(a^x=b(mod\\ \\ p)\\) \u7684 \\(x\\) \u6700\u5c0f\u7684\u89e3 ll bsgs ( ll a , ll b , ll p ) { map < ll , ll > hash ; hash . clear (); b %= p ; ll t = sqrt ( p ) + 1 ; for ( ll i = 0 ; i < t ; i ++ ) hash [ b * ksm ( a , i , p ) % p ] = i ; a = ksm ( a , t , p ); if ( ! a ) return b == 0 ? 1 : -1 ; for ( ll i = 1 ; i <= t ; i ++ ) { ll val = ksm ( a , i , p ); int j = hash . find ( val ) == hash . end () ? -1 : hash [ val ]; if ( j >= 0 && i * t - j >= 0 ) return i * t - j ; } return -1 ; //\u65e0\u89e3 } \u6570\u503c\u5206\u6790 \u00b6 Simpson \u516c\u5f0f \u00b6 \u5982\u679c\u539f\u51fd\u6570\u662f\u6b21\u6570\u4e0d\u8d85\u8fc7\u4e8c\u6b21\u7684\u591a\u9879\u5f0f\uff0c\u53ef\u4ee5\u7cbe\u786e\u8ba1\u7b97\u79ef\u5206\u503c\uff0c\u53ea\u9700\u8981\u77e5\u9053\u7aef\u70b9\u548c\u4e2d\u70b9\u7684\u503c $$ \\int_{a}^{b}{f(x)}dx \\approx \\frac{b-a}{6}(\\quad f(a)+4f(\\frac{a+b}{2})+f(b)\\quad) $$ \u9ad8\u65af\u7ea6\u65e6\u6d88\u5143 \u00b6 \u6d1b\u8c37 P3389 \\(O(n^3)\\) \uff0c\u65b9\u7a0b\u6570\u548c\u672a\u77e5\u6570\u90fd\u8981\u6c42\u662fn\uff0c\u7ed3\u679c\u5728 \\(a[i][n+1]\\) \u4e2d\uff0c\u8fd4\u56de\u503c1\u8868\u793a\u6709\u552f\u4e00\u89e3\uff0c0\u8868\u793a\u65e0\u89e3 const double eps = 1e-8 ; int guass_jordan ( int n ) { for ( int i = 1 ; i <= n ; i ++ ) { int r = i ; for ( int j = i ; j <= n ; j ++ ) //\u628a\u6b63\u5728\u5904\u7406\u7684\u672a\u77e5\u6570\u7cfb\u6570\u7edd\u5bf9\u503c\u6700\u5927\u7684\u653e\u4e0a\u6765 if ( fabs ( a [ r ][ i ]) < fabs ( a [ j ][ i ])) r = j ; if ( r != i ) //\u4ea4\u6362 for ( int j = 1 ; j <= n + 1 ; j ++ ) swap ( a [ i ][ j ], a [ r ][ j ]); if ( fabs ( a [ i ][ i ]) < eps ) return 0 ; //\u65e0\u89e3 for ( int j = i + 1 ; j <= n + 1 ; j ++ ) a [ i ][ j ] /= a [ i ][ i ]; //\u7cfb\u6570\u5316\u4e3a1,\u6ce8\u610fi+1\uff0c\u5982\u679c\u4ecei\u5f00\u59cb\u4f1a\u5f71\u54cd\u5230\u540e\u9762 for ( int j = 1 ; j <= n ; j ++ ) if ( j != i ) for ( int k = i + 1 ; k <= n + 1 ; k ++ ) //\u6ce8\u610fi+1\uff0c\u5982\u679c\u4ecei\u5f00\u59cb\u4f1a\u5f71\u54cd\u5230\u540e\u9762 a [ j ][ k ] -= a [ i ][ k ] * a [ j ][ i ]; } return 1 ; } \u5176\u4ed6 \u00b6 \u88f4\u8700\u5b9a\u7406 \u00b6 \u82e5 \\(a,b\\) \u662f\u6574\u6570,\u4e14 \\(gcd(a,b)=d\\) \uff0c\u90a3\u4e48\u5bf9\u4e8e\u4efb\u610f\u7684\u6574\u6570 \\(x,y\\) , \\(ax+by\\) \u90fd\u4e00\u5b9a\u662f \\(d\\) \u7684\u500d\u6570\uff0c\u5373 \\(d|(ax+by)\\) \u7279\u522b\u5730\uff0c\u4e00\u5b9a\u5b58\u5728\u6574\u6570 \\(x,y\\) \uff0c\u4f7f \\(ax+by=d\\) \u6210\u7acb\u3002 \u91cd\u8981\u63a8\u8bba\uff1a \\(a,b\\) \u4e92\u8d28\u7684\u5145\u8981\u6761\u4ef6\u662f\u5b58\u5728\u6574\u6570 \\(x,y\\) \u4f7f \\(ax+by=1\\) \u552f\u4e00\u5206\u89e3\u5b9a\u7406 \u00b6 \u6b63\u6574\u6570 \\(N\\) \u7684\u6807\u51c6\u5206\u89e3\u5f0f\uff1a \\(N=p_1^{a_1}p_2^{a_2}...p_n^{a_n}\\) \u90a3 \\(N\\) \u7684\u6b63\u56e0\u6570\u4e2a\u6570\u4e3a \\(\\sigma_0(N)=(1+a_1)(1+a_2)...(1+a_n)\\) \u6240\u6709\u6b63\u56e0\u6570\u7684\u548c\u4e3a \\(\\sigma_1(N)=(1+p_1+p_1^2+...+p_1^{a_1})...(1+p_n+p_n^2+...+p_n^{a_n})\\) \u6574\u6570\u5206\u5757 \u00b6 \\(\\frac{n}{1}+\\frac{n}{2}+\\frac{n}{3}+..+\\frac{n}{n}\\) \u7684\u548c ll ans = 0 ; for ( int l = 1 , r ; l <= n ; l = r + 1 ) { r = n / ( n / l ); //\u6bcf\u6bb5\u533a\u95f4\u7684\u53f3\u7aef\u70b9 ans += ( ll )( n / l ) * ( r - l + 1 ); } \u65af\u7279\u6797\u516c\u5f0f \u00b6 \\[ n! \\approx \\sqrt{2 \\pi n}(\\frac{n}{e})^n \\] \u7528 \\(log10\\) \u5feb\u901f\u8ba1\u7b97\u5927\u6570\u7684\u4f4d\u6570 \u9519\u6392\u516c\u5f0f \u00b6 \\[ f(n) = (n-1)(f(n-1)f(n-2)) \\] \u5bb9\u65a5\u539f\u7406 \u00b6 HDU 4135 $$ |U(A_i)|=\\sum_{1\\leq i\\leq m}{|A_i|}-\\sum_{i\\leq i<j\\leq m}{|A_i\\bigcap A_j|}+ \\dots+(-1)^{m+1}\\sum|A_1\\bigcap A_2\\bigcap \\dots\\bigcap A_m| $$ void solve () { int res = 0 ; for ( int i = 1 ; i < ( 1 << m ); i ++ ) { int cnt = 0 ; for ( int j = i ; j != 0 ; j >>= 1 ) cnt += j & 1 ; ll lcm = 1 ; for ( int j = 0 ; j < m ; j ++ ) { if ( ( i >> j ) & 1 ) { lcm = lcm / gcd ( lcm , num [ j ]) * num [ j ]; //eg,\u662f2\u7684\u500d\u6570\u4e0d\u4e00\u5b9a\u662f4\u7684\u500d\u6570 if ( lcm > n ) break ; } } if ( cnt % 2 == 0 ) res -= n / lcm ; else res += n / lcm ; } cout << res ; } Catalan\u6570 \u00b6 \u8bbe h(n) \u8868\u793a Catalan\u6570\u7684\u7b2cn\u9879\uff0c \\(h(0) = 1, h(1) = 1\\) \u9012\u63a8\u5f0f\uff1a \\(h(n)=h(0)*h(n-1)+h(1)*h(n-2)+...+h(n-1)*h(0)(n\\geq2)\\) \u53e6\u7c7b\u9012\u63a8\u5f0f\uff1a \\(h(n)=h(n-1)*(4*n-2)/(n+1)\\) \u9012\u63a8\u5173\u7cfb\u7684\u89e3\uff1a \\(h(n)=C(2n,n)/(n+1)(n=0,1,2,...)\\) \u9012\u63a8\u5173\u7cfb\u7684\u53e6\u7c7b\u89e3\uff1a \\(h(n)=C(2n,n)-C(2n,n-1)(n=0,1,2,...)\\) eg\uff1a\u8fdb\u51fa\u6808\uff0c\u7535\u5f71\u8d2d\u7968\uff0c\u5706\u5185\u8fde\u5f26\uff0c\u51f8\u591a\u8fb9\u5f62\u7684\u5256\u5206\uff0cn\u5bf9\u62ec\u53f7\u5f62\u6210\u7684\u5408\u6cd5\u62ec\u53f7\u8868\u8fbe\u5f0f\u7684\u4e2a\u6570\uff0c n+1\u4e2a\u6570\u8fde\u4e58\u4e0d\u540c\u7684\u4e58\u6cd5\u987a\u5e8f\u6570\u3001 Bell\u6570\u548cStirling\u6570 \u00b6 \u7b2c\u4e00\u7c7b Stirling\u6570\u9012\u63a8\u5f0f\uff1a \\(S(i,j)=(i-1)*S(i-1,j)+S(i-1,j-1)\\) eg\uff1ai \u4e2a\u4e0d\u540c\u5143\u7d20\u6784\u6210 j \u4e2a\u5706\u6392\u5217\u7684\u6570\u76ee \u7b2c\u4e8c\u7c7b Stirling\u6570\u9012\u63a8\u5f0f\uff1a \\(S(i,j)=j*S(i-1,j)+S(i-1,j-1)\\) eg\uff1ai \u4e2a\u4e0d\u540c\u7684\u5143\u7d20\u5212\u5206\u4e3a j \u4e2a\u975e\u7a7a\u96c6\u7684\u65b9\u6cd5\u7684\u6570\u76ee Bell\u6570\u548c\u7b2c\u4e8c\u7c7bStirling\u6570\u4e4b\u95f4\u7684\u5173\u7cfb\uff1a \\(B_n=\\sum_{k=1}^n{S(n,k)}\\) eg\uff1an \u4e2a\u4e0d\u540c\u7684\u6570\u7684\u5212\u5206\u65b9\u6848\u6570","title":"\u6570\u8bba"},{"location":"OI/%E6%95%B0%E8%AE%BA/#_1","text":"","title":"\u6570\u8bba"},{"location":"OI/%E6%95%B0%E8%AE%BA/#_2","text":"","title":"\u57fa\u7840\u51fd\u6570"},{"location":"OI/%E6%95%B0%E8%AE%BA/#gcd","text":"\u8bbe \\(a/b=d, a\\%b=r\\) \u5373 \\(a=b\\times d+r\\) \uff0c\u6240\u4ee5 \\(gcd(b, r) | a\\) \uff0c\u53c8 \\(gcd(b, r) | b\\) \uff0c\u6240\u4ee5 \\(gcd(b, r) | gcd(a, b)\\) \u53c8 \\(r=a-b\\times d\\) \uff0c\u6240\u4ee5 \\(gcd(a, b) | r\\) \uff0c\u53c8 \\(gcd(a, b) | b\\) \uff0c\u6240\u4ee5 \\(gcd(a, b) | gcd(b, r)\\) \u6240\u4ee5 \\(gcd(a, b) = gcd(b, r)\\) , \u5373 \\(gcd(a, b) = gcd(b, a\\%b)\\) \u4e00\u4e9b\u6027\u8d28 \\(gcd(a,b)=gcd(a,a+b)=gcd(a,ka+b)\\) \\(gcd(ka,kb)=k*gcd(a,b)\\) \\(gcd(a,b,c)=gcd(gcd(a,b),c)\\) int gcd ( int a , int b ){ return b ? gcd ( b , a % b ) : a ; }","title":"gcd"},{"location":"OI/%E6%95%B0%E8%AE%BA/#lcm","text":"int lcm ( int a , int b ){ return a * b / gcd ( a , b ); }","title":"lcm"},{"location":"OI/%E6%95%B0%E8%AE%BA/#exgcd","text":"\u6c42 \\(ax + by = gcd(a, b)\\) \u7684\u4e00\u7ec4\u6574\u6570\u89e3 x\uff0cy b = 0\u65f6\uff0c \\(gcd(a, b) = a\\) , x=1\u200b, y=0 \u4e3a\u4e00\u7ec4\u89e3 b != 0 \u65f6 \u8bbe \\(ax_{1} + by_{1} = gcd(a, b)\\) \u200b \\(bx_{2}+ (a\\%b)y_{2} = gcd(b, a\\%b)\\) \u56e0\u4e3a \\(gcd(a, b) = gcd(b, a\\%b)\\) \u6240\u4ee5 \\(bx_{2} + (a\\%b)y_{2} = ax_{1} + by_{1}\\) \u200b \\(a\\%b = a-(a/b)*b\\) , \u4ee3\u5165\u4e0a\u5f0f\u5f97 \u200b \\(bx_{2}+ ( a - (a/b) * b)*y_{2} = ax_{1} + by_{1}\\) \u200b \\(ay_{2} + bx_{2~}- (a/b)*by_{2} = ax_{1} + by_{1}\\) \u200b \\(ay_{2} + b[x_{2}-(a/b)*y_{2}] = ax_{1} + by_{1}\\) \u6240\u4ee5 \\(x_{1} = y_{2}\\) \u200b \\(y_{1} = x_{2} - (a/b)*y_{2}\\) ll exgcd ( ll a , ll b , ll & x , ll & y ) { //\u8fd4\u56de gcd(a, b) if ( ! b ){ x = 1 , y = 0 ; return a ; } ll d = exgcd ( b , a % b , x , y ); ll t = x ; x = y ; y = t - ( a / b ) * y ; return d ; }","title":"exgcd"},{"location":"OI/%E6%95%B0%E8%AE%BA/#_3","text":"typedef long long ll ; ll pow ( ll a , ll b , ll p ) { // a^b (mod p) ll res = 1 ; while ( b ){ if ( b & 1 ) res = res * a % p ; a = a * a % p ; b >>= 1 ; } return res ; }","title":"\u5feb\u901f\u5e42"},{"location":"OI/%E6%95%B0%E8%AE%BA/#_4","text":"//\u9632\u6b62\u4e58\u6cd5\u7206ll ll mul ( ll a , ll b , ll p ){ ll res = 0 ; while ( b ){ if ( b & 1 ) res = ( res + a ) % p ; a = ( a + a ) % p ; b >>= 1 ; } return res ; }","title":"\u5feb\u901f\u4e58"},{"location":"OI/%E6%95%B0%E8%AE%BA/#_5","text":"bool isprime ( int x ){ if ( x <= 1 ) return false ; for ( int i = 2 ; i <= x / i ; i ++ ) if ( x % i == 0 ) return false ; return true ; }","title":"\u7d20\u6570"},{"location":"OI/%E6%95%B0%E8%AE%BA/#_6","text":"bool isprime [ N + 1 ]; //0 1 \u662f\u975e\u7d20\u6570 void getPrime (){ for ( int i = 2 , i <= N ; i ++ ) isprime [ i ] = true ; for ( int i = 2 ; i <= N / i ; i ++ ) //\u5982\u679c x>sqrt(N) \u662f\u5408\u6570\uff0c \u5728\u524d\u9762\u5c31\u4f1a\u88ab\u7b5b\u6389 if ( isprime [ i ]) for ( int j = i * i ; j <= N ; j += i ) //2i, 3i, 5i \u90fd\u5df2\u7ecf\u7b5b\u8fc7\uff0c\u53ef\u4ee5\u4ecei*i\u5f00\u59cb isprime [ i ] = false ; }","title":"\u57c3\u6c0f\u7b5b\u7d20\u6570"},{"location":"OI/%E6%95%B0%E8%AE%BA/#_7","text":"\\(O(n)\\) int cnt = 0 ; int prime [ N + 1 ]; //\u8bb0\u5f55\u7d20\u6570 bool isprime [ N + 1 ]; void euler (){ for ( int i = 2 ; i <= N ; i ++ ) isprime [ i ] = true ; for ( int i = 2 ; i <= N ; i ++ ){ if ( isprime [ i ]) prime [ cnt ++ ] = i ; //\u8bb0\u5f55 for ( int j = 0 ; j < cnt && i * prime [ j ] <= N ; j ++ ){ isprime [ i * prime [ j ]] = false ; if ( i % prime [ j ] == 0 ) break ; //\u4fdd\u8bc1\u5408\u6570\u88ab\u6700\u5c0f\u7684\u8d28\u56e0\u5b50\u7b5b\u53bb } } }","title":"\u6b27\u62c9\u7b5b\u7d20\u6570(\u7ebf\u6027\u7b5b)"},{"location":"OI/%E6%95%B0%E8%AE%BA/#_8","text":"//\u7b5b[l, r)\u4e4b\u95f4\u7684\u7d20\u6570 //\u6ce8\u610f\u533a\u95f4\u5f00\u95ed //\u5982\u679cl==1,l++\uff0c\u5426\u5219\u4f1a\u8ba4\u4e3a1\u662f\u7d20\u6570 bool isprime_small [ MAXN ]; //\u8bb0\u5f55\u524d sqrt(r) \u7684\u7d20\u6570 bool isprime [ MAXN ]; //\u5982\u679ci\u662f\u7d20\u6570\uff0c\u8bb0isprime[i-l] = true void segement_prime ( ll l , ll r ){ for ( ll i = 0 ; i * i < r ; i ++ ) isprime_small [ i ] = true ; for ( ll i = 0 ; i < r - l ; i ++ ) isprime [ i ] = true ; for ( ll i = 2 ; i * i < r ; i ++ ) if ( isprime_small [ i ]) { //\u5982\u679c\u662f\u7d20\u6570 for ( ll j = i * i ; j * j < r ; j += i ) //\u7b5b[2, sqrt(b)] isprime_small [ j ] = false ; for ( ll j = max ( 2L L , ( l + i -1 ) / i ) * i ; j < r ; j += i ) //\u7b5b[a, b] isprime [ j - l ] = false ; } }","title":"\u7b5b\u533a\u95f4\u5185\u7d20\u6570"},{"location":"OI/%E6%95%B0%E8%AE%BA/#miller-rabin","text":"bool check ( ll a , ll r , ll t , ll n ) { ll ret = pow ( a , r , n ), last = ret ; for ( int i = 0 ; i < t ; i ++ ) { ret = mul ( ret , ret , n ); if ( ret == 1 && last != 1 && last != n - 1 ) return true ; last = ret ; } return ret != 1 ; } bool Miller_Rabin ( ll n ) { if ( n == 2 ) return true ; if ( n < 2 || ! ( n & 1 )) return false ; ll r = n - 1 , t = 0 ; while ( ! ( r & 1 )) r >>= 1 , t ++ ; for ( int i = 1 , j ; i <= 8 ; i ++ ) { ll a = rand () % ( n - 2 ) + 2 ; if ( check ( a , r , t , n )) return false ; } return true ; }","title":"Miller-Rabin \u7d20\u6027\u6d4b\u8bd5"},{"location":"OI/%E6%95%B0%E8%AE%BA/#pollard-rho","text":"ll pollard ( ll n ) { if ( ! ( n & 1 )) return 2 ; ll c = rand () % ( n - 1 ) + 1 ; ll x = rand () % ( n - 1 ) + 1 , y = x , i = 1 , k = 2 ; while ( true ) { i ++ ; x = ( mul ( x , x , n ) + c ) % n ; ll d = gcd ( y - x + n , n ); if ( d != 1 && d != n ) return d ; if ( y == x ) return n ; if ( i == k ) { y = x ; k <<= 1 ; } } } /* \u500d\u589e\u4f18\u5316 ll pr(ll n) { ll x = 0, y = 0; ll c = 1ll * rand() % (n - 1) + 1; int step = 0, goal = 1; ll val = 1; for (goal = 1;; goal <<= 1, y = x, val = 1) { for (step = 1; step <= goal; ++step) { x = (mul(x, x, n) + c) % n; val = mul(val, abs(y - x), n); if ((step % 127) == 0) { ll d = gcd(val, n); if (d > 1) return d; } } ll d = gcd(val, n); if (d > 1) return d; } } */ ll fac [ 10000 ]; ll tot = 0 ; void find_fac ( ll n ) { if ( Miller_Rabin ( n )) { fac [ tot ++ ] = n ; return ; } ll p = n ; while ( p >= n ) p = pollard ( p ); find_fac ( p ), find_fac ( n / p ); }","title":"Pollard-Rho\u5927\u6570\u5206\u89e3"},{"location":"OI/%E6%95%B0%E8%AE%BA/#_9","text":"\u5b9a\u4e49: \\(\\varphi(n)\\) \u8868\u793a\u5c0f\u4e8e\u7b49\u4e8e \\(n\\) \u4e14\u4e0e \\(n\\) \u4e92\u8d28\u7684\u6570\u7684\u4e2a\u6570\uff0c\u6bd4\u5982 \\(\\varphi(1)=1\\) \u901a\u5f0f\uff1a \\(\\varphi(x)=x\\prod_{i=1}^n{(1-\\frac{1}{p_i})}\\) \uff0c\u5176\u4e2d \\(p_i\\) \u662f \\(x\\) \u7684\u6240\u6709\u8d28\u56e0\u6570","title":"\u6b27\u62c9\u51fd\u6570"},{"location":"OI/%E6%95%B0%E8%AE%BA/#_10","text":"\\(n\\) \u662f\u8d28\u6570\u65f6\uff0c \\(\\varphi(n)=n-1\\) \\(p\\) \u662f\u8d28\u6570\u65f6\uff0c \\(\\varphi(p^k)=(p-1)\\times p^{k-1}\\) \u79ef\u6027\u6027\u8d28\uff0c\u5982\u679c \\(gcd(a,b)=1\\) \uff0c\u5219 \\(\\varphi(a\\times b)=\\varphi(a)\\times \\varphi(b)\\) \u7279\u522b\u7684\uff0c \\(n\\) \u662f\u5947\u6570\u65f6\uff0c \\(\\varphi(2n)=\\varphi(n)\\) \\(n > 2\\) \u65f6\uff0c \\(\\varphi(n)\\) \u4e3a\u5076\u6570 \\(n=\\sum_{d|n}\\varphi(d)\\) \u6b27\u62c9\u5b9a\u7406\uff0c\u82e5 \\(gcd(a,m)=1\\) \uff0c\u5219 \\(a^{\\varphi(m)}\\equiv 1(mod \\quad m)\\) \u6269\u5c55\u6b27\u62c9\u5b9a\u7406 \\[ a^b\\equiv \\begin{cases} a^{b \\% \\varphi(p)}&gcd(a,p)=1 \\\\ a^b&gcd(a,p)\\neq1,b<\\varphi(p) \\\\ a^{b \\% \\varphi(p)+\\varphi(p)}&gcd(a,p)\\neq1,b\\geq\\varphi(p) \\end{cases} (mod\\ p) \\]","title":"\u57fa\u672c\u6027\u8d28"},{"location":"OI/%E6%95%B0%E8%AE%BA/#_11","text":"\\(O(\\sqrt{n})\\) ll phi ( ll n ){ ll res = n ; for ( ll i = 2 ; i * i <= n ; i ++ ){ if ( n % i == 0 ){ res -= res / i ; while ( n % i == 0 ) n /= i ; } } if ( n > 1 ) res -= res / n ; return res ; }","title":"\u6c42\u5355\u4e2a\u6570\u7684\u6b27\u62c9\u51fd\u6570"},{"location":"OI/%E6%95%B0%E8%AE%BA/#_12","text":"\\(\\varphi(x)=x\\prod_{i=1}^n{(1-\\frac{1}{p_i})}\\) void euler ( int n ){ for ( int i = 1 ; i <= n ; i ++ ) phi [ i ] = i ; for ( int i = 2 ; i <= n ; i ++ ) if ( phi [ i ] == i ) //\u8fd9\u4ee3\u8868i\u662f\u8d28\u6570 for ( int j = i ; j <= n ; j += i ) phi [ j ] = phi [ j ] / i * ( i -1 ); //\u628ai\u7684\u500d\u6570\u66f4\u65b0\u6389 }","title":"\u57c3\u6c0f\u6c42\u6b27\u62c9\u51fd\u6570"},{"location":"OI/%E6%95%B0%E8%AE%BA/#_13","text":"\\(if(i\\%prime[j] != 0)\\) \uff0c\u5219 \\(i\\) \u4e0e \\(prime[j]\\) \u4e92\u8d28 \u7531\u79ef\u6027\u6027\u8d28\u53ef\u5f97\uff0c \\(phi[i*prime[j]] = phi[i]*phi[prime[j]]\\) \\(if(i\\%prime[j] == 0)\\) \uff0c\u5219 \\(i\\) \u4e2d\u6709 \\(i*prime[j]\\) \u7684\u6240\u6709\u8d28\u56e0\u5b50\uff0c\u6709 \\(\\varphi(i*prime[j])=prime[j]*i*\\prod_{k=1}^n{(1-\\frac{1}{k_i})}=\\varphi(i)*prime[j]\\) int prime [ maxn ], cnt = 0 ; bool vis [ maxn ]; void euler ( int n ){ phi [ 1 ] = 1 ; //1\u8981\u7279\u5224 for ( int i = 2 ; i < = n ; i ++ ){ if ( vis [ i ] == 0 ){ //i\u662f\u8d28\u6570 prime [ cnt ++ ] = i ; phi [ i ] = i -1 ; } for ( int j = 1 ; j < cnt && prime [ j ] * i <= n ; j ++ ){ vis [ i * prime [ j ]] = 1 ; if ( i % prime [ j ] == 0 ){ phi [ i * prime [ j ]] = phi [ i ] * prime [ j ]; //\u82e5prime[j]\u662fi\u7684\u8d28\u56e0\u5b50\uff0c\u5219\u6839\u636e\u8ba1\u7b97\u516c\u5f0f\uff0ci\u5df2\u7ecf\u5305\u62eci*prime[j]\u7684\u6240\u6709\u8d28\u56e0\u5b50 break ; //\u4fdd\u8bc1\u6bcf\u4e2a\u6570\u53ea\u4f1a\u88ab\u81ea\u5df1\u6700\u5c0f\u7684\u56e0\u5b50\u7b5b\u6389\u4e00\u6b21 } else phi [ i * prime [ j ]] = phi [ i ] * phi [ prime [ j ]]; //\u79ef\u6027\u51fd\u6570\u7684\u6027\u8d28 } } }","title":"\u6b27\u62c9\u7b5b\u6c42\u6b27\u62c9\u51fd\u6570"},{"location":"OI/%E6%95%B0%E8%AE%BA/#_14","text":"","title":"\u4e2d\u56fd\u5269\u4f59\u5b9a\u7406"},{"location":"OI/%E6%95%B0%E8%AE%BA/#crt","text":"\u6d1b\u8c37 P3868 \\(X \u2261 r_{i} ( mod\\quad m_{i} )\\) \u8981\u6c42\uff1a \\(m_i\\) \u4e24\u4e24\u4e92\u8d28 ll CRT ( ll n , ll * r , ll * m ){ ll res = 0 , M = 1 ; for ( int i = 0 ; i < n ; i ++ ) M *= m [ i ]; for ( int i = 0 ; i < n ; i ++ ) { ll x , y ; ll tmp = M / m [ i ]; ll d = exgcd ( tmp , m [ i ], x , y ); //gcd(tmp, m[i]) = 1 x = ( x % m [ i ] + m [ i ]) % m [ i ]; res = ( res + tmp * x * r [ i ]) % M ; //\u53ef\u80fd\u9700\u8981\u7528\u5230\u5feb\u901f\u4e58\u9632\u6b62\u6ea2\u51fa } return ( res + M ) % M ; }","title":"CRT"},{"location":"OI/%E6%95%B0%E8%AE%BA/#excrt","text":"\u6d1b\u8c37 P4777 \\(X \u2261 r_{i} ( mod\\quad m_{i} )\\) \u4e0d\u8981\u6c42 \\(m_i\\) \u4e24\u4e24\u4e92\u8d28 \u6ee1\u8db3\u7b2c\u4e00\u4e2a\u6761\u4ef6\u7684\u89e3\u4e3a \\(r_1\\) \u5047\u8bbe\u6ee1\u8db3\u524d \\(k-1\\) \u4e2a\u6761\u4ef6\u7684\u4e00\u4e2a\u7279\u89e3\u4e3a \\(res\\) \uff0c \\(M_{k-1}\\) \u4e3a\u524d \\(k-1\\) \u4e2a \\(m\\) \u7684 lcm \u5219\u524d \\(k-1\\) \u4e2a\u65b9\u7a0b\u7684\u901a\u89e3\u4e3a $$ res+x\\times M_{k-1} $$ \u90a3\u4e48\u5bf9\u4e8e\u524d \\(k\\) \u4e2a\u65b9\u7a0b,\u5982\u679c\u6709\u89e3\uff0c\u5219 \u5b58\u5728\u6574\u6570 \\(x\\) \uff0c\u4f7f $$ res+x\\times M_{k-1}\\equiv r_k\\quad (mod\\quad m_k) $$ \u5373 $$ x\\times M_{k-1}\\equiv r_k-res\\quad (mod\\quad m_k) $$ \u5229\u7528\u62d3\u6b27\u6c42\u89e3\u5f97 \\(x\\) \uff0c\u5219\u524d \\(k\\) \u4e2a\u65b9\u7a0b\u7684\u4e00\u4e2a\u7279\u89e3\u4e3a $$ res+x\\times M_{k-1} $$ \u901a\u89e3\u4e3a \\(\u7279\u89e3 + x^{'}M_k\\) ll EXCRT ( ll n , ll * r , ll * m ){ ll res = r [ 0 ], M = m [ 0 ]; ll x , y ; for ( int i = 1 ; i < n ; i ++ ) { ll c = ( r [ i ] - res % m [ i ] + m [ i ]) % m [ i ]; ll d = exgcd ( M , m [ i ], x , y ), bg = m [ i ] / d ; x = ( x % bg + bg ) % bg ; if ( c % d != 0 ) return -1 ; //\u65e0\u89e3,\u56e0\u4e3a\u65e0\u6cd5\u8ba9\u4f59\u6570\u6269\u5927\u6210c x = mul ( x , c / d , bg ); //\u5feb\u901f\u4e58 res += x * M ; M *= bg ; //lcm res = ( res % M + M ) % M ; } return res ; }","title":"EXCRT"},{"location":"OI/%E6%95%B0%E8%AE%BA/#_15","text":"","title":"\u540c\u4f59\u95ee\u9898"},{"location":"OI/%E6%95%B0%E8%AE%BA/#_16","text":"\u540c\u4f59\u4e0d\u6ee1\u8db3\u9664\u6cd5\uff0c \\(a/b\\quad mod \\quad p\\quad != (a\\quad mod\\quad p)/(b\\quad mod\\quad p)\\) \u5f15\u5165 \\(b\\) \u7684\u9006\u5143 \\(x\\) , \u5373 \\(b*x = 1 (mod\\quad p)\\) \uff0cb \u4e0e p \u4e92\u8d28 \u5047\u8bbe \\(a/b = k (mod\\quad p)\\) \u540c\u4e58 \\(bx\\) \u5f97 $ a/b * bx = k * 1\uff08mod\\quad p)$ \u200b \\(a*x = k (mod\\quad p)\\) \u6ce8\u610f\uff1a b \u548c p \u4e92\u8d28\uff0cb \u624d\u6709\u5173\u4e8e p \u7684\u9006\u5143","title":"\u9006\u5143"},{"location":"OI/%E6%95%B0%E8%AE%BA/#_17","text":"\u8d39\u9a6c\u5c0f\u5b9a\u7406 \uff1a\u5982\u679c \\(p\\) \u4e3a\u8d28\u6570\uff0c\u4e14 \\(a\\) \u4e0e \\(p\\) \u4e92\u8d28(\u5373 \\(a\\) \u4e0d\u662f \\(p\\) \u7684\u500d\u6570)\uff0c\u5219 \\(a^{p-1} \\equiv 1 \uff08mod\\quad p)\\) \u6240\u4ee5\u6709 \\(a * a^{p-2} \\equiv 1 (mod\\quad p)\\) , \u5373 \\(a^{p-2} (mod\\quad p)\\) \u662f a \u7684\u9006\u5143 //\u7528\u5feb\u901f\u5e42 ll pow ( ll a , ll p ){ int res = 1 ; int d = p -2 ; while ( d ) { if ( d & 1 ) res = res * a % p ; a = a * a % p ; d >>= 1 ; } return res ; }","title":"\u8d39\u9a6c\u5c0f\u5b9a\u7406\u6c42\u9006\u5143"},{"location":"OI/%E6%95%B0%E8%AE%BA/#_18","text":"\u5982\u679c \\(b\\) \u4e0e \\(p\\) \u4e92\u8d28\uff0c\u5373 \\(gcd(b, p) = 1\\) \u8981\u89e3 \\(b*x = 1 (mod\\quad p)\\) , \u5373\u6c42 \\(bx + yp = 1 = gcd(b, p)\\) \u7684\u89e3 \\(x\\) ll inv ( ll b , ll p ) { ll x , y ; ll d = exgcd ( b , p , x , y ); return d == 1 ? ( x + p ) % p : -1 ; //\u8fd4\u56de -1 \u8bf4\u660e b,p \u4e0d\u4e92\u8d28 }","title":"\u62d3\u5c55\u6b27\u51e0\u91cc\u5f97\u6c42\u9006\u5143"},{"location":"OI/%E6%95%B0%E8%AE%BA/#_19","text":"\u6d1b\u8c37 P3811 \u662f\u8d39\u5c0f\u7684\u63a8\u5e7f\uff0c\u4e0d\u8981\u6c42 \\(p\\) \u4e3a\u8d28\u6570\uff0c\u4f46 \\(gcd(a,p)=1\\) \\(a^{\\varphi(p)}\\equiv1(mod\\quad p)\\) \uff0c\u6240\u4ee5\u5176\u9006\u5143\u4e3a \\(a^{\\varphi(n)-1}\\) ll phi ( ll n ){ ll res = n ; for ( ll i = 2 ; i * i <= n ; i ++ ) { if ( n % i == 0 ) { res -= res / i ; while ( n % i == 0 ) n /= i ; } } if ( n > 1 ) res -= res / n ; return res ; } ans = pow ( a , phi ( p ) -1 , p );","title":"\u6b27\u62c9\u51fd\u6570\u6c42\u9006\u5143"},{"location":"OI/%E6%95%B0%E8%AE%BA/#_20","text":"\u6c42\u9636\u4e58\u7684\u9006\u5143\uff0c\u5148\u7528\u8d39\u9a6c\u5c0f\u5b9a\u7406\u6c42\u51fa n! \u5728 p \u4e0b\u7684\u9006\u5143\uff0c\u518d\u5f80\u524d\u63a8 \u5047\u8bbe n! \u7684\u9006\u5143\u4e3a \\([n!]^{-1}\\) , \u8981\u6c42 \\((n-1)!\\) \u7684\u9006\u5143 $$ (n-1)! \\times n[n!]^{-1} \u2261 1 (mod\\quad p) $$ \u6240\u4ee5\uff0c \\((n-1)!\\) \u7684\u9006\u5143\u5c31\u662f \\(n[n!]^{-1}\\) void fa_inv ( ll n , ll p ){ fact [ 0 ] = 1 ; //factorial for ( int i = 1 ; i <= n ; i ++ ) fact [ i ] = fact [ i -1 ] * i % p ; finv [ N ] = pow ( fact [ n ], p -2 , p ); for ( int i = n -1 ; i >= 0 ; i -- ) finv [ i ] = ( i + 1 ) * finv [ i + 1 ] % p ; }","title":"\u9636\u4e58\u9006\u5143"},{"location":"OI/%E6%95%B0%E8%AE%BA/#_21","text":"\u6d1b\u8c37 P3811 \u8981\u6c42\u51fa 1~n \u4e2d\u6240\u6709\u6570\u5bf9 \\(p\\) \u7684\u9006\u5143\uff0c\u9009\u62e9\u6253\u8868 \u200b \\(1^{\u22121} \u2261 1 (mod\\quad p)\\) \u8bbe \\(p = k * i + r\\) \u5176\u4e2d 1 < r < i < p, \u5373 \\(k = p/i, r = p\\quad mod\\quad i\\) \u6240\u4ee5\u6709 \\(k * i + r \u2261 0 ( mod\\quad p )\\) \u4e24\u8fb9\u540c\u65f6\u4e58\u4e0a \\(i^{\u22121} * r^{\u22121}\\) \u5f97 \\(k * r^{\u22121} + i^{\u22121} \u2261 0 ( mod\\quad p )\\) \u200b \\(i^{\u22121} \u2261 \u2212k * r^{\u22121} ( mod\\quad p )\\) \u5f97\u9012\u63a8\u516c\u5f0f \\(i^{-1} \u2261 -\uff08p/i) * (p\\quad mod\\quad i)^{-1} (mod\\quad p)\\) \u6574\u7406\u5f97 \\(inv[i] = (p - p/i) * inv[p\\%i] \\% p\\) \u5176\u4e2d p % i \u6bd4 i \u5c0f void inverse =- ( int n , int p ) { inv [ 1 ] = 1 ; for ( int i = 2 ; i <= n ; i ++ ) inv [ i ] = ( ll )( p - p / i ) * inv [ p % i ] % p ; }","title":"\u7ebf\u6027\u6c42\u9006\u5143(\u6253\u8868)"},{"location":"OI/%E6%95%B0%E8%AE%BA/#lucas","text":"\u6d1b\u8c37 P3807 HDU 3037 \u89e3\u51b3\u7ec4\u5408\u6570\u53d6\u4f59\u7684\u95ee\u9898\uff1a (p\u5fc5\u987b\u662f\u7d20\u6570,\u4e0d\u7136\u4e0d\u80fd\u7528\u8d39\u9a6c\u5c0f\u5b9a\u7406\u6c42\u9006\u5143) $$ C(n,m) = \\prod_{i=0}^{k}{C(n_i, m_i)}(mod\\quad p) $$ \\[ n = n_k p^k+n_{k-1} p^{k-1}+\\cdots+n_1p+n_0 \\] \\[ m=m_k p^k+m_{k-1} p^{k-1}+\\cdots+m_1p+m_0 \\] //\u9884\u5904\u7406\u9636\u4e58 void getFact ( ll p ) { fact [ 0 ] = 1 ; for ( ll i = 1 ; i <= p ; i ++ ) f [ i ] = f [ i -1 ] * i % p ; } //\u8ba1\u7b97\u7ec4\u5408\u6570 ll comb ( ll n , ll m , ll p ) { if ( m > n ) return 0 ; return fact [ n ] * pow ( f [ m ], p -2 , p ) % p * pow ( f [ n - m ], p -2 , p ) % p ; //\u8d39\u9a6c\u5c0f\u5b9a\u7406\u6c42\u9006\u5143 } ll lucas ( ll n , ll m , ll p ) { if ( ! m ) return 1 ; return lucas ( n / p , m / p , p ) % p * comb ( n % p , m % p , p ) % p ; }","title":"Lucas\u5b9a\u7406"},{"location":"OI/%E6%95%B0%E8%AE%BA/#bsgs","text":"\u6c42 \\(a^x=b(mod\\ \\ p)\\) \u7684 \\(x\\) \u6700\u5c0f\u7684\u89e3 ll bsgs ( ll a , ll b , ll p ) { map < ll , ll > hash ; hash . clear (); b %= p ; ll t = sqrt ( p ) + 1 ; for ( ll i = 0 ; i < t ; i ++ ) hash [ b * ksm ( a , i , p ) % p ] = i ; a = ksm ( a , t , p ); if ( ! a ) return b == 0 ? 1 : -1 ; for ( ll i = 1 ; i <= t ; i ++ ) { ll val = ksm ( a , i , p ); int j = hash . find ( val ) == hash . end () ? -1 : hash [ val ]; if ( j >= 0 && i * t - j >= 0 ) return i * t - j ; } return -1 ; //\u65e0\u89e3 }","title":"BSGS"},{"location":"OI/%E6%95%B0%E8%AE%BA/#_22","text":"","title":"\u6570\u503c\u5206\u6790"},{"location":"OI/%E6%95%B0%E8%AE%BA/#simpson","text":"\u5982\u679c\u539f\u51fd\u6570\u662f\u6b21\u6570\u4e0d\u8d85\u8fc7\u4e8c\u6b21\u7684\u591a\u9879\u5f0f\uff0c\u53ef\u4ee5\u7cbe\u786e\u8ba1\u7b97\u79ef\u5206\u503c\uff0c\u53ea\u9700\u8981\u77e5\u9053\u7aef\u70b9\u548c\u4e2d\u70b9\u7684\u503c $$ \\int_{a}^{b}{f(x)}dx \\approx \\frac{b-a}{6}(\\quad f(a)+4f(\\frac{a+b}{2})+f(b)\\quad) $$","title":"Simpson \u516c\u5f0f"},{"location":"OI/%E6%95%B0%E8%AE%BA/#_23","text":"\u6d1b\u8c37 P3389 \\(O(n^3)\\) \uff0c\u65b9\u7a0b\u6570\u548c\u672a\u77e5\u6570\u90fd\u8981\u6c42\u662fn\uff0c\u7ed3\u679c\u5728 \\(a[i][n+1]\\) \u4e2d\uff0c\u8fd4\u56de\u503c1\u8868\u793a\u6709\u552f\u4e00\u89e3\uff0c0\u8868\u793a\u65e0\u89e3 const double eps = 1e-8 ; int guass_jordan ( int n ) { for ( int i = 1 ; i <= n ; i ++ ) { int r = i ; for ( int j = i ; j <= n ; j ++ ) //\u628a\u6b63\u5728\u5904\u7406\u7684\u672a\u77e5\u6570\u7cfb\u6570\u7edd\u5bf9\u503c\u6700\u5927\u7684\u653e\u4e0a\u6765 if ( fabs ( a [ r ][ i ]) < fabs ( a [ j ][ i ])) r = j ; if ( r != i ) //\u4ea4\u6362 for ( int j = 1 ; j <= n + 1 ; j ++ ) swap ( a [ i ][ j ], a [ r ][ j ]); if ( fabs ( a [ i ][ i ]) < eps ) return 0 ; //\u65e0\u89e3 for ( int j = i + 1 ; j <= n + 1 ; j ++ ) a [ i ][ j ] /= a [ i ][ i ]; //\u7cfb\u6570\u5316\u4e3a1,\u6ce8\u610fi+1\uff0c\u5982\u679c\u4ecei\u5f00\u59cb\u4f1a\u5f71\u54cd\u5230\u540e\u9762 for ( int j = 1 ; j <= n ; j ++ ) if ( j != i ) for ( int k = i + 1 ; k <= n + 1 ; k ++ ) //\u6ce8\u610fi+1\uff0c\u5982\u679c\u4ecei\u5f00\u59cb\u4f1a\u5f71\u54cd\u5230\u540e\u9762 a [ j ][ k ] -= a [ i ][ k ] * a [ j ][ i ]; } return 1 ; }","title":"\u9ad8\u65af\u7ea6\u65e6\u6d88\u5143"},{"location":"OI/%E6%95%B0%E8%AE%BA/#_24","text":"","title":"\u5176\u4ed6"},{"location":"OI/%E6%95%B0%E8%AE%BA/#_25","text":"\u82e5 \\(a,b\\) \u662f\u6574\u6570,\u4e14 \\(gcd(a,b)=d\\) \uff0c\u90a3\u4e48\u5bf9\u4e8e\u4efb\u610f\u7684\u6574\u6570 \\(x,y\\) , \\(ax+by\\) \u90fd\u4e00\u5b9a\u662f \\(d\\) \u7684\u500d\u6570\uff0c\u5373 \\(d|(ax+by)\\) \u7279\u522b\u5730\uff0c\u4e00\u5b9a\u5b58\u5728\u6574\u6570 \\(x,y\\) \uff0c\u4f7f \\(ax+by=d\\) \u6210\u7acb\u3002 \u91cd\u8981\u63a8\u8bba\uff1a \\(a,b\\) \u4e92\u8d28\u7684\u5145\u8981\u6761\u4ef6\u662f\u5b58\u5728\u6574\u6570 \\(x,y\\) \u4f7f \\(ax+by=1\\)","title":"\u88f4\u8700\u5b9a\u7406"},{"location":"OI/%E6%95%B0%E8%AE%BA/#_26","text":"\u6b63\u6574\u6570 \\(N\\) \u7684\u6807\u51c6\u5206\u89e3\u5f0f\uff1a \\(N=p_1^{a_1}p_2^{a_2}...p_n^{a_n}\\) \u90a3 \\(N\\) \u7684\u6b63\u56e0\u6570\u4e2a\u6570\u4e3a \\(\\sigma_0(N)=(1+a_1)(1+a_2)...(1+a_n)\\) \u6240\u6709\u6b63\u56e0\u6570\u7684\u548c\u4e3a \\(\\sigma_1(N)=(1+p_1+p_1^2+...+p_1^{a_1})...(1+p_n+p_n^2+...+p_n^{a_n})\\)","title":"\u552f\u4e00\u5206\u89e3\u5b9a\u7406"},{"location":"OI/%E6%95%B0%E8%AE%BA/#_27","text":"\\(\\frac{n}{1}+\\frac{n}{2}+\\frac{n}{3}+..+\\frac{n}{n}\\) \u7684\u548c ll ans = 0 ; for ( int l = 1 , r ; l <= n ; l = r + 1 ) { r = n / ( n / l ); //\u6bcf\u6bb5\u533a\u95f4\u7684\u53f3\u7aef\u70b9 ans += ( ll )( n / l ) * ( r - l + 1 ); }","title":"\u6574\u6570\u5206\u5757"},{"location":"OI/%E6%95%B0%E8%AE%BA/#_28","text":"\\[ n! \\approx \\sqrt{2 \\pi n}(\\frac{n}{e})^n \\] \u7528 \\(log10\\) \u5feb\u901f\u8ba1\u7b97\u5927\u6570\u7684\u4f4d\u6570","title":"\u65af\u7279\u6797\u516c\u5f0f"},{"location":"OI/%E6%95%B0%E8%AE%BA/#_29","text":"\\[ f(n) = (n-1)(f(n-1)f(n-2)) \\]","title":"\u9519\u6392\u516c\u5f0f"},{"location":"OI/%E6%95%B0%E8%AE%BA/#_30","text":"HDU 4135 $$ |U(A_i)|=\\sum_{1\\leq i\\leq m}{|A_i|}-\\sum_{i\\leq i<j\\leq m}{|A_i\\bigcap A_j|}+ \\dots+(-1)^{m+1}\\sum|A_1\\bigcap A_2\\bigcap \\dots\\bigcap A_m| $$ void solve () { int res = 0 ; for ( int i = 1 ; i < ( 1 << m ); i ++ ) { int cnt = 0 ; for ( int j = i ; j != 0 ; j >>= 1 ) cnt += j & 1 ; ll lcm = 1 ; for ( int j = 0 ; j < m ; j ++ ) { if ( ( i >> j ) & 1 ) { lcm = lcm / gcd ( lcm , num [ j ]) * num [ j ]; //eg,\u662f2\u7684\u500d\u6570\u4e0d\u4e00\u5b9a\u662f4\u7684\u500d\u6570 if ( lcm > n ) break ; } } if ( cnt % 2 == 0 ) res -= n / lcm ; else res += n / lcm ; } cout << res ; }","title":"\u5bb9\u65a5\u539f\u7406"},{"location":"OI/%E6%95%B0%E8%AE%BA/#catalan","text":"\u8bbe h(n) \u8868\u793a Catalan\u6570\u7684\u7b2cn\u9879\uff0c \\(h(0) = 1, h(1) = 1\\) \u9012\u63a8\u5f0f\uff1a \\(h(n)=h(0)*h(n-1)+h(1)*h(n-2)+...+h(n-1)*h(0)(n\\geq2)\\) \u53e6\u7c7b\u9012\u63a8\u5f0f\uff1a \\(h(n)=h(n-1)*(4*n-2)/(n+1)\\) \u9012\u63a8\u5173\u7cfb\u7684\u89e3\uff1a \\(h(n)=C(2n,n)/(n+1)(n=0,1,2,...)\\) \u9012\u63a8\u5173\u7cfb\u7684\u53e6\u7c7b\u89e3\uff1a \\(h(n)=C(2n,n)-C(2n,n-1)(n=0,1,2,...)\\) eg\uff1a\u8fdb\u51fa\u6808\uff0c\u7535\u5f71\u8d2d\u7968\uff0c\u5706\u5185\u8fde\u5f26\uff0c\u51f8\u591a\u8fb9\u5f62\u7684\u5256\u5206\uff0cn\u5bf9\u62ec\u53f7\u5f62\u6210\u7684\u5408\u6cd5\u62ec\u53f7\u8868\u8fbe\u5f0f\u7684\u4e2a\u6570\uff0c n+1\u4e2a\u6570\u8fde\u4e58\u4e0d\u540c\u7684\u4e58\u6cd5\u987a\u5e8f\u6570\u3001","title":"Catalan\u6570"},{"location":"OI/%E6%95%B0%E8%AE%BA/#bellstirling","text":"\u7b2c\u4e00\u7c7b Stirling\u6570\u9012\u63a8\u5f0f\uff1a \\(S(i,j)=(i-1)*S(i-1,j)+S(i-1,j-1)\\) eg\uff1ai \u4e2a\u4e0d\u540c\u5143\u7d20\u6784\u6210 j \u4e2a\u5706\u6392\u5217\u7684\u6570\u76ee \u7b2c\u4e8c\u7c7b Stirling\u6570\u9012\u63a8\u5f0f\uff1a \\(S(i,j)=j*S(i-1,j)+S(i-1,j-1)\\) eg\uff1ai \u4e2a\u4e0d\u540c\u7684\u5143\u7d20\u5212\u5206\u4e3a j \u4e2a\u975e\u7a7a\u96c6\u7684\u65b9\u6cd5\u7684\u6570\u76ee Bell\u6570\u548c\u7b2c\u4e8c\u7c7bStirling\u6570\u4e4b\u95f4\u7684\u5173\u7cfb\uff1a \\(B_n=\\sum_{k=1}^n{S(n,k)}\\) eg\uff1an \u4e2a\u4e0d\u540c\u7684\u6570\u7684\u5212\u5206\u65b9\u6848\u6570","title":"Bell\u6570\u548cStirling\u6570"},{"location":"OI/%E8%AE%A1%E7%AE%97%E5%87%A0%E4%BD%95/","text":"\u8ba1\u7b97\u51e0\u4f55 \u00b6 \u70b9\u548c\u7ebf \u00b6 \u7cbe\u5ea6\u63a7\u5236 \u00b6 const double eps = 1e-10 ; double dcmp ( double x ) { //\u5224\u65ad \u6b63/\u8d1f/0 if ( fabs ( x ) < eps ) return 0 ; else return x > 0 ? 1 : -1 ; } \u70b9\u548c\u5411\u91cf\u5b58\u50a8 \u00b6 struct Vector { double x , y ; Point ( double x = 0 , y = 0 ) : x ( x ), y ( y ){} Vector rotate_90 () { return Vector ( y , - x );} //\u987a\u65f6\u948890\u5ea6 Vector rotate_90_c () { return Vector ( - y , x );} //\u9006\u65f6\u948890\u5ea6 }; typedef Vector Point ; \u5411\u91cf\u7684\u56db\u5219\u8fd0\u7b97 \u00b6 //\u8fd9\u79cd\u8fd4\u56de\u65b9\u5f0f\u4f3c\u4e4e\u6709\u65f6\u5019\u4f1a\u51fa\u95ee\u9898 //\u5411\u91cf+\u5411\u91cf=\u5411\u91cf \u70b9+\u5411\u91cf=\u70b9 Vector operator + ( Vector a , Vector b ){ return Vector ( a . x + b . x , a . y + b . y ); } //\u70b9-\u70b9=\u5411\u91cf Vector operator - ( Vector a , Vector b ){ return Vector ( a . x - b . x , a . y - b . y ); } //\u5411\u91cf*\u6570=\u5411\u91cf Vector operator * ( Vector a , double p ){ return Vector ( a . x * p , a . y * p ); } //\u5411\u91cf/\u6570=\u5411\u91cf Vector operator / ( Vector a , double p ){ return Vector ( a . x / p . a . y / p ); } \u70b9\u79ef \u53c9\u79ef \u53ca \u5e94\u7528 \u00b6 \\[\\vec{a} \\cdot \\vec{b} = |a||b|cos\\theta\\] \\( \\(|\\vec{a} \\times \\vec{b}| = |a||b|sin\\theta\\) \\) \uff0c\u6b63\u8d1f\u7531\u4e24\u5411\u91cf\u7684\u76f8\u5bf9\u5173\u7cfb\u51b3\u5b9a //\u70b9\u79ef double Dot ( Vector a , Vector b ){ return a . x * b . x + a . y * b . y ; } //\u53c9\u79ef double Cross ( Vector a , Vector b ){ return a . x * b . y - a . y * b . x ; } //\u5e94\u7528 //\u6c42\u6a21\u957f double Length ( Vector a ){ return sqrt ( Dot ( a , a )); } //\u6c42\u89d2\u5ea6 double Angle ( Vector a , Vector b ){ return acos ( Dot ( a , b ) / Length ( a ) / Length ( b )); } \u5224\u65ad\u70b9\u662f\u5426\u5728\u7ebf\u6bb5\u4e0a \u00b6 bool OnSegment ( Point p1 , Point p2 , Point q ){ //p1-p2\u662f\u7ebf\u6bb5 return Cross ( p1 - q , p2 - q ) == 0 && Dot ( p1 - q , p2 - q ) <= 0 ; } \u6c42\u4e24\u76f4\u7ebf\u7684\u4ea4\u70b9 \u00b6 \u7531 \\( \\(q_2,q_1,p_2,p_1\\) \\) \u786e\u5b9a\u7684\u4e24\u6761\u76f4\u7ebf\uff0c\u5047\u8bbe\u4ea4\u70b9\u4e3a \\( \\(p_1+t(p_2-p_1)\\) \\) \u6709 \\( \\((q_2-q_1) \\times (p_1 + t(p_2-p_1)-q_1)=0\\) \\) \u5f97 \\( \\(t = \\frac{(q_2-q_1)\\times(q_1-p_1)}{(q_2-q_1)\\times(p_2-p_1)}\\) \\) /*Point GetLineIntersection(Point p1, Point p2, Point q1, Point q2){ return p1+(p2-p1)*Cross(q2-q1, q1-p1)/Cross(q2-q1, p2-p1) }*/ Point GetLineIntersection ( Point p , Vector v1 , Point q , Vector v2 ){ return p + v1 * Cross ( v2 , q - p ) / Cross ( v2 , v1 ); } //\u5e73\u884c\u7279\u5224 \u7ebf\u6bb5\u76f8\u4ea4\u5224\u5b9a \u00b6 \u8de8\u7acb\u5b9e\u9a8c\uff1a\u5224\u65adq1,q2\u5728\u7ebf\u6bb5p2-p1\u4e24\u4fa7 \u4e14 p1,p2\u5728\u7ebf\u6bb5q2-q1\u4e24\u4fa7 bool SegmentProperIntersection ( Point p1 , Point p2 , Point q1 , Point q2 ){ double a1 = Cross ( p2 - p1 , q2 - p1 ), a2 = Cross ( p2 - p1 , q1 - p1 ); double a3 = Cross ( q2 - q1 , p1 - q1 ), a4 = Cross ( q2 - q1 , p2 - q1 ); return dcmp ( a1 ) * dcmp ( a2 ) < 0 && dcmp ( a3 ) * dcmp ( a4 ) < 0 ; } /*\u7279\u5224\u7aef\u70b9\u5728\u53e6\u4e00\u6761\u7ebf\u6bb5\u7684\u60c5\u51b5 if(OnSegment(p[i],q[i],p[j]) || OnSegment(p[i],q[i],q[j]) || OnSegment(p[j],q[j],p[i]) || OnSegment(p[j],q[j],q[i]) ) G[i][j] = G[j][i] = true; */ \u7ebf\u6bb5\u548c\u76f4\u7ebf\u76f8\u4ea4\u5224\u5b9a \u00b6 bool fun ( Point a , Point b , Point c , Point d ) { //a b \u786e\u5b9a\u76f4\u7ebf c d \u786e\u5b9a\u7ebf\u6bb5 return Cross ( a - b , a - c ) * Cross ( a - b , a - d ) <= eps } \u5411\u91cf\u65cb\u8f6c\u4e0e\u5355\u4f4d\u5316 \u00b6 \u9006\u65f6\u9488\uff1a $$ \\left[ \\matrix{ x^{'} \\ y^{'} } \\right] = \\left[ \\matrix{ x \\ y } \\right] \\left[ \\matrix{ cos\\theta & sin\\theta\\ -sin\\theta & cos\\theta } \\right] $$ \u987a\u65f6\u9488\uff1a $$ \\left[ \\matrix{ x^{'} \\ y^{'} } \\right] = \\left[ \\matrix{ x \\ y } \\right] \\left[ \\matrix{ cos\\theta & -sin\\theta\\ sin\\theta & cos\\theta } \\right] $$ //rad \u662f\u5f27\u5ea6, \u9006\u65f6\u9488 Vector Rotate ( Vector a , double rad ) { return Vector ( a . x * cos ( rad ) - a . y * sin ( rad ), a . x * sin ( rad ) + a . y * soc ( rad )); } //\u5355\u4f4d\u5316 Vector Normal ( Vector a ) { double L = length ( a ); return Vector ( a . x / L , a . y / L ); } \u70b9\u5230\u76f4\u7ebf\u7684\u8ddd\u79bb \u00b6 double DistaceToLine ( Point p , Point a , Point b ) { Vector v1 = b - a , v2 = p - a ; return fabs ( Cross ( v1 , v2 )) / Length ( v1 ); //\u5e73\u884c\u56db\u8fb9\u5f62\u9762\u79ef \u9664/\u5e95=\u9ad8 } \u5706 \u00b6 \u5706\u7684\u5b58\u50a8 \u00b6 struct Circle { Point c ; double r ; Circle ( Point a , double b = 0 ) : c ( a ), r ( b ){} } \u4e09\u89d2\u5f62\u5916\u63a5\u5706 \u00b6 //\u4e09\u70b9\u4e0d\u5171\u7ebf Circle circumcircle ( Point p1 , Point p2 , Point p3 ) { Point p = GetLineIntersection (( p1 + p2 ) / 2 , ( p2 - p1 ). rotate_90 (), ( p1 + p3 ) / 2 , ( p3 - p1 ). rotate_90 ()); return Circle ( p , Length ( p1 - p )); } \u6700\u5c0f\u5706\u8986\u76d6 \u00b6 \u968f\u673a\u589e\u91cf\u6cd5 \\(O(n)\\) //\u6d1b\u8c37 P1742 #include <iostream> #include <algorithm> #include <cmath> using namespace std ; const int maxn = 1e5 + 5 ; typedef struct Vector { double x , y ; Vector ( double a = 0 , double b = 0 ) : x ( a ), y ( b ){} Vector rotate_90 (){ return Vector ( y , - x ); } } Point ; struct Circle { Point c ; double r ; Circle ( Point a , double b ) : c ( a ), r ( b ){} }; Point operator - ( const Point & a , const Point & b ){ return Vector ( a . x - b . x , a . y - b . y ); } Point operator + ( const Point & a , const Point & b ){ return Vector ( a . x + b . x , a . y + b . y ); } Point operator / ( const Point & a , const double & b ){ return Vector ( a . x / b , a . y / b ); } Point operator * ( const Point & a , const double & b ){ return Vector ( a . x * b , a . y * b ); } double Dot ( Vector a , Vector b ){ return a . x * b . x + a . y * b . y ; } double Cross ( Vector a , Vector b ){ return a . x * b . y - a . y * b . x ; } double Length ( Vector a ){ return sqrt ( Dot ( a , a )); } Point GetLineIntersection ( Point p , Vector v1 , Point q , Vector v2 ){ return p + v1 * Cross ( v2 , q - p ) / Cross ( v2 , v1 ); } Circle circumcircle ( Point p1 , Point p2 , Point p3 ){ Point p = GetLineIntersection (( p1 + p2 ) / 2 , ( p2 - p1 ). rotate_90 (), ( p1 + p3 ) / 2 , ( p3 - p1 ). rotate_90 ()); return Circle ( p , Length ( p1 - p )); } Circle min_circle ( Point * p , int n ) { //\u6700\u5c0f\u5706\u8986\u76d6 random_shuffle ( p + 1 , p + 1 + n ); Point o ; double r = 0 ; for ( int i = 1 ; i <= n ; i ++ ) if ( Length ( p [ i ] - o ) > r ) { o = p [ i ], r = 0 ; for ( int j = 1 ; j < i ; j ++ ) if ( Length ( p [ j ] - o ) > r ) { o = ( p [ i ] + p [ j ]) / 2 , r = Length ( p [ i ] - p [ j ]) / 2 ; for ( int k = 1 ; k < j ; k ++ ) if ( Length ( o - p [ k ]) > r ) { Circle tmp = circumcircle ( p [ i ], p [ j ], p [ k ]); o = tmp . c , r = tmp . r ; } } } return Circle ( o , r ); } int main (){ int n ; Point p [ maxn ]; cin >> n ; for ( int i = 1 ; i <= n ; i ++ ) cin >> p [ i ]. x >> p [ i ]. y ; Circle res = min_circle ( p , n ); printf ( \"%.10lf \\n %.10lf %.10lf \\n \" , res . r , res . c . x , res . c . y ); return 0 ; } \u51f8\u5305 \u00b6 Graham\u626b\u63cf\u6cd5 \u7b97\u51f8\u5305 \u00b6 \u6309x\uff0cy\u5750\u6807\u5347\u5e8f\u6392\u5217\uff0c\u786e\u5b9a\u51f8\u5305\u76842\u7684\u9876\u70b9\uff0c\u7136\u540e\u518d\u786e\u5b9a\u4e0a\u4e0b\u4e24\u4e2a\u51f8\u58f3 \u6392\u5e8f \\( \\(O(nlogn)\\) \\) \u5176\u4ed6 \\( \\(O(n)\\) \\) bool cmp ( Point & p , Point & q ){ if ( p . x != p . x ) return p . x < q . x ; else return p . y < q . y ; } vector < Point > ConvexHull ( Point * ps , int n ){ sort ( ps , ps + n , cmp ); int k = 0 ; //\u51f8\u5305\u9876\u70b9\u6570 vector < Point > qs ( n * 2 ); //\u4e0b\u51f8\u58f3 for ( int i = 0 ; i < n ; i ++ ){ //while\u8981\u6ce8\u610f while ( k > 1 && Cross ( qs [ k -1 ] - qs [ k -2 ], ps [ i ] - qs [ k -1 ] <= 0 )) k -- ; qs [ k ++ ] = ps [ i ]; } //\u4e0a\u51f8\u58f3 for ( int i = n -2 , t = k ; i >= 0 ; i -- ){ while ( k > t && Cross ( qs [ k -1 ] - qs [ k -2 ], ps [ i ] - qs [ k -1 ] <= 0 )) k -- ; qs [ k ++ ] = ps [ i ]; } qs . resize ( k -1 ); return qs ; }","title":"\u8ba1\u7b97\u51e0\u4f55"},{"location":"OI/%E8%AE%A1%E7%AE%97%E5%87%A0%E4%BD%95/#_1","text":"","title":"\u8ba1\u7b97\u51e0\u4f55"},{"location":"OI/%E8%AE%A1%E7%AE%97%E5%87%A0%E4%BD%95/#_2","text":"","title":"\u70b9\u548c\u7ebf"},{"location":"OI/%E8%AE%A1%E7%AE%97%E5%87%A0%E4%BD%95/#_3","text":"const double eps = 1e-10 ; double dcmp ( double x ) { //\u5224\u65ad \u6b63/\u8d1f/0 if ( fabs ( x ) < eps ) return 0 ; else return x > 0 ? 1 : -1 ; }","title":"\u7cbe\u5ea6\u63a7\u5236"},{"location":"OI/%E8%AE%A1%E7%AE%97%E5%87%A0%E4%BD%95/#_4","text":"struct Vector { double x , y ; Point ( double x = 0 , y = 0 ) : x ( x ), y ( y ){} Vector rotate_90 () { return Vector ( y , - x );} //\u987a\u65f6\u948890\u5ea6 Vector rotate_90_c () { return Vector ( - y , x );} //\u9006\u65f6\u948890\u5ea6 }; typedef Vector Point ;","title":"\u70b9\u548c\u5411\u91cf\u5b58\u50a8"},{"location":"OI/%E8%AE%A1%E7%AE%97%E5%87%A0%E4%BD%95/#_5","text":"//\u8fd9\u79cd\u8fd4\u56de\u65b9\u5f0f\u4f3c\u4e4e\u6709\u65f6\u5019\u4f1a\u51fa\u95ee\u9898 //\u5411\u91cf+\u5411\u91cf=\u5411\u91cf \u70b9+\u5411\u91cf=\u70b9 Vector operator + ( Vector a , Vector b ){ return Vector ( a . x + b . x , a . y + b . y ); } //\u70b9-\u70b9=\u5411\u91cf Vector operator - ( Vector a , Vector b ){ return Vector ( a . x - b . x , a . y - b . y ); } //\u5411\u91cf*\u6570=\u5411\u91cf Vector operator * ( Vector a , double p ){ return Vector ( a . x * p , a . y * p ); } //\u5411\u91cf/\u6570=\u5411\u91cf Vector operator / ( Vector a , double p ){ return Vector ( a . x / p . a . y / p ); }","title":"\u5411\u91cf\u7684\u56db\u5219\u8fd0\u7b97"},{"location":"OI/%E8%AE%A1%E7%AE%97%E5%87%A0%E4%BD%95/#_6","text":"\\[\\vec{a} \\cdot \\vec{b} = |a||b|cos\\theta\\] \\( \\(|\\vec{a} \\times \\vec{b}| = |a||b|sin\\theta\\) \\) \uff0c\u6b63\u8d1f\u7531\u4e24\u5411\u91cf\u7684\u76f8\u5bf9\u5173\u7cfb\u51b3\u5b9a //\u70b9\u79ef double Dot ( Vector a , Vector b ){ return a . x * b . x + a . y * b . y ; } //\u53c9\u79ef double Cross ( Vector a , Vector b ){ return a . x * b . y - a . y * b . x ; } //\u5e94\u7528 //\u6c42\u6a21\u957f double Length ( Vector a ){ return sqrt ( Dot ( a , a )); } //\u6c42\u89d2\u5ea6 double Angle ( Vector a , Vector b ){ return acos ( Dot ( a , b ) / Length ( a ) / Length ( b )); }","title":"\u70b9\u79ef \u53c9\u79ef \u53ca \u5e94\u7528"},{"location":"OI/%E8%AE%A1%E7%AE%97%E5%87%A0%E4%BD%95/#_7","text":"bool OnSegment ( Point p1 , Point p2 , Point q ){ //p1-p2\u662f\u7ebf\u6bb5 return Cross ( p1 - q , p2 - q ) == 0 && Dot ( p1 - q , p2 - q ) <= 0 ; }","title":"\u5224\u65ad\u70b9\u662f\u5426\u5728\u7ebf\u6bb5\u4e0a"},{"location":"OI/%E8%AE%A1%E7%AE%97%E5%87%A0%E4%BD%95/#_8","text":"\u7531 \\( \\(q_2,q_1,p_2,p_1\\) \\) \u786e\u5b9a\u7684\u4e24\u6761\u76f4\u7ebf\uff0c\u5047\u8bbe\u4ea4\u70b9\u4e3a \\( \\(p_1+t(p_2-p_1)\\) \\) \u6709 \\( \\((q_2-q_1) \\times (p_1 + t(p_2-p_1)-q_1)=0\\) \\) \u5f97 \\( \\(t = \\frac{(q_2-q_1)\\times(q_1-p_1)}{(q_2-q_1)\\times(p_2-p_1)}\\) \\) /*Point GetLineIntersection(Point p1, Point p2, Point q1, Point q2){ return p1+(p2-p1)*Cross(q2-q1, q1-p1)/Cross(q2-q1, p2-p1) }*/ Point GetLineIntersection ( Point p , Vector v1 , Point q , Vector v2 ){ return p + v1 * Cross ( v2 , q - p ) / Cross ( v2 , v1 ); } //\u5e73\u884c\u7279\u5224","title":"\u6c42\u4e24\u76f4\u7ebf\u7684\u4ea4\u70b9"},{"location":"OI/%E8%AE%A1%E7%AE%97%E5%87%A0%E4%BD%95/#_9","text":"\u8de8\u7acb\u5b9e\u9a8c\uff1a\u5224\u65adq1,q2\u5728\u7ebf\u6bb5p2-p1\u4e24\u4fa7 \u4e14 p1,p2\u5728\u7ebf\u6bb5q2-q1\u4e24\u4fa7 bool SegmentProperIntersection ( Point p1 , Point p2 , Point q1 , Point q2 ){ double a1 = Cross ( p2 - p1 , q2 - p1 ), a2 = Cross ( p2 - p1 , q1 - p1 ); double a3 = Cross ( q2 - q1 , p1 - q1 ), a4 = Cross ( q2 - q1 , p2 - q1 ); return dcmp ( a1 ) * dcmp ( a2 ) < 0 && dcmp ( a3 ) * dcmp ( a4 ) < 0 ; } /*\u7279\u5224\u7aef\u70b9\u5728\u53e6\u4e00\u6761\u7ebf\u6bb5\u7684\u60c5\u51b5 if(OnSegment(p[i],q[i],p[j]) || OnSegment(p[i],q[i],q[j]) || OnSegment(p[j],q[j],p[i]) || OnSegment(p[j],q[j],q[i]) ) G[i][j] = G[j][i] = true; */","title":"\u7ebf\u6bb5\u76f8\u4ea4\u5224\u5b9a"},{"location":"OI/%E8%AE%A1%E7%AE%97%E5%87%A0%E4%BD%95/#_10","text":"bool fun ( Point a , Point b , Point c , Point d ) { //a b \u786e\u5b9a\u76f4\u7ebf c d \u786e\u5b9a\u7ebf\u6bb5 return Cross ( a - b , a - c ) * Cross ( a - b , a - d ) <= eps }","title":"\u7ebf\u6bb5\u548c\u76f4\u7ebf\u76f8\u4ea4\u5224\u5b9a"},{"location":"OI/%E8%AE%A1%E7%AE%97%E5%87%A0%E4%BD%95/#_11","text":"\u9006\u65f6\u9488\uff1a $$ \\left[ \\matrix{ x^{'} \\ y^{'} } \\right] = \\left[ \\matrix{ x \\ y } \\right] \\left[ \\matrix{ cos\\theta & sin\\theta\\ -sin\\theta & cos\\theta } \\right] $$ \u987a\u65f6\u9488\uff1a $$ \\left[ \\matrix{ x^{'} \\ y^{'} } \\right] = \\left[ \\matrix{ x \\ y } \\right] \\left[ \\matrix{ cos\\theta & -sin\\theta\\ sin\\theta & cos\\theta } \\right] $$ //rad \u662f\u5f27\u5ea6, \u9006\u65f6\u9488 Vector Rotate ( Vector a , double rad ) { return Vector ( a . x * cos ( rad ) - a . y * sin ( rad ), a . x * sin ( rad ) + a . y * soc ( rad )); } //\u5355\u4f4d\u5316 Vector Normal ( Vector a ) { double L = length ( a ); return Vector ( a . x / L , a . y / L ); }","title":"\u5411\u91cf\u65cb\u8f6c\u4e0e\u5355\u4f4d\u5316"},{"location":"OI/%E8%AE%A1%E7%AE%97%E5%87%A0%E4%BD%95/#_12","text":"double DistaceToLine ( Point p , Point a , Point b ) { Vector v1 = b - a , v2 = p - a ; return fabs ( Cross ( v1 , v2 )) / Length ( v1 ); //\u5e73\u884c\u56db\u8fb9\u5f62\u9762\u79ef \u9664/\u5e95=\u9ad8 }","title":"\u70b9\u5230\u76f4\u7ebf\u7684\u8ddd\u79bb"},{"location":"OI/%E8%AE%A1%E7%AE%97%E5%87%A0%E4%BD%95/#_13","text":"","title":"\u5706"},{"location":"OI/%E8%AE%A1%E7%AE%97%E5%87%A0%E4%BD%95/#_14","text":"struct Circle { Point c ; double r ; Circle ( Point a , double b = 0 ) : c ( a ), r ( b ){} }","title":"\u5706\u7684\u5b58\u50a8"},{"location":"OI/%E8%AE%A1%E7%AE%97%E5%87%A0%E4%BD%95/#_15","text":"//\u4e09\u70b9\u4e0d\u5171\u7ebf Circle circumcircle ( Point p1 , Point p2 , Point p3 ) { Point p = GetLineIntersection (( p1 + p2 ) / 2 , ( p2 - p1 ). rotate_90 (), ( p1 + p3 ) / 2 , ( p3 - p1 ). rotate_90 ()); return Circle ( p , Length ( p1 - p )); }","title":"\u4e09\u89d2\u5f62\u5916\u63a5\u5706"},{"location":"OI/%E8%AE%A1%E7%AE%97%E5%87%A0%E4%BD%95/#_16","text":"\u968f\u673a\u589e\u91cf\u6cd5 \\(O(n)\\) //\u6d1b\u8c37 P1742 #include <iostream> #include <algorithm> #include <cmath> using namespace std ; const int maxn = 1e5 + 5 ; typedef struct Vector { double x , y ; Vector ( double a = 0 , double b = 0 ) : x ( a ), y ( b ){} Vector rotate_90 (){ return Vector ( y , - x ); } } Point ; struct Circle { Point c ; double r ; Circle ( Point a , double b ) : c ( a ), r ( b ){} }; Point operator - ( const Point & a , const Point & b ){ return Vector ( a . x - b . x , a . y - b . y ); } Point operator + ( const Point & a , const Point & b ){ return Vector ( a . x + b . x , a . y + b . y ); } Point operator / ( const Point & a , const double & b ){ return Vector ( a . x / b , a . y / b ); } Point operator * ( const Point & a , const double & b ){ return Vector ( a . x * b , a . y * b ); } double Dot ( Vector a , Vector b ){ return a . x * b . x + a . y * b . y ; } double Cross ( Vector a , Vector b ){ return a . x * b . y - a . y * b . x ; } double Length ( Vector a ){ return sqrt ( Dot ( a , a )); } Point GetLineIntersection ( Point p , Vector v1 , Point q , Vector v2 ){ return p + v1 * Cross ( v2 , q - p ) / Cross ( v2 , v1 ); } Circle circumcircle ( Point p1 , Point p2 , Point p3 ){ Point p = GetLineIntersection (( p1 + p2 ) / 2 , ( p2 - p1 ). rotate_90 (), ( p1 + p3 ) / 2 , ( p3 - p1 ). rotate_90 ()); return Circle ( p , Length ( p1 - p )); } Circle min_circle ( Point * p , int n ) { //\u6700\u5c0f\u5706\u8986\u76d6 random_shuffle ( p + 1 , p + 1 + n ); Point o ; double r = 0 ; for ( int i = 1 ; i <= n ; i ++ ) if ( Length ( p [ i ] - o ) > r ) { o = p [ i ], r = 0 ; for ( int j = 1 ; j < i ; j ++ ) if ( Length ( p [ j ] - o ) > r ) { o = ( p [ i ] + p [ j ]) / 2 , r = Length ( p [ i ] - p [ j ]) / 2 ; for ( int k = 1 ; k < j ; k ++ ) if ( Length ( o - p [ k ]) > r ) { Circle tmp = circumcircle ( p [ i ], p [ j ], p [ k ]); o = tmp . c , r = tmp . r ; } } } return Circle ( o , r ); } int main (){ int n ; Point p [ maxn ]; cin >> n ; for ( int i = 1 ; i <= n ; i ++ ) cin >> p [ i ]. x >> p [ i ]. y ; Circle res = min_circle ( p , n ); printf ( \"%.10lf \\n %.10lf %.10lf \\n \" , res . r , res . c . x , res . c . y ); return 0 ; }","title":"\u6700\u5c0f\u5706\u8986\u76d6"},{"location":"OI/%E8%AE%A1%E7%AE%97%E5%87%A0%E4%BD%95/#_17","text":"","title":"\u51f8\u5305"},{"location":"OI/%E8%AE%A1%E7%AE%97%E5%87%A0%E4%BD%95/#graham","text":"\u6309x\uff0cy\u5750\u6807\u5347\u5e8f\u6392\u5217\uff0c\u786e\u5b9a\u51f8\u5305\u76842\u7684\u9876\u70b9\uff0c\u7136\u540e\u518d\u786e\u5b9a\u4e0a\u4e0b\u4e24\u4e2a\u51f8\u58f3 \u6392\u5e8f \\( \\(O(nlogn)\\) \\) \u5176\u4ed6 \\( \\(O(n)\\) \\) bool cmp ( Point & p , Point & q ){ if ( p . x != p . x ) return p . x < q . x ; else return p . y < q . y ; } vector < Point > ConvexHull ( Point * ps , int n ){ sort ( ps , ps + n , cmp ); int k = 0 ; //\u51f8\u5305\u9876\u70b9\u6570 vector < Point > qs ( n * 2 ); //\u4e0b\u51f8\u58f3 for ( int i = 0 ; i < n ; i ++ ){ //while\u8981\u6ce8\u610f while ( k > 1 && Cross ( qs [ k -1 ] - qs [ k -2 ], ps [ i ] - qs [ k -1 ] <= 0 )) k -- ; qs [ k ++ ] = ps [ i ]; } //\u4e0a\u51f8\u58f3 for ( int i = n -2 , t = k ; i >= 0 ; i -- ){ while ( k > t && Cross ( qs [ k -1 ] - qs [ k -2 ], ps [ i ] - qs [ k -1 ] <= 0 )) k -- ; qs [ k ++ ] = ps [ i ]; } qs . resize ( k -1 ); return qs ; }","title":"Graham\u626b\u63cf\u6cd5 \u7b97\u51f8\u5305"},{"location":"Python/Easygui/","text":"","title":"Easygui"},{"location":"Python/Matplotlib/","text":"Matplotlib \u00b6 Matplotlib: Python plotting \u2014 Matplotlib 3.4.2 documentation pyplot.plot() \u00b6 import matplotlib.pyplot as plt plt . plot ([ x ], y , [ fmt ], * , data = None , ** kwargs ) # \u5355\u7ebf\u6761 plt . plot ([ x ], y , [ fmt ], [ x2 ], y2 , [ fmt2 ], ... , ** kwargs ) # \u591a\u7ebf\u6761 eg : plot ( y ) # plot y using x as index array 0..N-1 # fmt = '[color][marker][line]' \u53ef\u4ee5\u7528\u7f29\u5199\u6765\u8bbe\u7f6e\u989c\u8272,\u70b9\u578b\uff0c\u7ebf\u578b\uff0c\u4f46\u7528\u5173\u952e\u5b57\u7684\u4f18\u5148\u7ea7\u66f4\u9ad8 \u5e26\u6807\u7b7e\u4f5c\u56fe \u00b6 plt . plot ( 'xlabel' , 'ylabel' , data = obj ) # All indexable objects are supported. This could e.g. be a dict, a pandas.DataFrame or a structured numpy array. \u5bf9\u591a\u7ec4\u6570\u636e\u4f5c\u56fe \u00b6 # \u6cd5\u4e00 plot multiple times plt . plot ( x1 , y1 , 'bo' ) plt . plot ( x2 , y2 , 'go' ) # \u6cd5\u4e8c plt . plot ([ x ], y , [ fmt ], [ x2 ], y2 , [ fmt2 ], ... , ** kwargs ) \u53ef\u9009\u53c2\u6570 \u00b6 color \u00b6 \u4e5f\u53ef\u4ee5\u7528\u5341\u516d\u8fdb\u5236\u7684 RGB \u5b57\u7b26\u4e32\uff0c\u5982 color='#900302' character color 'b' blue \u84dd 'g' green \u7eff 'r' red \u7ea2 'c' cyan \u84dd\u7eff 'm' magenta \u6d0b\u7ea2 'y' yellow \u9ec4 'k' black \u9ed1 'w' white \u767d marker \u00b6 \u53ea\u652f\u6301\u7b80\u5199 character description '.' point marker ',' pixel marker 'o' circle marker 'v' triangle_down marker '^' triangle_up marker '<' triangle_left marker '>' triangle_right marker '1' tri_down marker '2' tri_up marker '3' tri_left marker '4' tri_right marker 's' square marker 'p' pentagon marker '*' star marker 'h' hexagon1 marker 'H' hexagon2 marker '+' plus marker 'x' x marker 'D' diamond marker 'd' thin_diamond marker '|' vline marker '_' hline marker linestyle \u00b6 character description '-' solid line style \u5b9e\u7ebf '--' dashed line style \u865a\u7ebf '-.' dash-dot line style \u70b9\u753b\u7ebf ':' dotted line style \u70b9\u7ebf \u5176\u4ed6 \u00b6 Property Description alpha scalar or None markeredgecolor / mec color markeredgewidth / mew float markersize / ms float linewidth / lw float \u8bbe\u7f6e\u5750\u6807\u8f74 \u00b6 matplotlib . pyplot . xlim ( * args , ** kwargs ) # \u8bbe\u7f6e\u6a2a\u5750\u6807\u8303\u56f4 left , right = xlim () # return the current xlim plt . xlim (( left , right )) # set the xlim to left, right plt . lim ( left , right ) # set the xlim to left, right plt . xlim ( right = 3 ) # adjust the right leaving left unchanged plt . xlim ( left = 1 ) # adjust the left leaving right unchanged matplotlib . pyplot . xlabel ( xlabel , fontdict = None , labelpad = None , * , loc = None , ** kwargs ) # \u8bbe\u7f6exlabel # fontsize:\u6570\u5b57\u6216\u2019small\u2019\uff0c\u2018large\u2019\uff0c\u2018medium\u2019 plt . xlabel ( r '$b$' , fontsize = 16 ) \u7b49\u9ad8\u7ebf \u00b6 contourf() / contour() \u753b\u4e09\u7ef4\u7b49\u9ad8\u7ebf\u56fe\uff0c\u4e0d\u540c\u70b9\u5728\u4e8econtour() \u662f\u7ed8\u5236\u8f6e\u5ed3\u7ebf\uff0ccontourf()\u4f1a\u586b\u5145\u8f6e\u5ed3 matplotlib . pyplot . contourf ([ X , Y ,] Z , [ level ], ** kwargs ) # \u5982\u679c XY \u90fd\u662f\u4e00\u7ef4\u7684, \u90a3 z \u7684\u884c\u6570\u7b49\u4e8e len(y), \u5217\u6570\u7b49\u4e8e len(x) \u53c2\u6570 \u8bf4\u660e colors alpha float, default 1, between 0 (transparent) and 1 (opaque) cmap colormap eg: \u70ed\u529b\u56fe cmap=plt.cm.hot level \u5bc6\u96c6\u7a0b\u5ea6 eg: plt.contour(X, Y, Z, 8) inline \u662f\u5426\u6dfb\u52a0\u7b49\u9ad8\u7ebf\u7684\u6570\u503c eg: plt.contour(X, Y, Z, inline = True) fontsize \u5b57\u4f53\u5927\u5c0f eg: plt.contour(X, Y, Z, inline = True, fontsize = 12) \u7ed8\u5236\u591a\u56fe \u00b6 plt.figure() \u00b6 plt . figure ( name ) # \u56fe\u50cf\u7f16\u53f7\u6216\u540d\u79f0\uff0c\u7528\u4ee5\u7ed8\u5236\u591a\u56fe # plt.figure(1) # plt.figure(2) # plt.show() \u4f1a\u8f93\u51fa2\u5f20\u56fe plt.subplot() \u00b6 plt . subplot () # \u7ed8\u5236\u4e00\u5f20\u56fe\u4e2d\u7684\u5b50\u56fe # plt.subplot(221) \u7ed8\u52362\u884c2\u5217\u7684\u5b50\u56fe\u7684\u7b2c\u4e00\u5f20 # plt.subplot(222) # plt.subplot(223) # plt.subplot(224) cmap \u00b6 \u8bbe\u7f6e\u989c\u8272 # \u4ee5\u7070\u5ea6\u56fe\u4e3a\u4f8b cmap = plt . get_cmap ( 'Greys' ) # \u7b49\u6548\u4e8e cmap = plt.cm.Greys norm = plt . Normalize ( vmin =- 3 , vmax = 3 ) # \u5c06\u6570\u503c\u8303\u56f4\u6807\u51c6\u5316\uff0c\u6295\u5f71\u5230\u6240\u9009\u7684\u989c\u8272\u96c6\u4e0a plt . imshow ( grid . T , extent = ( 0 , 1 , 0 , 1 ), cmap = cmap , norm = norm ) # \u7ed8\u56fe \u5176\u4ed6 \u00b6 matplotlib . use ( \u2018 agg \u2019 ) # \u5728\u6267\u884cimport matplotlib.pyplot as plt\u524d\u8fd0\u884c, \u4e0d\u4f1a\u663e\u793a\u7ed8\u56fe plt . show () # \u663e\u793a\u7ed8\u56fe \u53c2\u8003 \u00b6 matplotlib.pyplot.plot()\u53c2\u6570\u8be6\u89e3_ims\u7684\u535a\u5ba2-CSDN\u535a\u5ba2 matplotlib.pyplot contourf()\u51fd\u6570\u7684\u4f7f\u7528_lens_\u7684\u535a\u5ba2-CSDN\u535a\u5ba2 \u753b\u56fe\u79bb\u4e0d\u5f00\u8272\u5f69--\u8bf4\u8bf4matplot\u7684cmap | \u7530\u91ce\u5149\u7684\u6280\u672f\u5c0f\u7ad9","title":"Matplotlib"},{"location":"Python/Matplotlib/#matplotlib","text":"Matplotlib: Python plotting \u2014 Matplotlib 3.4.2 documentation","title":"Matplotlib"},{"location":"Python/Matplotlib/#pyplotplot","text":"import matplotlib.pyplot as plt plt . plot ([ x ], y , [ fmt ], * , data = None , ** kwargs ) # \u5355\u7ebf\u6761 plt . plot ([ x ], y , [ fmt ], [ x2 ], y2 , [ fmt2 ], ... , ** kwargs ) # \u591a\u7ebf\u6761 eg : plot ( y ) # plot y using x as index array 0..N-1 # fmt = '[color][marker][line]' \u53ef\u4ee5\u7528\u7f29\u5199\u6765\u8bbe\u7f6e\u989c\u8272,\u70b9\u578b\uff0c\u7ebf\u578b\uff0c\u4f46\u7528\u5173\u952e\u5b57\u7684\u4f18\u5148\u7ea7\u66f4\u9ad8","title":"pyplot.plot()"},{"location":"Python/Matplotlib/#_1","text":"plt . plot ( 'xlabel' , 'ylabel' , data = obj ) # All indexable objects are supported. This could e.g. be a dict, a pandas.DataFrame or a structured numpy array.","title":"\u5e26\u6807\u7b7e\u4f5c\u56fe"},{"location":"Python/Matplotlib/#_2","text":"# \u6cd5\u4e00 plot multiple times plt . plot ( x1 , y1 , 'bo' ) plt . plot ( x2 , y2 , 'go' ) # \u6cd5\u4e8c plt . plot ([ x ], y , [ fmt ], [ x2 ], y2 , [ fmt2 ], ... , ** kwargs )","title":"\u5bf9\u591a\u7ec4\u6570\u636e\u4f5c\u56fe"},{"location":"Python/Matplotlib/#_3","text":"","title":"\u53ef\u9009\u53c2\u6570"},{"location":"Python/Matplotlib/#color","text":"\u4e5f\u53ef\u4ee5\u7528\u5341\u516d\u8fdb\u5236\u7684 RGB \u5b57\u7b26\u4e32\uff0c\u5982 color='#900302' character color 'b' blue \u84dd 'g' green \u7eff 'r' red \u7ea2 'c' cyan \u84dd\u7eff 'm' magenta \u6d0b\u7ea2 'y' yellow \u9ec4 'k' black \u9ed1 'w' white \u767d","title":"color"},{"location":"Python/Matplotlib/#marker","text":"\u53ea\u652f\u6301\u7b80\u5199 character description '.' point marker ',' pixel marker 'o' circle marker 'v' triangle_down marker '^' triangle_up marker '<' triangle_left marker '>' triangle_right marker '1' tri_down marker '2' tri_up marker '3' tri_left marker '4' tri_right marker 's' square marker 'p' pentagon marker '*' star marker 'h' hexagon1 marker 'H' hexagon2 marker '+' plus marker 'x' x marker 'D' diamond marker 'd' thin_diamond marker '|' vline marker '_' hline marker","title":"marker"},{"location":"Python/Matplotlib/#linestyle","text":"character description '-' solid line style \u5b9e\u7ebf '--' dashed line style \u865a\u7ebf '-.' dash-dot line style \u70b9\u753b\u7ebf ':' dotted line style \u70b9\u7ebf","title":"linestyle"},{"location":"Python/Matplotlib/#_4","text":"Property Description alpha scalar or None markeredgecolor / mec color markeredgewidth / mew float markersize / ms float linewidth / lw float","title":"\u5176\u4ed6"},{"location":"Python/Matplotlib/#_5","text":"matplotlib . pyplot . xlim ( * args , ** kwargs ) # \u8bbe\u7f6e\u6a2a\u5750\u6807\u8303\u56f4 left , right = xlim () # return the current xlim plt . xlim (( left , right )) # set the xlim to left, right plt . lim ( left , right ) # set the xlim to left, right plt . xlim ( right = 3 ) # adjust the right leaving left unchanged plt . xlim ( left = 1 ) # adjust the left leaving right unchanged matplotlib . pyplot . xlabel ( xlabel , fontdict = None , labelpad = None , * , loc = None , ** kwargs ) # \u8bbe\u7f6exlabel # fontsize:\u6570\u5b57\u6216\u2019small\u2019\uff0c\u2018large\u2019\uff0c\u2018medium\u2019 plt . xlabel ( r '$b$' , fontsize = 16 )","title":"\u8bbe\u7f6e\u5750\u6807\u8f74"},{"location":"Python/Matplotlib/#_6","text":"contourf() / contour() \u753b\u4e09\u7ef4\u7b49\u9ad8\u7ebf\u56fe\uff0c\u4e0d\u540c\u70b9\u5728\u4e8econtour() \u662f\u7ed8\u5236\u8f6e\u5ed3\u7ebf\uff0ccontourf()\u4f1a\u586b\u5145\u8f6e\u5ed3 matplotlib . pyplot . contourf ([ X , Y ,] Z , [ level ], ** kwargs ) # \u5982\u679c XY \u90fd\u662f\u4e00\u7ef4\u7684, \u90a3 z \u7684\u884c\u6570\u7b49\u4e8e len(y), \u5217\u6570\u7b49\u4e8e len(x) \u53c2\u6570 \u8bf4\u660e colors alpha float, default 1, between 0 (transparent) and 1 (opaque) cmap colormap eg: \u70ed\u529b\u56fe cmap=plt.cm.hot level \u5bc6\u96c6\u7a0b\u5ea6 eg: plt.contour(X, Y, Z, 8) inline \u662f\u5426\u6dfb\u52a0\u7b49\u9ad8\u7ebf\u7684\u6570\u503c eg: plt.contour(X, Y, Z, inline = True) fontsize \u5b57\u4f53\u5927\u5c0f eg: plt.contour(X, Y, Z, inline = True, fontsize = 12)","title":"\u7b49\u9ad8\u7ebf"},{"location":"Python/Matplotlib/#_7","text":"","title":"\u7ed8\u5236\u591a\u56fe"},{"location":"Python/Matplotlib/#pltfigure","text":"plt . figure ( name ) # \u56fe\u50cf\u7f16\u53f7\u6216\u540d\u79f0\uff0c\u7528\u4ee5\u7ed8\u5236\u591a\u56fe # plt.figure(1) # plt.figure(2) # plt.show() \u4f1a\u8f93\u51fa2\u5f20\u56fe","title":"plt.figure()"},{"location":"Python/Matplotlib/#pltsubplot","text":"plt . subplot () # \u7ed8\u5236\u4e00\u5f20\u56fe\u4e2d\u7684\u5b50\u56fe # plt.subplot(221) \u7ed8\u52362\u884c2\u5217\u7684\u5b50\u56fe\u7684\u7b2c\u4e00\u5f20 # plt.subplot(222) # plt.subplot(223) # plt.subplot(224)","title":"plt.subplot()"},{"location":"Python/Matplotlib/#cmap","text":"\u8bbe\u7f6e\u989c\u8272 # \u4ee5\u7070\u5ea6\u56fe\u4e3a\u4f8b cmap = plt . get_cmap ( 'Greys' ) # \u7b49\u6548\u4e8e cmap = plt.cm.Greys norm = plt . Normalize ( vmin =- 3 , vmax = 3 ) # \u5c06\u6570\u503c\u8303\u56f4\u6807\u51c6\u5316\uff0c\u6295\u5f71\u5230\u6240\u9009\u7684\u989c\u8272\u96c6\u4e0a plt . imshow ( grid . T , extent = ( 0 , 1 , 0 , 1 ), cmap = cmap , norm = norm ) # \u7ed8\u56fe","title":"cmap"},{"location":"Python/Matplotlib/#_8","text":"matplotlib . use ( \u2018 agg \u2019 ) # \u5728\u6267\u884cimport matplotlib.pyplot as plt\u524d\u8fd0\u884c, \u4e0d\u4f1a\u663e\u793a\u7ed8\u56fe plt . show () # \u663e\u793a\u7ed8\u56fe","title":"\u5176\u4ed6"},{"location":"Python/Matplotlib/#_9","text":"matplotlib.pyplot.plot()\u53c2\u6570\u8be6\u89e3_ims\u7684\u535a\u5ba2-CSDN\u535a\u5ba2 matplotlib.pyplot contourf()\u51fd\u6570\u7684\u4f7f\u7528_lens_\u7684\u535a\u5ba2-CSDN\u535a\u5ba2 \u753b\u56fe\u79bb\u4e0d\u5f00\u8272\u5f69--\u8bf4\u8bf4matplot\u7684cmap | \u7530\u91ce\u5149\u7684\u6280\u672f\u5c0f\u7ad9","title":"\u53c2\u8003"},{"location":"Python/Numpy/","text":"Numpy \u00b6 NumPy Reference \u2014 NumPy v1.20 Manual ndarray \u00b6 \u521b\u5efa ndarray \u00b6 import numpy as np np . array ( object , dtype = None , copy = True ) np . empty ( shape , dtype = float , order = 'C' , * , like = None ) # \u5e76\u4e0d\u521d\u59cb\u5316\u4e3a0 np . ones ( shape , dtype = None , order = 'C' , * , like = None ) # \u521d\u59cb\u5316\u4e3a 1 np . zeros ( shape , dtype = float , order = 'C' , * , like = None ) # \u521d\u59cb\u5316\u4e3a 0 a = np . arange ( 24 ) . reshape (( 2 , 3 , 4 )) # range\u521b\u5efalist,arange\u521b\u5efaarray a = np . arange ( 24 ) . reshape (( 2 , 3 , - 1 )) # \u53c2\u6570\u6709-1\u65f6\u4f1a\u81ea\u52a8\u6839\u636e\u5176\u4ed6\u7684\u53c2\u6570\u8ba1\u7b97 \u540d\u79f0 \u63cf\u8ff0 object \u6570\u7ec4\u6216\u5d4c\u5957\u7684\u6570\u5217 dtype \u6570\u7ec4\u5143\u7d20\u7684\u6570\u636e\u7c7b\u578b\uff0c\u53ef\u9009 copy \u5bf9\u8c61\u662f\u5426\u9700\u8981\u590d\u5236\uff0c\u53ef\u9009 order \u521b\u5efa\u6570\u7ec4\u7684\u6837\u5f0f\uff0cC\u4e3a\u884c\u65b9\u5411\uff0cF\u4e3a\u5217\u65b9\u5411\uff0cA\u4e3a\u4efb\u610f\u65b9\u5411\uff08\u9ed8\u8ba4\uff09 subok \u9ed8\u8ba4\u8fd4\u56de\u4e00\u4e2a\u4e0e\u57fa\u7c7b\u7c7b\u578b\u4e00\u81f4\u7684\u6570\u7ec4 ndmin \u6307\u5b9a\u751f\u6210\u6570\u7ec4\u7684\u6700\u5c0f\u7ef4\u5ea6 \u8bfb\u53d6\u6570\u636e \u00b6 # \u4e00\u7ef4 a [ 2 ] a [ 1 : 4 : 2 ] # \u5207\u7247 3 5 \u6b65\u957f2 # \u591a\u7ef4\u6570\u7ec4 a = np . arange ( 24 ) . reshape (( 2 , 3 , 4 )) a [ 1 , 2 , 3 ] a [::,::,::] # \u5207\u7247 # \u591a\u7ef4\u6570\u636e\u53ea\u89c4\u5b9a\u7b2c\u4e00\u7ef4 a [ size :] # size~\u6700\u540e\u4e00\u884c \u6570\u636e\u8d4b\u503c \u00b6 \u589e\u52a0\u6570\u636e \u00b6 # concatenate axis=1 \u6c34\u5e73\u8fde\u63a5 np . concatenate (( a1 , a2 , ... ), axis = 0 ) # \u62fc\u63a5 # append axis=0 \u5217\u589e\u52a0 np . append ( arr , values , axis = None ) \u5220\u9664\u6570\u636e \u00b6 \u6570\u636e\u5904\u7406 \u00b6 \u6570\u636e\u7edf\u8ba1 \u00b6 \u5747\u503c \u00b6 # \u6c42\u5e73\u5747\u503c axis=0 \u6c42\u5217\u5747\u503c, axis=1 \u6c42\u884c\u5747\u503c\uff0c\u9ed8\u8ba4\u6c42\u6240\u6709\u6570\u7684\u5747\u503c np . mean ( matrix , axis = None ) \u6c42\u548c \u00b6 # \u6c42\u548c np . sum ( matrix , axis = None ) \u6807\u51c6\u5dee \u00b6 # \u6c42\u6807\u51c6\u5dee np . std ( matrix , axis = None ) \u65b9\u5dee \u00b6 # \u6c42\u65b9\u5dee np . var ( matrix , axis = None ) \u534f\u65b9\u5dee \u00b6 # \u6c42\u534f\u65b9\u5dee rowvar=True\u4ee5\u884c\u4e3a\u53d8\u91cf\uff0c\u5426\u5219\u4ee5\u5217\u4e3a\u53d8\u91cf np . cov ( matrix , rowvar = True ) \u8303\u6570 \u00b6 x_norm = np . linalg . norm ( x , ord = 2 , axis = None , keepdims = False ) \u9ed8\u8ba4 2 \u8303\u6570 \u53c2\u6570 \u8bf4\u660e \u5f0f\u5b50 ord=1 1\u8303\u6570 $ ord=2\uff08\u9ed8\u8ba4\uff09 2\u8303\u6570 \\(\\sqrt{x_1^2+x_2^2+...}\\) ord=np.inf \u65e0\u7a77\u8303\u6570 $max( \u77e9\u9635\u8fd0\u7b97 \u00b6 \u77e9\u9635\u8f6c\u7f6e \u00b6 # \u8f6c\u7f6e \u4e0d\u6539\u53d8\u539f\u77e9\u9635 a . T () / np . transpose ( a ) a.T \u7684 a \u4e00\u5b9a\u8981\u662f ndarray, \u5982\u679c a \u662f list, \u53ea\u80fd\u7528 np.transpose(a) \u4e14\u8fd4\u56de\u7684\u662f ndarray, \u5982\u679c a \u662f\u4e00\u7ef4\u7684 ndarray \u4e0d\u8d77\u4f5c\u7528 \u5982\u679c\u60f3\u8ba9\u4e00\u4e2a 1 n \u7ef4\u7684 ndarray \u6216 list \u53d8\u6210 n 1 \u7ef4, \u6709 2 \u4e2a\u65b9\u6cd5 \u6cd5\u4e00\uff1a a = np . transpose ([ a ]) # [a] \u662f\u4e00\u4e2a list \u6cd5\u4e8c\uff1a a = np . array ([ a ]) a = a . T \u77e9\u9635\u4e58\u6cd5 \u00b6 # \u70b9\u4e58 \u53c9\u4e58 np . dot ( x , w ) # \u5411\u91cf\u70b9\u4e58 np . corss ( x , w ) # \u53c9\u4e58 matmul() np\u4f7f\u7528\u4e4bnp.matmul_alwaysyxl\u7684\u535a\u5ba2-CSDN\u535a\u5ba2 np . matmul ( a , b , out = None ) # \u5982\u679c\u90fd\u662f\u4e8c\u7ef4\u7684\uff0c\u5c31\u662f\u666e\u901a\u7684\u77e9\u9635\u4e58\u6cd5 # \u5982\u679c\u67d0\u4e2a\u53c2\u6570\u662f N(n>2) \u7ef4\u7684\uff0c\u8be5\u53c2\u6570\u5457\u7406\u89e3\u4e3a\u4e00\u4e9b\u77e9\u9635(\u7ef4\u6570\u4e3a\u6700\u540e2\u7ef4)\u7684stack,\u8ba1\u7b97\u65f6\u4f1a\u5f97\u5230\u76f8\u5e94\u7684\u5e7f\u64ad # eg\uff1aa:(2,2,4)\u548cb:(2,4,2), a\u4f1a\u88ab\u7406\u89e3\u4e3a2\u4e2a(2,4),b\u4f1a\u88ab\u7406\u89e3\u4e3a2\u4e2a(4,2),\u7ed3\u679c\u662fa\u7684\u7b2c\u4e00\u4e2a\u548cb\u7684\u7b2c\u4e00\u4e2a\uff0ca\u7684\u7b2c\u4e8c\u4e2a\u548cb\u7684\u7b2c\u4e8c\u4e2a\u76f8\u4e58\uff0c\u7ed3\u679c\u4e3a(2,2,2) # a:(2,2,4)\u548cc:(1,4,2)\uff0cc\u4f1a\u88ab\u5e7f\u64ad\u62102\u4e2a\uff0ca\u4e2d\u76842\u4e2a\u5206\u522b\u4e0ec\u76f8\u4e58\uff0c\u7ed3\u679c\u4e3a(2,2,2) \u6570\u5b66\u8fd0\u7b97 \u00b6 np . power ( a , 2 ) # \u5bf9a\u4e2d\u6bcf\u4e2a\u5143\u7d20\u5e73\u65b9, \u800c\u4e0d\u662f\u8ba1\u7b97 a*a, \u53ef\u4ee5\u7b80\u5199\u4e3a a**2 np . power ( a , b ) # a \u4e0e b \u7684\u5217\u6570\u8981\u76f8\u540c, \u5bf9 b \u4e2d\u7684\u6bcf\u4e2a\u5143\u7d20, \u8ba1\u7b97 a[j] \u7684 b[i][j]\u6b21\u65b9 # \u9664\u4e86\u6b21\u65b9\u5916\uff0c\u5176\u4ed6\u7684\u8fd0\u7b97\u540c\u7406\uff0c\u6bd4\u5982\u5982\u679c\u8981\u5bf9\u6bcf\u4e2a\u6570\u5b57\u8fdb\u884c log2 \u7684\u64cd\u4f5c\u4e0d\u80fd\u4f7f\u7528 math.log2(),\u7c7b\u4f3c\u7684\u6709 np . log2 ( a ) np . around ( a ) np . abs ( a ) + - * / NumPy\u4e2dndarray\u548cmatrix\u7684\u56db\u5219\u8fd0\u7b97_\u85cf\u77e5\u9601 ndarray \u7528 + - * / \u505a\u56db\u5219\u8fd0\u7b97\u65f6\u4ec5\u4ec5\u662f\u628a\u6bcf\u4e00\u4e2a\u5355\u5143\u505a\u76f8\u5e94\u7684\u8fd0\u7b97\uff0c\u7ef4\u5ea6\u4e0d\u5bf9\u5e94\u4f1a\u4f4e\u7ef4\u5411\u9ad8\u7ef4\u5e7f\u64ad astype() \u00b6 # \u6570\u636e\u7c7b\u578b\u8f6c\u6362 ndarray . astype ( dtype , order = 'K' , casting = 'unsafe' , subok = True , copy = True ) meshgrid() / mgird() \u00b6 meshgrid() # \u751f\u6210\u7f51\u683c\u70b9\u5750\u6807\u77e9\u9635 np . meshgrid ( * xi , copy = True , sparse = False , indexing = 'xy' ) X , Y = np . meshgrid ( x , y ) # \u628a x,y \u8fdb\u884c\u7b1b\u5361\u5c14\u79ef\u7684\u7ed3\u679c\u7684\u7b2c\u4e00\u4f4d\u5143\u7d20\u653e\u8fdb X, \u7b2c\u4e8c\u4f4d\u5143\u7d20\u7ed9 Y mgird() >>> np . mgrid [ 0 : 5 , 0 : 5 ] # \u4e0e meshgird \u7684\u6548\u679c\u7c7b\u4f3c array ([[[ 0 , 0 , 0 , 0 , 0 ], [ 1 , 1 , 1 , 1 , 1 ], [ 2 , 2 , 2 , 2 , 2 ], [ 3 , 3 , 3 , 3 , 3 ], [ 4 , 4 , 4 , 4 , 4 ]], [[ 0 , 1 , 2 , 3 , 4 ], [ 0 , 1 , 2 , 3 , 4 ], [ 0 , 1 , 2 , 3 , 4 ], [ 0 , 1 , 2 , 3 , 4 ], [ 0 , 1 , 2 , 3 , 4 ]]]) >>> np . mgrid [ - 1 : 1 : 5 j ] # 5j \u8868\u793a\u751f\u62105\u4e2a\u70b9 array ([ - 1. , - 0.5 , 0. , 0.5 , 1. ]) >>> np . mgrid [ 0 : 1 : 100 j , 0 : 1 : 100 j ] # \u4e8c\u7ef4\u7684\u4f8b\u5b50 shape \u00b6 ndarray . shape # \u8fd4\u56de shape # \u4e5f\u53ef\u4ee5\u7528\u6765 reshape ndarray . shape = ( int , int ) # eg\uff1a\u83b7\u53d6\u6570\u636e\u7684\u5217\u6570 print ( data . shape [ 1 ]) clip() \u00b6 np . clip ( a , a_min , a_max ) # a \u4e2d\u5c0f\u4e8e a_min \u7684\u6570\u90fd\u53d8\u6210 a_min, \u5927\u4e8e a_max \u7684\u6570\u90fd\u53d8\u6210 a_max random.shuffle() \u00b6 # \u6253\u4e71\u987a\u5e8f arr = np . arange ( 10 ) np . random . shuffle ( arr ) argmax() \u00b6 Returns the indices of the maximum values along an axis. np . argmax ( a , axis = None , out = None ) \u53c2\u8003 \u00b6 np\u5165\u95e8\u8be6\u7ec6\u6559\u7a0b(\u4e8c)_Smallactive-CSDN\u535a\u5ba2 np\u5165\u95e8\u8be6\u7ec6\u6559\u7a0b(\u4e09)_Smallactive-CSDN\u535a\u5ba2","title":"Numpy"},{"location":"Python/Numpy/#numpy","text":"NumPy Reference \u2014 NumPy v1.20 Manual","title":"Numpy"},{"location":"Python/Numpy/#ndarray","text":"","title":"ndarray"},{"location":"Python/Numpy/#ndarray_1","text":"import numpy as np np . array ( object , dtype = None , copy = True ) np . empty ( shape , dtype = float , order = 'C' , * , like = None ) # \u5e76\u4e0d\u521d\u59cb\u5316\u4e3a0 np . ones ( shape , dtype = None , order = 'C' , * , like = None ) # \u521d\u59cb\u5316\u4e3a 1 np . zeros ( shape , dtype = float , order = 'C' , * , like = None ) # \u521d\u59cb\u5316\u4e3a 0 a = np . arange ( 24 ) . reshape (( 2 , 3 , 4 )) # range\u521b\u5efalist,arange\u521b\u5efaarray a = np . arange ( 24 ) . reshape (( 2 , 3 , - 1 )) # \u53c2\u6570\u6709-1\u65f6\u4f1a\u81ea\u52a8\u6839\u636e\u5176\u4ed6\u7684\u53c2\u6570\u8ba1\u7b97 \u540d\u79f0 \u63cf\u8ff0 object \u6570\u7ec4\u6216\u5d4c\u5957\u7684\u6570\u5217 dtype \u6570\u7ec4\u5143\u7d20\u7684\u6570\u636e\u7c7b\u578b\uff0c\u53ef\u9009 copy \u5bf9\u8c61\u662f\u5426\u9700\u8981\u590d\u5236\uff0c\u53ef\u9009 order \u521b\u5efa\u6570\u7ec4\u7684\u6837\u5f0f\uff0cC\u4e3a\u884c\u65b9\u5411\uff0cF\u4e3a\u5217\u65b9\u5411\uff0cA\u4e3a\u4efb\u610f\u65b9\u5411\uff08\u9ed8\u8ba4\uff09 subok \u9ed8\u8ba4\u8fd4\u56de\u4e00\u4e2a\u4e0e\u57fa\u7c7b\u7c7b\u578b\u4e00\u81f4\u7684\u6570\u7ec4 ndmin \u6307\u5b9a\u751f\u6210\u6570\u7ec4\u7684\u6700\u5c0f\u7ef4\u5ea6","title":"\u521b\u5efa ndarray"},{"location":"Python/Numpy/#_1","text":"# \u4e00\u7ef4 a [ 2 ] a [ 1 : 4 : 2 ] # \u5207\u7247 3 5 \u6b65\u957f2 # \u591a\u7ef4\u6570\u7ec4 a = np . arange ( 24 ) . reshape (( 2 , 3 , 4 )) a [ 1 , 2 , 3 ] a [::,::,::] # \u5207\u7247 # \u591a\u7ef4\u6570\u636e\u53ea\u89c4\u5b9a\u7b2c\u4e00\u7ef4 a [ size :] # size~\u6700\u540e\u4e00\u884c","title":"\u8bfb\u53d6\u6570\u636e"},{"location":"Python/Numpy/#_2","text":"","title":"\u6570\u636e\u8d4b\u503c"},{"location":"Python/Numpy/#_3","text":"# concatenate axis=1 \u6c34\u5e73\u8fde\u63a5 np . concatenate (( a1 , a2 , ... ), axis = 0 ) # \u62fc\u63a5 # append axis=0 \u5217\u589e\u52a0 np . append ( arr , values , axis = None )","title":"\u589e\u52a0\u6570\u636e"},{"location":"Python/Numpy/#_4","text":"","title":"\u5220\u9664\u6570\u636e"},{"location":"Python/Numpy/#_5","text":"","title":"\u6570\u636e\u5904\u7406"},{"location":"Python/Numpy/#_6","text":"","title":"\u6570\u636e\u7edf\u8ba1"},{"location":"Python/Numpy/#_7","text":"# \u6c42\u5e73\u5747\u503c axis=0 \u6c42\u5217\u5747\u503c, axis=1 \u6c42\u884c\u5747\u503c\uff0c\u9ed8\u8ba4\u6c42\u6240\u6709\u6570\u7684\u5747\u503c np . mean ( matrix , axis = None )","title":"\u5747\u503c"},{"location":"Python/Numpy/#_8","text":"# \u6c42\u548c np . sum ( matrix , axis = None )","title":"\u6c42\u548c"},{"location":"Python/Numpy/#_9","text":"# \u6c42\u6807\u51c6\u5dee np . std ( matrix , axis = None )","title":"\u6807\u51c6\u5dee"},{"location":"Python/Numpy/#_10","text":"# \u6c42\u65b9\u5dee np . var ( matrix , axis = None )","title":"\u65b9\u5dee"},{"location":"Python/Numpy/#_11","text":"# \u6c42\u534f\u65b9\u5dee rowvar=True\u4ee5\u884c\u4e3a\u53d8\u91cf\uff0c\u5426\u5219\u4ee5\u5217\u4e3a\u53d8\u91cf np . cov ( matrix , rowvar = True )","title":"\u534f\u65b9\u5dee"},{"location":"Python/Numpy/#_12","text":"x_norm = np . linalg . norm ( x , ord = 2 , axis = None , keepdims = False ) \u9ed8\u8ba4 2 \u8303\u6570 \u53c2\u6570 \u8bf4\u660e \u5f0f\u5b50 ord=1 1\u8303\u6570 $ ord=2\uff08\u9ed8\u8ba4\uff09 2\u8303\u6570 \\(\\sqrt{x_1^2+x_2^2+...}\\) ord=np.inf \u65e0\u7a77\u8303\u6570 $max(","title":"\u8303\u6570"},{"location":"Python/Numpy/#_13","text":"","title":"\u77e9\u9635\u8fd0\u7b97"},{"location":"Python/Numpy/#_14","text":"# \u8f6c\u7f6e \u4e0d\u6539\u53d8\u539f\u77e9\u9635 a . T () / np . transpose ( a ) a.T \u7684 a \u4e00\u5b9a\u8981\u662f ndarray, \u5982\u679c a \u662f list, \u53ea\u80fd\u7528 np.transpose(a) \u4e14\u8fd4\u56de\u7684\u662f ndarray, \u5982\u679c a \u662f\u4e00\u7ef4\u7684 ndarray \u4e0d\u8d77\u4f5c\u7528 \u5982\u679c\u60f3\u8ba9\u4e00\u4e2a 1 n \u7ef4\u7684 ndarray \u6216 list \u53d8\u6210 n 1 \u7ef4, \u6709 2 \u4e2a\u65b9\u6cd5 \u6cd5\u4e00\uff1a a = np . transpose ([ a ]) # [a] \u662f\u4e00\u4e2a list \u6cd5\u4e8c\uff1a a = np . array ([ a ]) a = a . T","title":"\u77e9\u9635\u8f6c\u7f6e"},{"location":"Python/Numpy/#_15","text":"# \u70b9\u4e58 \u53c9\u4e58 np . dot ( x , w ) # \u5411\u91cf\u70b9\u4e58 np . corss ( x , w ) # \u53c9\u4e58 matmul() np\u4f7f\u7528\u4e4bnp.matmul_alwaysyxl\u7684\u535a\u5ba2-CSDN\u535a\u5ba2 np . matmul ( a , b , out = None ) # \u5982\u679c\u90fd\u662f\u4e8c\u7ef4\u7684\uff0c\u5c31\u662f\u666e\u901a\u7684\u77e9\u9635\u4e58\u6cd5 # \u5982\u679c\u67d0\u4e2a\u53c2\u6570\u662f N(n>2) \u7ef4\u7684\uff0c\u8be5\u53c2\u6570\u5457\u7406\u89e3\u4e3a\u4e00\u4e9b\u77e9\u9635(\u7ef4\u6570\u4e3a\u6700\u540e2\u7ef4)\u7684stack,\u8ba1\u7b97\u65f6\u4f1a\u5f97\u5230\u76f8\u5e94\u7684\u5e7f\u64ad # eg\uff1aa:(2,2,4)\u548cb:(2,4,2), a\u4f1a\u88ab\u7406\u89e3\u4e3a2\u4e2a(2,4),b\u4f1a\u88ab\u7406\u89e3\u4e3a2\u4e2a(4,2),\u7ed3\u679c\u662fa\u7684\u7b2c\u4e00\u4e2a\u548cb\u7684\u7b2c\u4e00\u4e2a\uff0ca\u7684\u7b2c\u4e8c\u4e2a\u548cb\u7684\u7b2c\u4e8c\u4e2a\u76f8\u4e58\uff0c\u7ed3\u679c\u4e3a(2,2,2) # a:(2,2,4)\u548cc:(1,4,2)\uff0cc\u4f1a\u88ab\u5e7f\u64ad\u62102\u4e2a\uff0ca\u4e2d\u76842\u4e2a\u5206\u522b\u4e0ec\u76f8\u4e58\uff0c\u7ed3\u679c\u4e3a(2,2,2)","title":"\u77e9\u9635\u4e58\u6cd5"},{"location":"Python/Numpy/#_16","text":"np . power ( a , 2 ) # \u5bf9a\u4e2d\u6bcf\u4e2a\u5143\u7d20\u5e73\u65b9, \u800c\u4e0d\u662f\u8ba1\u7b97 a*a, \u53ef\u4ee5\u7b80\u5199\u4e3a a**2 np . power ( a , b ) # a \u4e0e b \u7684\u5217\u6570\u8981\u76f8\u540c, \u5bf9 b \u4e2d\u7684\u6bcf\u4e2a\u5143\u7d20, \u8ba1\u7b97 a[j] \u7684 b[i][j]\u6b21\u65b9 # \u9664\u4e86\u6b21\u65b9\u5916\uff0c\u5176\u4ed6\u7684\u8fd0\u7b97\u540c\u7406\uff0c\u6bd4\u5982\u5982\u679c\u8981\u5bf9\u6bcf\u4e2a\u6570\u5b57\u8fdb\u884c log2 \u7684\u64cd\u4f5c\u4e0d\u80fd\u4f7f\u7528 math.log2(),\u7c7b\u4f3c\u7684\u6709 np . log2 ( a ) np . around ( a ) np . abs ( a ) + - * / NumPy\u4e2dndarray\u548cmatrix\u7684\u56db\u5219\u8fd0\u7b97_\u85cf\u77e5\u9601 ndarray \u7528 + - * / \u505a\u56db\u5219\u8fd0\u7b97\u65f6\u4ec5\u4ec5\u662f\u628a\u6bcf\u4e00\u4e2a\u5355\u5143\u505a\u76f8\u5e94\u7684\u8fd0\u7b97\uff0c\u7ef4\u5ea6\u4e0d\u5bf9\u5e94\u4f1a\u4f4e\u7ef4\u5411\u9ad8\u7ef4\u5e7f\u64ad","title":"\u6570\u5b66\u8fd0\u7b97"},{"location":"Python/Numpy/#astype","text":"# \u6570\u636e\u7c7b\u578b\u8f6c\u6362 ndarray . astype ( dtype , order = 'K' , casting = 'unsafe' , subok = True , copy = True )","title":"astype()"},{"location":"Python/Numpy/#meshgrid-mgird","text":"meshgrid() # \u751f\u6210\u7f51\u683c\u70b9\u5750\u6807\u77e9\u9635 np . meshgrid ( * xi , copy = True , sparse = False , indexing = 'xy' ) X , Y = np . meshgrid ( x , y ) # \u628a x,y \u8fdb\u884c\u7b1b\u5361\u5c14\u79ef\u7684\u7ed3\u679c\u7684\u7b2c\u4e00\u4f4d\u5143\u7d20\u653e\u8fdb X, \u7b2c\u4e8c\u4f4d\u5143\u7d20\u7ed9 Y mgird() >>> np . mgrid [ 0 : 5 , 0 : 5 ] # \u4e0e meshgird \u7684\u6548\u679c\u7c7b\u4f3c array ([[[ 0 , 0 , 0 , 0 , 0 ], [ 1 , 1 , 1 , 1 , 1 ], [ 2 , 2 , 2 , 2 , 2 ], [ 3 , 3 , 3 , 3 , 3 ], [ 4 , 4 , 4 , 4 , 4 ]], [[ 0 , 1 , 2 , 3 , 4 ], [ 0 , 1 , 2 , 3 , 4 ], [ 0 , 1 , 2 , 3 , 4 ], [ 0 , 1 , 2 , 3 , 4 ], [ 0 , 1 , 2 , 3 , 4 ]]]) >>> np . mgrid [ - 1 : 1 : 5 j ] # 5j \u8868\u793a\u751f\u62105\u4e2a\u70b9 array ([ - 1. , - 0.5 , 0. , 0.5 , 1. ]) >>> np . mgrid [ 0 : 1 : 100 j , 0 : 1 : 100 j ] # \u4e8c\u7ef4\u7684\u4f8b\u5b50","title":"meshgrid() / mgird()"},{"location":"Python/Numpy/#shape","text":"ndarray . shape # \u8fd4\u56de shape # \u4e5f\u53ef\u4ee5\u7528\u6765 reshape ndarray . shape = ( int , int ) # eg\uff1a\u83b7\u53d6\u6570\u636e\u7684\u5217\u6570 print ( data . shape [ 1 ])","title":"shape"},{"location":"Python/Numpy/#clip","text":"np . clip ( a , a_min , a_max ) # a \u4e2d\u5c0f\u4e8e a_min \u7684\u6570\u90fd\u53d8\u6210 a_min, \u5927\u4e8e a_max \u7684\u6570\u90fd\u53d8\u6210 a_max","title":"clip()"},{"location":"Python/Numpy/#randomshuffle","text":"# \u6253\u4e71\u987a\u5e8f arr = np . arange ( 10 ) np . random . shuffle ( arr )","title":"random.shuffle()"},{"location":"Python/Numpy/#argmax","text":"Returns the indices of the maximum values along an axis. np . argmax ( a , axis = None , out = None )","title":"argmax()"},{"location":"Python/Numpy/#_17","text":"np\u5165\u95e8\u8be6\u7ec6\u6559\u7a0b(\u4e8c)_Smallactive-CSDN\u535a\u5ba2 np\u5165\u95e8\u8be6\u7ec6\u6559\u7a0b(\u4e09)_Smallactive-CSDN\u535a\u5ba2","title":"\u53c2\u8003"},{"location":"Python/Opencv/","text":"Opencv \u00b6 \u4e0b\u8f7d\u5b89\u88c5 \u00b6 pip install opencv-python \u5e38\u7528\u64cd\u4f5c \u00b6 cv2.imread() \u00b6 import cv2 img = cv2 . imread ( path ) \u7528 opencv \u5904\u7406\u56fe\u50cf\u65f6\uff0c\u53ef\u4ee5\u53d1\u73b0\u83b7\u5f97\u7684\u77e9\u9635\u7c7b\u578b\u90fd\u662f uint8\uff08dtype='uint8'\uff09 cv2.resize() \u00b6 img = cv2 . resize ( img , ( r , w ))","title":"Opencv"},{"location":"Python/Opencv/#opencv","text":"","title":"Opencv"},{"location":"Python/Opencv/#_1","text":"pip install opencv-python","title":"\u4e0b\u8f7d\u5b89\u88c5"},{"location":"Python/Opencv/#_2","text":"","title":"\u5e38\u7528\u64cd\u4f5c"},{"location":"Python/Opencv/#cv2imread","text":"import cv2 img = cv2 . imread ( path ) \u7528 opencv \u5904\u7406\u56fe\u50cf\u65f6\uff0c\u53ef\u4ee5\u53d1\u73b0\u83b7\u5f97\u7684\u77e9\u9635\u7c7b\u578b\u90fd\u662f uint8\uff08dtype='uint8'\uff09","title":"cv2.imread()"},{"location":"Python/Opencv/#cv2resize","text":"img = cv2 . resize ( img , ( r , w ))","title":"cv2.resize()"},{"location":"Python/Pandas/","text":"Pandas \u00b6 pandas documentation \u2014 pandas 1.2.4 documentation (pydata.org) DataFrame \u00b6 \u521b\u5efa DataFrame \u00b6 pandas . DataFrame ( data = None , index = None , columns = None , dtype = None , copy = None ) # \u6570\u636e \u7d22\u5f15\uff08\u884c\u6807\u7b7e\uff09 \u5217\u6807\u7b7e \u6570\u636e\u7c7b\u578b \u62f7\u8d1d\u6570\u636e \u7528\u5b57\u5178\u521b\u5efa \u00b6 data = { \"one\" : np . random . randn ( 4 ), \"two\" : np . linspace ( 1 , 4 , 4 ), \"three\" :[ 'zhangsan' , '\u674e\u56db' , 999 , 0.1 ]} df = pd . DataFrame ( data , index = [ 1 , 2 , 3 , 4 ]) \u7528\u6570\u7ec4\u521b\u5efa \u00b6 data = np . random . randn ( 6 , 4 ) #\u521b\u5efa\u4e00\u4e2a6\u884c4\u5217\u7684\u6570\u7ec4 df = pd . DataFrame ( data , columns = list ( 'ABCD' ), index = [ 1 , 2 , 'a' , 'b' , '2006-10-1' , '\u7b2c\u516d\u884c' ]) \u7a7a DataFrame \u00b6 pd . DataFrame ( columns = ( 'id' , 'name' , 'grade' , 'class' )) \u7d22\u5f15\u8bbe\u7f6e \u00b6 \u521b\u5efa df \u662f\u4e0d\u6307\u5b9a\u7d22\u5f15\u9ed8\u8ba4\u4f1a\u4ece 0 \u5f00\u59cb set_index \uff1a\u5c06 df \u4e2d\u7684\u67d0\u5217\u8bbe\u7f6e\u4e3a\u7d22\u5f15 df . set_index ( 'one' , drop = False ) # drop\u9ed8\u8ba4\u4e3aTrue, \u8868\u793a\u8bbe\u7f6e\u7d22\u5f15\u540e\u5c06\u8be5\u5217\u5220\u9664 reset_index \uff1a\u91cd\u7f6e\u7d22\u5f15 df . set_index ( drop = True ) # drop\u9ed8\u8ba4\u4e3aFalse, \u8868\u793a\u539f\u7d22\u5f15\u5c06\u4f5c\u4e3a\u6570\u636e\u4fdd\u7559 \u8bfb\u53d6 DataFrame \u00b6 loc \u90fd\u662f\u884c\u540d\u548c\u5217\u540d\uff0ciloc \u90fd\u662f\u884c\u53f7\u548c\u5217\u53f7 loc \u4e0d\u652f\u6301\u884c\u53f7\u5207\u7247 \u6309\u5217\u8bfb\u53d6 \u00b6 # \u6309\u5217\u540d f . \u5217\u540d df [ '\u5217\u540d' ] / df [[ '\u5217\u540d' ]] / df [[ '\u5217\u540d1' , '\u5217\u540d2' , ... ]] # series Dataframe Dataframe # \u6309\u5217\u53f7 iloc df . iloc [:, 0 : 2 ] # [0,2)\u5217 \u6309\u884c\u8bfb\u53d6 \u00b6 # \u6309\u884c\u6807\u7b7e loc\uff08\u884c\u6807\u7b7e\u4e0d\u4e00\u5b9a\u662f\u5b57\u7b26\u4e32 df . loc [ '\u884c\u6807\u7b7e' ] / df . loc [[ '\u884c\u6807\u7b7e' ]] / df . loc [[ '\u884c\u6807\u7b7e1' , '\u884c\u6807\u7b7e2' , ... ]] # series Dataframe Dataframe # \u6309\u884c\u53f7 iloc df . iloc [ \u884c\u53f7 ] / df . iloc [[ \u884c\u53f7 ]] / df . iloc [[ \u884c\u53f71 , \u884c\u53f72 , ... ]] / df . iloc [ \u884c\u53f71 : \u884c\u53f72 ] # \u7b2c\u4e00\u4e2a\u662fseries \u540e\u9762\u7684\u662fDataframe \u6309\u5355\u5143\u683c\u8bfb\u53d6 \u00b6 df [ col ][ row ] # df['a'][1] /* loc */ # \u4e00\u4e2a\u5355\u5143\u683c df . loc [ row ][ col ] / df . loc [ row , col ] # \u4e00\u884c\u591a\u5217 df . loc [ row ][[ col1 , col2 ]] / df . loc [ 1 ,[ col1 , col2 ]] / df . loc [ row ][ firstCol : endCol ] / df . loc [ row , firstCol : endCol ] # \u591a\u884c\u4e00\u5217 \u884c\u53f7\u4e0d\u80fd\u7528\u5207\u7247 df . loc [[ row1 , row2 ]][ col ] / df . loc [[ row1 , row2 ]] . col / df . loc [[ row1 , row2 ], col ] # \u591a\u884c\u591a\u5217 \u884c\u53f7\u4e0d\u80fd\u7528\u5207\u7247 df . loc [[ row1 , row2 ],[ col1 , col2 ]] / df . loc [[ row1 , row2 ]][[ col1 , col2 ]] / df . loc [[ row1 , row3 ], firstCol : endCol ] /* iloc */ # \u4e00\u4e2a\u5355\u5143\u683c \u4e0d\u652f\u6301df.iloc[rowNo,col] df . iloc [ rowNo ] . col / df . iloc [ rowNo ][ col ] / df . iloc [ rowNo , colNo ] # \u4e00\u884c\u591a\u5217 \u4e0d\u652f\u6301df.iloc[rowNo,[col1,col2]],df.iloc[rowNo,firstColNo:endColNo] df . iloc [ rowNo , firestColNo : endColNo ] / df . iloc [ rowNo ][[ col1 , col2 ]] / df . iloc [ rowNo ][ firesCol : endCol ] # \u591a\u884c\u4e00\u5217 df . iloc [[ rowNo1 , rowNo2 ], colNo ] / df . iloc [ firstRowNo : endRowNo , colNo ] / df . iloc [[ rowNo1 , rowNo2 ]][ col ] / df . iloc [ firstRowNo : endRowNo ][ col ] # \u591a\u884c\u591a\u5217 df . iloc [ firstRowNo : endRowNo , firstColNo : endColNo ] / df . iloc [[ RowNo1 , RowNo2 ],[ ColNo1 , ColNo2 ]] / df . iloc [ firstRowNo : endRowNo ][[ col1 , col2 ]] \u8d4b\u503c \u00b6 \u5982\u679c\u7528\u4e00\u4e2a\u5217\u8868\u6216\u6570\u7ec4\u8d4b\u503c\uff0c\u5176\u957f\u5ea6\u5fc5\u987b\u76f8\u540c \u6309\u5217\u8d4b\u503c \u00b6 df . col = colList / colValue df [ col ] = colList / colValue # eg: df.A=[1,2,3,4,5,6],df['A']=0 \u6309\u884c\u8d4b\u503c \u00b6 df . loc [ row ] = rowList df . loc [ row ] = rowValue \u591a\u884c\u591a\u5217\u8d4b\u503c \u00b6 df . loc [[ row1 , row2 ],[ col1 , col2 ]] = value / valueList df . iloc [[ rowNo1 , rowNo2 ],[ colNo1 , colNo2 ]] = value / valueList df . iloc [[ rowNo1 , rowNo2 ]][[ col1 , col2 ]] = value / valueList \u5176\u4ed6 \u00b6 df [ df == 'NR' ] = 0 # \u6240\u6709 NR \u66ff\u6362\u6210 0 \u589e\u52a0\u6570\u636e \u00b6 \u5220\u9664\u6570\u636e \u00b6 \u5176\u4ed6 \u00b6 __version \u00b6 pd . __version__ # \u67e5\u770b\u7248\u672c read_csv() \u00b6 df = pd . read_csv ( 'nba.csv' , encoding = 'utf_8' \uff0c sheet_name = \"\" ) \u5e38\u7528\u5c5e\u6027\uff1a sep\uff1a\u5206\u9694\u7b26\uff0c\u5982 sep=',' header\uff1a\u6307\u5b9a\u4e00\u884c\u4e3a\u8868\u5934\uff0c\u5982 header=0 \u5373\u6307\u5b9a\u7b2c\u4e00\u884c\u4e3a\u8868\u5934 name\uff1a\u6307\u5b9a\u8868\u5934\uff0c\u5982name=['a','b] header\u4e0d\u6307\u5b9a\uff0cname\u4e0d\u6307\u5b9a\uff1a\u7b2c\u4e00\u884c\u4f5c\u4e3a\u8868\u5934 header\u6307\u5b9a\uff0cname\u6307\u5b9a\uff1a\u5148\u7528header\u6307\u5b9a\u884c\u4f5c\u4e3a\u8868\u5934\uff0c\u7136\u540e\u7528name\u8986\u76d6\uff0c\u76f8\u5f53\u4e8e\u5220\u9664\u4e86header\u6307\u5b9a\u7684\u884c\uff0c\u5e76\u7528name\u6307\u5b9a\u8868\u5934 to_csv() \u00b6 \u4f7f\u7528 to_csv() \u65b9\u6cd5\u5c06 DataFrame \u5b58\u50a8\u4e3a csv \u6587\u4ef6 df . to_csv ( 'site.csv' , encoding = 'utf_8' ) head(n) / tail(n) \u00b6 print ( df . head ( 10 )) # \u8bfb\u53d6\u524d10\u884c\uff0c\u9ed8\u8ba4\u4e3a5\u884c to_numpy() \u00b6 data = df . to_numpy () # \u8f6c\u6362\u4e3a numpy to_string() \u00b6 print ( df . to_string ()) #to_string() \u7528\u4e8e\u8fd4\u56de DataFrame \u7c7b\u578b\u7684\u6570\u636e\uff0c\u5982\u679c\u4e0d\u4f7f\u7528\u8be5\u51fd\u6570\uff0c\u5219\u8f93\u51fa\u7ed3\u679c\u4e3a\u6570\u636e\u7684\u524d\u9762 5 \u884c\u548c\u672b\u5c3e 5 \u884c\uff0c\u4e2d\u95f4\u90e8\u5206\u4ee5 ... \u4ee3\u66ff set_index \u53c2\u8003 \u00b6 pandas \u5165\u95e8\uff1aDataFrame\u7684\u521b\u5efa\uff0c\u8bfb\u5199\uff0c\u63d2\u5165\u548c\u5220\u9664_\u4e0d\u53bb\u60f3\u7ed3\u679c\uff0c\u4e00\u76f4\u5728\u8def\u4e0a-CSDN\u535a\u5ba2 \u8be6\u89e3pandas\u7684read_csv\u65b9\u6cd5 - \u53e4\u660e\u5730\u76c6 - \u535a\u5ba2\u56ed","title":"Pandas"},{"location":"Python/Pandas/#pandas","text":"pandas documentation \u2014 pandas 1.2.4 documentation (pydata.org)","title":"Pandas"},{"location":"Python/Pandas/#dataframe","text":"","title":"DataFrame"},{"location":"Python/Pandas/#dataframe_1","text":"pandas . DataFrame ( data = None , index = None , columns = None , dtype = None , copy = None ) # \u6570\u636e \u7d22\u5f15\uff08\u884c\u6807\u7b7e\uff09 \u5217\u6807\u7b7e \u6570\u636e\u7c7b\u578b \u62f7\u8d1d\u6570\u636e","title":"\u521b\u5efa DataFrame"},{"location":"Python/Pandas/#_1","text":"data = { \"one\" : np . random . randn ( 4 ), \"two\" : np . linspace ( 1 , 4 , 4 ), \"three\" :[ 'zhangsan' , '\u674e\u56db' , 999 , 0.1 ]} df = pd . DataFrame ( data , index = [ 1 , 2 , 3 , 4 ])","title":"\u7528\u5b57\u5178\u521b\u5efa"},{"location":"Python/Pandas/#_2","text":"data = np . random . randn ( 6 , 4 ) #\u521b\u5efa\u4e00\u4e2a6\u884c4\u5217\u7684\u6570\u7ec4 df = pd . DataFrame ( data , columns = list ( 'ABCD' ), index = [ 1 , 2 , 'a' , 'b' , '2006-10-1' , '\u7b2c\u516d\u884c' ])","title":"\u7528\u6570\u7ec4\u521b\u5efa"},{"location":"Python/Pandas/#dataframe_2","text":"pd . DataFrame ( columns = ( 'id' , 'name' , 'grade' , 'class' ))","title":"\u7a7a DataFrame"},{"location":"Python/Pandas/#_3","text":"\u521b\u5efa df \u662f\u4e0d\u6307\u5b9a\u7d22\u5f15\u9ed8\u8ba4\u4f1a\u4ece 0 \u5f00\u59cb set_index \uff1a\u5c06 df \u4e2d\u7684\u67d0\u5217\u8bbe\u7f6e\u4e3a\u7d22\u5f15 df . set_index ( 'one' , drop = False ) # drop\u9ed8\u8ba4\u4e3aTrue, \u8868\u793a\u8bbe\u7f6e\u7d22\u5f15\u540e\u5c06\u8be5\u5217\u5220\u9664 reset_index \uff1a\u91cd\u7f6e\u7d22\u5f15 df . set_index ( drop = True ) # drop\u9ed8\u8ba4\u4e3aFalse, \u8868\u793a\u539f\u7d22\u5f15\u5c06\u4f5c\u4e3a\u6570\u636e\u4fdd\u7559","title":"\u7d22\u5f15\u8bbe\u7f6e"},{"location":"Python/Pandas/#dataframe_3","text":"loc \u90fd\u662f\u884c\u540d\u548c\u5217\u540d\uff0ciloc \u90fd\u662f\u884c\u53f7\u548c\u5217\u53f7 loc \u4e0d\u652f\u6301\u884c\u53f7\u5207\u7247","title":"\u8bfb\u53d6 DataFrame"},{"location":"Python/Pandas/#_4","text":"# \u6309\u5217\u540d f . \u5217\u540d df [ '\u5217\u540d' ] / df [[ '\u5217\u540d' ]] / df [[ '\u5217\u540d1' , '\u5217\u540d2' , ... ]] # series Dataframe Dataframe # \u6309\u5217\u53f7 iloc df . iloc [:, 0 : 2 ] # [0,2)\u5217","title":"\u6309\u5217\u8bfb\u53d6"},{"location":"Python/Pandas/#_5","text":"# \u6309\u884c\u6807\u7b7e loc\uff08\u884c\u6807\u7b7e\u4e0d\u4e00\u5b9a\u662f\u5b57\u7b26\u4e32 df . loc [ '\u884c\u6807\u7b7e' ] / df . loc [[ '\u884c\u6807\u7b7e' ]] / df . loc [[ '\u884c\u6807\u7b7e1' , '\u884c\u6807\u7b7e2' , ... ]] # series Dataframe Dataframe # \u6309\u884c\u53f7 iloc df . iloc [ \u884c\u53f7 ] / df . iloc [[ \u884c\u53f7 ]] / df . iloc [[ \u884c\u53f71 , \u884c\u53f72 , ... ]] / df . iloc [ \u884c\u53f71 : \u884c\u53f72 ] # \u7b2c\u4e00\u4e2a\u662fseries \u540e\u9762\u7684\u662fDataframe","title":"\u6309\u884c\u8bfb\u53d6"},{"location":"Python/Pandas/#_6","text":"df [ col ][ row ] # df['a'][1] /* loc */ # \u4e00\u4e2a\u5355\u5143\u683c df . loc [ row ][ col ] / df . loc [ row , col ] # \u4e00\u884c\u591a\u5217 df . loc [ row ][[ col1 , col2 ]] / df . loc [ 1 ,[ col1 , col2 ]] / df . loc [ row ][ firstCol : endCol ] / df . loc [ row , firstCol : endCol ] # \u591a\u884c\u4e00\u5217 \u884c\u53f7\u4e0d\u80fd\u7528\u5207\u7247 df . loc [[ row1 , row2 ]][ col ] / df . loc [[ row1 , row2 ]] . col / df . loc [[ row1 , row2 ], col ] # \u591a\u884c\u591a\u5217 \u884c\u53f7\u4e0d\u80fd\u7528\u5207\u7247 df . loc [[ row1 , row2 ],[ col1 , col2 ]] / df . loc [[ row1 , row2 ]][[ col1 , col2 ]] / df . loc [[ row1 , row3 ], firstCol : endCol ] /* iloc */ # \u4e00\u4e2a\u5355\u5143\u683c \u4e0d\u652f\u6301df.iloc[rowNo,col] df . iloc [ rowNo ] . col / df . iloc [ rowNo ][ col ] / df . iloc [ rowNo , colNo ] # \u4e00\u884c\u591a\u5217 \u4e0d\u652f\u6301df.iloc[rowNo,[col1,col2]],df.iloc[rowNo,firstColNo:endColNo] df . iloc [ rowNo , firestColNo : endColNo ] / df . iloc [ rowNo ][[ col1 , col2 ]] / df . iloc [ rowNo ][ firesCol : endCol ] # \u591a\u884c\u4e00\u5217 df . iloc [[ rowNo1 , rowNo2 ], colNo ] / df . iloc [ firstRowNo : endRowNo , colNo ] / df . iloc [[ rowNo1 , rowNo2 ]][ col ] / df . iloc [ firstRowNo : endRowNo ][ col ] # \u591a\u884c\u591a\u5217 df . iloc [ firstRowNo : endRowNo , firstColNo : endColNo ] / df . iloc [[ RowNo1 , RowNo2 ],[ ColNo1 , ColNo2 ]] / df . iloc [ firstRowNo : endRowNo ][[ col1 , col2 ]]","title":"\u6309\u5355\u5143\u683c\u8bfb\u53d6"},{"location":"Python/Pandas/#_7","text":"\u5982\u679c\u7528\u4e00\u4e2a\u5217\u8868\u6216\u6570\u7ec4\u8d4b\u503c\uff0c\u5176\u957f\u5ea6\u5fc5\u987b\u76f8\u540c","title":"\u8d4b\u503c"},{"location":"Python/Pandas/#_8","text":"df . col = colList / colValue df [ col ] = colList / colValue # eg: df.A=[1,2,3,4,5,6],df['A']=0","title":"\u6309\u5217\u8d4b\u503c"},{"location":"Python/Pandas/#_9","text":"df . loc [ row ] = rowList df . loc [ row ] = rowValue","title":"\u6309\u884c\u8d4b\u503c"},{"location":"Python/Pandas/#_10","text":"df . loc [[ row1 , row2 ],[ col1 , col2 ]] = value / valueList df . iloc [[ rowNo1 , rowNo2 ],[ colNo1 , colNo2 ]] = value / valueList df . iloc [[ rowNo1 , rowNo2 ]][[ col1 , col2 ]] = value / valueList","title":"\u591a\u884c\u591a\u5217\u8d4b\u503c"},{"location":"Python/Pandas/#_11","text":"df [ df == 'NR' ] = 0 # \u6240\u6709 NR \u66ff\u6362\u6210 0","title":"\u5176\u4ed6"},{"location":"Python/Pandas/#_12","text":"","title":"\u589e\u52a0\u6570\u636e"},{"location":"Python/Pandas/#_13","text":"","title":"\u5220\u9664\u6570\u636e"},{"location":"Python/Pandas/#_14","text":"","title":"\u5176\u4ed6"},{"location":"Python/Pandas/#__version","text":"pd . __version__ # \u67e5\u770b\u7248\u672c","title":"__version"},{"location":"Python/Pandas/#read_csv","text":"df = pd . read_csv ( 'nba.csv' , encoding = 'utf_8' \uff0c sheet_name = \"\" ) \u5e38\u7528\u5c5e\u6027\uff1a sep\uff1a\u5206\u9694\u7b26\uff0c\u5982 sep=',' header\uff1a\u6307\u5b9a\u4e00\u884c\u4e3a\u8868\u5934\uff0c\u5982 header=0 \u5373\u6307\u5b9a\u7b2c\u4e00\u884c\u4e3a\u8868\u5934 name\uff1a\u6307\u5b9a\u8868\u5934\uff0c\u5982name=['a','b] header\u4e0d\u6307\u5b9a\uff0cname\u4e0d\u6307\u5b9a\uff1a\u7b2c\u4e00\u884c\u4f5c\u4e3a\u8868\u5934 header\u6307\u5b9a\uff0cname\u6307\u5b9a\uff1a\u5148\u7528header\u6307\u5b9a\u884c\u4f5c\u4e3a\u8868\u5934\uff0c\u7136\u540e\u7528name\u8986\u76d6\uff0c\u76f8\u5f53\u4e8e\u5220\u9664\u4e86header\u6307\u5b9a\u7684\u884c\uff0c\u5e76\u7528name\u6307\u5b9a\u8868\u5934","title":"read_csv()"},{"location":"Python/Pandas/#to_csv","text":"\u4f7f\u7528 to_csv() \u65b9\u6cd5\u5c06 DataFrame \u5b58\u50a8\u4e3a csv \u6587\u4ef6 df . to_csv ( 'site.csv' , encoding = 'utf_8' )","title":"to_csv()"},{"location":"Python/Pandas/#headn-tailn","text":"print ( df . head ( 10 )) # \u8bfb\u53d6\u524d10\u884c\uff0c\u9ed8\u8ba4\u4e3a5\u884c","title":"head(n) / tail(n)"},{"location":"Python/Pandas/#to_numpy","text":"data = df . to_numpy () # \u8f6c\u6362\u4e3a numpy","title":"to_numpy()"},{"location":"Python/Pandas/#to_string","text":"print ( df . to_string ()) #to_string() \u7528\u4e8e\u8fd4\u56de DataFrame \u7c7b\u578b\u7684\u6570\u636e\uff0c\u5982\u679c\u4e0d\u4f7f\u7528\u8be5\u51fd\u6570\uff0c\u5219\u8f93\u51fa\u7ed3\u679c\u4e3a\u6570\u636e\u7684\u524d\u9762 5 \u884c\u548c\u672b\u5c3e 5 \u884c\uff0c\u4e2d\u95f4\u90e8\u5206\u4ee5 ... \u4ee3\u66ff set_index","title":"to_string()"},{"location":"Python/Pandas/#_15","text":"pandas \u5165\u95e8\uff1aDataFrame\u7684\u521b\u5efa\uff0c\u8bfb\u5199\uff0c\u63d2\u5165\u548c\u5220\u9664_\u4e0d\u53bb\u60f3\u7ed3\u679c\uff0c\u4e00\u76f4\u5728\u8def\u4e0a-CSDN\u535a\u5ba2 \u8be6\u89e3pandas\u7684read_csv\u65b9\u6cd5 - \u53e4\u660e\u5730\u76c6 - \u535a\u5ba2\u56ed","title":"\u53c2\u8003"},{"location":"Python/Pymssql/","text":"Pymssql \u00b6 pymssql \u2014 pymssql 2.2.2.dev0+gff84c14.d20210416 documentation \u8fde\u63a5 \u00b6 # \u8fde\u63a5 autocommit \u81ea\u52a8\u4fee\u6539\u64cd\u4f5c conn = sql . connect ( serverName , userName , password , autocommit = True ) cursor = conn . cursor () # \u5173\u95ed\u8fde\u63a5 conn . close () \u53ef\u80fd\u9047\u5230\u7684\u9519\u8bef\uff1a 18456 \uff1a\u5148\u7528 windows \u8eab\u4efd\u9a8c\u8bc1\u767b\u5f55\uff0c\u53f3\u51fb\u6570\u636e\u5e93\uff08\u4e0d\u662f\u91cc\u9762\u6570\u636e\u5e93\u90a3\u4e2a\u6587\u4ef6\u5939\uff0c\u662f\u6700\u5916\u9762\u90a3\u4e2a\uff0c\u56fe\u6807\u662f\u6570\u636e\u5e93\uff09\uff0c\u53f3\u51fb\u5c5e\u6027\uff0c\u5b89\u5168\u6027\uff0c\u670d\u52a1\u5668\u9a8c\u8bc1\u8eab\u4efd\u6539\u4e3a SQL Server \u548c Windows \u8eab\u4efd\u9a8c\u8bc1\u6a21\u5f0f 233 \uff1a\u6253\u5f00 SQL Server \u914d\u7f6e\u7ba1\u7406\u5668\uff0cSQL Server\u7f51\u7edc\u914d\u7f6e\uff0cMSSQLSERVER\u7684\u534f\u8bae\uff0c\u542f\u7528 TCP / IP\uff0c\u6700\u597d\u518d\u91cd\u542f\u4e00\u4e0b SQL Server\u914d\u7f6e\u7ba1\u7406\u5668\uff08\u672c\u5730\uff09\u4e2d\u7684 SQL Server \u6267\u884c\u6307\u4ee4 \u00b6 # \u6267\u884c cursor . execute ( 'sql\u8bed\u53e5' ) # \u8c03\u7528\u5b58\u50a8\u8fc7\u7a0b cursor . callproc ( 'FindPerson' , ( 'Jane Doe' ,)) # \u5b58\u50a8\u8fc7\u7a0b\u540d \u53c2\u6570 \u83b7\u53d6\u7ed3\u679c \u00b6 cnt = cursor . fetchone ()[ 0 ] # \u83b7\u53d6\u7b2c\u4e00\u884c # \u83b7\u53d6\u591a\u884c row = cursor . fetchone () while row : print ( \"ID= %d , Name= %s \" % ( row [ 0 ], row [ 1 ])) row = cursor . fetchone () cursor . execute ( 'SELECT * FROM persons WHERE salesrep= %s ' , 'John Doe' ) for row in cursor : print ( 'row = %r ' % ( row ,)) cursor . execute ( 'SELECT * FROM persons' ) for row in cursor : print ( \"ID= %d , Name= %s \" % ( row [ 'id' ], row [ 'name' ])) \u6ce8\u610f\u4e8b\u9879\uff1a\u4e00\u6761\u94fe\u63a5\u5728\u4efb\u4f55\u65f6\u5019\u53ea\u4f1a\u6709\u4e00\u4e2aCursor\u5bf9\u8c61\u5904\u4e8e\u67e5\u8be2\u72b6\u6001","title":"Pymssql"},{"location":"Python/Pymssql/#pymssql","text":"pymssql \u2014 pymssql 2.2.2.dev0+gff84c14.d20210416 documentation","title":"Pymssql"},{"location":"Python/Pymssql/#_1","text":"# \u8fde\u63a5 autocommit \u81ea\u52a8\u4fee\u6539\u64cd\u4f5c conn = sql . connect ( serverName , userName , password , autocommit = True ) cursor = conn . cursor () # \u5173\u95ed\u8fde\u63a5 conn . close () \u53ef\u80fd\u9047\u5230\u7684\u9519\u8bef\uff1a 18456 \uff1a\u5148\u7528 windows \u8eab\u4efd\u9a8c\u8bc1\u767b\u5f55\uff0c\u53f3\u51fb\u6570\u636e\u5e93\uff08\u4e0d\u662f\u91cc\u9762\u6570\u636e\u5e93\u90a3\u4e2a\u6587\u4ef6\u5939\uff0c\u662f\u6700\u5916\u9762\u90a3\u4e2a\uff0c\u56fe\u6807\u662f\u6570\u636e\u5e93\uff09\uff0c\u53f3\u51fb\u5c5e\u6027\uff0c\u5b89\u5168\u6027\uff0c\u670d\u52a1\u5668\u9a8c\u8bc1\u8eab\u4efd\u6539\u4e3a SQL Server \u548c Windows \u8eab\u4efd\u9a8c\u8bc1\u6a21\u5f0f 233 \uff1a\u6253\u5f00 SQL Server \u914d\u7f6e\u7ba1\u7406\u5668\uff0cSQL Server\u7f51\u7edc\u914d\u7f6e\uff0cMSSQLSERVER\u7684\u534f\u8bae\uff0c\u542f\u7528 TCP / IP\uff0c\u6700\u597d\u518d\u91cd\u542f\u4e00\u4e0b SQL Server\u914d\u7f6e\u7ba1\u7406\u5668\uff08\u672c\u5730\uff09\u4e2d\u7684 SQL Server","title":"\u8fde\u63a5"},{"location":"Python/Pymssql/#_2","text":"# \u6267\u884c cursor . execute ( 'sql\u8bed\u53e5' ) # \u8c03\u7528\u5b58\u50a8\u8fc7\u7a0b cursor . callproc ( 'FindPerson' , ( 'Jane Doe' ,)) # \u5b58\u50a8\u8fc7\u7a0b\u540d \u53c2\u6570","title":"\u6267\u884c\u6307\u4ee4"},{"location":"Python/Pymssql/#_3","text":"cnt = cursor . fetchone ()[ 0 ] # \u83b7\u53d6\u7b2c\u4e00\u884c # \u83b7\u53d6\u591a\u884c row = cursor . fetchone () while row : print ( \"ID= %d , Name= %s \" % ( row [ 0 ], row [ 1 ])) row = cursor . fetchone () cursor . execute ( 'SELECT * FROM persons WHERE salesrep= %s ' , 'John Doe' ) for row in cursor : print ( 'row = %r ' % ( row ,)) cursor . execute ( 'SELECT * FROM persons' ) for row in cursor : print ( \"ID= %d , Name= %s \" % ( row [ 'id' ], row [ 'name' ])) \u6ce8\u610f\u4e8b\u9879\uff1a\u4e00\u6761\u94fe\u63a5\u5728\u4efb\u4f55\u65f6\u5019\u53ea\u4f1a\u6709\u4e00\u4e2aCursor\u5bf9\u8c61\u5904\u4e8e\u67e5\u8be2\u72b6\u6001","title":"\u83b7\u53d6\u7ed3\u679c"},{"location":"Python/Scipy/","text":"Scipy \u00b6 \u63d2\u503c \u00b6 griddata \u00b6 from scipy.interpolate import griddata grid_x , grid_y = np . mgrid [ 0 : 1 : 100 j , 0 : 1 : 100 j ] grid = griddata ( points , values , ( grid_x , grid_y ), method = 'linear' , fill_value = nan ) \u5982\u679c\u662f\u5728\u4e8c\u7ef4\u4e0a\u4f5c\u56fe\uff08 (X,Y) -> Z \uff09\uff0cpoint \u7684\u7ef4\u6570\u662f [data_size, 2]\uff0cvalues \u662f [1, data_size] method \uff1a\u8868\u793a\u63d2\u503c\u65b9\u5f0f\uff0c\u6709 nearest / linear / cubic fill_value \uff1a\u8bbe\u7f6e\u5916\u503c\uff0c\u9ed8\u8ba4 non\uff0c\u5bf9 nearest \u4e0d\u8d77\u4f5c\u7528","title":"Scipy"},{"location":"Python/Scipy/#scipy","text":"","title":"Scipy"},{"location":"Python/Scipy/#_1","text":"","title":"\u63d2\u503c"},{"location":"Python/Scipy/#griddata","text":"from scipy.interpolate import griddata grid_x , grid_y = np . mgrid [ 0 : 1 : 100 j , 0 : 1 : 100 j ] grid = griddata ( points , values , ( grid_x , grid_y ), method = 'linear' , fill_value = nan ) \u5982\u679c\u662f\u5728\u4e8c\u7ef4\u4e0a\u4f5c\u56fe\uff08 (X,Y) -> Z \uff09\uff0cpoint \u7684\u7ef4\u6570\u662f [data_size, 2]\uff0cvalues \u662f [1, data_size] method \uff1a\u8868\u793a\u63d2\u503c\u65b9\u5f0f\uff0c\u6709 nearest / linear / cubic fill_value \uff1a\u8bbe\u7f6e\u5916\u503c\uff0c\u9ed8\u8ba4 non\uff0c\u5bf9 nearest \u4e0d\u8d77\u4f5c\u7528","title":"griddata"},{"location":"Python/Streamlit/","text":"Streamlit \u00b6 \u4ec5\u8bb0\u5f55\u4e00\u4e9b\u7528\u5230\u4e86\u7684 import streamlit as st st . set_page_config ( layout = \"wide\" , page_icon = \":shark:\" ) # \u5bbd\u5c4f\u6a21\u5f0f\uff0c\u56fe\u6807\u9ca8\u9c7c st . markdown ( \"...\" ) # \u8f93\u51famd st . text_input ( \"...\" ) # \u8f93\u5165\u6587\u5b57 st . number_input ( \"...\" ) # \u8f93\u5165\u6570\u5b57 st . table ( df ) # \u4e5f\u53ef\u4ee5\u76f4\u63a5 df st . button ( \"...\" ) # \u8fd4\u56de bool st . write ( \"...\" ) # \u8f93\u51fa st . selectbox ( \"...\" , ( \"-\" , \"...\" )) # \u9009\u62e9\u6846 st . st . sidebar . selectbox ( \"...\" ) # \u4fa7\u8fb9\u680f siderbar.\u5176\u4ed6API \u53c2\u8003 \u00b6 Python\uff1a\u4f7f\u7528Streamlit\u5feb\u901f\u642d\u5efa\u6570\u636e\u79d1\u5b66Web App_\u5fd7\u6d69\u540c\u5b66\u7684\u535a\u5ba2-CSDN\u535a\u5ba2_python streamlit","title":"Streamlit"},{"location":"Python/Streamlit/#streamlit","text":"\u4ec5\u8bb0\u5f55\u4e00\u4e9b\u7528\u5230\u4e86\u7684 import streamlit as st st . set_page_config ( layout = \"wide\" , page_icon = \":shark:\" ) # \u5bbd\u5c4f\u6a21\u5f0f\uff0c\u56fe\u6807\u9ca8\u9c7c st . markdown ( \"...\" ) # \u8f93\u51famd st . text_input ( \"...\" ) # \u8f93\u5165\u6587\u5b57 st . number_input ( \"...\" ) # \u8f93\u5165\u6570\u5b57 st . table ( df ) # \u4e5f\u53ef\u4ee5\u76f4\u63a5 df st . button ( \"...\" ) # \u8fd4\u56de bool st . write ( \"...\" ) # \u8f93\u51fa st . selectbox ( \"...\" , ( \"-\" , \"...\" )) # \u9009\u62e9\u6846 st . st . sidebar . selectbox ( \"...\" ) # \u4fa7\u8fb9\u680f siderbar.\u5176\u4ed6API","title":"Streamlit"},{"location":"Python/Streamlit/#_1","text":"Python\uff1a\u4f7f\u7528Streamlit\u5feb\u901f\u642d\u5efa\u6570\u636e\u79d1\u5b66Web App_\u5fd7\u6d69\u540c\u5b66\u7684\u535a\u5ba2-CSDN\u535a\u5ba2_python streamlit","title":"\u53c2\u8003"},{"location":"Python/%E8%AF%B4%E6%98%8E/","text":"\u8bf4\u660e \u00b6 Python\u5b66\u4e60\u4e2d\u7684\u7b14\u8bb0","title":"\u8bf4\u660e"},{"location":"Python/%E8%AF%B4%E6%98%8E/#_1","text":"Python\u5b66\u4e60\u4e2d\u7684\u7b14\u8bb0","title":"\u8bf4\u660e"},{"location":"%E5%85%B6%E4%BB%96/Markdown/","text":"Markdown \u00b6 \u4e00\u79cd\u65b9\u4fbf\u7b80\u5355\u7684\u6392\u7248\u8bed\u8a00 \u4e0d\u540c\u7684\u5e73\u53f0\u4f7f\u7528 Markdow \u89c4\u5219\u53ef\u80fd\u6709\u4e9b\u8bb8\u4e0d\u540c\uff0c\u6bd4\u5982\u6807\u9898 # \u540e\u9762\u53ef\u80fd\u4e0d\u9700\u8981\u52a0\u7a7a\u683c\uff0c\u672c\u6587\u4e3b\u8981\u57fa\u4e8e typora \u57fa\u672c\u8bed\u6cd5 \u00b6 \u6807\u9898 \u00b6 \u4e00\u7ea7\u6807\u9898 # + \u7a7a\u683c \u4e8c\u7ea7\u6807\u9898 ## + \u7a7a\u683c ...\u6700\u591a\u6709\u516d\u7ea7\u6807\u9898 # Markdown ## \u57fa\u672c\u8bed\u6cd5 \u5f15\u7528 \u00b6 > + \u7a7a\u683c \u8fd9\u662f\u4e00\u4e2a\u4f8b\u5b50 \u5f15\u7528\u53ef\u4ee5\u5d4c\u5957 \u4f8b\u5b50 \u5d4c\u5957 \u5f3a\u8c03 \u00b6 * \u548c _ \u90fd\u53ef\u4ee5\u8868\u793a\u5f3a\u8c03 \u4f7f\u7528\u65b9\u5f0f\uff1a\u5728\u9700\u8981\u5f3a\u8c03\u7684\u90e8\u5206\u7684\u5934\u548c\u5c3e\u90fd\u8981\u52a0 \u4e00\u4e2a * \u6216\u8005 _ \u8868\u793a \u503e\u659c \u4e24\u4e2a * \u6216\u8005 _ \u8868\u793a \u52a0\u7c97 \u4e09\u4e2a * \u6216\u8005 _ \u8868\u793a \u52a0\u7c97\uff0b\u503e\u659c `\u53ef\u4ee5\u7528\u4e8e\u5f3a\u8c03\u4e00\u4e9b\u5b57\u7b26\uff0c\u8bed\u6cd5\u5982\u4e0b\uff1a `+` \u6548\u679c\uff1a + \u5217\u8868 \u00b6 * + \u7a7a\u683c \u6216\u8005 + + \u7a7a\u683c \u8fd9\u662f\u4e00\u4e2a\u4f8b\u5b50 \u8fd9\u662f\u4e00\u4e2a\u4f8b\u5b50 \u5728\u4e00\u4e2a\u5217\u8868\u4e0b\u6309 tab \u4f1a\u53d8\u6210\u4e8c\u7ea7\u5217\u8868 \u8fd9\u662f\u4e00\u7ea7\u5217\u8868 \u8fd9\u662f\u4e8c\u7ea7\u5217\u8868 \u4ee3\u7801\u5757 \u00b6 ``` + \u8bed\u8a00(\u6bd4\u5982C++) + \u56de\u8f66 \u6548\u679c\u5982\u4e0b: #include <iostream> using namespace std ; int main () { cout << \"hello, world.\" return 0 ; } \u5206\u5272\u7ebf \u00b6 \u4e09\u4e2a\u6216\u8005\u66f4\u591a\u7684 + \u6216 _ \u6216 - + \u56de\u8f66 \u6548\u679c\uff1a \u8d85\u94fe\u63a5\u4e0e\u56fe\u7247 \u00b6 \u884c\u5185\u5f0f \u683c\u5f0f\uff1a[\u540d\u5b57] (URL) [ \u767e\u5ea6 ]( https://www.baidu.com/ ) \u6548\u679c\u5982\u4e0b\uff1a \u767e\u5ea6 \u53c2\u8003\u5f0f \u5728\u8981\u591a\u6b21\u4f7f\u7528\u540c\u4e00\u4e2a\u8d85\u94fe\u63a5\u65f6\u4f7f\u7528 \u683c\u5f0f\uff1a[\u7ed9\u7f51\u7ad9\u8d77\u7684\u540d\u5b57]\uff1aURL \uff08\u76f8\u5f53\u4e8e\u5b9a\u4e49\uff09 \u4f7f\u7528\u65b9\u5f0f\uff1a[\u8d85\u94fe\u63a5\u7684\u540d\u5b57] [\u7ed9\u7f51\u7ad9\u8d77\u7684\u540d\u5b57] [ \u767e\u5ea6 ]: https://www.baidu.com/ [ here ][ \u767e\u5ea6 ] \u56fe\u7247 \u4e5f\u6709\u884c\u5185\u5f0f\u4e0e\u53c2\u8003\u5f0f\uff0c\u9700\u8981\u5728\u524d\u9762\u52a0\u4e2a ! ![\u56fe\u7247\u540d][\u5177\u4f53\u5730\u5740\uff0c\u672c\u5730\u6216\u8005\u7f51\u9875] \u6570\u5b66\u516c\u5f0f \u00b6 1.\u5185\u8054\u5f0f typora\u4e2d \u6587\u4ef6-\u504f\u597d\u8bbe\u7f6e-markdown-\u6253\u5f00\u5185\u8054\u516c\u5f0f $\u516c\u5f0f\u5185\u5bb9$ 2.\u975e\u5185\u8054\u5f0f \u6dfb\u52a0\u6570\u5b66\u516c\u5f0f\uff1a $$ \u516c\u5f0f\u5185\u5bb9 $$ \u5e38\u7528\u7b26\u53f7 \u8fd9\u91cc\u4ec5\u5217\u51fa\u4e00\u4e9b\u5e38\u7528\u7684\uff0c\u5177\u4f53\u8bf7\u770b\u53c2\u8003 \u7b26\u53f7 \u6548\u679c \u8868\u793a\u65b9\u5f0f \u4e0a\u4e0b\u6807 \\(x^2\\) x^2 x_2 \u5206\u5f0f \\(\\frac{1}{2}\\) \\frac{1}{2} \u6839\u53f7 \\(\\sqrt{2}\\) \\sqrt{2} \u77e2\u91cf \\(\\vec{a}\\) \\vec{a} \u4e0d\u5b9a\u79ef\u5206 \\(\\int{x}dx\\) \\int{x}dx \u5b9a\u79ef\u5206 \\(\\int_{1}^{2}{x}dx\\) \\int_{1}^{2}{x}dx \u7a7a\u683c \\quad \u6781\u9650 \\(\\lim{a+b}\\) \\lim{a+b} \\(\\lim_{n\\rightarrow+\\infty}\\) \\lim_{n\\rightarrow+\\infty} \\(\\lim_{n\\rightarrow+\\infty}{a+b}\\) \\lim_{n\\rightarrow+\\infty}{a+b} \u7d2f\u52a0 \\(\\sum{a}\\) \\sum{a} \\(\\sum_{i=1}^{n}{a_i}\\) \\sum_{i=1}^{n}{a_i} \u7d2f\u4e58 \\(\\prod{x}\\) \\prod{x} \\(\\prod_{i=1}^{n}{x_i}\\) \\prod_{i=1}^{n}{x_i} \u5bf9\u6570\u51fd\u6570 \\(\\ln2\\) \\ln2 \\(\\log_{11}{121}\\) \\log_{11}{121} \\(\\lg10\\) \\lg10 \u52a0\u51cf \\(\\pm\\) \\pm \u53c9\u4e58 \\(\\times\\) \\times \u70b9\u4e58 \\(\\cdot\\) \\cdot \u9664\u6cd5 \\(\u00f7\\) \\div \u4e0d\u7b49 \\(\\neq\\) \\neq \u6052\u7b49 \\(\\equiv\\) \\equiv \u5c0f\u4e8e\u7b49\u4e8e \\(\\leq\\) \\leq \u5927\u4e8e\u7b49\u4e8e \\(\\geq\\) \\geq \u7ea6\u7b49\u4e8e \\(\\approx\\) \\approx \u56e0\u4e3a \\(\\because\\) \\because \u6240\u4ee5 \\(\\therefore\\) \\therefore \u5408\u53d6 \\(\\wedge\\) \\wedge \u6790\u53d6 \\(\\vee\\) \\vee \u8574\u542b \\(\\Rightarrow\\) \\Rightarrow \u975e \\(\\urcorner\\) \\urcorner \u5927\u62ec\u53f7 \\[ y = \\begin{cases} 1 &x\\geq 0 \\\\ 0 &x<0 \\end{cases} \\] y = \\begin{cases} 1 &x\\geq 0 \\\\ 0 &x<0 \\end{cases} \u77e9\u9635 \\[ \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix} \\] \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix} \u8868\u683c\u5143\u7d20 \u00b6 typora \u4e2d\u4f7f\u7528\u5feb\u6377\u952e Ctrl+T name|score ----|---- abcd|100 defg|0 name score abcd 100 defg 0 \u6298\u53e0\u4ee3\u7801\u548c\u4fa7\u8fb9\u680f \u00b6 typora\u4e2d\u6298\u53e0\u4fa7\u8fb9\u680f\uff1a\u6587\u4ef6-\u504f\u597d\u8bbe\u7f6e-\u5916\u89c2-\u4fa7\u8fb9\u680f \u6298\u53e0\u4ee3\u7801\uff1a <details> <summary>tag</summary> <code> Hello world! </code> </details> \u6548\u679c\u5982\u4e0b\uff1a tag Hello world! \u5bfc\u51fa\u5176\u4ed6\u683c\u5f0f \u00b6 typora \u4e2d\u53ef\u4ee5\u76f4\u63a5\u70b9\u51fb \u6587\u4ef6-\u5bfc\u51fa \u5e76\u9009\u62e9\u6587\u4ef6\u683c\u5f0f\u5373\u53ef \u5bfc\u51fa\u4e3a word \u4e4b\u524d\u9700\u8981\u4e0b\u8f7d pandoc\uff0c\u5177\u4f53\u53ef\u4ee5\u53c2\u8003\u7f51\u4e0a\u535a\u5ba2 \u53c2\u8003 \u00b6 Introduction | Learning-Markdown (Markdown \u5165\u95e8\u53c2\u8003) Supported Functions \u00b7 KaTeX Mathjax\u516c\u5f0f\u6559\u7a0b_dabokele\u7684\u535a\u5ba2-CSDN\u535a\u5ba2_mathjax\u516c\u5f0f","title":"Markdown"},{"location":"%E5%85%B6%E4%BB%96/Markdown/#markdown","text":"\u4e00\u79cd\u65b9\u4fbf\u7b80\u5355\u7684\u6392\u7248\u8bed\u8a00 \u4e0d\u540c\u7684\u5e73\u53f0\u4f7f\u7528 Markdow \u89c4\u5219\u53ef\u80fd\u6709\u4e9b\u8bb8\u4e0d\u540c\uff0c\u6bd4\u5982\u6807\u9898 # \u540e\u9762\u53ef\u80fd\u4e0d\u9700\u8981\u52a0\u7a7a\u683c\uff0c\u672c\u6587\u4e3b\u8981\u57fa\u4e8e typora","title":"Markdown"},{"location":"%E5%85%B6%E4%BB%96/Markdown/#_1","text":"","title":"\u57fa\u672c\u8bed\u6cd5"},{"location":"%E5%85%B6%E4%BB%96/Markdown/#_2","text":"\u4e00\u7ea7\u6807\u9898 # + \u7a7a\u683c \u4e8c\u7ea7\u6807\u9898 ## + \u7a7a\u683c ...\u6700\u591a\u6709\u516d\u7ea7\u6807\u9898 # Markdown ## \u57fa\u672c\u8bed\u6cd5","title":"\u6807\u9898"},{"location":"%E5%85%B6%E4%BB%96/Markdown/#_3","text":"> + \u7a7a\u683c \u8fd9\u662f\u4e00\u4e2a\u4f8b\u5b50 \u5f15\u7528\u53ef\u4ee5\u5d4c\u5957 \u4f8b\u5b50 \u5d4c\u5957","title":"\u5f15\u7528"},{"location":"%E5%85%B6%E4%BB%96/Markdown/#_4","text":"* \u548c _ \u90fd\u53ef\u4ee5\u8868\u793a\u5f3a\u8c03 \u4f7f\u7528\u65b9\u5f0f\uff1a\u5728\u9700\u8981\u5f3a\u8c03\u7684\u90e8\u5206\u7684\u5934\u548c\u5c3e\u90fd\u8981\u52a0 \u4e00\u4e2a * \u6216\u8005 _ \u8868\u793a \u503e\u659c \u4e24\u4e2a * \u6216\u8005 _ \u8868\u793a \u52a0\u7c97 \u4e09\u4e2a * \u6216\u8005 _ \u8868\u793a \u52a0\u7c97\uff0b\u503e\u659c `\u53ef\u4ee5\u7528\u4e8e\u5f3a\u8c03\u4e00\u4e9b\u5b57\u7b26\uff0c\u8bed\u6cd5\u5982\u4e0b\uff1a `+` \u6548\u679c\uff1a +","title":"\u5f3a\u8c03"},{"location":"%E5%85%B6%E4%BB%96/Markdown/#_5","text":"* + \u7a7a\u683c \u6216\u8005 + + \u7a7a\u683c \u8fd9\u662f\u4e00\u4e2a\u4f8b\u5b50 \u8fd9\u662f\u4e00\u4e2a\u4f8b\u5b50 \u5728\u4e00\u4e2a\u5217\u8868\u4e0b\u6309 tab \u4f1a\u53d8\u6210\u4e8c\u7ea7\u5217\u8868 \u8fd9\u662f\u4e00\u7ea7\u5217\u8868 \u8fd9\u662f\u4e8c\u7ea7\u5217\u8868","title":"\u5217\u8868"},{"location":"%E5%85%B6%E4%BB%96/Markdown/#_6","text":"``` + \u8bed\u8a00(\u6bd4\u5982C++) + \u56de\u8f66 \u6548\u679c\u5982\u4e0b: #include <iostream> using namespace std ; int main () { cout << \"hello, world.\" return 0 ; }","title":"\u4ee3\u7801\u5757"},{"location":"%E5%85%B6%E4%BB%96/Markdown/#_7","text":"\u4e09\u4e2a\u6216\u8005\u66f4\u591a\u7684 + \u6216 _ \u6216 - + \u56de\u8f66 \u6548\u679c\uff1a","title":"\u5206\u5272\u7ebf"},{"location":"%E5%85%B6%E4%BB%96/Markdown/#_8","text":"\u884c\u5185\u5f0f \u683c\u5f0f\uff1a[\u540d\u5b57] (URL) [ \u767e\u5ea6 ]( https://www.baidu.com/ ) \u6548\u679c\u5982\u4e0b\uff1a \u767e\u5ea6 \u53c2\u8003\u5f0f \u5728\u8981\u591a\u6b21\u4f7f\u7528\u540c\u4e00\u4e2a\u8d85\u94fe\u63a5\u65f6\u4f7f\u7528 \u683c\u5f0f\uff1a[\u7ed9\u7f51\u7ad9\u8d77\u7684\u540d\u5b57]\uff1aURL \uff08\u76f8\u5f53\u4e8e\u5b9a\u4e49\uff09 \u4f7f\u7528\u65b9\u5f0f\uff1a[\u8d85\u94fe\u63a5\u7684\u540d\u5b57] [\u7ed9\u7f51\u7ad9\u8d77\u7684\u540d\u5b57] [ \u767e\u5ea6 ]: https://www.baidu.com/ [ here ][ \u767e\u5ea6 ] \u56fe\u7247 \u4e5f\u6709\u884c\u5185\u5f0f\u4e0e\u53c2\u8003\u5f0f\uff0c\u9700\u8981\u5728\u524d\u9762\u52a0\u4e2a ! ![\u56fe\u7247\u540d][\u5177\u4f53\u5730\u5740\uff0c\u672c\u5730\u6216\u8005\u7f51\u9875]","title":"\u8d85\u94fe\u63a5\u4e0e\u56fe\u7247"},{"location":"%E5%85%B6%E4%BB%96/Markdown/#_9","text":"1.\u5185\u8054\u5f0f typora\u4e2d \u6587\u4ef6-\u504f\u597d\u8bbe\u7f6e-markdown-\u6253\u5f00\u5185\u8054\u516c\u5f0f $\u516c\u5f0f\u5185\u5bb9$ 2.\u975e\u5185\u8054\u5f0f \u6dfb\u52a0\u6570\u5b66\u516c\u5f0f\uff1a $$ \u516c\u5f0f\u5185\u5bb9 $$ \u5e38\u7528\u7b26\u53f7 \u8fd9\u91cc\u4ec5\u5217\u51fa\u4e00\u4e9b\u5e38\u7528\u7684\uff0c\u5177\u4f53\u8bf7\u770b\u53c2\u8003 \u7b26\u53f7 \u6548\u679c \u8868\u793a\u65b9\u5f0f \u4e0a\u4e0b\u6807 \\(x^2\\) x^2 x_2 \u5206\u5f0f \\(\\frac{1}{2}\\) \\frac{1}{2} \u6839\u53f7 \\(\\sqrt{2}\\) \\sqrt{2} \u77e2\u91cf \\(\\vec{a}\\) \\vec{a} \u4e0d\u5b9a\u79ef\u5206 \\(\\int{x}dx\\) \\int{x}dx \u5b9a\u79ef\u5206 \\(\\int_{1}^{2}{x}dx\\) \\int_{1}^{2}{x}dx \u7a7a\u683c \\quad \u6781\u9650 \\(\\lim{a+b}\\) \\lim{a+b} \\(\\lim_{n\\rightarrow+\\infty}\\) \\lim_{n\\rightarrow+\\infty} \\(\\lim_{n\\rightarrow+\\infty}{a+b}\\) \\lim_{n\\rightarrow+\\infty}{a+b} \u7d2f\u52a0 \\(\\sum{a}\\) \\sum{a} \\(\\sum_{i=1}^{n}{a_i}\\) \\sum_{i=1}^{n}{a_i} \u7d2f\u4e58 \\(\\prod{x}\\) \\prod{x} \\(\\prod_{i=1}^{n}{x_i}\\) \\prod_{i=1}^{n}{x_i} \u5bf9\u6570\u51fd\u6570 \\(\\ln2\\) \\ln2 \\(\\log_{11}{121}\\) \\log_{11}{121} \\(\\lg10\\) \\lg10 \u52a0\u51cf \\(\\pm\\) \\pm \u53c9\u4e58 \\(\\times\\) \\times \u70b9\u4e58 \\(\\cdot\\) \\cdot \u9664\u6cd5 \\(\u00f7\\) \\div \u4e0d\u7b49 \\(\\neq\\) \\neq \u6052\u7b49 \\(\\equiv\\) \\equiv \u5c0f\u4e8e\u7b49\u4e8e \\(\\leq\\) \\leq \u5927\u4e8e\u7b49\u4e8e \\(\\geq\\) \\geq \u7ea6\u7b49\u4e8e \\(\\approx\\) \\approx \u56e0\u4e3a \\(\\because\\) \\because \u6240\u4ee5 \\(\\therefore\\) \\therefore \u5408\u53d6 \\(\\wedge\\) \\wedge \u6790\u53d6 \\(\\vee\\) \\vee \u8574\u542b \\(\\Rightarrow\\) \\Rightarrow \u975e \\(\\urcorner\\) \\urcorner \u5927\u62ec\u53f7 \\[ y = \\begin{cases} 1 &x\\geq 0 \\\\ 0 &x<0 \\end{cases} \\] y = \\begin{cases} 1 &x\\geq 0 \\\\ 0 &x<0 \\end{cases} \u77e9\u9635 \\[ \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix} \\] \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix}","title":"\u6570\u5b66\u516c\u5f0f"},{"location":"%E5%85%B6%E4%BB%96/Markdown/#_10","text":"typora \u4e2d\u4f7f\u7528\u5feb\u6377\u952e Ctrl+T name|score ----|---- abcd|100 defg|0 name score abcd 100 defg 0","title":"\u8868\u683c\u5143\u7d20"},{"location":"%E5%85%B6%E4%BB%96/Markdown/#_11","text":"typora\u4e2d\u6298\u53e0\u4fa7\u8fb9\u680f\uff1a\u6587\u4ef6-\u504f\u597d\u8bbe\u7f6e-\u5916\u89c2-\u4fa7\u8fb9\u680f \u6298\u53e0\u4ee3\u7801\uff1a <details> <summary>tag</summary> <code> Hello world! </code> </details> \u6548\u679c\u5982\u4e0b\uff1a tag Hello world!","title":"\u6298\u53e0\u4ee3\u7801\u548c\u4fa7\u8fb9\u680f"},{"location":"%E5%85%B6%E4%BB%96/Markdown/#_12","text":"typora \u4e2d\u53ef\u4ee5\u76f4\u63a5\u70b9\u51fb \u6587\u4ef6-\u5bfc\u51fa \u5e76\u9009\u62e9\u6587\u4ef6\u683c\u5f0f\u5373\u53ef \u5bfc\u51fa\u4e3a word \u4e4b\u524d\u9700\u8981\u4e0b\u8f7d pandoc\uff0c\u5177\u4f53\u53ef\u4ee5\u53c2\u8003\u7f51\u4e0a\u535a\u5ba2","title":"\u5bfc\u51fa\u5176\u4ed6\u683c\u5f0f"},{"location":"%E5%85%B6%E4%BB%96/Markdown/#_13","text":"Introduction | Learning-Markdown (Markdown \u5165\u95e8\u53c2\u8003) Supported Functions \u00b7 KaTeX Mathjax\u516c\u5f0f\u6559\u7a0b_dabokele\u7684\u535a\u5ba2-CSDN\u535a\u5ba2_mathjax\u516c\u5f0f","title":"\u53c2\u8003"},{"location":"%E5%85%B6%E4%BB%96/Mkdocs/","text":"\u57fa\u4e8eMaterial for MkDocs\u642d\u5efa\u9759\u6001\u6587\u6863 \u00b6 Mkdocs \u53ef\u4ee5\u5341\u5206\u65b9\u4fbf\u7684\u5efa\u7acb\u4e00\u4e2a\u9759\u6001\u6587\u6863\uff0c\u6bd4\u5982 OI Wiki \uff0c\u6b64\u6587\u6863\u4e5f\u662f\u57fa\u4e8e Mkdocs \u6b64\u6587\u6863\u5185\u5bb9\u4ec5\u662f\u57fa\u4e8e\u4e2a\u4eba\u7ecf\u5386\u7684\u7406\u89e3 \u53ef\u80fd\u9700\u8981\u7684\u7528\u5230\u7684\u5de5\u5177\uff1a Markdown \uff0c python3 \u5b89\u88c5/\u521d\u59cb\u5316/\u914d\u7f6e\u8303\u4f8b \u00b6 \u5b89\u88c5 \u00b6 \u5229\u7528 python3 \u81ea\u5e26\u7684 pip \u5de5\u5177\u5728 cmd \u4e2d\u8f93\u5165 pip install mkdocs mkdocs-material \u5982\u679c\u540e\u9762\u63d0\u793a 'mkdocs' \u4e0d\u662f\u5185\u90e8\u6216\u5916\u90e8\u547d\u4ee4.... \u7684\u8bdd\u5c31\u9700\u8981\u81ea\u5df1\u52a0\u4e00\u4e0b\u73af\u5883\u53d8\u91cf\uff0c\u6b64\u5904\u4e0d\u5c55\u5f00\u8bf4\u660e \u521d\u59cb\u5316 \u00b6 \u5728\u4f60\u60f3\u8981\u65b0\u5efa\u6587\u6863\u7684\u76ee\u5f55\u542f\u52a8 cmd\uff0c\u5e76\u8f93\u5165\u4ee5\u4e0b\u547d\u4ee4 mkdocs new my-project \u7136\u540e\u6253\u5f00\u65b0\u5efa\u7684\u6587\u4ef6\u5939\u6253\u5f00 mkdocs.yml \uff0c\u4ee5\u4e0b\u5217\u51fa\u6211\u5199\u6b64\u6587\u6863\u65f6\u7684\u914d\u7f6e\u5e76\u914d\u4e0a\u4e86\u6ce8\u91ca\u4f5c\u4e3a\u53c2\u8003 # site site_name: hucorz's Docs # \u6587\u6863\u7684\u540d\u5b57\uff0c\u4f1a\u4f53\u73b0\u5728\u5de6\u4e0a\u89d2 site_url: https://hucorz.github.io/myDoc/ # \u7f51\u7ad9\u7684\u94fe\u63a5\uff0c\u4f3c\u4e4e\u70b9\u51fb\u5de6\u4e0a\u89d2\u7684logo\u540e\u4f1a\u8fdb\u53bb\uff0c\u6211\u4e5f\u6ca1\u505a\u5b9e\u9a8c # repo repo_name: 'hucorz/myDoc' # github\u4ed3\u5e93\u7684\u540d\u5b57\uff0c\u4f1a\u4f53\u73b0\u5728\u53f3\u4e0a\u89d2 repo_url: https://github.com/hucorz/myDoc # github\u4ed3\u5e93\u7684\u94fe\u63a5\uff0c\u70b9\u51fb\u53f3\u4e0a\u89d2\u7684logo\u540e\u4f1a\u8fdb\u53bb nav: # \u5bfc\u822a\u9875\uff0c\u5177\u4f53\u5185\u5bb9\u8981\u57fa\u4e8e\u81ea\u5df1\u6587\u6863\u7684\u5185\u5bb9 - Home: 'index.md' # : \u540e\u9762\u662f\u6587\u4ef6\u7684\u540d\u5b57\uff0c\u524d\u9762\u662f\u6587\u6863\u4e2d\u663e\u793a\u7684\u540d\u5b57\uff0c\u53ef\u4ee5\u5d4c\u5957 - Makrdown: 'Markdown.md' - OI: - \u53c2\u8003: 'OI/\u53c2\u8003.md' - \u6570\u8bba: 'OI/\u6570\u8bba.md' - \u8ba1\u7b97\u51e0\u4f55: 'OI/\u8ba1\u7b97\u51e0\u4f55.md' - \u56fe\u8bba: 'OI/\u56fe\u8bba.md' - \u6570\u636e\u7ed3\u6784: 'OI/\u6570\u636e\u7ed3\u6784.md' - \u5b57\u7b26\u4e32: 'OI/\u5b57\u7b26\u4e32.md' - \u5176\u4ed6: 'OI/\u5176\u4ed6.md' - STL: 'OI/STL.md' - \u8bfe\u7a0b\u7b14\u8bb0: - \u53c2\u8003: '\u8bfe\u7a0b\u7b14\u8bb0/\u53c2\u8003.md' - \u6570\u636e\u5e93\u7cfb\u7edf: '\u8bfe\u7a0b\u7b14\u8bb0/\u6570\u636e\u5e93\u7cfb\u7edf.md' theme: name: 'material' # \u4e3b\u9898\uff0c\u5c31\u7528 material features: # \u8fd9\u540e\u9762\u662f\u4e3b\u9898\u7684\u914d\u7f6e\uff0c\u5177\u4f53\u6211\u4f1a\u5199\u5728\u6587\u6863\u540e\u9762 - navigation.tabs - navigation.tabs.sticky palette: primary: 'white' # \u914d\u8272 accent: 'indigo' logo: 'img/cat-solid.svg' # \u5de6\u4e0a\u89d2logo icon: repo: fontawesome/brands/github-alt # repo\u7684logo favicon: 'img/favicon.ico' #\u7f51\u9875\u56fe\u6807 markdown_extensions: - pymdownx.arithmatex: generic: true - pymdownx.emoji: emoji_index: !!python/name:materialx.emoji.twemoji emoji_generator: !!python/name:materialx.emoji.to_svg - pymdownx.highlight # \u4ee3\u7801\u9ad8\u4eae - pymdownx.superfences - toc: permalink: true # \u6bcf\u4e2a\u6807\u9898\u540e\u9762\u7684 \u951a\u94fe\u63a5 #toc_depth: 2 # table of content \u663e\u793a\u7684\u7ea7\u6570\uff0c0\u5c31\u4e0d\u4f1a\u663e\u793a extra_javascript: - javascripts/config.js - https://polyfill.io/v3/polyfill.min.js?features=es6 - https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js plugins: - search: lang: ja # \u5b9e\u6d4b\u641c\u7d22\u8bed\u8a00\u6539\u6210\u65e5\u672c\u53ef\u4ee5\u652f\u6301\u4e2d\u6587\u641c\u641c \u90e8\u7f72 github \u00b6 \u8fd9\u91cc\u7684\u6b65\u9aa4\u53ef\u80fd\u9700\u8981\u79d1\u5b66\u4e0a\u7f51\uff0c\u4e0d\u8fc7 github \u6709\u65f6\u5019\u4e5f\u4e0d\u9700\u8981 \u9996\u5148\u9700\u8981\u4e00\u4e2a github \u8d26\u53f7\uff0c\u7136\u540e\u65b0\u5efa\u4e00\u4e2a\u7a7a\u4ed3\u5e93\uff0c\u5e76\u5229\u7528 git \u5c06\u4ed3\u5e93 clone \u5230\u672c\u5730\uff0c\u8fd9\u91cc\u4e0d\u5c55\u5f00\uff0c\u56e0\u4e3a\u672c\u849f\u84bb\u4e5f\u4e0d\u662f\u5f88\u61c2\uff0c\u7f51\u4e0a\u7684\u535a\u5ba2\u8fd8\u662f\u5f88\u591a \u4ec5\u8bb2\u4e00\u4e0b\u6211\u9047\u5230\u7684\u95ee\u9898\uff1a Failed to connect to github.com port 443: Timed out \u89e3\u51b3\u65b9\u6cd5\uff1a\u7ed9 git \u8bbe\u7f6e\u4ee3\u7406 \u79d1\u5b66\u4e0a\u7f51\u65f6\u6253\u5f00 win10 \u8bbe\u7f6e\u91cc\u7684\u4ee3\u7406\u8bbe\u7f6e\uff0c\u627e\u5230\u4ee3\u7406\u7684\u5730\u5740\u548c\u7aef\u53e3 git config --global http.proxy 172.17.18.80:8080 # \u540e\u9762\u662f \u5730\u5740:\u7aef\u53e3 \u67e5\u770b\u662f\u5426\u6210\u529f git config --get http.proxy \u514b\u9686\u6210\u529f\u540e\u628a .yml \u548c docs \u653e\u5728\u514b\u9686\u6587\u4ef6\u5939\u91cc\uff0c\u7136\u540e\u5728\u6b64\u6587\u4ef6\u5939\u542f\u52a8 cmd\uff0c\u8f93\u5165\u4ee5\u4e0b\u6307\u4ee4\u5373\u53ef\u90e8\u7f72 mkdocs gh-deploy \u7f8e\u5316\u914d\u7f6e \u00b6 \u5b98\u65b9\u6587\u6863 \u6587\u6863\u540d\u79f0 \u00b6 site_name: hucorz's Docs site_url: https://hucorz.github.io/myDoc/ \u6587\u6863\u4e3b\u9898 \u00b6 theme: name: 'material' \u914d\u8272 \u00b6 \u914d\u8272\u76f8\u5173\u914d\u7f6e theme: palette: primary: 'white' accent: 'indigo' \u5bfc\u822a\u9875 \u00b6 \u5bfc\u822a\u9875\u76f8\u5173\u914d\u7f6e features: - navigation.tabs - navigation.tabs.sticky logo && favicon \u00b6 \u6587\u6863\u7684 logo && favicon \u00b6 logo && favicon \u76f8\u5173\u914d\u7f6e theme: # \u8fd9\u4e24\u4e2a\u6211\u90fd\u662f\u4e0b\u4e0b\u6765\u540e\u7528\u7684 logo: 'img/cat-solid.svg' favicon: 'img/favicon.ico' repo \u7684 logo \u00b6 repo \u76f8\u5173\u914d\u7f6e \u4f60\u9700\u8981\u5148\u5728\u914d\u7f6e\u4e2d\u6dfb\u52a0 repo \u7684\u540d\u5b57\u548c url repo_name: 'hucorz/myDoc' repo_url: https://github.com/hucorz/myDoc \u7136\u540e logo \u53c2\u8003\u7684\u5b98\u65b9\u6587\u6863\uff1a theme: icon: repo: fontawesome/brands/github-alt \u6269\u5c55 \u00b6 markdown\u6269\u5c55 \u00b6 \u6570\u5b66\u516c\u5f0f MathJax - Material for MkDocs \u503c\u5f97\u5410\u69fd\u7684\u662f\u6211\u89c9\u5f97 Material for MkDocs \u5bf9\u6570\u5b66\u516c\u5f0f\u7684\u652f\u6301\u5f88\u70c2\uff0c\u5f88\u591a\u4e1c\u897f\u90fd\u4e0d\u80fd\u6b63\u5e38\u663e\u793a \u5982\u679c\u9047\u5230\u6bd4\u5982\u5927\u62ec\u53f7\uff0c\u77e9\u9635\u6324\u5728\u4e00\u884c\u53ef\u4ee5\u5c1d\u8bd5 $$ \u4e4b\u524d\u52a0\u4e00\u4e2a\u56de\u8f66\uff08\u5373\u548c\u4e0a\u9762\u7684\u4e1c\u897f\u7a7a\u4e00\u884c\uff09 markdown_extensions: - pymdownx.arithmatex: generic: true extra_javascript: - javascripts/config.js - https://polyfill.io/v3/polyfill.min.js?features=es6 - https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js \u4ee3\u7801\u9ad8\u4eae Code blocks - Material for MkDocs markdown_extensions: - pymdownx.highlight # code hilight - pymdownx.superfences toc\uff08table of content\uff09 Setting up navigation - Material for MkDocs markdown_extensions: # \u8fd92\u4e2a\u90fd\u662f\u548c\u6bcf\u4e2amarkdown\u6587\u6863\u7684\u6807\u9898\u6709\u5173 - toc: permalink: true # \u5f00\u542f\u6bcf\u4e2a\u6807\u9898\u540e\u9762\u7684 \u951a\u94fe\u63a5 #toc_depth: 2 # toc\u663e\u793a\u7684\u7ea7\u6570,\u8d8a\u9ad8\u663e\u793a\u7684\u8d8a\u591a\uff0c\u4e0d\u5199\u90fd\u663e\u793a\uff0c0\u4e0d\u663e\u793a \u652f\u6301\u4e2d\u6587\u641c\u7d22 \u00b6 Setting up site search - Material for MkDocs plugins: - search: lang: ja \u53c2\u8003 \u00b6 1.\u4ecb\u7ecd - \u57fa\u4e8e Material for MkDocs \u642d\u5efa\u9759\u6001\u7f51\u9875 Material for MkDocs - Material forMkDocs Failed to connect to github.com port 443: Timed out_\u5929\u751f\u6211\u6750\u5fc5\u6709\u7528-CSDN\u535a\u5ba2","title":"Mkdocs"},{"location":"%E5%85%B6%E4%BB%96/Mkdocs/#material-for-mkdocs","text":"Mkdocs \u53ef\u4ee5\u5341\u5206\u65b9\u4fbf\u7684\u5efa\u7acb\u4e00\u4e2a\u9759\u6001\u6587\u6863\uff0c\u6bd4\u5982 OI Wiki \uff0c\u6b64\u6587\u6863\u4e5f\u662f\u57fa\u4e8e Mkdocs \u6b64\u6587\u6863\u5185\u5bb9\u4ec5\u662f\u57fa\u4e8e\u4e2a\u4eba\u7ecf\u5386\u7684\u7406\u89e3 \u53ef\u80fd\u9700\u8981\u7684\u7528\u5230\u7684\u5de5\u5177\uff1a Markdown \uff0c python3","title":"\u57fa\u4e8eMaterial for MkDocs\u642d\u5efa\u9759\u6001\u6587\u6863"},{"location":"%E5%85%B6%E4%BB%96/Mkdocs/#_1","text":"","title":"\u5b89\u88c5/\u521d\u59cb\u5316/\u914d\u7f6e\u8303\u4f8b"},{"location":"%E5%85%B6%E4%BB%96/Mkdocs/#_2","text":"\u5229\u7528 python3 \u81ea\u5e26\u7684 pip \u5de5\u5177\u5728 cmd \u4e2d\u8f93\u5165 pip install mkdocs mkdocs-material \u5982\u679c\u540e\u9762\u63d0\u793a 'mkdocs' \u4e0d\u662f\u5185\u90e8\u6216\u5916\u90e8\u547d\u4ee4.... \u7684\u8bdd\u5c31\u9700\u8981\u81ea\u5df1\u52a0\u4e00\u4e0b\u73af\u5883\u53d8\u91cf\uff0c\u6b64\u5904\u4e0d\u5c55\u5f00\u8bf4\u660e","title":"\u5b89\u88c5"},{"location":"%E5%85%B6%E4%BB%96/Mkdocs/#_3","text":"\u5728\u4f60\u60f3\u8981\u65b0\u5efa\u6587\u6863\u7684\u76ee\u5f55\u542f\u52a8 cmd\uff0c\u5e76\u8f93\u5165\u4ee5\u4e0b\u547d\u4ee4 mkdocs new my-project \u7136\u540e\u6253\u5f00\u65b0\u5efa\u7684\u6587\u4ef6\u5939\u6253\u5f00 mkdocs.yml \uff0c\u4ee5\u4e0b\u5217\u51fa\u6211\u5199\u6b64\u6587\u6863\u65f6\u7684\u914d\u7f6e\u5e76\u914d\u4e0a\u4e86\u6ce8\u91ca\u4f5c\u4e3a\u53c2\u8003 # site site_name: hucorz's Docs # \u6587\u6863\u7684\u540d\u5b57\uff0c\u4f1a\u4f53\u73b0\u5728\u5de6\u4e0a\u89d2 site_url: https://hucorz.github.io/myDoc/ # \u7f51\u7ad9\u7684\u94fe\u63a5\uff0c\u4f3c\u4e4e\u70b9\u51fb\u5de6\u4e0a\u89d2\u7684logo\u540e\u4f1a\u8fdb\u53bb\uff0c\u6211\u4e5f\u6ca1\u505a\u5b9e\u9a8c # repo repo_name: 'hucorz/myDoc' # github\u4ed3\u5e93\u7684\u540d\u5b57\uff0c\u4f1a\u4f53\u73b0\u5728\u53f3\u4e0a\u89d2 repo_url: https://github.com/hucorz/myDoc # github\u4ed3\u5e93\u7684\u94fe\u63a5\uff0c\u70b9\u51fb\u53f3\u4e0a\u89d2\u7684logo\u540e\u4f1a\u8fdb\u53bb nav: # \u5bfc\u822a\u9875\uff0c\u5177\u4f53\u5185\u5bb9\u8981\u57fa\u4e8e\u81ea\u5df1\u6587\u6863\u7684\u5185\u5bb9 - Home: 'index.md' # : \u540e\u9762\u662f\u6587\u4ef6\u7684\u540d\u5b57\uff0c\u524d\u9762\u662f\u6587\u6863\u4e2d\u663e\u793a\u7684\u540d\u5b57\uff0c\u53ef\u4ee5\u5d4c\u5957 - Makrdown: 'Markdown.md' - OI: - \u53c2\u8003: 'OI/\u53c2\u8003.md' - \u6570\u8bba: 'OI/\u6570\u8bba.md' - \u8ba1\u7b97\u51e0\u4f55: 'OI/\u8ba1\u7b97\u51e0\u4f55.md' - \u56fe\u8bba: 'OI/\u56fe\u8bba.md' - \u6570\u636e\u7ed3\u6784: 'OI/\u6570\u636e\u7ed3\u6784.md' - \u5b57\u7b26\u4e32: 'OI/\u5b57\u7b26\u4e32.md' - \u5176\u4ed6: 'OI/\u5176\u4ed6.md' - STL: 'OI/STL.md' - \u8bfe\u7a0b\u7b14\u8bb0: - \u53c2\u8003: '\u8bfe\u7a0b\u7b14\u8bb0/\u53c2\u8003.md' - \u6570\u636e\u5e93\u7cfb\u7edf: '\u8bfe\u7a0b\u7b14\u8bb0/\u6570\u636e\u5e93\u7cfb\u7edf.md' theme: name: 'material' # \u4e3b\u9898\uff0c\u5c31\u7528 material features: # \u8fd9\u540e\u9762\u662f\u4e3b\u9898\u7684\u914d\u7f6e\uff0c\u5177\u4f53\u6211\u4f1a\u5199\u5728\u6587\u6863\u540e\u9762 - navigation.tabs - navigation.tabs.sticky palette: primary: 'white' # \u914d\u8272 accent: 'indigo' logo: 'img/cat-solid.svg' # \u5de6\u4e0a\u89d2logo icon: repo: fontawesome/brands/github-alt # repo\u7684logo favicon: 'img/favicon.ico' #\u7f51\u9875\u56fe\u6807 markdown_extensions: - pymdownx.arithmatex: generic: true - pymdownx.emoji: emoji_index: !!python/name:materialx.emoji.twemoji emoji_generator: !!python/name:materialx.emoji.to_svg - pymdownx.highlight # \u4ee3\u7801\u9ad8\u4eae - pymdownx.superfences - toc: permalink: true # \u6bcf\u4e2a\u6807\u9898\u540e\u9762\u7684 \u951a\u94fe\u63a5 #toc_depth: 2 # table of content \u663e\u793a\u7684\u7ea7\u6570\uff0c0\u5c31\u4e0d\u4f1a\u663e\u793a extra_javascript: - javascripts/config.js - https://polyfill.io/v3/polyfill.min.js?features=es6 - https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js plugins: - search: lang: ja # \u5b9e\u6d4b\u641c\u7d22\u8bed\u8a00\u6539\u6210\u65e5\u672c\u53ef\u4ee5\u652f\u6301\u4e2d\u6587\u641c\u641c","title":"\u521d\u59cb\u5316"},{"location":"%E5%85%B6%E4%BB%96/Mkdocs/#github","text":"\u8fd9\u91cc\u7684\u6b65\u9aa4\u53ef\u80fd\u9700\u8981\u79d1\u5b66\u4e0a\u7f51\uff0c\u4e0d\u8fc7 github \u6709\u65f6\u5019\u4e5f\u4e0d\u9700\u8981 \u9996\u5148\u9700\u8981\u4e00\u4e2a github \u8d26\u53f7\uff0c\u7136\u540e\u65b0\u5efa\u4e00\u4e2a\u7a7a\u4ed3\u5e93\uff0c\u5e76\u5229\u7528 git \u5c06\u4ed3\u5e93 clone \u5230\u672c\u5730\uff0c\u8fd9\u91cc\u4e0d\u5c55\u5f00\uff0c\u56e0\u4e3a\u672c\u849f\u84bb\u4e5f\u4e0d\u662f\u5f88\u61c2\uff0c\u7f51\u4e0a\u7684\u535a\u5ba2\u8fd8\u662f\u5f88\u591a \u4ec5\u8bb2\u4e00\u4e0b\u6211\u9047\u5230\u7684\u95ee\u9898\uff1a Failed to connect to github.com port 443: Timed out \u89e3\u51b3\u65b9\u6cd5\uff1a\u7ed9 git \u8bbe\u7f6e\u4ee3\u7406 \u79d1\u5b66\u4e0a\u7f51\u65f6\u6253\u5f00 win10 \u8bbe\u7f6e\u91cc\u7684\u4ee3\u7406\u8bbe\u7f6e\uff0c\u627e\u5230\u4ee3\u7406\u7684\u5730\u5740\u548c\u7aef\u53e3 git config --global http.proxy 172.17.18.80:8080 # \u540e\u9762\u662f \u5730\u5740:\u7aef\u53e3 \u67e5\u770b\u662f\u5426\u6210\u529f git config --get http.proxy \u514b\u9686\u6210\u529f\u540e\u628a .yml \u548c docs \u653e\u5728\u514b\u9686\u6587\u4ef6\u5939\u91cc\uff0c\u7136\u540e\u5728\u6b64\u6587\u4ef6\u5939\u542f\u52a8 cmd\uff0c\u8f93\u5165\u4ee5\u4e0b\u6307\u4ee4\u5373\u53ef\u90e8\u7f72 mkdocs gh-deploy","title":"\u90e8\u7f72 github"},{"location":"%E5%85%B6%E4%BB%96/Mkdocs/#_4","text":"\u5b98\u65b9\u6587\u6863","title":"\u7f8e\u5316\u914d\u7f6e"},{"location":"%E5%85%B6%E4%BB%96/Mkdocs/#_5","text":"site_name: hucorz's Docs site_url: https://hucorz.github.io/myDoc/","title":"\u6587\u6863\u540d\u79f0"},{"location":"%E5%85%B6%E4%BB%96/Mkdocs/#_6","text":"theme: name: 'material'","title":"\u6587\u6863\u4e3b\u9898"},{"location":"%E5%85%B6%E4%BB%96/Mkdocs/#_7","text":"\u914d\u8272\u76f8\u5173\u914d\u7f6e theme: palette: primary: 'white' accent: 'indigo'","title":"\u914d\u8272"},{"location":"%E5%85%B6%E4%BB%96/Mkdocs/#_8","text":"\u5bfc\u822a\u9875\u76f8\u5173\u914d\u7f6e features: - navigation.tabs - navigation.tabs.sticky","title":"\u5bfc\u822a\u9875"},{"location":"%E5%85%B6%E4%BB%96/Mkdocs/#logo-favicon","text":"","title":"logo &amp;&amp; favicon"},{"location":"%E5%85%B6%E4%BB%96/Mkdocs/#logo-favicon_1","text":"logo && favicon \u76f8\u5173\u914d\u7f6e theme: # \u8fd9\u4e24\u4e2a\u6211\u90fd\u662f\u4e0b\u4e0b\u6765\u540e\u7528\u7684 logo: 'img/cat-solid.svg' favicon: 'img/favicon.ico'","title":"\u6587\u6863\u7684 logo &amp;&amp; favicon"},{"location":"%E5%85%B6%E4%BB%96/Mkdocs/#repo-logo","text":"repo \u76f8\u5173\u914d\u7f6e \u4f60\u9700\u8981\u5148\u5728\u914d\u7f6e\u4e2d\u6dfb\u52a0 repo \u7684\u540d\u5b57\u548c url repo_name: 'hucorz/myDoc' repo_url: https://github.com/hucorz/myDoc \u7136\u540e logo \u53c2\u8003\u7684\u5b98\u65b9\u6587\u6863\uff1a theme: icon: repo: fontawesome/brands/github-alt","title":"repo \u7684 logo"},{"location":"%E5%85%B6%E4%BB%96/Mkdocs/#_9","text":"","title":"\u6269\u5c55"},{"location":"%E5%85%B6%E4%BB%96/Mkdocs/#markdown","text":"\u6570\u5b66\u516c\u5f0f MathJax - Material for MkDocs \u503c\u5f97\u5410\u69fd\u7684\u662f\u6211\u89c9\u5f97 Material for MkDocs \u5bf9\u6570\u5b66\u516c\u5f0f\u7684\u652f\u6301\u5f88\u70c2\uff0c\u5f88\u591a\u4e1c\u897f\u90fd\u4e0d\u80fd\u6b63\u5e38\u663e\u793a \u5982\u679c\u9047\u5230\u6bd4\u5982\u5927\u62ec\u53f7\uff0c\u77e9\u9635\u6324\u5728\u4e00\u884c\u53ef\u4ee5\u5c1d\u8bd5 $$ \u4e4b\u524d\u52a0\u4e00\u4e2a\u56de\u8f66\uff08\u5373\u548c\u4e0a\u9762\u7684\u4e1c\u897f\u7a7a\u4e00\u884c\uff09 markdown_extensions: - pymdownx.arithmatex: generic: true extra_javascript: - javascripts/config.js - https://polyfill.io/v3/polyfill.min.js?features=es6 - https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js \u4ee3\u7801\u9ad8\u4eae Code blocks - Material for MkDocs markdown_extensions: - pymdownx.highlight # code hilight - pymdownx.superfences toc\uff08table of content\uff09 Setting up navigation - Material for MkDocs markdown_extensions: # \u8fd92\u4e2a\u90fd\u662f\u548c\u6bcf\u4e2amarkdown\u6587\u6863\u7684\u6807\u9898\u6709\u5173 - toc: permalink: true # \u5f00\u542f\u6bcf\u4e2a\u6807\u9898\u540e\u9762\u7684 \u951a\u94fe\u63a5 #toc_depth: 2 # toc\u663e\u793a\u7684\u7ea7\u6570,\u8d8a\u9ad8\u663e\u793a\u7684\u8d8a\u591a\uff0c\u4e0d\u5199\u90fd\u663e\u793a\uff0c0\u4e0d\u663e\u793a","title":"markdown\u6269\u5c55"},{"location":"%E5%85%B6%E4%BB%96/Mkdocs/#_10","text":"Setting up site search - Material for MkDocs plugins: - search: lang: ja","title":"\u652f\u6301\u4e2d\u6587\u641c\u7d22"},{"location":"%E5%85%B6%E4%BB%96/Mkdocs/#_11","text":"1.\u4ecb\u7ecd - \u57fa\u4e8e Material for MkDocs \u642d\u5efa\u9759\u6001\u7f51\u9875 Material for MkDocs - Material forMkDocs Failed to connect to github.com port 443: Timed out_\u5929\u751f\u6211\u6750\u5fc5\u6709\u7528-CSDN\u535a\u5ba2","title":"\u53c2\u8003"},{"location":"%E5%89%8D%E7%AB%AF/CSS/","text":"CSS \u00b6 Cascading Style Sheets\uff1a\u5c42\u53e0\u6837\u5f0f\u8868 \u548c HTML \u4e00\u6837\u4e5f\u662f\u4e00\u79cd\u6807\u8bb0\u8bed\u8a00 \u4f5c\u7528\uff1a\u7f8e\u5316 HTML \u6587\u6863\uff0c\u5b9e\u73b0\u7ed3\u6784\uff08HTML\uff09\u4e0e\u6837\u5f0f\uff08CSS\uff09\u76f8\u5206\u79bb \u9009\u62e9\u5668\u5206\u7c7b\uff1a\u57fa\u7840\u9009\u62e9\u5668 \u548c \u590d\u5408\u9009\u62e9\u5668 \u57fa\u7840\u6982\u5ff5 \u00b6 CSS \u89c4\u5219\u7684\u6784\u6210\uff1a\u9009\u62e9\u5668(HTML\u6807\u7b7e) + \u4e00\u6761\u6216\u591a\u6761\u58f0\u660e \u4e00\u822c\u5199\u5728 \\(<head>\\) \u4e2d eg\uff1a < head > < style > /*style \u53ef\u4ee5\u5199\u5728\u4efb\u4f55\u5730\u65b9*/ p { color : red ; /*\u6bb5\u843d\u8bbe\u7f6e\u4e3a\u7ea2\u8272*/ font-size : 12 px ; /*\u5b57\u4f53\u5927\u5c0f12\u50cf\u7d20*/ } </ style > </ head > CSS\u5f15\u5165\u65b9\u5f0f \u00b6 \u884c\u5185\u5f0f\uff0c\u5728\u6807\u7b7e\u7684\u5c5e\u6027\u91cc\u76f4\u63a5\u6dfb\u52a0\u6837\u5f0f \\(<p\\ style=\"\\ color:red;\\ \">\\) \uff0c\u9002\u5408\u4fee\u6539\u7b80\u5355\u6837\u5f0f\uff0c\u6ca1\u6709\u4e0e\u7ed3\u6784\u5206\u79bb \u5d4c\u5165\u5f0f\uff0c\u5199\u5728 html \u9875\u9762\u5185\u90e8\uff0c\u5373 \\(<style></style>\\) \u4e2d\uff0c\u5e76\u6ca1\u6709\u5b8c\u5168\u4e0e\u7ed3\u6784\u5206\u79bb \u94fe\u63a5\u5f0f\uff0c\u5355\u72ec\u5199\u5728 CSS \u6587\u4ef6\u4e2d\uff0c\u9002\u7528\u4e8e\u6837\u5f0f\u6bd4\u8f83\u591a\u7684\u65f6\u5019\uff0c\u5b9e\u73b0\u4e86\u4e0e\u7ed3\u6784\u5206\u79bb /*.css\u6587\u4ef6\u4e2d*/ \u4e0d\u9700\u8981\u5199 < style ></ style > , \u53ea\u9700\u8981\u5199\u6837\u5f0f /*.html\u6587\u4ef6\u4e2d*/ < link rel = \"stylesheet\" href = \"css\u6587\u4ef6\u8def\u5f84\" > \u57fa\u7840\u9009\u62e9\u5668 \u00b6 \u57fa\u7840\u9009\u62e9\u5668\u7531\u5355\u4e2a\u9009\u62e9\u5668\u7ec4\u6210 \u6807\u7b7e\u9009\u62e9\u5668 \u00b6 \u6807\u7b7e\u540d\u4f5c\u4e3a\u9009\u62e9\u5668 \u6807\u7b7e\u540d { \u5c5e\u60271: \u5c5e\u6027\u503c1; ... } \u7c7b\u9009\u62e9\u5668 \u00b6 \u53ef\u4ee5\u5355\u72ec\u9009\u62e9\u4e00\u4e2a\u6216\u51e0\u4e2a\u6807\u7b7e\uff0c\u4e00\u4e2a\u6807\u7b7e\u4e5f\u53ef\u4ee5\u6709\u591a\u4e2a\u7c7b\u540d\uff0c\u7528 . \u6765\u5b9a\u4e49 .\u7c7b\u540d { \u5c5e\u60271: \u5c5e\u6027\u503c1; ... } < div class = \"\u7c7b\u540d\" > eg </ div > < div class = \"\u7c7b\u540d1 \u7c7b\u540d2\" > </ div > id\u9009\u62e9\u5668 \u00b6 \u4e3a\u6807\u6709\u7279\u5b9a id \u7684 HTML\u5143\u7d20 \u6307\u5b9a\u6837\u5f0f\uff0c\u7528 # \u6765\u5b9a\u4e49 \u4e0e\u7c7b\u9009\u62e9\u5668\u7684\u533a\u522b\u5728\u4e8e\uff0cid\u9009\u62e9\u5668\u53ea\u80fd\u8c03\u7528\u4e00\u6b21 #\u7c7b\u540d { \u5c5e\u60271: \u5c5e\u6027\u503c1; ... } \u901a\u914d\u7b26\u9009\u62e9\u5668 \u00b6 \u4e3a\u9875\u9762\u4e2d\u6240\u6709\u7684\u5143\u7d20\u6307\u5b9a\u6837\u5f0f\uff0c\u7528 * \u6765\u5b9a\u4e49 \u4e0d\u9700\u8981\u8c03\u7528 * { \u5c5e\u60271: \u5c5e\u6027\u503c1; ... } \u590d\u5408\u9009\u62e9\u5668 \u00b6 \u540e\u4ee3\u9009\u62e9\u5668 \u00b6 \u53c8\u79f0\u5305\u542b\u9009\u62e9\u5668 # \u5143\u7d20 \u53ef\u4ee5\u662f\u4efb\u4f55\u57fa\u7840\u9009\u62e9\u5668 \u5143\u7d201 \u5143\u7d202 {\u6837\u5f0f\u58f0\u660e} # \u6b64\u6837\u5f0f\u53ea\u4f1a\u5e94\u7528\u4e8e \u5143\u7d201 \u4e2d\u6240\u6709\u7684 \u5143\u7d202\uff08\u4e0d\u4e00\u5b9a\u6b63\u597d\u662f\u4e0b\u4e00\u7ea7\uff09\uff0c\u5373\u540e\u4ee3\u5143\u7d20 \u5143\u7d201 \u5143\u7d202 \u5143\u7d203 ... {\u6837\u5f0f\u58f0\u660e} # \u540e\u4ee3\u53ef\u4ee5\u6709\u591a\u5c42, \u4f46\u53ea\u4f1a\u5e94\u7528\u4e8e\u6700\u540e\u4e00\u5c42 # eg: \u7c7b\u9009\u62e9\u5668 + li + a .nav li a { color: red; } \u5b50\u9009\u62e9\u5668 \u00b6 \u9009\u62e9\u67d0\u5143\u7d20\u6700\u8fd1\u4e00\u7ea7\u7684\u5b50\u5143\u7d20 \u5143\u7d201 > \u5143\u7d202 {\u6837\u5f0f\u58f0\u660e} # \u6b64\u6837\u5f0f\u53ea\u4f1a\u5e94\u7528\u4e8e \u5143\u7d201 \u4e2d\u6700\u8fd1\u7684 \u5143\u7d202, \u5143\u7d202 \u5fc5\u987b\u662f\u513f\u5b50 \u5e76\u96c6\u9009\u62e9\u5668 \u00b6 \u4f2a\u7c7b\u9009\u62e9\u5668 \u00b6 \u5e38\u7528\u5c5e\u6027\u603b\u7ed3 \u00b6 \u5b57\u4f53\u5c5e\u6027 \u00b6 \u5b57\u4f53\uff0c\u5927\u5c0f\uff0c\u7c97\u7ec6\uff0c\u6587\u672c\u6837\u5f0f \u5c5e\u6027 \u542b\u4e49 \u5c5e\u6027\u503c\u4e3e\u4f8b font-family \u5b57\u4f53 \"Microsoft YaHei\" font-size \u5927\u5c0f 20px\uff08\u4e0d\u4f1a\u5f71\u54cd\u6807\u9898\uff09 font-weight \u7c97\u7ec6 700\uff08\u52a0\u7c97:100\uff0c\u666e\u901a:100\uff09 font-style \u6587\u5b57\u6837\u5f0f normal\uff08\u659c\u4f53:italic\uff09 \u590d\u5408\u5c5e\u6027 /*font: font-style font-weight font-size/line-height font-family*/ /*\u4e0a\u9762\u7684\u987a\u5e8f\u4e0d\u80fd\u66f4\u6539*/ /*font-size \u548c font-famliy \u4e0d\u53ef\u4ee5\u7701\u7565*/ font: italic 700 16px 'Microsoft yahei'; \u6587\u672c\u5c5e\u6027 \u00b6 \u6587\u672c\u7684\u5916\u89c2\u5c5e\u6027 \u5c5e\u6027 \u542b\u4e49 \u5c5e\u6027\u503c\u4e3e\u4f8b color \u989c\u8272 red / #FF0000 text-align \u6c34\u5e73\u5bf9\u9f50 center / left / right text-decoration \u88c5\u9970\u6587\u672c none / underline / overline / line-through text-indent \u9996\u884c\u7f29\u8fdb 10px / 2em\uff082\u4e2a\u5f53\u524d\u6587\u5b57\u5927\u5c0f\uff09 ling-height \u884c\u95f4\u8ddd 26px \u88c5\u9970\u5c5e\u6027\u53d6 none \u5e38\u7528\u5728\u53d6\u6d88\u8d85\u94fe\u63a5\u7684\u4e0b\u5212\u7ebf \u5176\u4ed6 \u00b6 \u5c5e\u6027\u540d \u542b\u4e49 width / height \u9ad8\u5ea6 / \u5bbd\u5ea6 background-color \u80cc\u666f\u989c\u8272 margin padding \u5176\u4ed6 \u00b6 Emmet \u8bed\u6cd5 \u00b6 \u524d\u8eab\u662f Zen coding\uff0c\u80fd\u591f\u4f7f\u7528\u7f29\u5199\u63d0\u9ad8 html / css \u7684\u7f16\u5199\u901f\u5ea6\uff0cvscode \u5185\u90e8\u96c6\u6210 \u5feb\u901f\u751f\u6210 HTML \u8bed\u6cd5 \u751f\u6210\u6807\u7b7e\uff1a\u6807\u7b7e\u540d + tab \u751f\u6210\u591a\u4e2a\u6807\u7b7e\uff1a\u6807\u7b7e\u540d * \u4e2a\u6570+ tab \uff0c\u5982 div*3+tab \u7236\u5b50\u7ea7\u5173\u7cfb\u6807\u7b7e\uff0c\u7528 > \uff0c\u6bd4\u5982 ul>li+tab \u5144\u5f1f\u5173\u7cfb\u6807\u7b7e\uff0c\u7528 + \uff0c\u6bd4\u5982 dip+p+tab \u5e26\u7c7b\u6807\u7b7e\uff0c\u7528 \u6807\u7b7e\u540d.\u7c7b\u540d \uff0c\u6bd4\u5982 p.demo+tab\uff0c\u4e0d\u5199\u6807\u7b7e\u540d\u9ed8\u8ba4\u6807\u7b7e\u662f div \u5e26 id \u6807\u7b7e\uff0c\u7528 \u6807\u7b7e\u540d#\u7c7b\u540d \uff0c\u4e0d\u5199\u6807\u7b7e\u540d\u9ed8\u8ba4\u662f div \u751f\u6210\u6709\u5e8f\u7c7b\u540d\uff0c .\u7c7b\u540d$*\u6570\u5b57 \uff0c\u4f1a\u751f\u6210 \u7c7b\u540d1\uff0c\u7c7b\u540d2\uff0c\uff0c\uff0c \u6807\u7b7e\u5185\u9ed8\u8ba4\u6587\u5b57\uff0c\u7528 {} \uff0c\u5982 div{eg}+tab\uff0cdiv{$}*5\u4f1a\u751f\u62105\u4e2a\u81ea\u5e2612345\u7684div \u5feb\u901f\u751f\u6210 CSS \u8bed\u6cd5 \u7f29\u5199+ tab \uff0c\u5982\uff1a tac+tab \u8868\u793a text-align: center; w100+tab \u8868\u793a width: 100px; tx2em+tab \u8868\u793a text-indent: 2em; \u7c7b\u540d\u89c4\u8303 \u00b6 \u7c7b\u540d\u542b\u4e49 \u7c7b\u540d \u9875\u5c3e / \u9875\u811a footer \u56fe\u7247 pic \u5de5\u5177 \u00b6 FSCaputer\uff1a\u6d4b\u884c\u9ad8\uff0c\u62fe\u8272\u5668 \u4e00\u4e9b\u5b9e\u4f8b \u00b6 \u56fe\u7247\u5c45\u4e2d\u5bf9\u9f50 \u00b6 .pic { text-align:center; } < div class = \"pic\" > < img src = \"...\" alt = \"...\" > </ div >","title":"CSS"},{"location":"%E5%89%8D%E7%AB%AF/CSS/#css","text":"Cascading Style Sheets\uff1a\u5c42\u53e0\u6837\u5f0f\u8868 \u548c HTML \u4e00\u6837\u4e5f\u662f\u4e00\u79cd\u6807\u8bb0\u8bed\u8a00 \u4f5c\u7528\uff1a\u7f8e\u5316 HTML \u6587\u6863\uff0c\u5b9e\u73b0\u7ed3\u6784\uff08HTML\uff09\u4e0e\u6837\u5f0f\uff08CSS\uff09\u76f8\u5206\u79bb \u9009\u62e9\u5668\u5206\u7c7b\uff1a\u57fa\u7840\u9009\u62e9\u5668 \u548c \u590d\u5408\u9009\u62e9\u5668","title":"CSS"},{"location":"%E5%89%8D%E7%AB%AF/CSS/#_1","text":"CSS \u89c4\u5219\u7684\u6784\u6210\uff1a\u9009\u62e9\u5668(HTML\u6807\u7b7e) + \u4e00\u6761\u6216\u591a\u6761\u58f0\u660e \u4e00\u822c\u5199\u5728 \\(<head>\\) \u4e2d eg\uff1a < head > < style > /*style \u53ef\u4ee5\u5199\u5728\u4efb\u4f55\u5730\u65b9*/ p { color : red ; /*\u6bb5\u843d\u8bbe\u7f6e\u4e3a\u7ea2\u8272*/ font-size : 12 px ; /*\u5b57\u4f53\u5927\u5c0f12\u50cf\u7d20*/ } </ style > </ head >","title":"\u57fa\u7840\u6982\u5ff5"},{"location":"%E5%89%8D%E7%AB%AF/CSS/#css_1","text":"\u884c\u5185\u5f0f\uff0c\u5728\u6807\u7b7e\u7684\u5c5e\u6027\u91cc\u76f4\u63a5\u6dfb\u52a0\u6837\u5f0f \\(<p\\ style=\"\\ color:red;\\ \">\\) \uff0c\u9002\u5408\u4fee\u6539\u7b80\u5355\u6837\u5f0f\uff0c\u6ca1\u6709\u4e0e\u7ed3\u6784\u5206\u79bb \u5d4c\u5165\u5f0f\uff0c\u5199\u5728 html \u9875\u9762\u5185\u90e8\uff0c\u5373 \\(<style></style>\\) \u4e2d\uff0c\u5e76\u6ca1\u6709\u5b8c\u5168\u4e0e\u7ed3\u6784\u5206\u79bb \u94fe\u63a5\u5f0f\uff0c\u5355\u72ec\u5199\u5728 CSS \u6587\u4ef6\u4e2d\uff0c\u9002\u7528\u4e8e\u6837\u5f0f\u6bd4\u8f83\u591a\u7684\u65f6\u5019\uff0c\u5b9e\u73b0\u4e86\u4e0e\u7ed3\u6784\u5206\u79bb /*.css\u6587\u4ef6\u4e2d*/ \u4e0d\u9700\u8981\u5199 < style ></ style > , \u53ea\u9700\u8981\u5199\u6837\u5f0f /*.html\u6587\u4ef6\u4e2d*/ < link rel = \"stylesheet\" href = \"css\u6587\u4ef6\u8def\u5f84\" >","title":"CSS\u5f15\u5165\u65b9\u5f0f"},{"location":"%E5%89%8D%E7%AB%AF/CSS/#_2","text":"\u57fa\u7840\u9009\u62e9\u5668\u7531\u5355\u4e2a\u9009\u62e9\u5668\u7ec4\u6210","title":"\u57fa\u7840\u9009\u62e9\u5668"},{"location":"%E5%89%8D%E7%AB%AF/CSS/#_3","text":"\u6807\u7b7e\u540d\u4f5c\u4e3a\u9009\u62e9\u5668 \u6807\u7b7e\u540d { \u5c5e\u60271: \u5c5e\u6027\u503c1; ... }","title":"\u6807\u7b7e\u9009\u62e9\u5668"},{"location":"%E5%89%8D%E7%AB%AF/CSS/#_4","text":"\u53ef\u4ee5\u5355\u72ec\u9009\u62e9\u4e00\u4e2a\u6216\u51e0\u4e2a\u6807\u7b7e\uff0c\u4e00\u4e2a\u6807\u7b7e\u4e5f\u53ef\u4ee5\u6709\u591a\u4e2a\u7c7b\u540d\uff0c\u7528 . \u6765\u5b9a\u4e49 .\u7c7b\u540d { \u5c5e\u60271: \u5c5e\u6027\u503c1; ... } < div class = \"\u7c7b\u540d\" > eg </ div > < div class = \"\u7c7b\u540d1 \u7c7b\u540d2\" > </ div >","title":"\u7c7b\u9009\u62e9\u5668"},{"location":"%E5%89%8D%E7%AB%AF/CSS/#id","text":"\u4e3a\u6807\u6709\u7279\u5b9a id \u7684 HTML\u5143\u7d20 \u6307\u5b9a\u6837\u5f0f\uff0c\u7528 # \u6765\u5b9a\u4e49 \u4e0e\u7c7b\u9009\u62e9\u5668\u7684\u533a\u522b\u5728\u4e8e\uff0cid\u9009\u62e9\u5668\u53ea\u80fd\u8c03\u7528\u4e00\u6b21 #\u7c7b\u540d { \u5c5e\u60271: \u5c5e\u6027\u503c1; ... }","title":"id\u9009\u62e9\u5668"},{"location":"%E5%89%8D%E7%AB%AF/CSS/#_5","text":"\u4e3a\u9875\u9762\u4e2d\u6240\u6709\u7684\u5143\u7d20\u6307\u5b9a\u6837\u5f0f\uff0c\u7528 * \u6765\u5b9a\u4e49 \u4e0d\u9700\u8981\u8c03\u7528 * { \u5c5e\u60271: \u5c5e\u6027\u503c1; ... }","title":"\u901a\u914d\u7b26\u9009\u62e9\u5668"},{"location":"%E5%89%8D%E7%AB%AF/CSS/#_6","text":"","title":"\u590d\u5408\u9009\u62e9\u5668"},{"location":"%E5%89%8D%E7%AB%AF/CSS/#_7","text":"\u53c8\u79f0\u5305\u542b\u9009\u62e9\u5668 # \u5143\u7d20 \u53ef\u4ee5\u662f\u4efb\u4f55\u57fa\u7840\u9009\u62e9\u5668 \u5143\u7d201 \u5143\u7d202 {\u6837\u5f0f\u58f0\u660e} # \u6b64\u6837\u5f0f\u53ea\u4f1a\u5e94\u7528\u4e8e \u5143\u7d201 \u4e2d\u6240\u6709\u7684 \u5143\u7d202\uff08\u4e0d\u4e00\u5b9a\u6b63\u597d\u662f\u4e0b\u4e00\u7ea7\uff09\uff0c\u5373\u540e\u4ee3\u5143\u7d20 \u5143\u7d201 \u5143\u7d202 \u5143\u7d203 ... {\u6837\u5f0f\u58f0\u660e} # \u540e\u4ee3\u53ef\u4ee5\u6709\u591a\u5c42, \u4f46\u53ea\u4f1a\u5e94\u7528\u4e8e\u6700\u540e\u4e00\u5c42 # eg: \u7c7b\u9009\u62e9\u5668 + li + a .nav li a { color: red; }","title":"\u540e\u4ee3\u9009\u62e9\u5668"},{"location":"%E5%89%8D%E7%AB%AF/CSS/#_8","text":"\u9009\u62e9\u67d0\u5143\u7d20\u6700\u8fd1\u4e00\u7ea7\u7684\u5b50\u5143\u7d20 \u5143\u7d201 > \u5143\u7d202 {\u6837\u5f0f\u58f0\u660e} # \u6b64\u6837\u5f0f\u53ea\u4f1a\u5e94\u7528\u4e8e \u5143\u7d201 \u4e2d\u6700\u8fd1\u7684 \u5143\u7d202, \u5143\u7d202 \u5fc5\u987b\u662f\u513f\u5b50","title":"\u5b50\u9009\u62e9\u5668"},{"location":"%E5%89%8D%E7%AB%AF/CSS/#_9","text":"","title":"\u5e76\u96c6\u9009\u62e9\u5668"},{"location":"%E5%89%8D%E7%AB%AF/CSS/#_10","text":"","title":"\u4f2a\u7c7b\u9009\u62e9\u5668"},{"location":"%E5%89%8D%E7%AB%AF/CSS/#_11","text":"","title":"\u5e38\u7528\u5c5e\u6027\u603b\u7ed3"},{"location":"%E5%89%8D%E7%AB%AF/CSS/#_12","text":"\u5b57\u4f53\uff0c\u5927\u5c0f\uff0c\u7c97\u7ec6\uff0c\u6587\u672c\u6837\u5f0f \u5c5e\u6027 \u542b\u4e49 \u5c5e\u6027\u503c\u4e3e\u4f8b font-family \u5b57\u4f53 \"Microsoft YaHei\" font-size \u5927\u5c0f 20px\uff08\u4e0d\u4f1a\u5f71\u54cd\u6807\u9898\uff09 font-weight \u7c97\u7ec6 700\uff08\u52a0\u7c97:100\uff0c\u666e\u901a:100\uff09 font-style \u6587\u5b57\u6837\u5f0f normal\uff08\u659c\u4f53:italic\uff09 \u590d\u5408\u5c5e\u6027 /*font: font-style font-weight font-size/line-height font-family*/ /*\u4e0a\u9762\u7684\u987a\u5e8f\u4e0d\u80fd\u66f4\u6539*/ /*font-size \u548c font-famliy \u4e0d\u53ef\u4ee5\u7701\u7565*/ font: italic 700 16px 'Microsoft yahei';","title":"\u5b57\u4f53\u5c5e\u6027"},{"location":"%E5%89%8D%E7%AB%AF/CSS/#_13","text":"\u6587\u672c\u7684\u5916\u89c2\u5c5e\u6027 \u5c5e\u6027 \u542b\u4e49 \u5c5e\u6027\u503c\u4e3e\u4f8b color \u989c\u8272 red / #FF0000 text-align \u6c34\u5e73\u5bf9\u9f50 center / left / right text-decoration \u88c5\u9970\u6587\u672c none / underline / overline / line-through text-indent \u9996\u884c\u7f29\u8fdb 10px / 2em\uff082\u4e2a\u5f53\u524d\u6587\u5b57\u5927\u5c0f\uff09 ling-height \u884c\u95f4\u8ddd 26px \u88c5\u9970\u5c5e\u6027\u53d6 none \u5e38\u7528\u5728\u53d6\u6d88\u8d85\u94fe\u63a5\u7684\u4e0b\u5212\u7ebf","title":"\u6587\u672c\u5c5e\u6027"},{"location":"%E5%89%8D%E7%AB%AF/CSS/#_14","text":"\u5c5e\u6027\u540d \u542b\u4e49 width / height \u9ad8\u5ea6 / \u5bbd\u5ea6 background-color \u80cc\u666f\u989c\u8272 margin padding","title":"\u5176\u4ed6"},{"location":"%E5%89%8D%E7%AB%AF/CSS/#_15","text":"","title":"\u5176\u4ed6"},{"location":"%E5%89%8D%E7%AB%AF/CSS/#emmet","text":"\u524d\u8eab\u662f Zen coding\uff0c\u80fd\u591f\u4f7f\u7528\u7f29\u5199\u63d0\u9ad8 html / css \u7684\u7f16\u5199\u901f\u5ea6\uff0cvscode \u5185\u90e8\u96c6\u6210 \u5feb\u901f\u751f\u6210 HTML \u8bed\u6cd5 \u751f\u6210\u6807\u7b7e\uff1a\u6807\u7b7e\u540d + tab \u751f\u6210\u591a\u4e2a\u6807\u7b7e\uff1a\u6807\u7b7e\u540d * \u4e2a\u6570+ tab \uff0c\u5982 div*3+tab \u7236\u5b50\u7ea7\u5173\u7cfb\u6807\u7b7e\uff0c\u7528 > \uff0c\u6bd4\u5982 ul>li+tab \u5144\u5f1f\u5173\u7cfb\u6807\u7b7e\uff0c\u7528 + \uff0c\u6bd4\u5982 dip+p+tab \u5e26\u7c7b\u6807\u7b7e\uff0c\u7528 \u6807\u7b7e\u540d.\u7c7b\u540d \uff0c\u6bd4\u5982 p.demo+tab\uff0c\u4e0d\u5199\u6807\u7b7e\u540d\u9ed8\u8ba4\u6807\u7b7e\u662f div \u5e26 id \u6807\u7b7e\uff0c\u7528 \u6807\u7b7e\u540d#\u7c7b\u540d \uff0c\u4e0d\u5199\u6807\u7b7e\u540d\u9ed8\u8ba4\u662f div \u751f\u6210\u6709\u5e8f\u7c7b\u540d\uff0c .\u7c7b\u540d$*\u6570\u5b57 \uff0c\u4f1a\u751f\u6210 \u7c7b\u540d1\uff0c\u7c7b\u540d2\uff0c\uff0c\uff0c \u6807\u7b7e\u5185\u9ed8\u8ba4\u6587\u5b57\uff0c\u7528 {} \uff0c\u5982 div{eg}+tab\uff0cdiv{$}*5\u4f1a\u751f\u62105\u4e2a\u81ea\u5e2612345\u7684div \u5feb\u901f\u751f\u6210 CSS \u8bed\u6cd5 \u7f29\u5199+ tab \uff0c\u5982\uff1a tac+tab \u8868\u793a text-align: center; w100+tab \u8868\u793a width: 100px; tx2em+tab \u8868\u793a text-indent: 2em;","title":"Emmet \u8bed\u6cd5"},{"location":"%E5%89%8D%E7%AB%AF/CSS/#_16","text":"\u7c7b\u540d\u542b\u4e49 \u7c7b\u540d \u9875\u5c3e / \u9875\u811a footer \u56fe\u7247 pic","title":"\u7c7b\u540d\u89c4\u8303"},{"location":"%E5%89%8D%E7%AB%AF/CSS/#_17","text":"FSCaputer\uff1a\u6d4b\u884c\u9ad8\uff0c\u62fe\u8272\u5668","title":"\u5de5\u5177"},{"location":"%E5%89%8D%E7%AB%AF/CSS/#_18","text":"","title":"\u4e00\u4e9b\u5b9e\u4f8b"},{"location":"%E5%89%8D%E7%AB%AF/CSS/#_19","text":".pic { text-align:center; } < div class = \"pic\" > < img src = \"...\" alt = \"...\" > </ div >","title":"\u56fe\u7247\u5c45\u4e2d\u5bf9\u9f50"},{"location":"%E5%89%8D%E7%AB%AF/HTML/","text":"HTML \u00b6 \u57fa\u7840\u6982\u5ff5 \u00b6 HTML \u00b6 HTML \u662f\u4e00\u79cd\u8d85\u6587\u672c\u6807\u8bb0\u8bed\u8a00\uff08\u5373\u53ef\u4ee5\u52a0\u5165\u591a\u5a92\u4f53\u5185\u5bb9\uff0c\u8d85\u8d8a\u4e86\u6587\u672c\u9650\u5236\uff0c\u8fd8\u652f\u6301\u8d85\u94fe\u63a5\uff09 WEB\u6807\u51c6 \u00b6 \u6784\u6210\uff1a\u7ed3\u6784\uff08HTML\uff09\uff0c\u8868\u73b0\uff08CSS\uff09\uff0c\u884c\u4e3a\uff08JS\uff09 VSCODE\u4f7f\u7528 \u00b6 \u63d2\u4ef6 \u00b6 \u63d2\u4ef6 \u4f5c\u7528 open in browser \u53f3\u952e\u5373\u53ef\u5728\u6d4f\u89c8\u5668\u4e2d\u6253\u5f00 Auto Rename Tag \u81ea\u52a8\u8865\u5168\u53cc\u6807\u7b7e \u5feb\u901f\u683c\u5f0f\u5316 \u00b6 \u5feb\u901f\u683c\u5f0f\u5316\u6587\u6863\uff1a ALT SHIFT F \u4fdd\u5b58\u6587\u4ef6\u81ea\u52a8\u683c\u5f0f\u5316\uff1a\u5728 setting.json \u4e2d\u52a0\u4e0a \"editor.formatOnType\" : true , // HTML \u6587\u4ef6\u4fdd\u5b58\u81ea\u52a8\u683c\u5f0f\u5316 \"editor.formatOnSave\" : true \u6807\u7b7e \u00b6 \u57fa\u672c\u7ed3\u6784\u6807\u7b7e \u00b6 \u6807\u7b7e\u540d \u8bf4\u660e \\(<html></html>\\) \u6839\u6807\u7b7e \\(<head></head>\\) \u5934\u90e8\u6807\u7b7e \\(<title></title>\\) \u6807\u9898\u6807\u7b7e \\(<body></body>\\) \u4e3b\u4f53\u6807\u7b7e \\(<!DOCTYPE html>\\) \u58f0\u660ehtml\u7248\u672c \\(<html lang=\"zh-CN\">\\) \u58f0\u660e\u7f51\u9875\u8bed\u8a00 \\(<meta charset=\"UTF-8\">\\) \u58f0\u660e\u5b57\u7b26\u96c6\u4e3a\u4e07\u56fd\u7801 \u6807\u9898\u6807\u7b7e \u00b6 \u6700\u591a\u67096\u7ea7\u6807\u9898\u6807\u7b7e < h1 > \u4e00\u7ea7\u6807\u9898 </ h1 > < h2 > \u4e8c\u7ea7\u6807\u9898 </ h2 > < h3 > \u4e09\u7ea7\u6807\u9898 </ h3 > \u6bb5\u843d\u548c\u6362\u884c\u6807\u7b7e \u00b6 \u6807\u7b7e\u540d \u8bf4\u660e \\(<p></p>\\) \u6bb5\u843d\u6807\u7b7e\uff0cparagraph \\(<br>\\) \u6362\u884c\u6807\u7b7e\uff0cbreak \u6587\u672c\u683c\u5f0f\u5316\u6807\u7b7e \u00b6 \u6807\u7b7e\u540d \u8bf4\u660e \\(<strong></strong>\\) \u6216\u8005 \\(<b></b>\\) \u52a0\u7c97 \\(<em></em>\\) \u6216\u8005 \\(<i></i>\\) \u503e\u659c \\(<del></del>\\) \u6216\u8005 \\(<s></s>\\) \u5220\u9664\u7ebf \\(<ins></ins>\\) \u6216\u8005 \\(<u></u>\\) \u4e0b\u5212\u7ebf div \u548c span \u6807\u7b7e \u00b6 \u8fd92\u4e2a\u6807\u7b7e\u90fd\u662f\u5e03\u5c40\u7528 \u6807\u7b7e\u540d \u8bf4\u660e \\(<div></div>\\) \u5206\u533a\uff0c\u5360\u4e00\u884c\uff0cdivision \\(<span></span>\\) \u8de8\u8ddd\uff0c\u53ef\u4ee5\u591a\u4e2a\u5360\u4e00\u884c\uff0c \u56fe\u50cf\u6807\u7b7e \u00b6 < img src = \"\u8def\u5f84\u6216\u8005\u94fe\u63a5\" /> img \u6807\u7b7e\u4e2d\u53ef\u52a0\u7684\u5c5e\u6027 \u5c5e\u6027 \u8bf4\u660e src \u8def\u5f84\u6216\u94fe\u63a5\uff0csource alt \u663e\u793a\u5931\u8d25\u65f6\u7684\u66ff\u6362\u6587\u672c\uff0calternative title \u9f20\u6807\u653e\u5728\u56fe\u7247\u4e0a\u65f6\u7684\u8bf4\u660e\u6587\u5b57 width \u8bbe\u5b9a\u5bbd\u5ea6 height \u8bbe\u5b9a\u9ad8\u5ea6 border \u8bbe\u5b9a\u8fb9\u6846\u7c97\u7ec6 \u5bbd\u5ea6\u548c\u9ad8\u5ea6\u53ea\u8bbe\u5b9a\u4e00\u4e2a\u65f6\u7eb5\u6a2a\u6bd4\u662f\u56fa\u5b9a\u7684 \u8d85\u94fe\u63a5\u6807\u7b7e \u00b6 <!-- anchor --> <!-- target=\"_self\"\u65f6\u4e0d\u5f00\u65b0\u7a97\u53e3 \"_blank\"\u65f6\u5f00\u65b0\u7a97\u53e3 --> < a herf = \"\u8df3\u8f6c\u76ee\u6807\" target = \"\u7a97\u53e3\u5f39\u51fa\u65b9\u5f0f\" > \u6587\u672c\u6216\u56fe\u50cf\u6807\u7b7e </ a > <!-- herf \u662fhtml\u6587\u4ef6\u65f6\u662f\u5185\u90e8\u94fe\u63a5\uff0c\u662f\u7f51\u9875\u94fe\u63a5\u65f6\u662f\u5916\u90e8\u94fe\u63a5 --> <!-- herf = \"#\" \u8868\u793a \u7a7a\u94fe\u63a5--> <!-- herf = \"\u6587\u4ef6\u8def\u5f84\" \u65f6\u53ef\u4ee5\u5b9e\u73b0\u4e0b\u8f7d\u6587\u4ef6--> \u951a\u70b9\u94fe\u63a5 <!-- \u51fa\u53d1\u4f4d\u7f6e --> < a herf = \"#tag\" > \u6587\u672c\u6216\u56fe\u50cf\u6807\u7b7e </ a > <!-- \u76ee\u6807\u4f4d\u7f6e\u5728\u6807\u9898\u5904 --> < h2 id = \"tag\" > \u6807\u9898 </ h2 > \u6ce8\u91ca\u548c\u7279\u6b8a\u5b57\u7b26 \u00b6 <!-- \u8fd9\u662f\u6ce8\u91ca\u6807\u7b7e\uff0cvscode \u7528 Ctrl+/ --> \u7279\u6b8a\u5b57\u7b26\uff1a HTML \u7b26\u53f7\u5b9e\u4f53\u53c2\u8003\u624b\u518c | \u83dc\u9e1f\u6559\u7a0b \u5e38\u7528\uff1a | \u63cf\u8ff0 | \u4ee3\u7801 | | -------- | ----------- | | \u7a7a\u683c | &nbsp; | | \u5927\u4e8e | &gt; | | \u5c0f\u4e8e | &lt; | | \u4e0e\u53f7 | &amp; | | \u4e58\u6cd5 | &times; | | \u9664\u6cd5 | &divide; | | \u5e73\u65b9 | &sup2; | | \u7acb\u65b9 | &sup3; | \u8868\u683c\u6807\u7b7e \u00b6 < table > <!-- \u8868\u683c\u6839\u6807\u7b7e --> < tr > <!-- \u8868\u683c\u4e2d\u7684\u884c --> < td > \u5355\u5143\u683c\u5185\u7684\u6587\u5b57 </ td > <!-- \u6bcf\u884c\u4e2d\u6bcf\u683c\u7684\u5185\u5bb9 --> ... </ tr > ... </ table > <!-- \u8868\u5934\u5355\u5143\u683c\u6807\u7b7e\uff0c\u6307\u660e\u67d0\u4e00\u884c\u662f\u8868\u5934\uff0c\u548ctd\u540c\u7ea7\uff0c\u4f1a\u52a0\u7c97\u5e76\u5c45\u4e2d --> < th > ... </ th > \u8868\u683c\u5c5e\u6027 \u4e0d\u592a\u5e38\u7528\uff0c\u4f1a\u901a\u8fc7CSS\u8bbe\u7f6e \u5c5e\u6027\u540d \u5c5e\u6027\u503c \u63cf\u8ff0 align left / center / right \u76f8\u5bf9\u5468\u56f4\u5143\u7d20\u7684\u5bf9\u9f50\u65b9\u5f0f border 1 / \"\" \u662f\u5426\u6709\u8fb9\u6846\uff0c\"\"\u4e3a\u9ed8\u8ba4\uff0c\u8868\u793a\u6ca1\u6709 cellpadding \u50cf\u7d20\u503c \u8fb9\u6cbf\u4e0e\u5185\u5bb9\u4e4b\u95f4\u7684\u7a7a\u767d\uff0c\u9ed8\u8ba4\u4e3a1 cellspacing \u50cf\u7d20\u503c \u5355\u5143\u683c\u4e4b\u95f4\u7684\u7a7a\u767d\uff0c\u9ed8\u8ba42 width \u50cf\u7d20\u503c / \u767e\u5206\u6bd4 \u5bbd\u5ea6 height \u50cf\u7d20\u503c / \u767e\u5206\u6bd4 \u9ad8\u5ea6 \u8868\u683c\u7ed3\u6784\u6807\u7b7e < table > < thead ></ thead > <!-- \u5934\u90e8\u6807\u7b7e --> < tbody ></ tbody > <!-- \u4e3b\u4f53\u6807\u7b7e --> </ table > \u5408\u5e76\u5355\u5143\u683c\uff08td\u7684\u5c5e\u6027\uff09 \u8de8\u884c\u5408\u5e76\uff1arowspan=\"\u5408\u5e76\u5355\u5143\u683c\u7684\u4e2a\u6570\"\uff0c\u6700\u4e0a\u4fa7\u5355\u5143\u683c\u4e3a\u76ee\u6807\u5355\u5143\u683c \u8de8\u5217\u5408\u5e76\uff1acolspan=\"\u5408\u5e76\u5355\u5143\u683c\u7684\u4e2a\u6570\"\uff0c\u6700\u5de6\u4fa7\u5355\u5143\u683c\u4e3a\u76ee\u6807\u5355\u5143\u683c \u5217\u8868\u6807\u7b7e \u00b6 \u5206\u7c7b\uff1a\u65e0\u5e8f\u5217\u8868\uff0c\u6709\u5e8f\u5217\u8868\uff0c\u81ea\u5b9a\u4e49\u5217\u8868 \u5217\u8868\u81ea\u5e26\u7684\u6837\u5f0f\u5c5e\u6027\u53ef\u4ee5\u901a\u8fc7CSS\u4fee\u6539 \u65e0\u5e8f\u5217\u8868 < ul > <!-- ul\u4e2d\u53ea\u80fd\u653eli\u6807\u7b7e\uff0c\u4f46li\u4e2d\u53ef\u4ee5\u653e\u4efb\u4f55\u6807\u7b7e --> < li > \u5217\u8868\u98791 </ li > < li > \u5217\u8868\u98792 </ li > < li > \u5217\u8868\u98793 </ li > ... </ ul > \u6709\u5e8f\u5217\u8868 < ol > <!-- ol\u4e2d\u53ea\u80fd\u653eli\u6807\u7b7e\uff0c\u4f46li\u4e2d\u53ef\u4ee5\u653e\u4efb\u4f55\u6807\u7b7e --> < li > \u5217\u8868\u98791 </ li > < li > \u5217\u8868\u98792 </ li > < li > \u5217\u8868\u98793 </ li > ... </ ol > \u81ea\u5b9a\u4e49\u5217\u8868 < dl > <!-- dl\u4e2d\u53ea\u80fd\u653edt/dd\u6807\u7b7e\uff0c\u4f46dt/dd\u4e2d\u53ef\u4ee5\u653e\u4efb\u4f55\u6807\u7b7e --> < dt > \u540d\u8bcd1 </ dt > < dd > \u540d\u8bcd1\u89e3\u91ca1 </ dd > < dd > \u540d\u8bcd1\u89e3\u91ca2 </ dd > </ dl > \u8868\u5355\u6807\u7b7e \u00b6 \u8868\u5355\u7528\u4e8e\u6536\u96c6\u7528\u6237\u4fe1\u606f \u8868\u5355\u7531 \u8868\u5355\u57df\uff0c\u8868\u5355\u63a7\u4ef6(\u8868\u5355\u5143\u7d20)\uff0c\u63d0\u793a\u4fe1\u606f \u6784\u6210 < form > </ form > \u5c5e\u6027 \u5c5e\u6027\u503c \u4f5c\u7528 action url\u5730\u5740 \u6307\u5b9a\u63a5\u53d7\u5e76\u5904\u7406\u8868\u8fbe\u90a3\u6570\u636e\u7684\u670d\u52a1\u5668\u7a0b\u5e8f\u7684url\u5730\u5740 method get/post \u8bbe\u7f6e\u8868\u5355\u6570\u636e\u7684\u63d0\u4ea4\u65b9\u5f0f name \u540d\u79f0 \u8bbe\u7f6e\u8868\u5355\u540d\u79f0 input \u8f93\u5165\u8868\u5355\u5143\u7d20 \u00b6 < input type = \"\" /> <!-- type\u6307\u5b9a\u4e0d\u540c\u7684\u63a7\u4ef6\u7c7b\u578b --> <!-- eg --> <!-- \u5355\u9009\u5c5e\u6027\u5fc5\u987b\u6709\u76f8\u540c\u7684name\u503c --> \u6027\u522b\uff1a\u7537 < input type = \"radio\" name = \"sex\" > \u5973 < input type = \"radio\" name = \"sex\" > type\u5c5e\u6027\u503c \u63cf\u8ff0 button \u70b9\u51fb\u6309\u94ae\uff08\u591a\u6570\u60c5\u51b5\u4e0b\u901a\u8fc7JS\u542f\u52a8\u811a\u672c\uff09 checkbox \u590d\u9009\u6846 file \u8f93\u5165\u5b57\u6bb5\u548c\"\u6d4f\u89c8\"\u6309\u94ae\uff0c\u4f9b\u6587\u4ef6\u4e0a\u4f20 hidden \u9690\u85cf\u7684\u8f93\u5165\u5b57\u6bb5 image \u56fe\u50cf\u5f62\u5f0f\u7684\u63d0\u4ea4\u6309\u94ae password \u5bc6\u7801\u5b57\u6bb5\uff0c\u6697\u6587\u8f93\u5165 radio \u5355\u9009\u6309\u94ae reset \u91cd\u7f6e\u6309\u94ae submit \u63d0\u4ea4\u6309\u94ae text \u8f93\u5165\u5b57\u6bb5\uff0c\u5bbd\u5ea6\u9ed8\u8ba4\u4e3a20\u5b57\u7b26 input\u5176\u4ed6\u5c5e\u6027 \u5c5e\u6027\u503c \u63cf\u8ff0 name \u81ea\u5b9a\u4e49 \u540d\u79f0 value \u81ea\u5b9a\u4e49 input\u7684\u5143\u7d20\u503c checked checked \u89c4\u5b9a\u6b64input\u5143\u7d20\u9996\u6b21\u52a0\u8f7d\u65f6\u5e94\u5f53\u88ab\u9009\u4e2d maxlength \u6b63\u6574\u6570 \u8f93\u5165\u5b57\u6bb5\u5b57\u7b26\u7684\u6700\u5927\u957f\u5ea6 label \u6807\u7b7e \u00b6 \u7ed1\u5b9a\u4e00\u4e2a\u8868\u5355\u5143\u7d20\uff0c\u5f53\u7528\u6237\u70b9\u51fb label \u6807\u7b7e\u5185\u7684\u6587\u672c\u65f6\uff0c\u4f1a\u81ea\u52a8\u5bf9\u5e94\u5230\u5bf9\u5e94\u7684\u8868\u5355\u5143\u7d20\u4e0a < label for = \"sex\" > \u7537 </ label > < input type = \"radio\" name = \"sex\" id = \"sex\" /> <!-- for \u4e0e id \u7684\u5c5e\u6027\u503c\u8981\u76f8\u540c --> select \u4e0b\u62c9\u8868\u5355\u5143\u7d20 \u00b6 select \u4e2d\u81f3\u5c11\u6709\u4e00\u4e2a option\uff0coption < select > < option > \u9009\u98791 </ option > < option > \u9009\u98792 </ option > <!-- selected \u8868\u793a\u9ed8\u8ba4\u9009\u4e2d\u9879 --> < option selected = \"selected\" > \u9009\u98793 </ option > ... </ select > textarea \u6587\u672c\u57df\u5143\u7d20 \u00b6 \u7528\u4e8e\u8f93\u5165\u591a\u884c\u7684\u6587\u672c\u8f93\u5165\u7684\u63a7\u4ef6 <!-- \u5b9e\u9645\u5f00\u53d1\u4e2d\u90fd\u662f\u7528CSS\u6765\u6539\u53d8\u5927\u5c0f --> < textraea rows = \"3\" cols = \"20\" > \u6587\u672c\u5185\u5bb9 </ textraea > \u5176\u4ed6\u6807\u7b7e \u00b6 button \u00b6 < button > \u641c\u7d22 </ button > /*\u7b49\u6548\u4e8e < input type = \"button\" value = \"\u641c\u7d22\" > */ \u53c2\u8003 \u00b6 \u9ed1\u9a6c\u7a0b\u5e8f\u5458pink\u8001\u5e08\u524d\u7aef\u5165\u95e8\u6559\u7a0b\uff0c\u96f6\u57fa\u7840\u5fc5\u770b\u7684h5(html5)+css3+\u79fb\u52a8\u7aef\u524d\u7aef\u89c6\u9891\u6559\u7a0b_\u54d4\u54e9\u54d4\u54e9_bilibili","title":"HTML"},{"location":"%E5%89%8D%E7%AB%AF/HTML/#html","text":"","title":"HTML"},{"location":"%E5%89%8D%E7%AB%AF/HTML/#_1","text":"","title":"\u57fa\u7840\u6982\u5ff5"},{"location":"%E5%89%8D%E7%AB%AF/HTML/#html_1","text":"HTML \u662f\u4e00\u79cd\u8d85\u6587\u672c\u6807\u8bb0\u8bed\u8a00\uff08\u5373\u53ef\u4ee5\u52a0\u5165\u591a\u5a92\u4f53\u5185\u5bb9\uff0c\u8d85\u8d8a\u4e86\u6587\u672c\u9650\u5236\uff0c\u8fd8\u652f\u6301\u8d85\u94fe\u63a5\uff09","title":"HTML"},{"location":"%E5%89%8D%E7%AB%AF/HTML/#web","text":"\u6784\u6210\uff1a\u7ed3\u6784\uff08HTML\uff09\uff0c\u8868\u73b0\uff08CSS\uff09\uff0c\u884c\u4e3a\uff08JS\uff09","title":"WEB\u6807\u51c6"},{"location":"%E5%89%8D%E7%AB%AF/HTML/#vscode","text":"","title":"VSCODE\u4f7f\u7528"},{"location":"%E5%89%8D%E7%AB%AF/HTML/#_2","text":"\u63d2\u4ef6 \u4f5c\u7528 open in browser \u53f3\u952e\u5373\u53ef\u5728\u6d4f\u89c8\u5668\u4e2d\u6253\u5f00 Auto Rename Tag \u81ea\u52a8\u8865\u5168\u53cc\u6807\u7b7e","title":"\u63d2\u4ef6"},{"location":"%E5%89%8D%E7%AB%AF/HTML/#_3","text":"\u5feb\u901f\u683c\u5f0f\u5316\u6587\u6863\uff1a ALT SHIFT F \u4fdd\u5b58\u6587\u4ef6\u81ea\u52a8\u683c\u5f0f\u5316\uff1a\u5728 setting.json \u4e2d\u52a0\u4e0a \"editor.formatOnType\" : true , // HTML \u6587\u4ef6\u4fdd\u5b58\u81ea\u52a8\u683c\u5f0f\u5316 \"editor.formatOnSave\" : true","title":"\u5feb\u901f\u683c\u5f0f\u5316"},{"location":"%E5%89%8D%E7%AB%AF/HTML/#_4","text":"","title":"\u6807\u7b7e"},{"location":"%E5%89%8D%E7%AB%AF/HTML/#_5","text":"\u6807\u7b7e\u540d \u8bf4\u660e \\(<html></html>\\) \u6839\u6807\u7b7e \\(<head></head>\\) \u5934\u90e8\u6807\u7b7e \\(<title></title>\\) \u6807\u9898\u6807\u7b7e \\(<body></body>\\) \u4e3b\u4f53\u6807\u7b7e \\(<!DOCTYPE html>\\) \u58f0\u660ehtml\u7248\u672c \\(<html lang=\"zh-CN\">\\) \u58f0\u660e\u7f51\u9875\u8bed\u8a00 \\(<meta charset=\"UTF-8\">\\) \u58f0\u660e\u5b57\u7b26\u96c6\u4e3a\u4e07\u56fd\u7801","title":"\u57fa\u672c\u7ed3\u6784\u6807\u7b7e"},{"location":"%E5%89%8D%E7%AB%AF/HTML/#_6","text":"\u6700\u591a\u67096\u7ea7\u6807\u9898\u6807\u7b7e < h1 > \u4e00\u7ea7\u6807\u9898 </ h1 > < h2 > \u4e8c\u7ea7\u6807\u9898 </ h2 > < h3 > \u4e09\u7ea7\u6807\u9898 </ h3 >","title":"\u6807\u9898\u6807\u7b7e"},{"location":"%E5%89%8D%E7%AB%AF/HTML/#_7","text":"\u6807\u7b7e\u540d \u8bf4\u660e \\(<p></p>\\) \u6bb5\u843d\u6807\u7b7e\uff0cparagraph \\(<br>\\) \u6362\u884c\u6807\u7b7e\uff0cbreak","title":"\u6bb5\u843d\u548c\u6362\u884c\u6807\u7b7e"},{"location":"%E5%89%8D%E7%AB%AF/HTML/#_8","text":"\u6807\u7b7e\u540d \u8bf4\u660e \\(<strong></strong>\\) \u6216\u8005 \\(<b></b>\\) \u52a0\u7c97 \\(<em></em>\\) \u6216\u8005 \\(<i></i>\\) \u503e\u659c \\(<del></del>\\) \u6216\u8005 \\(<s></s>\\) \u5220\u9664\u7ebf \\(<ins></ins>\\) \u6216\u8005 \\(<u></u>\\) \u4e0b\u5212\u7ebf","title":"\u6587\u672c\u683c\u5f0f\u5316\u6807\u7b7e"},{"location":"%E5%89%8D%E7%AB%AF/HTML/#div-span","text":"\u8fd92\u4e2a\u6807\u7b7e\u90fd\u662f\u5e03\u5c40\u7528 \u6807\u7b7e\u540d \u8bf4\u660e \\(<div></div>\\) \u5206\u533a\uff0c\u5360\u4e00\u884c\uff0cdivision \\(<span></span>\\) \u8de8\u8ddd\uff0c\u53ef\u4ee5\u591a\u4e2a\u5360\u4e00\u884c\uff0c","title":"div \u548c span \u6807\u7b7e"},{"location":"%E5%89%8D%E7%AB%AF/HTML/#_9","text":"< img src = \"\u8def\u5f84\u6216\u8005\u94fe\u63a5\" /> img \u6807\u7b7e\u4e2d\u53ef\u52a0\u7684\u5c5e\u6027 \u5c5e\u6027 \u8bf4\u660e src \u8def\u5f84\u6216\u94fe\u63a5\uff0csource alt \u663e\u793a\u5931\u8d25\u65f6\u7684\u66ff\u6362\u6587\u672c\uff0calternative title \u9f20\u6807\u653e\u5728\u56fe\u7247\u4e0a\u65f6\u7684\u8bf4\u660e\u6587\u5b57 width \u8bbe\u5b9a\u5bbd\u5ea6 height \u8bbe\u5b9a\u9ad8\u5ea6 border \u8bbe\u5b9a\u8fb9\u6846\u7c97\u7ec6 \u5bbd\u5ea6\u548c\u9ad8\u5ea6\u53ea\u8bbe\u5b9a\u4e00\u4e2a\u65f6\u7eb5\u6a2a\u6bd4\u662f\u56fa\u5b9a\u7684","title":"\u56fe\u50cf\u6807\u7b7e"},{"location":"%E5%89%8D%E7%AB%AF/HTML/#_10","text":"<!-- anchor --> <!-- target=\"_self\"\u65f6\u4e0d\u5f00\u65b0\u7a97\u53e3 \"_blank\"\u65f6\u5f00\u65b0\u7a97\u53e3 --> < a herf = \"\u8df3\u8f6c\u76ee\u6807\" target = \"\u7a97\u53e3\u5f39\u51fa\u65b9\u5f0f\" > \u6587\u672c\u6216\u56fe\u50cf\u6807\u7b7e </ a > <!-- herf \u662fhtml\u6587\u4ef6\u65f6\u662f\u5185\u90e8\u94fe\u63a5\uff0c\u662f\u7f51\u9875\u94fe\u63a5\u65f6\u662f\u5916\u90e8\u94fe\u63a5 --> <!-- herf = \"#\" \u8868\u793a \u7a7a\u94fe\u63a5--> <!-- herf = \"\u6587\u4ef6\u8def\u5f84\" \u65f6\u53ef\u4ee5\u5b9e\u73b0\u4e0b\u8f7d\u6587\u4ef6--> \u951a\u70b9\u94fe\u63a5 <!-- \u51fa\u53d1\u4f4d\u7f6e --> < a herf = \"#tag\" > \u6587\u672c\u6216\u56fe\u50cf\u6807\u7b7e </ a > <!-- \u76ee\u6807\u4f4d\u7f6e\u5728\u6807\u9898\u5904 --> < h2 id = \"tag\" > \u6807\u9898 </ h2 >","title":"\u8d85\u94fe\u63a5\u6807\u7b7e"},{"location":"%E5%89%8D%E7%AB%AF/HTML/#_11","text":"<!-- \u8fd9\u662f\u6ce8\u91ca\u6807\u7b7e\uff0cvscode \u7528 Ctrl+/ --> \u7279\u6b8a\u5b57\u7b26\uff1a HTML \u7b26\u53f7\u5b9e\u4f53\u53c2\u8003\u624b\u518c | \u83dc\u9e1f\u6559\u7a0b \u5e38\u7528\uff1a | \u63cf\u8ff0 | \u4ee3\u7801 | | -------- | ----------- | | \u7a7a\u683c | &nbsp; | | \u5927\u4e8e | &gt; | | \u5c0f\u4e8e | &lt; | | \u4e0e\u53f7 | &amp; | | \u4e58\u6cd5 | &times; | | \u9664\u6cd5 | &divide; | | \u5e73\u65b9 | &sup2; | | \u7acb\u65b9 | &sup3; |","title":"\u6ce8\u91ca\u548c\u7279\u6b8a\u5b57\u7b26"},{"location":"%E5%89%8D%E7%AB%AF/HTML/#_12","text":"< table > <!-- \u8868\u683c\u6839\u6807\u7b7e --> < tr > <!-- \u8868\u683c\u4e2d\u7684\u884c --> < td > \u5355\u5143\u683c\u5185\u7684\u6587\u5b57 </ td > <!-- \u6bcf\u884c\u4e2d\u6bcf\u683c\u7684\u5185\u5bb9 --> ... </ tr > ... </ table > <!-- \u8868\u5934\u5355\u5143\u683c\u6807\u7b7e\uff0c\u6307\u660e\u67d0\u4e00\u884c\u662f\u8868\u5934\uff0c\u548ctd\u540c\u7ea7\uff0c\u4f1a\u52a0\u7c97\u5e76\u5c45\u4e2d --> < th > ... </ th > \u8868\u683c\u5c5e\u6027 \u4e0d\u592a\u5e38\u7528\uff0c\u4f1a\u901a\u8fc7CSS\u8bbe\u7f6e \u5c5e\u6027\u540d \u5c5e\u6027\u503c \u63cf\u8ff0 align left / center / right \u76f8\u5bf9\u5468\u56f4\u5143\u7d20\u7684\u5bf9\u9f50\u65b9\u5f0f border 1 / \"\" \u662f\u5426\u6709\u8fb9\u6846\uff0c\"\"\u4e3a\u9ed8\u8ba4\uff0c\u8868\u793a\u6ca1\u6709 cellpadding \u50cf\u7d20\u503c \u8fb9\u6cbf\u4e0e\u5185\u5bb9\u4e4b\u95f4\u7684\u7a7a\u767d\uff0c\u9ed8\u8ba4\u4e3a1 cellspacing \u50cf\u7d20\u503c \u5355\u5143\u683c\u4e4b\u95f4\u7684\u7a7a\u767d\uff0c\u9ed8\u8ba42 width \u50cf\u7d20\u503c / \u767e\u5206\u6bd4 \u5bbd\u5ea6 height \u50cf\u7d20\u503c / \u767e\u5206\u6bd4 \u9ad8\u5ea6 \u8868\u683c\u7ed3\u6784\u6807\u7b7e < table > < thead ></ thead > <!-- \u5934\u90e8\u6807\u7b7e --> < tbody ></ tbody > <!-- \u4e3b\u4f53\u6807\u7b7e --> </ table > \u5408\u5e76\u5355\u5143\u683c\uff08td\u7684\u5c5e\u6027\uff09 \u8de8\u884c\u5408\u5e76\uff1arowspan=\"\u5408\u5e76\u5355\u5143\u683c\u7684\u4e2a\u6570\"\uff0c\u6700\u4e0a\u4fa7\u5355\u5143\u683c\u4e3a\u76ee\u6807\u5355\u5143\u683c \u8de8\u5217\u5408\u5e76\uff1acolspan=\"\u5408\u5e76\u5355\u5143\u683c\u7684\u4e2a\u6570\"\uff0c\u6700\u5de6\u4fa7\u5355\u5143\u683c\u4e3a\u76ee\u6807\u5355\u5143\u683c","title":"\u8868\u683c\u6807\u7b7e"},{"location":"%E5%89%8D%E7%AB%AF/HTML/#_13","text":"\u5206\u7c7b\uff1a\u65e0\u5e8f\u5217\u8868\uff0c\u6709\u5e8f\u5217\u8868\uff0c\u81ea\u5b9a\u4e49\u5217\u8868 \u5217\u8868\u81ea\u5e26\u7684\u6837\u5f0f\u5c5e\u6027\u53ef\u4ee5\u901a\u8fc7CSS\u4fee\u6539 \u65e0\u5e8f\u5217\u8868 < ul > <!-- ul\u4e2d\u53ea\u80fd\u653eli\u6807\u7b7e\uff0c\u4f46li\u4e2d\u53ef\u4ee5\u653e\u4efb\u4f55\u6807\u7b7e --> < li > \u5217\u8868\u98791 </ li > < li > \u5217\u8868\u98792 </ li > < li > \u5217\u8868\u98793 </ li > ... </ ul > \u6709\u5e8f\u5217\u8868 < ol > <!-- ol\u4e2d\u53ea\u80fd\u653eli\u6807\u7b7e\uff0c\u4f46li\u4e2d\u53ef\u4ee5\u653e\u4efb\u4f55\u6807\u7b7e --> < li > \u5217\u8868\u98791 </ li > < li > \u5217\u8868\u98792 </ li > < li > \u5217\u8868\u98793 </ li > ... </ ol > \u81ea\u5b9a\u4e49\u5217\u8868 < dl > <!-- dl\u4e2d\u53ea\u80fd\u653edt/dd\u6807\u7b7e\uff0c\u4f46dt/dd\u4e2d\u53ef\u4ee5\u653e\u4efb\u4f55\u6807\u7b7e --> < dt > \u540d\u8bcd1 </ dt > < dd > \u540d\u8bcd1\u89e3\u91ca1 </ dd > < dd > \u540d\u8bcd1\u89e3\u91ca2 </ dd > </ dl >","title":"\u5217\u8868\u6807\u7b7e"},{"location":"%E5%89%8D%E7%AB%AF/HTML/#_14","text":"\u8868\u5355\u7528\u4e8e\u6536\u96c6\u7528\u6237\u4fe1\u606f \u8868\u5355\u7531 \u8868\u5355\u57df\uff0c\u8868\u5355\u63a7\u4ef6(\u8868\u5355\u5143\u7d20)\uff0c\u63d0\u793a\u4fe1\u606f \u6784\u6210 < form > </ form > \u5c5e\u6027 \u5c5e\u6027\u503c \u4f5c\u7528 action url\u5730\u5740 \u6307\u5b9a\u63a5\u53d7\u5e76\u5904\u7406\u8868\u8fbe\u90a3\u6570\u636e\u7684\u670d\u52a1\u5668\u7a0b\u5e8f\u7684url\u5730\u5740 method get/post \u8bbe\u7f6e\u8868\u5355\u6570\u636e\u7684\u63d0\u4ea4\u65b9\u5f0f name \u540d\u79f0 \u8bbe\u7f6e\u8868\u5355\u540d\u79f0","title":"\u8868\u5355\u6807\u7b7e"},{"location":"%E5%89%8D%E7%AB%AF/HTML/#input","text":"< input type = \"\" /> <!-- type\u6307\u5b9a\u4e0d\u540c\u7684\u63a7\u4ef6\u7c7b\u578b --> <!-- eg --> <!-- \u5355\u9009\u5c5e\u6027\u5fc5\u987b\u6709\u76f8\u540c\u7684name\u503c --> \u6027\u522b\uff1a\u7537 < input type = \"radio\" name = \"sex\" > \u5973 < input type = \"radio\" name = \"sex\" > type\u5c5e\u6027\u503c \u63cf\u8ff0 button \u70b9\u51fb\u6309\u94ae\uff08\u591a\u6570\u60c5\u51b5\u4e0b\u901a\u8fc7JS\u542f\u52a8\u811a\u672c\uff09 checkbox \u590d\u9009\u6846 file \u8f93\u5165\u5b57\u6bb5\u548c\"\u6d4f\u89c8\"\u6309\u94ae\uff0c\u4f9b\u6587\u4ef6\u4e0a\u4f20 hidden \u9690\u85cf\u7684\u8f93\u5165\u5b57\u6bb5 image \u56fe\u50cf\u5f62\u5f0f\u7684\u63d0\u4ea4\u6309\u94ae password \u5bc6\u7801\u5b57\u6bb5\uff0c\u6697\u6587\u8f93\u5165 radio \u5355\u9009\u6309\u94ae reset \u91cd\u7f6e\u6309\u94ae submit \u63d0\u4ea4\u6309\u94ae text \u8f93\u5165\u5b57\u6bb5\uff0c\u5bbd\u5ea6\u9ed8\u8ba4\u4e3a20\u5b57\u7b26 input\u5176\u4ed6\u5c5e\u6027 \u5c5e\u6027\u503c \u63cf\u8ff0 name \u81ea\u5b9a\u4e49 \u540d\u79f0 value \u81ea\u5b9a\u4e49 input\u7684\u5143\u7d20\u503c checked checked \u89c4\u5b9a\u6b64input\u5143\u7d20\u9996\u6b21\u52a0\u8f7d\u65f6\u5e94\u5f53\u88ab\u9009\u4e2d maxlength \u6b63\u6574\u6570 \u8f93\u5165\u5b57\u6bb5\u5b57\u7b26\u7684\u6700\u5927\u957f\u5ea6","title":"input \u8f93\u5165\u8868\u5355\u5143\u7d20"},{"location":"%E5%89%8D%E7%AB%AF/HTML/#label","text":"\u7ed1\u5b9a\u4e00\u4e2a\u8868\u5355\u5143\u7d20\uff0c\u5f53\u7528\u6237\u70b9\u51fb label \u6807\u7b7e\u5185\u7684\u6587\u672c\u65f6\uff0c\u4f1a\u81ea\u52a8\u5bf9\u5e94\u5230\u5bf9\u5e94\u7684\u8868\u5355\u5143\u7d20\u4e0a < label for = \"sex\" > \u7537 </ label > < input type = \"radio\" name = \"sex\" id = \"sex\" /> <!-- for \u4e0e id \u7684\u5c5e\u6027\u503c\u8981\u76f8\u540c -->","title":"label \u6807\u7b7e"},{"location":"%E5%89%8D%E7%AB%AF/HTML/#select","text":"select \u4e2d\u81f3\u5c11\u6709\u4e00\u4e2a option\uff0coption < select > < option > \u9009\u98791 </ option > < option > \u9009\u98792 </ option > <!-- selected \u8868\u793a\u9ed8\u8ba4\u9009\u4e2d\u9879 --> < option selected = \"selected\" > \u9009\u98793 </ option > ... </ select >","title":"select \u4e0b\u62c9\u8868\u5355\u5143\u7d20"},{"location":"%E5%89%8D%E7%AB%AF/HTML/#textarea","text":"\u7528\u4e8e\u8f93\u5165\u591a\u884c\u7684\u6587\u672c\u8f93\u5165\u7684\u63a7\u4ef6 <!-- \u5b9e\u9645\u5f00\u53d1\u4e2d\u90fd\u662f\u7528CSS\u6765\u6539\u53d8\u5927\u5c0f --> < textraea rows = \"3\" cols = \"20\" > \u6587\u672c\u5185\u5bb9 </ textraea >","title":"textarea \u6587\u672c\u57df\u5143\u7d20"},{"location":"%E5%89%8D%E7%AB%AF/HTML/#_15","text":"","title":"\u5176\u4ed6\u6807\u7b7e"},{"location":"%E5%89%8D%E7%AB%AF/HTML/#button","text":"< button > \u641c\u7d22 </ button > /*\u7b49\u6548\u4e8e < input type = \"button\" value = \"\u641c\u7d22\" > */","title":"button"},{"location":"%E5%89%8D%E7%AB%AF/HTML/#_16","text":"\u9ed1\u9a6c\u7a0b\u5e8f\u5458pink\u8001\u5e08\u524d\u7aef\u5165\u95e8\u6559\u7a0b\uff0c\u96f6\u57fa\u7840\u5fc5\u770b\u7684h5(html5)+css3+\u79fb\u52a8\u7aef\u524d\u7aef\u89c6\u9891\u6559\u7a0b_\u54d4\u54e9\u54d4\u54e9_bilibili","title":"\u53c2\u8003"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/","text":"\u6570\u636e\u5e93\u7cfb\u7edf \u00b6 \u7b2c\u4e00\u7ae0 \u6570\u636e\u5e93\u6982\u89c8 \u00b6 \u6570\u636e\u5e93\u53d1\u5c55\u4e09\u9636\u6bb5 \u00b6 \u4eba\u5de5\u7ba1\u7406\u9636\u6bb5\uff1a\u4e0d\u80fd\u957f\u671f\u4fdd\u5b58\uff0c\u4e0d\u5177\u6709\u72ec\u7acb\u6027\uff0c\u4e0d\u5171\u4eab \u6587\u4ef6\u7cfb\u7edf\u9636\u6bb5\uff1a\u957f\u671f\u4fdd\u5b58\uff0c\u72ec\u7acb\u6027\u5dee\uff0c\u5171\u4eab\u6027\u5dee\uff0c\u5197\u4f59\u5ea6\u5927\uff0c \u6570\u636e\u5e93\u7cfb\u7edf\u9636\u6bb5\uff1a\u7279\u70b9\uff1a1.\u6570\u636e\u7ed3\u6784\u5316 2.\u5171\u4eab\u6027\u9ad8\uff0c\u5197\u4f59\u5ea6\u4f4e\uff0c\u6613\u4e8e\u6269\u5145 3.\u6570\u636e\u72ec\u7acb\u6027\u9ad8 4.\u6570\u636e\u7edf\u4e00\u7ba1\u7406\u4e0e\u63a7\u5236 \u6570\u636e\u5e93\u7cfb\u7edf\u7ec4\u6210 \u00b6 \u6570\u636e\u5e93 \u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf\uff08DBMS\uff09 \u6570\u636e\u5e93\u7684\u5e94\u7528\u7a0b\u5e8f \u6570\u636e\u5e93\u7cfb\u7edf\u7684\u4eba\u5458\uff1a\u7ba1\u7406\u5458\uff08DBA\uff09 ... \u4e09\u7ea7\u6a21\u5f0f\u4e0e\u4e8c\u7ea7\u6620\u50cf \u00b6 \u4e09\u7ea7\u6a21\u5f0f\uff1a\u5916\u6a21\u5f0f\uff0c\u6a21\u5f0f\uff0c\u5185\u6a21\u5f0f \u6a21\u5f0f\uff1a\u4e5f\u79f0\u903b\u8f91\u6a21\u5f0f\uff0c\u4e00\u4e2a\u6570\u636e\u5e93\u53ea\u6709\u4e00\u4e2a\u6a21\u5f0f\uff0c\u662f\u6570\u636e\u5e93\u5168\u4f53\u6570\u636e\u7684\u903b\u8f91\u7ed3\u6784\u548c\u7279\u5f81\u7684\u63cf\u8ff0 \u5916\u6a21\u5f0f\uff1a\u4e5f\u79f0\u5b50\u6a21\u5f0f\u6216\u7528\u6237\u6a21\u5f0f\uff0c\u662f\u6a21\u5f0f\u7684\u5b50\u96c6\uff0c\u4e00\u4e2a\u6570\u636e\u5e93\u53ef\u4ee5\u6709\u591a\u4e2a\u5916\u6a21\u5f0f \u5185\u6a21\u5f0f\uff1a\u4e5f\u79f0\u5b58\u50a8\u6a21\u5f0f\uff0c\u53ea\u6709\u4e00\u4e2a\u5185\u6a21\u5f0f\uff0c\u662f\u6570\u636e\u7269\u7406\u7ed3\u6784\u548c\u5b58\u50a8\u65b9\u5f0f\u7684\u63cf\u8ff0 \u4e8c\u7ea7\u6620\u50cf\uff1a \u5916\u6a21\u5f0f/\u6a21\u5f0f\u6620\u50cf\uff1a\u6a21\u5f0f\u6539\u53d8\u65f6\uff0c\u5bf9\u6620\u50cf\u505a\u51fa\u76f8\u5e94\u7684\u6539\u53d8\u53ef\u4ee5\u4f7f\u5916\u6a21\u5f0f\u4fdd\u6301\u4e0d\u53d8\uff0c\u4fdd\u8bc1\u6570\u636e\u548c\u7a0b\u5e8f\u7684\u903b\u8f91\u72ec\u7acb\u6027 \u6a21\u5f0f/\u5185\u6a21\u5f0f\u6620\u50cf\uff1a\u5185\u6a21\u5f0f\u6539\u53d8\u65f6\uff0c\u5bf9\u6620\u50cf\u505a\u51fa\u76f8\u5e94\u7684\u6539\u53d8\u53ef\u4ee5\u4f7f\u6a21\u5f0f\u4fdd\u6301\u4e0d\u53d8\uff0c\u4fdd\u8bc1\u6570\u636e\u7684\u7269\u7406\u72ec\u7acb\u6027 \u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf \u00b6 \u529f\u80fd\uff1a\u6570\u636e\u5b9a\u4e49\uff0c\u6570\u636e\u64cd\u7eb5\uff0c\u6570\u636e\u5e93\u7684\u4e8b\u52a1\u7ba1\u7406\u548c\u8fd0\u884c\u7ba1\u7406\uff0c\u6570\u636e\u5e93\u7684\u521b\u5efa\u548c\u7ef4\u62a4 \u6570\u636e\u6a21\u578b \u00b6 \u5206\u7c7b\uff1a\u6982\u5ff5\u6570\u636e\u6a21\u578b\uff0c\u903b\u8f91\u6570\u636e\u6a21\u578b\uff0c\u7269\u7406\u6570\u636e\u6a21\u578b \u6982\u5ff5\u6570\u636e\u6a21\u578b\uff1aER\u56fe ER\u6a21\u578b\u4e09\u8981\u7d20\uff1a\u5b9e\u4f53\uff0c\u5c5e\u6027\uff0c\u8054\u7cfb \u903b\u8f91\u6570\u636e\u6a21\u578b\uff08\u4e00\u822c\u90fd\u76f4\u63a5\u53eb\u6570\u636e\u6a21\u578b\uff09\uff1a\u5c42\u6b21\u6a21\u578b\uff0c\u7f51\u72b6\u6a21\u578b\uff0c\u5173\u7cfb\u6a21\u578b\uff0c\u9762\u5411\u5bf9\u8c61\u6a21\u578b \u6570\u636e\u6a21\u578b\u4e09\u8981\u7d20\uff1a\u6570\u636e\u7ed3\u6784\uff0c\u6570\u636e\u64cd\u4f5c\uff0c\u6570\u636e\u5b8c\u6574\u6027\u7ea6\u675f \u5c42\u6b21\u6a21\u578b\u662f\u4e00\u68f5\u6811\uff0c\u5173\u7cfb\u6a21\u578b\u662f\u4e00\u5f20\u4e8c\u7ef4\u8868 \u7b2c\u4e8c\u7ae0 \u5173\u7cfb\u6570\u636e\u5e93\u6a21\u578b \u00b6 \u5173\u7cfb\u7684\u6027\u8d28 \u00b6 \u5217\u662f\u540c\u8d28\u7684\uff0c\u5373\u6570\u636e\u7c7b\u578b\u76f8\u540c \u4e0d\u540c\u7684\u5217\u53ef\u4ee5\u51fa\u5176\u540c\u4e00\u4e2a\u57df\uff0c\u4f46\u5c5e\u6027\u540d\u8981\u4e0d\u540c \u5217\u7684\u987a\u5e8f\u53ef\u4ee5\u4efb\u610f\u4ea4\u6362 \u4efb\u610f\u4e24\u4e2a\u5143\u7ec4\u4e0d\u53ef\u4ee5\u5b8c\u5168\u76f8\u540c \u5143\u7ec4\u987a\u5e8f\u53ef\u4ee5\u4efb\u610f \u5206\u91cf\u5fc5\u987b\u53d6\u539f\u5b50\u503c\uff0c\u5373\u8981\u6c42\u6bcf\u4e2a\u5206\u91cf\u90fd\u662f\u4e0d\u53ef\u518d\u5206\u7684\u6570\u636e\u9879 \u5173\u7cfb\u6570\u636e\u7ed3\u6784 \u00b6 \u4e00\u4e2a\u5173\u7cfb\u5c31\u662f\u4e00\u4e2a\u89c4\u8303\u5316\u7684\u4e8c\u7ef4\u8868\uff0c\u7b1b\u5361\u5c14\u79ef\u7684\u6709\u610f\u4e49\u7684\u6709\u9650\u5b50\u96c6 \u4e00\u4e2a\u5173\u7cfb\u7531\u5173\u7cfb\u540d\uff0c\u5173\u7cfb\u6a21\u5f0f\uff0c\u5173\u7cfb\u5b9e\u4f8b\u7ec4\u6210 \u5143\u7ec4\uff0c\u5c5e\u6027\uff0c\u7801\uff0c\u57df\uff0c\u5206\u91cf\uff0c\u5173\u7cfb\u6a21\u5f0f \u5019\u9009\u7801\uff1a\u552f\u4e00\u6027\uff0c\u6700\u5c0f\u6027 \u8d85\u7801\uff1a\u53ef\u4ee5\u552f\u4e00\u7684\u786e\u5b9a\u4e00\u884c\uff0c\u5019\u9009\u7801\u662f\u8d85\u7801\u7684\u5b50\u96c6 \u4e3b\u7801\uff1a\u5982\u679c\u7531\u591a\u4e2a\u5019\u9009\u7801\uff0c\u9009\u4e00\u4e2a \u4e3b\u5c5e\u6027\uff1a\u5305\u542b\u5728\u5019\u9009\u7801\u4e2d\u7684\u5404\u5c5e\u6027 \u5916\u7801 \u5173\u7cfb\u6570\u636e\u8bed\u8a00\u7684\u5206\u7c7b \u00b6 \u5173\u7cfb\u4ee3\u6570\uff0c\u5173\u7cfb\u6f14\u7b97\uff0c\u57df\u6f14\u7b97\uff0cSQL \u5173\u7cfb\u64cd\u4f5c & \u5173\u7cfb\u4ee3\u6570 \u00b6 \u4f20\u7edf\u7684\u96c6\u5408\u8fd0\u7b97\uff1a\u7b1b\u5361\u5c14\u79ef\uff0c\u5e76\uff0c\u4ea4\uff0c\u5dee \u4e13\u95e8\u7684\u5173\u7cfb\u8fd0\u7b97\uff1a\u9009\u62e9\uff0c\u6295\u5f71\uff0c\u8fde\u63a5\uff08\u7b49\u503c\uff0c\u81ea\u7136\u8fde\u63a5\uff0c\u5916\u8fde\u63a5\uff0c\u5de6\u5916\uff0c\u53f3\u5916\uff09\uff0c\u9664\u6cd5 \u6570\u636e\u5b8c\u6574\u6027 \u00b6 \u5b9e\u4f53\u5b8c\u6574\u6027 \u53c2\u7167\u5b8c\u6574\u6027 \u7528\u6237\u81ea\u5b9a\u4e49\u5b8c\u6574\u6027 \u5217\u7ea7\u5b8c\u6574\u6027\u7ea6\u675f\u53ea\u80fd\u6d89\u53ca\u4e00\u4e2a\u5c5e\u6027\uff0c\u8868\u7ea7\u53ef\u4ee5\u6d89\u53ca\u591a\u4e2a\u5c5e\u6027 \u7b2c\u4e09\u7ae0 SQL\u8bed\u8a00 \u00b6 SQL\u6982\u8ff0 \u00b6 \u7279\u70b9\uff1a\u7efc\u5408\u7edf\u4e00\uff0c\u9ad8\u5ea6\u975e\u8fc7\u7a0b\u5316\uff0c\u9762\u5411\u96c6\u5408\u7684\u64cd\u4f5c\u65b9\u5f0f\uff0c\u4ee5\u540c\u4e00\u79cd\u8bed\u6cd5\u7ed3\u6784\u63d0\u4f9b\u4e24\u79cd\u4f7f\u7528\u65b9\u5f0f\uff0c\u8bed\u8a00\u7b80\u6d01\u6613\u5b66\u6613\u7528 \u6570\u636e\u5b9a\u4e49\uff08DDL\uff09\uff0c\u6570\u636e\u64cd\u7eb5\uff08DML\uff09\uff0c\u6570\u636e\u63a7\u5236\uff08DCL\uff09 \u5df4\u79d1\u65af\u8303\u5f0f\uff08BNF\uff09 \u00b6 <> \u5fc5\u9009\u9879 [ ] \u53ef\u4ee5\u51fa\u73b0\u4e00\u6b21\u6216\u4e0d\u51fa\u73b0 { } \u53ef\u4ee5\u591a\u6b21\u51fa\u73b0\u6216\u4e0d\u51fa\u73b0 | \u591a\u9009\u4e00 \u6570\u636e\u5b9a\u4e49 \u00b6 \u6570\u636e\u5e93 \u00b6 create database < \u6570\u636e\u5e93\u540d > use < \u6570\u636e\u5e93\u540d > alter database < \u6570\u636e\u5e93\u540d > drop database < \u6570\u636e\u5e93\u540d > \u57fa\u672c\u8868 \u00b6 \u5b9a\u4e49 create table < \u8868\u540d > ( < \u5217\u540d >< \u6570\u636e\u7c7b\u578b > [ < \u5217\u7ea7\u5b8c\u6574\u6027\u7ea6\u675f > ] { , < \u5217\u540d >< \u6570\u636e\u7c7b\u578b > [ < \u5217\u7ea7\u5b8c\u6574\u6027\u7ea6\u675f > ] } [, < \u8868\u7ea7\u5b8c\u6574\u6027\u7ea6\u675f > ] ) \u5217\u7ea7\u7ea6\u675f\uff1a not null, default, unique, check, primary key, foreign key foreign key: foreign key (<\u5217\u540d>) references <\u5916\u8868\u540d>(<\u5916\u8868\u5217\u540d>) \u4fee\u6539 alter table < \u8868\u540d > alter column < \u5217\u540d > < \u65b0\u6570\u636e\u7c7b\u578b > [ null | not null ] | add < \u5217\u540d > < \u6570\u636e\u7c7b\u578b > [ \u7ea6\u675f ] | drop column < \u5217\u540d > | add [ constraint < \u7ea6\u675f\u540d > ] < \u7ea6\u675f\u5b9a\u4e49 > | drop constraint < \u7ea6\u675f\u540d > \u5220\u9664 drop table < \u57fa\u672c\u8868\u540d > \u7d22\u5f15 \u00b6 \u5206\u7c7b\uff1a\u805a\u7c07\u7d22\u5f15\u548c\u975e\u805a\u7c07\u7d22\u5f15 \u9ed8\u8ba4\u975e\u805a\u7c07\uff0c\u805a\u7c07\u7d22\u5f15\u53ea\u53ef\u4ee5\u5efa\u7acb\u4e00\u4e2a \u805a\u7c07\u7d22\u5f15\uff1a\u7d22\u5f15\u9879\u987a\u5e8f\u548c\u7269\u7406\u987a\u5e8f\u4e00\u81f4 \u5b9a\u4e49 create [ unique ][ clustered | notclustered ] index < \u7d22\u5f15\u540d > on < \u57fa\u672c\u8868\u540d > ( < \u5217\u540d > [ asc | desc ] [ { ,( < \u5217\u540d > [ asc | desc ] } ...]) \u5220\u9664 drop index < \u8868\u540d > . < \u7d22\u5f15\u540d > \u6570\u636e\u67e5\u8be2 \u00b6 select [ all | distinct ] < \u76ee\u6807\u5217\u8868\u8fbe\u5f0f > [, < \u76ee\u6807\u5217\u8868\u8fbe\u5f0f > ]... from < \u8868\u540d\u6216\u89c6\u56fe\u540d > [, < \u8868\u540d\u6216\u89c6\u56fe\u540d > ]... [ where < \u6761\u4ef6\u8868\u8fbe\u5f0f > ] [ group by < \u5217\u540d 1 > ] [ having < \u6761\u4ef6\u8868\u8fbe\u5f0f > ] -- having \u7528\u4e8e\u6307\u5b9a\u5206\u7ec4\u8fc7\u6ee4\u6761\u4ef6 [ order by < \u5217\u540d 2 > [ asc | desc ]] \u66f4\u6539\u7ed3\u679c\u5217\u6807\u9898 \u00b6 select \u5ba2\u6237\u7f16\u53f7 as cno from CustomerInfo select 'cno' = \u5ba2\u6237\u7f16\u53f7 # = \u5217\u540d\u5fc5\u987b\u5199\u53f3\u8fb9 from CustomerInfo \u66ff\u6362\u67e5\u8be2\u7ed3\u679c\u4e2d\u7684\u6570\u636e \u00b6 select < \u5217\u540d > = case when \u6761\u4ef6 1 then \u8868\u8fbe\u5f0f 1 ... else \u8868\u8fbe\u5f0f end from < \u8868\u540d > where < \u6761\u4ef6\u8868\u8fbe\u5f0f > \u53bb\u9664\u91cd\u590d\u884c \u00b6 select unique < \u5217\u540d > from < \u8868\u540d > \u6a21\u7cca\u67e5\u8be2 \u00b6 % \u8868\u793a\u4efb\u610f\u957f\u5ea6\u7684\u5b57\u7b26\u4e32 _ \u8868\u793a\u4efb\u610f\u4e00\u4e2a\u5b57\u7b26 select * from < \u8868\u540d > where < \u5217\u540d > like '\u6c5f\u82cf%' \u5982\u679c\u67e5\u8be2\u7684\u6761\u4ef6\u4e2d\u5305\u542b\u901a\u914d\u7b26\u9700\u8981\u8f6c\u4e49\uff1a escape\\ where \u5fae\u4fe1\u53f7 like 'wxid\\_%' escape '\\' \u7a7a\u503c\u6bd4\u8f83 \u00b6 < \u8868\u8fbe\u5f0f > is [ not ] null \u5bf9\u7ed3\u679c\u96c6\u6392\u5e8f \u00b6 [ order by < \u5217\u540d > [ asc | desc ]] [, < \u5217\u540d > [ asc | desc ]]...] # \u9ed8\u8ba4 asc \u5347\u5e8f \u5bf9\u7ed3\u679c\u96c6\u5206\u7c7b \u00b6 group by < \u8868\u8fbe\u5f0f > # eg select \u5546\u54c1\u7c7b\u522b , count ( \u5546\u54c1\u7f16\u53f7 ) as '\u79cd\u6570' from GoodsInfo group by \u5546\u54c1\u7c7b\u522b having\u7b5b\u9009 \u00b6 having \u8bed\u53e5\u7528\u5728 group by \u5b50\u53e5\u540e\u6765\u8fdb\u884c\u7b5b\u9009\uff0c\u53ea\u8f93\u51fa\u7b26\u5408\u6761\u4ef6\u7684 [ having < \u6761\u4ef6 > ] # eg select \u5546\u54c1\u7c7b\u522b , count ( \u5546\u54c1\u7f16\u53f7 ) as '\u79cd\u6570' from GoodsInfo group by \u5546\u54c1\u7c7b\u522b having count ( * ) > 1 \u805a\u5408\u51fd\u6570 \u00b6 \u805a\u5408\u51fd\u6570 \u4e0d\u5141\u8bb8 \u5d4c\u5957 sum | avg () max | min () count () # eg select count ( \u5ba2\u6237\u7f16\u53f7 ) as '\u5ba2\u6237\u6570' from OrderList \u8fde\u63a5\u67e5\u8be2 \u00b6 \u8fde\u63a5\u8c13\u8bcd from < \u8868 1 > [ \u8868 1 \u522b\u540d ], < \u8868 2 > [ \u8868 2 \u522b\u540d ][, < \u8868 3 > [ \u8868 3 \u522b\u540d ]...] \u4ee5join\u5173\u952e\u5b57\u8fde\u63a5 # \u5185\u8fde\u63a5 \u9ed8\u8ba4\u5185\u8fde\u63a5 inner join ( inner\u53ef\u4ee5\u4e0d\u5199 ) select ... # 2 \u4e2a\u8868 from < \u8868 1 > join < \u8868 2 > on < \u6761\u4ef6 > where ... select ... # 3 \u4e2a\u8868 from < \u8868 1 > join < \u8868 2 > join < \u8868 3 > on < \u6761\u4ef6 1 > on < \u6761\u4ef6 2 > where ... # \u5916\u8fde\u63a5 outer join # \u5de6\u5916 : left outer join \u53f3\u5916 : right outer join \u5b8c\u5168\u5916 : full outer join \u5d4c\u5957\u67e5\u8be2 \u00b6 \u5b50\u67e5\u8be2\u4e0d\u80fd\u5305\u542b order by \uff0c\u5373 order by \u53ea\u80fd\u5bf9\u6700\u7ec8\u67e5\u8be2\u6392\u5e8f \u5e26 in \u7684\u5b50\u67e5\u8be2 \u00b6 where \u6240\u5728\u7701\u5e02 in ( \u5b50\u67e5\u8be2 ) \u5e26\u6bd4\u8f83\u8fd0\u7b97\u7b26\u7684\u5b50\u67e5\u8be2 \u00b6 where \u6570\u91cf > ( \u5b50\u67e5\u8be2 ) # \u8fd9\u91cc\u7684\u5b50\u67e5\u8be2\u8981\u6c42\u7ed3\u679c\u53ea\u6709\u4e00\u4e2a \u5e26 ALL / ANY \u8c13\u8bcd\u7684\u5b50\u67e5\u8be2 \u00b6 \u7528\u4ee5\u89e3\u9664\u6bd4\u8f83\u8fd0\u7b97\u7b26\u8981\u6c42\u5b50\u67e5\u8be2\u7684\u7ed3\u679c\u96c6\u5143\u7d20\u53ea\u80fd\u6709\u4e00\u4e2a\u7684\u9650\u5236 where \u6570\u91cf > all ( \u5b50\u67e5\u8be2 ) # \u7b49\u6548\u4e8e where \u6570\u91cf > ( \u5e26 MAX \u7684\u5b50\u67e5\u8be2 ) # \u5f53\u7136\u8fd9\u91cc\u5b50\u67e5\u8be2\u53ea\u80fd\u67e5\u8be2\u4e00\u5217 \u5e26 EXISTS \u8c13\u8bcd\u7684\u5b50\u67e5\u8be2 \u00b6 [ not ] exists ( \u5b50\u67e5\u8be2 ) \u96c6\u5408\u67e5\u8be2 \u00b6 select \u8bed\u53e5\u7684\u67e5\u8be2\u7ed3\u679c\u662f\u7ed3\u679c\u96c6\uff0c\u6240\u4ee5\u53ef\u4ee5\u8fdb\u884c\u96c6\u5408\u8fd0\u7b97 \u5e76 UNION \u4ea4 INTERSECT \u5dee EXCEPT \u8fd9\u91cc\u7684\u7ed3\u679c\u96c6\u5217\u6570\u5fc5\u987b\u76f8\u540c\uff0c\u5bf9\u5e94\u5217\u7684\u6570\u636e\u7c7b\u578b\u4e5f\u5fc5\u987b\u76f8\u540c select ... union select ... select ... intersect select ... \u6570\u636e\u66f4\u65b0\uff08\u63d2\u5165&\u4fee\u6539&\u5220\u9664\uff09 \u00b6 \u6570\u636e\u63d2\u5165 \u00b6 # \u63d2\u5165\u5143\u7ec4 insert into < \u8868\u540d > [( < \u5217 1 > [, < \u5217 2 > ...])] values ( < \u5e38\u91cf 1 > [, < \u5e38\u91cf 2 > ...]) # \u63d2\u5165\u5b50\u67e5\u8be2 insert into < \u8868\u540d > [( < \u5217 1 > [, < \u5217 2 > ...])] < \u5b50\u67e5\u8be2 > \u6570\u636e\u4fee\u6539 \u00b6 update < \u8868\u540d > [[ as ] < \u522b\u540d > ] set < \u5217\u540d > = < \u5e38\u91cf > [, < \u5217\u540d > = < \u5e38\u91cf > ...] [ where < \u6761\u4ef6\u8868\u8fbe\u5f0f > ] \u6570\u636e\u5220\u9664 \u00b6 delete [ from ] < \u8868\u540d > [ where < \u6761\u4ef6\u8868\u8fbe\u5f0f > ] \u89c6\u56fe \u00b6 \u865a\u8868\uff0c\u53ef\u4ee5\u7528\u4ee5\u4fdd\u62a4\u6570\u636e\u5b89\u5168\u548c\u6ee1\u8db3\u4e0d\u540c\u7528\u6237\u7684\u9700\u6c42 \u521b\u5efa\u89c6\u56fe \u00b6 create view < \u89c6\u56fe\u540d > [( < \u5217\u540d > [, < \u5217\u540d > ])] as < select \u67e5\u8be2\u8bed\u53e5 > \u4fee\u6539\u89c6\u56fe \u00b6 alter view < \u89c6\u56fe\u540d > [( < \u5217\u540d > [, < \u5217\u540d > ])] as < select \u67e5\u8be2\u8bed\u53e5 > \u5220\u9664\u89c6\u56fe \u00b6 drop view < \u89c6\u56fe\u540d > \u89c6\u56fe\u67e5\u8be2 \u00b6 \u548c \u57fa\u672c\u8868 \u4e00\u81f4 \u89c6\u56fe\u66f4\u65b0 \u00b6 \u9632\u6b62\u51fa\u73b0\u8303\u56f4\u5916\u7684\u6570\u636e\u53ef\u4ee5\u5728\u5b9a\u4e49\u89c6\u56fe\u65f6\u52a0\u4e0a with check option \u63d2\u5165\u6570\u636e\uff0c\u4fee\u6539\u6570\u636e\uff0c\u5220\u9664\u6570\u636e\u90fd\u548c \u57fa\u672c\u8868 \u4e00\u81f4 \u4f46\u6709\u5f88\u591a\u9650\u5236\uff0c\u5982\u679c\u66f4\u65b0\u6210\u529f\u4e86\u4f1a\u6620\u5c04\u5230\u57fa\u672c\u8868 \u7b2c\u56db\u7ae0 \u6570\u636e\u5e93\u8bbe\u8ba1 \u00b6 \u5e7f\u4e49\uff1a\u6570\u636e\u5e93\u53ca\u5176\u5e94\u7528\u7cfb\u7edf\u7684\u8bbe\u8ba1\uff0c\u5373\u8bbe\u8ba1\u6574\u4e2a\u7684\u6570\u636e\u5e93\u5e94\u7528\u7cfb\u7edf \u72ed\u4e49\uff1a\u6570\u636e\u5e93\u672c\u8eab\u7684\u8bbe\u8ba1\uff0c\u5373\u8bbe\u8ba1\u6570\u636e\u5e93\u7684\u5404\u7ea7\u6a21\u5f0f\u5e76\u5efa\u7acb\u6570\u636e\u5e93 \u6570\u636e\u5e93\u8bbe\u8ba1\u7684 6 \u4e2a\u9636\u6bb5\uff1a \u9700\u6c42\u5206\u6790\u9636\u6bb5\uff1a\u6570\u636e\u6d41\u56fe\uff0c\u6570\u636e\u5b57\u5178 \u6982\u5ff5\u7ed3\u6784\u8bbe\u8ba1\u9636\u6bb5\uff1a\u6982\u5ff5\u6570\u636e\u6a21\u578b ER \u56fe \u903b\u8f91\u7ed3\u6784\u8bbe\u8ba1\u9636\u6bb5 \u7269\u7406\u7ed3\u6784\u8bbe\u8ba1\u9636\u6bb5 \u6570\u636e\u5e93\u5b9e\u65bd\u9636\u6bb5 \u6570\u636e\u5e93\u8fd0\u884c\u4e0e\u7ef4\u62a4\u9636\u6bb5 \u6982\u5ff5\u7ed3\u6784\u8bbe\u8ba1 \u00b6 \u81ea\u9876\u5411\u4e0b\uff0c\u81ea\u5e95\u5411\u4e0a\uff0cER\u8bbe\u8ba1\u65b9\u6cd5\uff0cEER\u8bbe\u8ba1\u65b9\u6cd5 \u7531\u5c40\u90e8\u89c6\u56fe\u5230\u5168\u5c40\u6982\u5ff5\u7ed3\u6784\uff1a\u4e00\u6b21\u96c6\u6210\uff0c\u591a\u6b21\u96c6\u6210 \u96c6\u6210\u5305\u62ec\uff1a\u5408\u5e76\uff0c\u6d88\u9664\u5197\u4f59 \u5408\u5e76\u7684\u4e09\u79cd\u7c7b\u578b\u7684\u51b2\u7a81\uff1a\u547d\u540d\u51b2\u7a81\uff0c\u5c5e\u6027\u51b2\u7a81\uff0c\u6982\u5ff5\u51b2\u7a81 \u903b\u8f91\u7ed3\u6784\u8bbe\u8ba1 \u00b6 \u6b65\u9aa4\uff1a \u5c06\u6982\u5ff5\u6a21\u578b\u8f6c\u5316\u4e3a\u4e00\u822c\u7684\u5173\u7cfb\uff0c\u7f51\u72b6\uff0c\u5c42\u6b21\u6a21\u578b \u5bf9\u6570\u636e\u6a21\u578b\u8fdb\u884c\u4f18\u5316 \u8bbe\u8ba1\u7528\u6237\u5916\u6a21\u5f0f \u4e8c\u5143\u5173\u7cfb\uff1a1\u5bf91\uff0c1\u5bf9\u591a\uff0c\u591a\u5bf9\u591a \u7b2c\u4e94\u7ae0 \u5173\u7cfb\u89c4\u8303\u5316\u7406\u8bba \u00b6 \u6570\u636e\u5197\u4f59\u548c\u64cd\u4f5c\u5f02\u5e38 \u00b6 \u6570\u636e\u5197\u4f59\uff1a\u540c\u4e00\u6570\u636e\u5728\u4e00\u4e2a\u6216\u591a\u4e2a\u6570\u636e\u6587\u4ef6\u4e2d\u91cd\u590d\u50a8\u5b58 \u6570\u636e\u5197\u4f59\u4f1a\u5bfc\u81f4\u7684\u64cd\u4f5c\u5f02\u5e38\uff1a\u63d2\u5165\u5f02\u5e38\uff0c\u5220\u9664\u5f02\u5e38\uff0c\u4fee\u6539\u5f02\u5e38 \u51fd\u6570\u4f9d\u8d56 \u00b6 \u5206\u7c7b\uff1a \u5e73\u51e1\u51fd\u6570\u4f9d\u8d56\u548c\u975e\u5e73\u51e1\u51fd\u6570\u4f9d\u8d56 \u90e8\u5206\u51fd\u6570\u4f9d\u8d56\u4e0e\u5b8c\u5168\u51fd\u6570\u4f9d\u8d56 \u4f20\u9012\u51fd\u6570\u4f9d\u8d56 \u591a\u503c\u4f9d\u8d56\uff0c\u5e73\u51e1\u591a\u503c\u4f9d\u8d56 \u8303\u5f0f \u00b6 \u7b2c\u4e00\u8303\u5f0f\uff1a\u6bcf\u4e2a\u5173\u7cfb\u6a21\u5f0f\u5fc5\u5b9a\u5c5e\u4e8e1NF \u7b2c\u4e8c\u8303\u5f0f\uff1a\u6ca1\u6709\u90e8\u5206\u51fd\u6570\u4f9d\u8d56\uff0c\u5c5e\u4e8e2NF \u7b2c\u4e09\u8303\u5f0f\uff1a\u4e0d\u5b58\u5728\u4f20\u9012\u51fd\u6570\u4f9d\u8d56\uff0c\u5c5e\u4e8e3NF BC\u8303\u5f0f\uff1a\u6bcf\u4e2a\u51b3\u5b9a\u56e0\u7d20\u90fd\u542b\u6709\u5019\u9009\u7801 \u7b2c\u56db\u8303\u5f0f\uff1a\u6240\u6709\u7684\u975e\u5e73\u51e1\u591a\u503c\u4f9d\u8d56\u7684\u51b3\u5b9a\u56e0\u7d20\u90fd\u542b\u6709\u7801 \u6570\u636e\u4f9d\u8d56\u516c\u7406\u7cfb\u7edf \u00b6 \u903b\u8f91\u8574\u542b \u00b6 \u8bbe\u53c8\u6ee1\u8db3\u51fd\u6570\u4f9d\u8d56\u96c6 F \u7684\u5173\u7cfb\u6a21\u5f0f \\(R<U, F>\\) \uff0c\u5bf9\u4e8e R \u7684\u4efb\u4e00\u5173\u7cfb r\uff0c\u82e5\u4e00\u4e2a\u5173\u7cfb\u4e2d\u51fd\u6570\u4f9d\u8d56 \\(X\\rightarrow Y\\) \u90fd\u6210\u7acb\uff0c\u5219\u79f0\u903b\u8f91\u8574\u542b \\(X\\rightarrow Y\\) \uff0c\u8bb0\u4e3a \\(F\\Rightarrow X\\rightarrow Y\\) Armstrong \u516c\u7406\u7cfb\u7edf \u00b6 \u7528\u9014\uff1a\u6c42\u7ed9\u5b9a\u5173\u7cfb\u6a21\u5f0f\u7684\u7801\uff0c\u4ece\u4e00\u7ec4\u51fd\u6570\u4f9d\u8d56\u6c42\u5f97\u8574\u542b\u7684\u51fd\u6570\u4f9d\u8d56 \u5bf9\u4e8e\u5173\u7cfb\u6a21\u5f0f \\(R<U,F>\\) \uff0c\u6709\u4e00\u4e0b\u5b9a\u5f8b \u81ea\u53cd\u5f8b\uff1a\u82e5 \\(Y\\subseteq X \\subseteq U\\) \uff0c\u5219 \\(F\\Rightarrow X\\rightarrow Y\\) \u589e\u5e7f\u5f8b\uff1a\u82e5 \\(F\\Rightarrow X\\rightarrow Y\\) \uff0c\u4e14 \\(Z\\subseteq U\\) \uff0c\u5219 \\(F\\Rightarrow ZX\\rightarrow ZY\\) \u4f20\u9012\u5f8b\uff1a\u82e5 \\(F\\Rightarrow X\\rightarrow Y\\) \u53ca \\(F\\Rightarrow Y\\rightarrow Z\\) \uff0c\u5219 \\(F\\Rightarrow X\\rightarrow Z\\) \u63a8\u7406\u53ef\u5f97\u4ee5\u4e0b\u89c4\u5219 \u5408\u5e76\u89c4\u5219\uff1a\u82e5 \\(X\\rightarrow Y,X\\rightarrow Z\\) \uff0c\u5219 \\(X\\rightarrow YZ\\) \u4f2a\u4f20\u9012\u89c4\u5219\uff1a\u82e5 \\(X\\rightarrow Y,WY\\rightarrow Z\\) \uff0c\u5219\u6709 \\(WX\\rightarrow Z\\) \u5206\u89e3\u89c4\u5219\uff1a\u82e5 \\(X\\rightarrow Y\\) \uff0c\u4e14 \\(Z\\subseteq Y\\) \uff0c\u5219\u6709 \\(X\\rightarrow Z\\) \u51fd\u6570\u4f9d\u8d56\u96c6\u7684\u95ed\u5305 \u00b6 \\(X^+_F\\) \u79f0\u4e3a\u5c5e\u6027\u96c6 \\(X\\) \u5173\u4e8e\u51fd\u6570\u4f9d\u8d56\u96c6 \\(F\\) \u7684\u95ed\u5305 \u6c42 \\(X^+_F\\) \u7684\u65b9\u6cd5\uff1a\u5728\u51fd\u6570\u4f9d\u8d56 \\(F\\) \u627e\u5de6\u4fa7\u662f X \u7684\u5b50\u96c6\u7684\u4f9d\u8d56\u5e76\u4e0d\u65ad\u6269\u5927 \\(X\\) \u8fd9\u4e2a\u96c6\u5408\uff0c\u76f4\u5230\u4e0d\u80fd\u6269\u5927\u4e3a\u6b62 \u6700\u5c0f\u4f9d\u8d56\u96c6 \u00b6 \u51fd\u6570\u4f9d\u8d56\u96c6\u7b49\u4ef7\uff1a\u5982\u679c \\(G^+=F^+\\) \uff0c\u5219\u79f0\u51fd\u6570\u4f9d\u8d56\u96c6 \\(G\\) \u548c \\(F\\) \u7b49\u4ef7 / \u4e92\u4e3a\u8986\u76d6 \u6700\u5c0f\u4f9d\u8d56\u96c6\uff1a\u5982\u679c\u51fd\u6570\u4f9d\u8d56\u96c6 \\(F\\) \u6ee1\u8db3 $F $ \u4e2d\u4efb\u4e00\u51fd\u6570\u4f9d\u8d56\u7684\u53f3\u90e8\u4ec5\u6709\u5355\u4e00\u5c5e\u6027 \\(F\\) \u4e2d\u4e0d\u5b58\u5728\u8fd9\u6837\u7684\u51fd\u6570\u4f9d\u8d56 \\(X\\rightarrow A\\) \uff0c\u4f7f\u5f97 \\(F\\) \u4e0e \\(F-\\{X\\rightarrow A\\}\\) \u7b49\u4ef7 \\(F\\) \u4e2d\u4e0d\u5b58\u5728\u8fd9\u6837\u7684\u51fd\u6570\u4f9d\u8d56 \\(X\\rightarrow A\\) \uff0c \\(X\\) \u6709\u771f\u5b50\u96c6 \\(Z\\) \u4f7f\u5f97 \\(F\\) \u4e0e \\(F-\\{X\\rightarrow A\\}\\cup \\{Z\\rightarrow A\\}\\) \u7b49\u4ef7 \u5219\u79f0 \\(F\\) \u662f\u6700\u5c0f\u4f9d\u8d56\u96c6 \u6216 \u6700\u5c0f\u8986\u76d6\uff0c\u8bb0\u4e3a \\(F_{min}\\) \uff0c\u5373\u8981\u6c42\u51fd\u6570\u4f9d\u8d56\u96c6\u662f\u6700\u5c0f\u7684 \u6c42\u51fd\u6570\u4f9d\u8d56\u96c6 \\(F\\) \u7684 \\(F_{min}\\) \u7684\u65b9\u6cd5 \u5148\u5c06\u51fd\u6570\u4f9d\u8d56\u53f3\u4fa7\u53f3\u4fa7\u662f\u591a\u5c5e\u6027\u7684\u5206\u89e3\u5f00\u591a\u4e2a\u51fd\u6570\u4f9d\u8d56 \u7136\u540e\u9010\u4e00\u68c0\u67e5\u6bcf\u4e00\u4e2a\u51fd\u6570\u4f9d\u8d56\uff0c\u68c0\u67e5\u8fd9\u4e2a\u51fd\u6570\u4f9d\u8d56\u662f\u5426\u53ef\u53bb \u6700\u540e\u9010\u4e00\u68c0\u67e5\u6bcf\u4e00\u4e2a\u51fd\u6570\u4f9d\u8d56\u7684\u5de6\u4fa7\u4e2d\u7684\u6bcf\u4e00\u4e2a\u5c5e\u6027\uff0c\u68c0\u67e5\u5355\u4e2a\u5c5e\u6027\u662f\u5426\u53ef\u53bb \u5176\u4ed6\u8003\u70b9\uff1a\u8ba1\u7b97\u7801\u7684\u7b97\u6cd5 \u6a21\u5f0f\u5206\u89e3 \u00b6 \u65e0\u635f\u8fde\u63a5\u6027 \u00b6 \u638c\u63e1\u5224\u65ad\u6a21\u5f0f\u5206\u89e3\u65e0\u635f\u8fde\u63a5\u6027\u7684\u7b97\u6cd5\uff0c\u7565 \u51fd\u6570\u4f9d\u8d56\u4fdd\u6301 \u00b6 \u7565 \u7b2c\u516d\u7ae0 \u6570\u636e\u5e93\u5e94\u7528\u5f00\u53d1 \u00b6 T-SQL \u00b6 \u53d8\u91cf \u00b6 declare @< \u5c40\u90e8\u53d8\u91cf\u540d > < \u6570\u636e\u7c7b\u578b > [, @< \u5c40\u90e8\u53d8\u91cf\u540d > < \u6570\u636e\u7c7b\u578b > ...] # \u58f0\u660e set @< \u5c40\u90e8\u53d8\u91cf\u540d > = < \u8868\u8fbe\u5f0f > # \u8d4b\u503c select @< \u5c40\u90e8\u53d8\u91cf\u540d > = < \u8868\u8fbe\u5f0f > [, @< \u5c40\u90e8\u53d8\u91cf\u540d > = < \u8868\u8fbe\u5f0f > ] # select \u53ef\u4ee5\u4e00\u6b21\u8d4b\u503c\u591a\u4e2a\u53d8\u91cf set @< \u5c40\u90e8\u53d8\u91cf\u540d > = ( select \u67e5\u8be2 ) # \u67e5\u8be2\u7ed3\u679c\u8d4b\u503c print \u5b57\u7b26\u4e32 | \u5c40\u90e8\u53d8\u91cf | \u5168\u5c40\u53d8\u91cf | \u51fd\u6570 # \u8f93\u51fa \u6d41\u7a0b\u63a7\u5236\u8bed\u53e5 \u00b6 begin...end begin # \u4e00\u4e2a begin ... end \u662f\u4e00\u4e2a\u8bed\u53e5\u5757 SQL\u8bed\u53e51 SQL\u8bed\u53e52 ... end if...else if < \u6761\u4ef6\u8868\u8fbe\u5f0f > { \u8bed\u53e5 1 | \u8bed\u53e5\u5757 1 } # \u91cc\u9762\u6709 begin ... end [ else { \u8bed\u53e5 2 | \u8bed\u53e5\u5757 2 } ] while while < \u903b\u8f91\u8868\u8fbe\u5f0f > { \u8bed\u53e5 1 | \u8bed\u53e5\u5757 1 } # \u91cc\u9762\u6709 begin ... end break / continue / return \u7565 \u51fd\u6570 \u00b6 \u5185\u7f6e\u51fd\u6570 \u00b6 \u7565 \u7528\u6237\u81ea\u5b9a\u4e49\u51fd\u6570 \u00b6 \u6807\u91cf\u51fd\u6570 create function [ < \u6240\u6709\u8005 > .] < \u51fd\u6570\u540d > ([ { @< \u53c2\u6570\u540d > [ as ] < \u53c2\u6570\u7c7b\u578b > [ =< \u9ed8\u8ba4\u503c > ] } [,....] ]) returns < \u8fd4\u56de\u53c2\u6570\u7c7b\u578b > [ as ] begin < \u51fd\u6570\u4f53 > return < \u8fd4\u56de\u503c\u8868\u8fbe\u5f0f > end \u6807\u91cf\u51fd\u6570\u7684\u8c03\u7528 select @< \u53d8\u91cf\u540d > = dbo . < \u51fd\u6570\u540d > ( \u5b9e\u53c2 1 ,..., \u5b9e\u53c2 n ) # \u65b9\u5f0f 1 select exec @< \u53d8\u91cf\u540d > = dbo . < \u51fd\u6570\u540d > \u5b9e\u53c2 1 ,..., \u5b9e\u53c2 n # \u65b9\u5f0f 2 exec \u5185\u5d4c\u8868\u503c\u51fd\u6570 create function [ < \u6240\u6709\u8005 > .] < \u51fd\u6570\u540d > ([ { @< \u53c2\u6570\u540d > [ as ] < \u53c2\u6570\u7c7b\u578b > [ =< \u9ed8\u8ba4\u503c > ] } [,....] ]) returns table [ as ] begin return ( < select > \u8bed\u53e5 ) end \u5185\u5d4c\u8868\u503c\u51fd\u6570\u7684\u8c03\u7528 # \u53ea\u80fd\u901a\u8fc7 select select * from < \u51fd\u6570\u540d > ( \u53c2\u6570\u8868 ) \u591a\u8bed\u53e5\u8868\u503c\u51fd\u6570 create function [ < \u6240\u6709\u8005 > .] < \u51fd\u6570\u540d > ([ { @< \u53c2\u6570\u540d > [ as ] < \u53c2\u6570\u7c7b\u578b > [ =< \u9ed8\u8ba4\u503c > ] } [,....] ]) returns @ reuturn_variable table < \u8868\u7684\u5b9a\u4e49 > [ as ] begin < \u51fd\u6570\u4f53 > return end \u591a\u8bed\u53e5\u8868\u503c\u51fd\u6570 # \u53ea\u80fd\u901a\u8fc7 select select * from < \u51fd\u6570\u540d > ( \u53c2\u6570\u8868 ) \u5220\u9664\u51fd\u6570 drop function { [ < \u6240\u6709\u8005 > .] < \u51fd\u6570\u540d > } [,... n ] \u6e38\u6807 \u00b6 \u6e38\u6807\u7c7b\u578b \u00b6 \u9759\u6001\u6e38\u6807 \u53ea\u8bfb \u52a8\u6001\u6e38\u6807 \u80fd\u591f\u53cd\u6620\u5bf9\u7ed3\u679c\u96c6\u4e2d\u6240\u505a\u7684\u66f4\u6539 \u53ea\u8fdb\u6e38\u6807 \u53ea\u652f\u6301\u4ece\u5934\u5230\u5c3e\u63d0\u53d6\u6570\u636e \u952e\u96c6\u9a71\u52a8\u6e38\u6807 \u53ef\u4ee5\u4fee\u6539\u57fa\u672c\u8868\u4e2d\u975e\u5173\u952e\u5b57\u5217\u7684\u503c\uff0c\u4f46\u4e0d\u53ef\u4ee5\u63d2\u5165\u6570\u636e \u58f0\u660e\u6e38\u6807 \u00b6 declare < \u6e38\u6807\u540d > cursor [ local | global ] -- \u6e38\u6807\u4f5c\u7528\u57df [ forword_only | scroll ] -- \u6e38\u6807\u79fb\u52a8\u65b9\u5411 [ static | keyset | dynamic | fast_forward ] -- \u6e38\u6807\u7c7b\u578b [ read_only | scroll_locks | optimistic ] -- \u8bbf\u95ee\u5c5e\u6027 [ type_warning ] -- \u7c7b\u578b\u8f6c\u6362\u8b66\u544a for < select\u8bed\u53e5 > [ for update [ of < \u5217\u540d > [,... n ]] -- \u53ef\u4fee\u6539\u7684\u5217 \u6253\u5f00\u6e38\u6807 \u00b6 open { { [ global ] < \u6e38\u6807\u540d > } | @< \u6e38\u6807\u53d8\u91cf\u540d > } -- eg select '\u6e38\u6807 KH_cur \u6570\u636e\u884c\u6570' = @@ CURSOR_ROWS \u8bfb\u53d6\u6e38\u6807 \u00b6 fetch [ [ next | prior | first | last | absolute { n |@ nvar } | relative { n |@ nvar } ] from ] { { [ global ] < \u6e38\u6807\u540d > } | @< \u6e38\u6807\u53d8\u91cf\u540d > } [ into @ variable_name [,... n ]] \u5173\u95ed\u6e38\u6807 \u00b6 close { { [ global ] < \u6e38\u6807\u540d > } |@< \u6e38\u6807\u53d8\u91cf\u540d > } \u91ca\u653e\u6e38\u6807 \u00b6 deallocate { { [ global ] < \u6e38\u6807\u540d > } |@< \u6e38\u6807\u53d8\u91cf\u540d > } \u6e38\u6807\u53d8\u91cf \u00b6 \u7565 \u6e38\u6807\u51fd\u6570 \u00b6 CURSOR_STATUS ( 'loacl' | 'global' | 'variable' , '\u6e38\u6807\u540d' | '\u6e38\u6807\u53d8\u91cf\u540d' ) -- eg set @ statusVar = CURSOR_STATUS ( 'local' , 'CUR' ) \u5b58\u50a8\u8fc7\u7a0b \u00b6 \u5b58\u50a8\u8fc7\u7a0b\u7f16\u8bd1\u548c\u4f18\u5316\u540e\u5b58\u653e\u5728\u6570\u636e\u5e93\u670d\u52a1\u5668\u4e0a\uff0c\u6267\u884c\u4e00\u6b21\u540e\u5b58\u653e\u5728 \u9ad8\u7f13 \u4e2d \u4f18\u70b9\uff1a \u63d0\u9ad8\u7cfb\u7edf\u6027\u80fd \u4ee3\u7801\u590d\u7528\uff0c\u6267\u884c\u6548\u7387\u9ad8 \u5b58\u50a8\u8fc7\u7a0b\u7684\u5b9a\u4e49 \u00b6 create proc [ edure ] < \u5b58\u50a8\u8fc7\u7a0b\u540d > [ { @< \u53c2\u6570 >< \u6570\u636e\u7c7b\u578b > } [ = default ][ output ]] [,... n1 ] as < SQL\u8bed\u53e5 > [... n2 ] \u5b58\u50a8\u8fc7\u7a0b\u7684\u6267\u884c \u00b6 [ exec [ ute ]] < \u5b58\u50a8\u8fc7\u7a0b\u540d > [[ @< \u53c2\u6570\u540d >= ] { < \u503c >|@< \u53d8\u91cf > [ output ] | [ default ] } [,... n ]] -- deaflut \u8868\u793a\u7528\u9ed8\u8ba4\u503c \u5220\u9664\u540c\u540d\u5b58\u50a8\u8fc7\u7a0b \u00b6 if exists ( select name from sysobjects where name = 'eg' and type = 'P' ) drop procedure eg -- \u5220\u9664\u51fd\u6570\u7b49\u540c\u7406 \u4fee\u6539\u5b58\u50a8\u8fc7\u7a0b \u00b6 alter proc [ edure ] < \u5b58\u50a8\u8fc7\u7a0b\u540d > [ { @< \u53c2\u6570 >< \u6570\u636e\u7c7b\u578b > } [ = default ][ output ]] [,... n1 ] as < SQL\u8bed\u53e5 > [... n2 ] \u5220\u9664\u5b58\u50a8\u8fc7\u7a0b \u00b6 drop proc [ edure ] { < \u5b58\u50a8\u8fc7\u7a0b\u540d > } [,... n ] \u89e6\u53d1\u5668 \u00b6 \u89e6\u53d1\u5668\u7684\u5206\u7c7b \u00b6 \u89e6\u53d1\u7c7b\u578b\uff1ainsert / update / delete \u89e6\u53d1\u65b9\u5f0f\uff1aafter / instead of \u521b\u5efa\u89e6\u53d1\u5668 \u00b6 create trigger < \u89e6\u53d1\u5668\u540d > on { < \u57fa\u672c\u8868 >|< \u89c6\u56fe > } -- \u6307\u5b9a\u89e6\u53d1\u5668\u540d\u53ca\u64cd\u4f5c\u5bf9\u8c61 { for | after | instead of } { [ delete ][,][ insert ][,][ update ] } -- \u5b9a\u4e49\u89e6\u53d1\u5668\u7684\u7c7b\u578b\uff0c\u9ed8\u8ba4\u662f after as [ if update ( < \u5217\u540d > )[ { and | or } update ( < \u5217\u540d > )] [,... n ] ] < SQL\u8bed\u53e5 > [,... n ] -- \u53ef\u5305\u542b\u4e00\u6761\u6216\u591a\u6761SQL\u8bed\u53e5 \u89e6\u53d1\u5668\u7684\u7981\u6b62\u4e0e\u542f\u7528 \u00b6 alter table { enable | disable } < \u89e6\u53d1\u5668\u540d > \u4fee\u6539\u89e6\u53d1\u5668 \u00b6 alter trigger < \u89e6\u53d1\u5668\u540d > on { < \u57fa\u672c\u8868 >|< \u89c6\u56fe > } -- \u6307\u5b9a\u89e6\u53d1\u5668\u540d\u53ca\u64cd\u4f5c\u5bf9\u8c61 { for | after | instead of } { [ delete ][,][ insert ][,][ update ] } -- \u5b9a\u4e49\u89e6\u53d1\u5668\u7684\u7c7b\u578b\uff0c\u9ed8\u8ba4\u662f after as [ if update ( < \u5217\u540d > )[ { and | or } update ( < \u5217\u540d > )] [,... n ] ] < SQL\u8bed\u53e5 > [,... n ] -- \u53ef\u5305\u542b\u4e00\u6761\u6216\u591a\u6761SQL\u8bed\u53e5 \u5220\u9664\u89e6\u53d1\u5668 \u00b6 drop trigger { < \u89e6\u53d1\u5668\u540d > } [,... n ] \u6570\u636e\u5e93\u8bbf\u95ee\u63a5\u53e3 \u00b6 \u5f00\u653e\u6570\u636e\u5e93\u8fde\u63a5(ODBC) \u00b6 \u7ec4\u6210\uff1aODBC\u6570\u636e\u5e93\u5e94\u7528\u7a0b\u5e8f\uff0c\u9a71\u52a8\u7a0b\u5e8f\u7ba1\u7406\u5668\uff0c\u9a71\u52a8\u7a0b\u5e8f\uff0c\u6570\u636e\u6e90 5\u9636\u6bb5\uff1a\u914d\u7f6e\u6570\u636e\u6e90\uff0c\u8fde\u63a5\u6570\u636e\u6e90\uff0c\u521d\u59cb\u5316\u5e94\u7528\u7a0b\u5e8f\uff0cSQL\u5904\u7406\uff0c\u5904\u7406\u7ed3\u675f \u4f18\u70b9\uff1a\u4ee5\u7edf\u4e00\u7684\u65b9\u5f0f\u5904\u7406\u6240\u6709\u6570\u636e\u5e93 JDBC \u00b6 \u7ec4\u6210\uff1aJava\u5e94\u7528\u7a0b\u5e8f\uff0cJDBC\u9a71\u52a8\u7a0b\u5e8f\u7ba1\u7406\u5668\uff0cJDBC\u9a71\u52a8\u7a0b\u5e8f\uff0c\u6570\u636e\u5e93 ADO.NET \u00b6 \u6570\u636e\u5e93\u5e94\u7528\u7cfb\u7edf\u4f53\u7cfb\u7ed3\u6784 \u00b6 \u4f53\u7cfb\u7ed3\u6784\uff1a\u5355\u7528\u6237\u6a21\u5f0f\uff0c\u4e3b\u4ece\u5f0f\u591a\u7528\u6237\u6a21\u5f0f\uff0cC/S\u6a21\u5f0f\uff0cB/S\u6a21\u5f0f \u7b2c\u4e03\u7ae0 \u6570\u636e\u5e93\u4fdd\u62a4 \u00b6 \u5bf9\u6570\u636e\u5e93\u7684\u7834\u574f \u00b6 \u975e\u6cd5\u7528\u6237 \u975e\u6cd5\u6570\u636e \u5404\u79cd\u6545\u969c \u591a\u7528\u6237\u7684\u5e76\u53d1\u8bbf\u95ee \u6570\u636e\u5e93\u5b89\u5168 \u00b6 \u6570\u636e\u5e93\u7684\u5b89\u5168\u63a7\u5236 \u7528\u6237\u8bc6\u522b\u4e0e\u9274\u522b -- \u521b\u5efa\u767b\u5f55\u540d create login < \u767b\u5f55\u540d > with password = '<\u5bc6\u7801>' , default_database = < \u5173\u8054\u7684\u6570\u636e\u5e93 > -- \u521b\u5efa\u7528\u6237\u540d create user < \u7528\u6237\u540d > for login < \u767b\u5f55\u540d > # \u767b\u5f55\u540d\u4e0e\u7528\u6237\u540d\u5173\u8054 \u8bbf\u95ee\u63a7\u5236 -- \u6388\u6743 grant < \u6743\u9650 > [, < \u6743\u9650 > ...] # all privileges on < \u5bf9\u8c61\u7c7b\u578b > < \u5bf9\u8c61\u540d > [, < \u5bf9\u8c61\u7c7b\u578b > < \u5bf9\u8c61\u540d > ...] to < \u7528\u6237 > [, < \u7528\u6237 > ...] [ with grant option ] # \u5141\u8bb8\u8f6c\u6388 -- \u6536\u56de\u6743\u9650 revoke < \u6743\u9650 > [, < \u6743\u9650 > ...] on < \u5bf9\u8c61\u7c7b\u578b > < \u5bf9\u8c61\u540d > [, < \u5bf9\u8c61\u7c7b\u578b > < \u5bf9\u8c61\u540d > ...] from < \u7528\u6237 > [, < \u7528\u6237 > ...] [ cascade ] # cascade \u8868\u793a\u7ea7\u8054\u56de\u6536 \u89c6\u56fe\u673a\u5236 \u5b89\u5168\u5ba1\u8ba1\u673a\u5236 SQL Server\u7684\u5b89\u5168\u673a\u5236 \u8eab\u4efd\u9a8c\u8bc1\u6a21\u5f0f \u767b\u5f55\u548c\u7528\u6237 \u6743\u9650\u7ba1\u7406 \u89d2\u8272\u7ba1\u7406 \u6570\u636e\u5e93\u5b8c\u6574\u6027 \u00b6 \u51c6\u786e\u6027\uff0c\u6709\u6548\u6027\uff0c\u76f8\u5bb9\u6027 \u6570\u636e\u5e93\u5b8c\u6574\u6027\u63a7\u5236 \u00b6 \u5b9e\u4f53\u5b8c\u6574\u6027 \u53c2\u7167\u5b8c\u6574\u6027 \u7528\u6237\u81ea\u5b9a\u4e49\u5b8c\u6574\u6027 SQL Server \u7684\u5b8c\u6574\u6027\u673a\u5236 \u00b6 \u7ea6\u675f Constraint \u00b6 not null primary key check foreign key default unique check \u7ea6\u675f \u7ea6\u675f\u5b57\u6bb5\u6240\u5141\u8bb8\u7684\u8303\u56f4 [ constraint < \u7ea6\u675f\u540d > ] check ( < \u6761\u4ef6 > ) unique \u7ea6\u675f [ constraint < \u7ea6\u675f\u540d > ] unique \u89c4\u5219 Rule \u00b6 \u521b\u5efa\u89c4\u5219 create rule < \u89c4\u5219\u540d > as < \u6761\u4ef6\u8868\u8fbe\u5f0f > \u7ed1\u5b9a\u89c4\u5219 [ exec [ ute ]] sp_bindrule [ @ rulename = ] '<\u89c4\u5219\u540d>' ,[ @ objanme ] '<\u7ed1\u5b9a\u5bf9\u8c61\u540d>' \u89e3\u7ed1\u89c4\u5219 [ exec [ ute ]] sp_unbindrule [ @ objanme ] '<\u7ed1\u5b9a\u5bf9\u8c61\u540d>' \u5220\u9664\u89c4\u5219 drop rule < \u89c4\u5219\u540d > [,...] \u9ed8\u8ba4 Default \u00b6 \u7565 \u5e76\u53d1\u63a7\u5236 \u00b6 \u4e8b\u52a1\uff1a\u662f\u7528\u6237\u5b9a\u4e49\u7684\u4e00\u4e2a\u6570\u636e\u5e93\u64cd\u4f5c\u5e8f\u5217\uff0c\u8981\u4e48\u5168\u505a\uff0c\u8981\u4e48\u90fd\u4e0d\u505a\uff0c\u662f\u4e00\u4e2a\u4e0d\u53ef\u5206\u5272\u7684\u5de5\u4f5c\u5355\u4f4d\uff0c\u662fDBMS\u7684\u57fa\u672c\u5355\u4f4d \u4e8b\u52a1\u7684 ACID \u6027\u8d28 \u00b6 \u539f\u5b50\u6027 \u4e00\u81f4\u6027 \u9694\u79bb\u6027 \u6301\u4e45\u6027 \u4e8b\u52a1\u7684\u6d3b\u52a8\u8fc7\u7a0b \u00b6 4 \u4e2a\u72b6\u6001 \u4e8b\u52a1\u5f00\u59cb \u4e8b\u52a1\u8bfb / \u5199 \u4e8b\u52a1\u63d0\u4ea4 (COMMIT) \u4e8b\u52a1\u56de\u6eda (ROLLBACK) \u4e8b\u52a1\u7684\u5e76\u53d1\u6267\u884c \u00b6 \u4e22\u5931\u66f4\u65b0 \u8bfb \u201c\u810f\u201d \u6570\u636e \u4e0d\u53ef\u91cd\u590d\u8bfb \u5e76\u53d1\u8c03\u5ea6\u7684\u53ef\u4e32\u884c\u6027 \u00b6 \u4e8b\u52a1\u7684\u5e76\u53d1\u8c03\u5ea6\u662f\u6b63\u786e\u7684\u5f53\u4e14\u4ec5\u5f53\u5176\u7ed3\u679c\u4e0e\u4e32\u884c\u8c03\u5ea6\u6267\u884c\u7684\u7ed3\u679c\u76f8\u540c\uff0c\u53ef\u4e32\u884c\u5316\u662f\u5e76\u53d1\u63a7\u5236\u7684\u6b63\u786e\u6027\u7684\u51c6\u5219 \u5c01\u9501 \u00b6 \u5c01\u9501\u7c7b\u578b\uff1a \u6392\u4ed6\u9501\uff1a\u5199\u9501\u6216 X \u9501\uff0c\u81ea\u5df1\u53ef\u8bfb\u53ef\u5199\uff0c\u5176\u4ed6\u4e8b\u52a1\u65e0\u6cd5\u5bf9\u6570\u636e\u8fdb\u884c\u52a0\u9501\u6216\u64cd\u4f5c \u5171\u4eab\u9501\uff1a\u8bfb\u9501\u6216 S \u9501\uff0c\u81ea\u5df1\u53ea\u53ef\u8bfb\uff0c\u5176\u4ed6\u4e8b\u52a1\u53ea\u80fd\u52a0 S \u9501 \u5c01\u9501\u534f\u8bae\uff1a \u4e00\u7ea7\u5c01\u9501\u534f\u8bae\uff1a\u5bf9\u6570\u636e\u8fdb\u884c\u5199\u64cd\u4f5c\u65f6\u5fc5\u987b\u52a0X\u9501\uff0c\u4e8b\u52a1\u7ed3\u675f\u91ca\u653e\uff0c\u89e3\u51b3\u2018\u4e22\u5931\u66f4\u65b0\u2019 \u4e8c\u7ea7\u5c01\u9501\u534f\u8bae\uff1a\u4e00\u7ea7\u5c01\u9501\u534f\u8bae\u518d\u52a0\u4e0a\u5728\u8bfb\u6570\u636e\u524d\u52a0\u4e0a S \u9501\uff0c\u8bfb\u5b8c\u5373\u91ca\u653e\uff0c\u8fdb\u4e00\u6b65\u89e3\u51b3\u2018\u8bfb\u810f\u6570\u636e\u2019 \u4e09\u7ea7\u5c01\u9501\u534f\u8bae\uff1a\u4e00\u7ea7\u5c01\u9501\u534f\u8bae\u518d\u52a0\u4e0a\u5728\u8bfb\u6570\u636e\u524d\u52a0\u4e0a S \u9501\uff0c\u4e8b\u52a1\u7ed3\u675f\u91ca\u653e\uff0c\u8fdb\u4e00\u6b65\u89e3\u51b3\u2018\u4e0d\u53ef\u91cd\u590d\u5ea6\u2019 \u4e24\u6bb5\u9501\u534f\u8bae\uff1a\u6240\u6709\u4e8b\u52a1\u5fc5\u987b\u5206\u4e24\u4e2a\u9636\u6bb5\u5bf9\u6570\u636e\u52a0\u9501\u548c\u89e3\u9501\uff0c\u5373\u540c\u610f\u4e0a\u9501\uff0c\u7136\u540e\u518d\u7edf\u4e00\u89e3\u9501 \u6d3b\u9501 & \u6b7b\u9501\uff1a \u6d3b\u9501\uff1a\u5728\u5c01\u9501\u8fc7\u7a0b\u4e2d\u67d0\u4e2a\u4e8b\u52a1\u6c38\u8fdc\u5904\u4e8e\u7b49\u5f85\u7684\u72b6\u6001\u800c\u5f97\u4e0d\u5230\u5c01\u9501\u673a\u4f1a \u89e3\u51b3\u65b9\u6cd5\uff1a\u5148\u6765\u5148\u670d\u52a1 \u6b7b\u9501\uff1a\u82e5\u5e72\u4e8b\u52a1\u90fd\u5904\u4e8e\u7b49\u5f85\u72b6\u6001\uff0c\u76f8\u4e92\u7b49\u5f85\u5bf9\u65b9\u91ca\u653e\u9501 \u89e3\u51b3\u65b9\u6cd5\uff1a\u9884\u9632\u6cd5\uff1a\u987a\u5e8f\u7533\u8bf7\u6cd5\uff0c\u4e00\u6b21\u7533\u8bf7\u6cd5 \u200b \u89e3\u9664\u6cd5\uff1a\u5b9a\u65f6\u6cd5\uff0c\u6b7b\u9501\u68c0\u6d4b\u6cd5 \u6570\u636e\u5e93\u6062\u590d \u00b6 \u6545\u969c\u79cd\u7c7b \u00b6 \u7cfb\u7edf\u6545\u969c \u4e8b\u52a1\u6545\u969c \u4ecb\u8d28\u6545\u969c \u8ba1\u7b97\u673a\u75c5\u6bd2 \u8bef\u64cd\u4f5c \u81ea\u7136\u707e\u5bb3 \u76d7\u7a83 \u6570\u636e\u5e93\u6062\u590d\u6280\u672f \u00b6 \u628a\u6570\u636e\u5e93\u4ece\u9519\u8bef\u72b6\u6001\u6062\u590d\u5230\u67d0\u4e2a\u6b63\u786e\u7684\u72b6\u6001 \u6570\u636e\u5e93\u6062\u590d\u673a\u5236\u7684\u4e24\u4e2a\u65b9\u9762\uff1a\u4e00\u662f\u5efa\u7acb\u5197\u4f59\u6570\u636e\uff0c\u4e8c\u662f\u7cfb\u7edf\u51fa\u73b0\u6545\u969c\u540e\u5229\u7528\u5197\u4f59\u6570\u636e\u5c06\u6570\u636e\u5e93\u6062\u590d\u5230\u67d0\u4e2a\u6b63\u5e38\u7684\u72b6\u6001 \u5907\u4efd\uff1a\u6570\u636e\u8f6c\u5b58\uff0c\u767b\u5f55\u65e5\u5fd7\u6587\u4ef6 \u53c2\u8003 \u00b6 \u6570\u636e\u5e93\u57fa\u7840\u6559\u7a0b\uff08\u7b2c\u4e09\u7248\uff09 \u987e\u97f5\u534e \u7535\u5b50\u5de5\u4e1a\u51fa\u7248\u793e","title":"\u6570\u636e\u5e93\u7cfb\u7edf"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_1","text":"","title":"\u6570\u636e\u5e93\u7cfb\u7edf"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_2","text":"","title":"\u7b2c\u4e00\u7ae0 \u6570\u636e\u5e93\u6982\u89c8"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_3","text":"\u4eba\u5de5\u7ba1\u7406\u9636\u6bb5\uff1a\u4e0d\u80fd\u957f\u671f\u4fdd\u5b58\uff0c\u4e0d\u5177\u6709\u72ec\u7acb\u6027\uff0c\u4e0d\u5171\u4eab \u6587\u4ef6\u7cfb\u7edf\u9636\u6bb5\uff1a\u957f\u671f\u4fdd\u5b58\uff0c\u72ec\u7acb\u6027\u5dee\uff0c\u5171\u4eab\u6027\u5dee\uff0c\u5197\u4f59\u5ea6\u5927\uff0c \u6570\u636e\u5e93\u7cfb\u7edf\u9636\u6bb5\uff1a\u7279\u70b9\uff1a1.\u6570\u636e\u7ed3\u6784\u5316 2.\u5171\u4eab\u6027\u9ad8\uff0c\u5197\u4f59\u5ea6\u4f4e\uff0c\u6613\u4e8e\u6269\u5145 3.\u6570\u636e\u72ec\u7acb\u6027\u9ad8 4.\u6570\u636e\u7edf\u4e00\u7ba1\u7406\u4e0e\u63a7\u5236","title":"\u6570\u636e\u5e93\u53d1\u5c55\u4e09\u9636\u6bb5"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_4","text":"\u6570\u636e\u5e93 \u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf\uff08DBMS\uff09 \u6570\u636e\u5e93\u7684\u5e94\u7528\u7a0b\u5e8f \u6570\u636e\u5e93\u7cfb\u7edf\u7684\u4eba\u5458\uff1a\u7ba1\u7406\u5458\uff08DBA\uff09 ...","title":"\u6570\u636e\u5e93\u7cfb\u7edf\u7ec4\u6210"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_5","text":"\u4e09\u7ea7\u6a21\u5f0f\uff1a\u5916\u6a21\u5f0f\uff0c\u6a21\u5f0f\uff0c\u5185\u6a21\u5f0f \u6a21\u5f0f\uff1a\u4e5f\u79f0\u903b\u8f91\u6a21\u5f0f\uff0c\u4e00\u4e2a\u6570\u636e\u5e93\u53ea\u6709\u4e00\u4e2a\u6a21\u5f0f\uff0c\u662f\u6570\u636e\u5e93\u5168\u4f53\u6570\u636e\u7684\u903b\u8f91\u7ed3\u6784\u548c\u7279\u5f81\u7684\u63cf\u8ff0 \u5916\u6a21\u5f0f\uff1a\u4e5f\u79f0\u5b50\u6a21\u5f0f\u6216\u7528\u6237\u6a21\u5f0f\uff0c\u662f\u6a21\u5f0f\u7684\u5b50\u96c6\uff0c\u4e00\u4e2a\u6570\u636e\u5e93\u53ef\u4ee5\u6709\u591a\u4e2a\u5916\u6a21\u5f0f \u5185\u6a21\u5f0f\uff1a\u4e5f\u79f0\u5b58\u50a8\u6a21\u5f0f\uff0c\u53ea\u6709\u4e00\u4e2a\u5185\u6a21\u5f0f\uff0c\u662f\u6570\u636e\u7269\u7406\u7ed3\u6784\u548c\u5b58\u50a8\u65b9\u5f0f\u7684\u63cf\u8ff0 \u4e8c\u7ea7\u6620\u50cf\uff1a \u5916\u6a21\u5f0f/\u6a21\u5f0f\u6620\u50cf\uff1a\u6a21\u5f0f\u6539\u53d8\u65f6\uff0c\u5bf9\u6620\u50cf\u505a\u51fa\u76f8\u5e94\u7684\u6539\u53d8\u53ef\u4ee5\u4f7f\u5916\u6a21\u5f0f\u4fdd\u6301\u4e0d\u53d8\uff0c\u4fdd\u8bc1\u6570\u636e\u548c\u7a0b\u5e8f\u7684\u903b\u8f91\u72ec\u7acb\u6027 \u6a21\u5f0f/\u5185\u6a21\u5f0f\u6620\u50cf\uff1a\u5185\u6a21\u5f0f\u6539\u53d8\u65f6\uff0c\u5bf9\u6620\u50cf\u505a\u51fa\u76f8\u5e94\u7684\u6539\u53d8\u53ef\u4ee5\u4f7f\u6a21\u5f0f\u4fdd\u6301\u4e0d\u53d8\uff0c\u4fdd\u8bc1\u6570\u636e\u7684\u7269\u7406\u72ec\u7acb\u6027","title":"\u4e09\u7ea7\u6a21\u5f0f\u4e0e\u4e8c\u7ea7\u6620\u50cf"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_6","text":"\u529f\u80fd\uff1a\u6570\u636e\u5b9a\u4e49\uff0c\u6570\u636e\u64cd\u7eb5\uff0c\u6570\u636e\u5e93\u7684\u4e8b\u52a1\u7ba1\u7406\u548c\u8fd0\u884c\u7ba1\u7406\uff0c\u6570\u636e\u5e93\u7684\u521b\u5efa\u548c\u7ef4\u62a4","title":"\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_7","text":"\u5206\u7c7b\uff1a\u6982\u5ff5\u6570\u636e\u6a21\u578b\uff0c\u903b\u8f91\u6570\u636e\u6a21\u578b\uff0c\u7269\u7406\u6570\u636e\u6a21\u578b \u6982\u5ff5\u6570\u636e\u6a21\u578b\uff1aER\u56fe ER\u6a21\u578b\u4e09\u8981\u7d20\uff1a\u5b9e\u4f53\uff0c\u5c5e\u6027\uff0c\u8054\u7cfb \u903b\u8f91\u6570\u636e\u6a21\u578b\uff08\u4e00\u822c\u90fd\u76f4\u63a5\u53eb\u6570\u636e\u6a21\u578b\uff09\uff1a\u5c42\u6b21\u6a21\u578b\uff0c\u7f51\u72b6\u6a21\u578b\uff0c\u5173\u7cfb\u6a21\u578b\uff0c\u9762\u5411\u5bf9\u8c61\u6a21\u578b \u6570\u636e\u6a21\u578b\u4e09\u8981\u7d20\uff1a\u6570\u636e\u7ed3\u6784\uff0c\u6570\u636e\u64cd\u4f5c\uff0c\u6570\u636e\u5b8c\u6574\u6027\u7ea6\u675f \u5c42\u6b21\u6a21\u578b\u662f\u4e00\u68f5\u6811\uff0c\u5173\u7cfb\u6a21\u578b\u662f\u4e00\u5f20\u4e8c\u7ef4\u8868","title":"\u6570\u636e\u6a21\u578b"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_8","text":"","title":"\u7b2c\u4e8c\u7ae0 \u5173\u7cfb\u6570\u636e\u5e93\u6a21\u578b"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_9","text":"\u5217\u662f\u540c\u8d28\u7684\uff0c\u5373\u6570\u636e\u7c7b\u578b\u76f8\u540c \u4e0d\u540c\u7684\u5217\u53ef\u4ee5\u51fa\u5176\u540c\u4e00\u4e2a\u57df\uff0c\u4f46\u5c5e\u6027\u540d\u8981\u4e0d\u540c \u5217\u7684\u987a\u5e8f\u53ef\u4ee5\u4efb\u610f\u4ea4\u6362 \u4efb\u610f\u4e24\u4e2a\u5143\u7ec4\u4e0d\u53ef\u4ee5\u5b8c\u5168\u76f8\u540c \u5143\u7ec4\u987a\u5e8f\u53ef\u4ee5\u4efb\u610f \u5206\u91cf\u5fc5\u987b\u53d6\u539f\u5b50\u503c\uff0c\u5373\u8981\u6c42\u6bcf\u4e2a\u5206\u91cf\u90fd\u662f\u4e0d\u53ef\u518d\u5206\u7684\u6570\u636e\u9879","title":"\u5173\u7cfb\u7684\u6027\u8d28"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_10","text":"\u4e00\u4e2a\u5173\u7cfb\u5c31\u662f\u4e00\u4e2a\u89c4\u8303\u5316\u7684\u4e8c\u7ef4\u8868\uff0c\u7b1b\u5361\u5c14\u79ef\u7684\u6709\u610f\u4e49\u7684\u6709\u9650\u5b50\u96c6 \u4e00\u4e2a\u5173\u7cfb\u7531\u5173\u7cfb\u540d\uff0c\u5173\u7cfb\u6a21\u5f0f\uff0c\u5173\u7cfb\u5b9e\u4f8b\u7ec4\u6210 \u5143\u7ec4\uff0c\u5c5e\u6027\uff0c\u7801\uff0c\u57df\uff0c\u5206\u91cf\uff0c\u5173\u7cfb\u6a21\u5f0f \u5019\u9009\u7801\uff1a\u552f\u4e00\u6027\uff0c\u6700\u5c0f\u6027 \u8d85\u7801\uff1a\u53ef\u4ee5\u552f\u4e00\u7684\u786e\u5b9a\u4e00\u884c\uff0c\u5019\u9009\u7801\u662f\u8d85\u7801\u7684\u5b50\u96c6 \u4e3b\u7801\uff1a\u5982\u679c\u7531\u591a\u4e2a\u5019\u9009\u7801\uff0c\u9009\u4e00\u4e2a \u4e3b\u5c5e\u6027\uff1a\u5305\u542b\u5728\u5019\u9009\u7801\u4e2d\u7684\u5404\u5c5e\u6027 \u5916\u7801","title":"\u5173\u7cfb\u6570\u636e\u7ed3\u6784"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_11","text":"\u5173\u7cfb\u4ee3\u6570\uff0c\u5173\u7cfb\u6f14\u7b97\uff0c\u57df\u6f14\u7b97\uff0cSQL","title":"\u5173\u7cfb\u6570\u636e\u8bed\u8a00\u7684\u5206\u7c7b"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_12","text":"\u4f20\u7edf\u7684\u96c6\u5408\u8fd0\u7b97\uff1a\u7b1b\u5361\u5c14\u79ef\uff0c\u5e76\uff0c\u4ea4\uff0c\u5dee \u4e13\u95e8\u7684\u5173\u7cfb\u8fd0\u7b97\uff1a\u9009\u62e9\uff0c\u6295\u5f71\uff0c\u8fde\u63a5\uff08\u7b49\u503c\uff0c\u81ea\u7136\u8fde\u63a5\uff0c\u5916\u8fde\u63a5\uff0c\u5de6\u5916\uff0c\u53f3\u5916\uff09\uff0c\u9664\u6cd5","title":"\u5173\u7cfb\u64cd\u4f5c &amp; \u5173\u7cfb\u4ee3\u6570"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_13","text":"\u5b9e\u4f53\u5b8c\u6574\u6027 \u53c2\u7167\u5b8c\u6574\u6027 \u7528\u6237\u81ea\u5b9a\u4e49\u5b8c\u6574\u6027 \u5217\u7ea7\u5b8c\u6574\u6027\u7ea6\u675f\u53ea\u80fd\u6d89\u53ca\u4e00\u4e2a\u5c5e\u6027\uff0c\u8868\u7ea7\u53ef\u4ee5\u6d89\u53ca\u591a\u4e2a\u5c5e\u6027","title":"\u6570\u636e\u5b8c\u6574\u6027"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#sql","text":"","title":"\u7b2c\u4e09\u7ae0 SQL\u8bed\u8a00"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#sql_1","text":"\u7279\u70b9\uff1a\u7efc\u5408\u7edf\u4e00\uff0c\u9ad8\u5ea6\u975e\u8fc7\u7a0b\u5316\uff0c\u9762\u5411\u96c6\u5408\u7684\u64cd\u4f5c\u65b9\u5f0f\uff0c\u4ee5\u540c\u4e00\u79cd\u8bed\u6cd5\u7ed3\u6784\u63d0\u4f9b\u4e24\u79cd\u4f7f\u7528\u65b9\u5f0f\uff0c\u8bed\u8a00\u7b80\u6d01\u6613\u5b66\u6613\u7528 \u6570\u636e\u5b9a\u4e49\uff08DDL\uff09\uff0c\u6570\u636e\u64cd\u7eb5\uff08DML\uff09\uff0c\u6570\u636e\u63a7\u5236\uff08DCL\uff09","title":"SQL\u6982\u8ff0"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#bnf","text":"<> \u5fc5\u9009\u9879 [ ] \u53ef\u4ee5\u51fa\u73b0\u4e00\u6b21\u6216\u4e0d\u51fa\u73b0 { } \u53ef\u4ee5\u591a\u6b21\u51fa\u73b0\u6216\u4e0d\u51fa\u73b0 | \u591a\u9009\u4e00","title":"\u5df4\u79d1\u65af\u8303\u5f0f\uff08BNF\uff09"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_14","text":"","title":"\u6570\u636e\u5b9a\u4e49"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_15","text":"create database < \u6570\u636e\u5e93\u540d > use < \u6570\u636e\u5e93\u540d > alter database < \u6570\u636e\u5e93\u540d > drop database < \u6570\u636e\u5e93\u540d >","title":"\u6570\u636e\u5e93"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_16","text":"\u5b9a\u4e49 create table < \u8868\u540d > ( < \u5217\u540d >< \u6570\u636e\u7c7b\u578b > [ < \u5217\u7ea7\u5b8c\u6574\u6027\u7ea6\u675f > ] { , < \u5217\u540d >< \u6570\u636e\u7c7b\u578b > [ < \u5217\u7ea7\u5b8c\u6574\u6027\u7ea6\u675f > ] } [, < \u8868\u7ea7\u5b8c\u6574\u6027\u7ea6\u675f > ] ) \u5217\u7ea7\u7ea6\u675f\uff1a not null, default, unique, check, primary key, foreign key foreign key: foreign key (<\u5217\u540d>) references <\u5916\u8868\u540d>(<\u5916\u8868\u5217\u540d>) \u4fee\u6539 alter table < \u8868\u540d > alter column < \u5217\u540d > < \u65b0\u6570\u636e\u7c7b\u578b > [ null | not null ] | add < \u5217\u540d > < \u6570\u636e\u7c7b\u578b > [ \u7ea6\u675f ] | drop column < \u5217\u540d > | add [ constraint < \u7ea6\u675f\u540d > ] < \u7ea6\u675f\u5b9a\u4e49 > | drop constraint < \u7ea6\u675f\u540d > \u5220\u9664 drop table < \u57fa\u672c\u8868\u540d >","title":"\u57fa\u672c\u8868"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_17","text":"\u5206\u7c7b\uff1a\u805a\u7c07\u7d22\u5f15\u548c\u975e\u805a\u7c07\u7d22\u5f15 \u9ed8\u8ba4\u975e\u805a\u7c07\uff0c\u805a\u7c07\u7d22\u5f15\u53ea\u53ef\u4ee5\u5efa\u7acb\u4e00\u4e2a \u805a\u7c07\u7d22\u5f15\uff1a\u7d22\u5f15\u9879\u987a\u5e8f\u548c\u7269\u7406\u987a\u5e8f\u4e00\u81f4 \u5b9a\u4e49 create [ unique ][ clustered | notclustered ] index < \u7d22\u5f15\u540d > on < \u57fa\u672c\u8868\u540d > ( < \u5217\u540d > [ asc | desc ] [ { ,( < \u5217\u540d > [ asc | desc ] } ...]) \u5220\u9664 drop index < \u8868\u540d > . < \u7d22\u5f15\u540d >","title":"\u7d22\u5f15"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_18","text":"select [ all | distinct ] < \u76ee\u6807\u5217\u8868\u8fbe\u5f0f > [, < \u76ee\u6807\u5217\u8868\u8fbe\u5f0f > ]... from < \u8868\u540d\u6216\u89c6\u56fe\u540d > [, < \u8868\u540d\u6216\u89c6\u56fe\u540d > ]... [ where < \u6761\u4ef6\u8868\u8fbe\u5f0f > ] [ group by < \u5217\u540d 1 > ] [ having < \u6761\u4ef6\u8868\u8fbe\u5f0f > ] -- having \u7528\u4e8e\u6307\u5b9a\u5206\u7ec4\u8fc7\u6ee4\u6761\u4ef6 [ order by < \u5217\u540d 2 > [ asc | desc ]]","title":"\u6570\u636e\u67e5\u8be2"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_19","text":"select \u5ba2\u6237\u7f16\u53f7 as cno from CustomerInfo select 'cno' = \u5ba2\u6237\u7f16\u53f7 # = \u5217\u540d\u5fc5\u987b\u5199\u53f3\u8fb9 from CustomerInfo","title":"\u66f4\u6539\u7ed3\u679c\u5217\u6807\u9898"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_20","text":"select < \u5217\u540d > = case when \u6761\u4ef6 1 then \u8868\u8fbe\u5f0f 1 ... else \u8868\u8fbe\u5f0f end from < \u8868\u540d > where < \u6761\u4ef6\u8868\u8fbe\u5f0f >","title":"\u66ff\u6362\u67e5\u8be2\u7ed3\u679c\u4e2d\u7684\u6570\u636e"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_21","text":"select unique < \u5217\u540d > from < \u8868\u540d >","title":"\u53bb\u9664\u91cd\u590d\u884c"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_22","text":"% \u8868\u793a\u4efb\u610f\u957f\u5ea6\u7684\u5b57\u7b26\u4e32 _ \u8868\u793a\u4efb\u610f\u4e00\u4e2a\u5b57\u7b26 select * from < \u8868\u540d > where < \u5217\u540d > like '\u6c5f\u82cf%' \u5982\u679c\u67e5\u8be2\u7684\u6761\u4ef6\u4e2d\u5305\u542b\u901a\u914d\u7b26\u9700\u8981\u8f6c\u4e49\uff1a escape\\ where \u5fae\u4fe1\u53f7 like 'wxid\\_%' escape '\\'","title":"\u6a21\u7cca\u67e5\u8be2"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_23","text":"< \u8868\u8fbe\u5f0f > is [ not ] null","title":"\u7a7a\u503c\u6bd4\u8f83"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_24","text":"[ order by < \u5217\u540d > [ asc | desc ]] [, < \u5217\u540d > [ asc | desc ]]...] # \u9ed8\u8ba4 asc \u5347\u5e8f","title":"\u5bf9\u7ed3\u679c\u96c6\u6392\u5e8f"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_25","text":"group by < \u8868\u8fbe\u5f0f > # eg select \u5546\u54c1\u7c7b\u522b , count ( \u5546\u54c1\u7f16\u53f7 ) as '\u79cd\u6570' from GoodsInfo group by \u5546\u54c1\u7c7b\u522b","title":"\u5bf9\u7ed3\u679c\u96c6\u5206\u7c7b"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#having","text":"having \u8bed\u53e5\u7528\u5728 group by \u5b50\u53e5\u540e\u6765\u8fdb\u884c\u7b5b\u9009\uff0c\u53ea\u8f93\u51fa\u7b26\u5408\u6761\u4ef6\u7684 [ having < \u6761\u4ef6 > ] # eg select \u5546\u54c1\u7c7b\u522b , count ( \u5546\u54c1\u7f16\u53f7 ) as '\u79cd\u6570' from GoodsInfo group by \u5546\u54c1\u7c7b\u522b having count ( * ) > 1","title":"having\u7b5b\u9009"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_26","text":"\u805a\u5408\u51fd\u6570 \u4e0d\u5141\u8bb8 \u5d4c\u5957 sum | avg () max | min () count () # eg select count ( \u5ba2\u6237\u7f16\u53f7 ) as '\u5ba2\u6237\u6570' from OrderList","title":"\u805a\u5408\u51fd\u6570"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_27","text":"\u8fde\u63a5\u8c13\u8bcd from < \u8868 1 > [ \u8868 1 \u522b\u540d ], < \u8868 2 > [ \u8868 2 \u522b\u540d ][, < \u8868 3 > [ \u8868 3 \u522b\u540d ]...] \u4ee5join\u5173\u952e\u5b57\u8fde\u63a5 # \u5185\u8fde\u63a5 \u9ed8\u8ba4\u5185\u8fde\u63a5 inner join ( inner\u53ef\u4ee5\u4e0d\u5199 ) select ... # 2 \u4e2a\u8868 from < \u8868 1 > join < \u8868 2 > on < \u6761\u4ef6 > where ... select ... # 3 \u4e2a\u8868 from < \u8868 1 > join < \u8868 2 > join < \u8868 3 > on < \u6761\u4ef6 1 > on < \u6761\u4ef6 2 > where ... # \u5916\u8fde\u63a5 outer join # \u5de6\u5916 : left outer join \u53f3\u5916 : right outer join \u5b8c\u5168\u5916 : full outer join","title":"\u8fde\u63a5\u67e5\u8be2"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_28","text":"\u5b50\u67e5\u8be2\u4e0d\u80fd\u5305\u542b order by \uff0c\u5373 order by \u53ea\u80fd\u5bf9\u6700\u7ec8\u67e5\u8be2\u6392\u5e8f","title":"\u5d4c\u5957\u67e5\u8be2"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#in","text":"where \u6240\u5728\u7701\u5e02 in ( \u5b50\u67e5\u8be2 )","title":"\u5e26 in \u7684\u5b50\u67e5\u8be2"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_29","text":"where \u6570\u91cf > ( \u5b50\u67e5\u8be2 ) # \u8fd9\u91cc\u7684\u5b50\u67e5\u8be2\u8981\u6c42\u7ed3\u679c\u53ea\u6709\u4e00\u4e2a","title":"\u5e26\u6bd4\u8f83\u8fd0\u7b97\u7b26\u7684\u5b50\u67e5\u8be2"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#all-any","text":"\u7528\u4ee5\u89e3\u9664\u6bd4\u8f83\u8fd0\u7b97\u7b26\u8981\u6c42\u5b50\u67e5\u8be2\u7684\u7ed3\u679c\u96c6\u5143\u7d20\u53ea\u80fd\u6709\u4e00\u4e2a\u7684\u9650\u5236 where \u6570\u91cf > all ( \u5b50\u67e5\u8be2 ) # \u7b49\u6548\u4e8e where \u6570\u91cf > ( \u5e26 MAX \u7684\u5b50\u67e5\u8be2 ) # \u5f53\u7136\u8fd9\u91cc\u5b50\u67e5\u8be2\u53ea\u80fd\u67e5\u8be2\u4e00\u5217","title":"\u5e26 ALL / ANY \u8c13\u8bcd\u7684\u5b50\u67e5\u8be2"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#exists","text":"[ not ] exists ( \u5b50\u67e5\u8be2 )","title":"\u5e26 EXISTS \u8c13\u8bcd\u7684\u5b50\u67e5\u8be2"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_30","text":"select \u8bed\u53e5\u7684\u67e5\u8be2\u7ed3\u679c\u662f\u7ed3\u679c\u96c6\uff0c\u6240\u4ee5\u53ef\u4ee5\u8fdb\u884c\u96c6\u5408\u8fd0\u7b97 \u5e76 UNION \u4ea4 INTERSECT \u5dee EXCEPT \u8fd9\u91cc\u7684\u7ed3\u679c\u96c6\u5217\u6570\u5fc5\u987b\u76f8\u540c\uff0c\u5bf9\u5e94\u5217\u7684\u6570\u636e\u7c7b\u578b\u4e5f\u5fc5\u987b\u76f8\u540c select ... union select ... select ... intersect select ...","title":"\u96c6\u5408\u67e5\u8be2"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_31","text":"","title":"\u6570\u636e\u66f4\u65b0\uff08\u63d2\u5165&amp;\u4fee\u6539&amp;\u5220\u9664\uff09"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_32","text":"# \u63d2\u5165\u5143\u7ec4 insert into < \u8868\u540d > [( < \u5217 1 > [, < \u5217 2 > ...])] values ( < \u5e38\u91cf 1 > [, < \u5e38\u91cf 2 > ...]) # \u63d2\u5165\u5b50\u67e5\u8be2 insert into < \u8868\u540d > [( < \u5217 1 > [, < \u5217 2 > ...])] < \u5b50\u67e5\u8be2 >","title":"\u6570\u636e\u63d2\u5165"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_33","text":"update < \u8868\u540d > [[ as ] < \u522b\u540d > ] set < \u5217\u540d > = < \u5e38\u91cf > [, < \u5217\u540d > = < \u5e38\u91cf > ...] [ where < \u6761\u4ef6\u8868\u8fbe\u5f0f > ]","title":"\u6570\u636e\u4fee\u6539"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_34","text":"delete [ from ] < \u8868\u540d > [ where < \u6761\u4ef6\u8868\u8fbe\u5f0f > ]","title":"\u6570\u636e\u5220\u9664"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_35","text":"\u865a\u8868\uff0c\u53ef\u4ee5\u7528\u4ee5\u4fdd\u62a4\u6570\u636e\u5b89\u5168\u548c\u6ee1\u8db3\u4e0d\u540c\u7528\u6237\u7684\u9700\u6c42","title":"\u89c6\u56fe"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_36","text":"create view < \u89c6\u56fe\u540d > [( < \u5217\u540d > [, < \u5217\u540d > ])] as < select \u67e5\u8be2\u8bed\u53e5 >","title":"\u521b\u5efa\u89c6\u56fe"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_37","text":"alter view < \u89c6\u56fe\u540d > [( < \u5217\u540d > [, < \u5217\u540d > ])] as < select \u67e5\u8be2\u8bed\u53e5 >","title":"\u4fee\u6539\u89c6\u56fe"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_38","text":"drop view < \u89c6\u56fe\u540d >","title":"\u5220\u9664\u89c6\u56fe"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_39","text":"\u548c \u57fa\u672c\u8868 \u4e00\u81f4","title":"\u89c6\u56fe\u67e5\u8be2"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_40","text":"\u9632\u6b62\u51fa\u73b0\u8303\u56f4\u5916\u7684\u6570\u636e\u53ef\u4ee5\u5728\u5b9a\u4e49\u89c6\u56fe\u65f6\u52a0\u4e0a with check option \u63d2\u5165\u6570\u636e\uff0c\u4fee\u6539\u6570\u636e\uff0c\u5220\u9664\u6570\u636e\u90fd\u548c \u57fa\u672c\u8868 \u4e00\u81f4 \u4f46\u6709\u5f88\u591a\u9650\u5236\uff0c\u5982\u679c\u66f4\u65b0\u6210\u529f\u4e86\u4f1a\u6620\u5c04\u5230\u57fa\u672c\u8868","title":"\u89c6\u56fe\u66f4\u65b0"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_41","text":"\u5e7f\u4e49\uff1a\u6570\u636e\u5e93\u53ca\u5176\u5e94\u7528\u7cfb\u7edf\u7684\u8bbe\u8ba1\uff0c\u5373\u8bbe\u8ba1\u6574\u4e2a\u7684\u6570\u636e\u5e93\u5e94\u7528\u7cfb\u7edf \u72ed\u4e49\uff1a\u6570\u636e\u5e93\u672c\u8eab\u7684\u8bbe\u8ba1\uff0c\u5373\u8bbe\u8ba1\u6570\u636e\u5e93\u7684\u5404\u7ea7\u6a21\u5f0f\u5e76\u5efa\u7acb\u6570\u636e\u5e93 \u6570\u636e\u5e93\u8bbe\u8ba1\u7684 6 \u4e2a\u9636\u6bb5\uff1a \u9700\u6c42\u5206\u6790\u9636\u6bb5\uff1a\u6570\u636e\u6d41\u56fe\uff0c\u6570\u636e\u5b57\u5178 \u6982\u5ff5\u7ed3\u6784\u8bbe\u8ba1\u9636\u6bb5\uff1a\u6982\u5ff5\u6570\u636e\u6a21\u578b ER \u56fe \u903b\u8f91\u7ed3\u6784\u8bbe\u8ba1\u9636\u6bb5 \u7269\u7406\u7ed3\u6784\u8bbe\u8ba1\u9636\u6bb5 \u6570\u636e\u5e93\u5b9e\u65bd\u9636\u6bb5 \u6570\u636e\u5e93\u8fd0\u884c\u4e0e\u7ef4\u62a4\u9636\u6bb5","title":"\u7b2c\u56db\u7ae0 \u6570\u636e\u5e93\u8bbe\u8ba1"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_42","text":"\u81ea\u9876\u5411\u4e0b\uff0c\u81ea\u5e95\u5411\u4e0a\uff0cER\u8bbe\u8ba1\u65b9\u6cd5\uff0cEER\u8bbe\u8ba1\u65b9\u6cd5 \u7531\u5c40\u90e8\u89c6\u56fe\u5230\u5168\u5c40\u6982\u5ff5\u7ed3\u6784\uff1a\u4e00\u6b21\u96c6\u6210\uff0c\u591a\u6b21\u96c6\u6210 \u96c6\u6210\u5305\u62ec\uff1a\u5408\u5e76\uff0c\u6d88\u9664\u5197\u4f59 \u5408\u5e76\u7684\u4e09\u79cd\u7c7b\u578b\u7684\u51b2\u7a81\uff1a\u547d\u540d\u51b2\u7a81\uff0c\u5c5e\u6027\u51b2\u7a81\uff0c\u6982\u5ff5\u51b2\u7a81","title":"\u6982\u5ff5\u7ed3\u6784\u8bbe\u8ba1"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_43","text":"\u6b65\u9aa4\uff1a \u5c06\u6982\u5ff5\u6a21\u578b\u8f6c\u5316\u4e3a\u4e00\u822c\u7684\u5173\u7cfb\uff0c\u7f51\u72b6\uff0c\u5c42\u6b21\u6a21\u578b \u5bf9\u6570\u636e\u6a21\u578b\u8fdb\u884c\u4f18\u5316 \u8bbe\u8ba1\u7528\u6237\u5916\u6a21\u5f0f \u4e8c\u5143\u5173\u7cfb\uff1a1\u5bf91\uff0c1\u5bf9\u591a\uff0c\u591a\u5bf9\u591a","title":"\u903b\u8f91\u7ed3\u6784\u8bbe\u8ba1"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_44","text":"","title":"\u7b2c\u4e94\u7ae0 \u5173\u7cfb\u89c4\u8303\u5316\u7406\u8bba"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_45","text":"\u6570\u636e\u5197\u4f59\uff1a\u540c\u4e00\u6570\u636e\u5728\u4e00\u4e2a\u6216\u591a\u4e2a\u6570\u636e\u6587\u4ef6\u4e2d\u91cd\u590d\u50a8\u5b58 \u6570\u636e\u5197\u4f59\u4f1a\u5bfc\u81f4\u7684\u64cd\u4f5c\u5f02\u5e38\uff1a\u63d2\u5165\u5f02\u5e38\uff0c\u5220\u9664\u5f02\u5e38\uff0c\u4fee\u6539\u5f02\u5e38","title":"\u6570\u636e\u5197\u4f59\u548c\u64cd\u4f5c\u5f02\u5e38"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_46","text":"\u5206\u7c7b\uff1a \u5e73\u51e1\u51fd\u6570\u4f9d\u8d56\u548c\u975e\u5e73\u51e1\u51fd\u6570\u4f9d\u8d56 \u90e8\u5206\u51fd\u6570\u4f9d\u8d56\u4e0e\u5b8c\u5168\u51fd\u6570\u4f9d\u8d56 \u4f20\u9012\u51fd\u6570\u4f9d\u8d56 \u591a\u503c\u4f9d\u8d56\uff0c\u5e73\u51e1\u591a\u503c\u4f9d\u8d56","title":"\u51fd\u6570\u4f9d\u8d56"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_47","text":"\u7b2c\u4e00\u8303\u5f0f\uff1a\u6bcf\u4e2a\u5173\u7cfb\u6a21\u5f0f\u5fc5\u5b9a\u5c5e\u4e8e1NF \u7b2c\u4e8c\u8303\u5f0f\uff1a\u6ca1\u6709\u90e8\u5206\u51fd\u6570\u4f9d\u8d56\uff0c\u5c5e\u4e8e2NF \u7b2c\u4e09\u8303\u5f0f\uff1a\u4e0d\u5b58\u5728\u4f20\u9012\u51fd\u6570\u4f9d\u8d56\uff0c\u5c5e\u4e8e3NF BC\u8303\u5f0f\uff1a\u6bcf\u4e2a\u51b3\u5b9a\u56e0\u7d20\u90fd\u542b\u6709\u5019\u9009\u7801 \u7b2c\u56db\u8303\u5f0f\uff1a\u6240\u6709\u7684\u975e\u5e73\u51e1\u591a\u503c\u4f9d\u8d56\u7684\u51b3\u5b9a\u56e0\u7d20\u90fd\u542b\u6709\u7801","title":"\u8303\u5f0f"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_48","text":"","title":"\u6570\u636e\u4f9d\u8d56\u516c\u7406\u7cfb\u7edf"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_49","text":"\u8bbe\u53c8\u6ee1\u8db3\u51fd\u6570\u4f9d\u8d56\u96c6 F \u7684\u5173\u7cfb\u6a21\u5f0f \\(R<U, F>\\) \uff0c\u5bf9\u4e8e R \u7684\u4efb\u4e00\u5173\u7cfb r\uff0c\u82e5\u4e00\u4e2a\u5173\u7cfb\u4e2d\u51fd\u6570\u4f9d\u8d56 \\(X\\rightarrow Y\\) \u90fd\u6210\u7acb\uff0c\u5219\u79f0\u903b\u8f91\u8574\u542b \\(X\\rightarrow Y\\) \uff0c\u8bb0\u4e3a \\(F\\Rightarrow X\\rightarrow Y\\)","title":"\u903b\u8f91\u8574\u542b"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#armstrong","text":"\u7528\u9014\uff1a\u6c42\u7ed9\u5b9a\u5173\u7cfb\u6a21\u5f0f\u7684\u7801\uff0c\u4ece\u4e00\u7ec4\u51fd\u6570\u4f9d\u8d56\u6c42\u5f97\u8574\u542b\u7684\u51fd\u6570\u4f9d\u8d56 \u5bf9\u4e8e\u5173\u7cfb\u6a21\u5f0f \\(R<U,F>\\) \uff0c\u6709\u4e00\u4e0b\u5b9a\u5f8b \u81ea\u53cd\u5f8b\uff1a\u82e5 \\(Y\\subseteq X \\subseteq U\\) \uff0c\u5219 \\(F\\Rightarrow X\\rightarrow Y\\) \u589e\u5e7f\u5f8b\uff1a\u82e5 \\(F\\Rightarrow X\\rightarrow Y\\) \uff0c\u4e14 \\(Z\\subseteq U\\) \uff0c\u5219 \\(F\\Rightarrow ZX\\rightarrow ZY\\) \u4f20\u9012\u5f8b\uff1a\u82e5 \\(F\\Rightarrow X\\rightarrow Y\\) \u53ca \\(F\\Rightarrow Y\\rightarrow Z\\) \uff0c\u5219 \\(F\\Rightarrow X\\rightarrow Z\\) \u63a8\u7406\u53ef\u5f97\u4ee5\u4e0b\u89c4\u5219 \u5408\u5e76\u89c4\u5219\uff1a\u82e5 \\(X\\rightarrow Y,X\\rightarrow Z\\) \uff0c\u5219 \\(X\\rightarrow YZ\\) \u4f2a\u4f20\u9012\u89c4\u5219\uff1a\u82e5 \\(X\\rightarrow Y,WY\\rightarrow Z\\) \uff0c\u5219\u6709 \\(WX\\rightarrow Z\\) \u5206\u89e3\u89c4\u5219\uff1a\u82e5 \\(X\\rightarrow Y\\) \uff0c\u4e14 \\(Z\\subseteq Y\\) \uff0c\u5219\u6709 \\(X\\rightarrow Z\\)","title":"Armstrong \u516c\u7406\u7cfb\u7edf"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_50","text":"\\(X^+_F\\) \u79f0\u4e3a\u5c5e\u6027\u96c6 \\(X\\) \u5173\u4e8e\u51fd\u6570\u4f9d\u8d56\u96c6 \\(F\\) \u7684\u95ed\u5305 \u6c42 \\(X^+_F\\) \u7684\u65b9\u6cd5\uff1a\u5728\u51fd\u6570\u4f9d\u8d56 \\(F\\) \u627e\u5de6\u4fa7\u662f X \u7684\u5b50\u96c6\u7684\u4f9d\u8d56\u5e76\u4e0d\u65ad\u6269\u5927 \\(X\\) \u8fd9\u4e2a\u96c6\u5408\uff0c\u76f4\u5230\u4e0d\u80fd\u6269\u5927\u4e3a\u6b62","title":"\u51fd\u6570\u4f9d\u8d56\u96c6\u7684\u95ed\u5305"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_51","text":"\u51fd\u6570\u4f9d\u8d56\u96c6\u7b49\u4ef7\uff1a\u5982\u679c \\(G^+=F^+\\) \uff0c\u5219\u79f0\u51fd\u6570\u4f9d\u8d56\u96c6 \\(G\\) \u548c \\(F\\) \u7b49\u4ef7 / \u4e92\u4e3a\u8986\u76d6 \u6700\u5c0f\u4f9d\u8d56\u96c6\uff1a\u5982\u679c\u51fd\u6570\u4f9d\u8d56\u96c6 \\(F\\) \u6ee1\u8db3 $F $ \u4e2d\u4efb\u4e00\u51fd\u6570\u4f9d\u8d56\u7684\u53f3\u90e8\u4ec5\u6709\u5355\u4e00\u5c5e\u6027 \\(F\\) \u4e2d\u4e0d\u5b58\u5728\u8fd9\u6837\u7684\u51fd\u6570\u4f9d\u8d56 \\(X\\rightarrow A\\) \uff0c\u4f7f\u5f97 \\(F\\) \u4e0e \\(F-\\{X\\rightarrow A\\}\\) \u7b49\u4ef7 \\(F\\) \u4e2d\u4e0d\u5b58\u5728\u8fd9\u6837\u7684\u51fd\u6570\u4f9d\u8d56 \\(X\\rightarrow A\\) \uff0c \\(X\\) \u6709\u771f\u5b50\u96c6 \\(Z\\) \u4f7f\u5f97 \\(F\\) \u4e0e \\(F-\\{X\\rightarrow A\\}\\cup \\{Z\\rightarrow A\\}\\) \u7b49\u4ef7 \u5219\u79f0 \\(F\\) \u662f\u6700\u5c0f\u4f9d\u8d56\u96c6 \u6216 \u6700\u5c0f\u8986\u76d6\uff0c\u8bb0\u4e3a \\(F_{min}\\) \uff0c\u5373\u8981\u6c42\u51fd\u6570\u4f9d\u8d56\u96c6\u662f\u6700\u5c0f\u7684 \u6c42\u51fd\u6570\u4f9d\u8d56\u96c6 \\(F\\) \u7684 \\(F_{min}\\) \u7684\u65b9\u6cd5 \u5148\u5c06\u51fd\u6570\u4f9d\u8d56\u53f3\u4fa7\u53f3\u4fa7\u662f\u591a\u5c5e\u6027\u7684\u5206\u89e3\u5f00\u591a\u4e2a\u51fd\u6570\u4f9d\u8d56 \u7136\u540e\u9010\u4e00\u68c0\u67e5\u6bcf\u4e00\u4e2a\u51fd\u6570\u4f9d\u8d56\uff0c\u68c0\u67e5\u8fd9\u4e2a\u51fd\u6570\u4f9d\u8d56\u662f\u5426\u53ef\u53bb \u6700\u540e\u9010\u4e00\u68c0\u67e5\u6bcf\u4e00\u4e2a\u51fd\u6570\u4f9d\u8d56\u7684\u5de6\u4fa7\u4e2d\u7684\u6bcf\u4e00\u4e2a\u5c5e\u6027\uff0c\u68c0\u67e5\u5355\u4e2a\u5c5e\u6027\u662f\u5426\u53ef\u53bb \u5176\u4ed6\u8003\u70b9\uff1a\u8ba1\u7b97\u7801\u7684\u7b97\u6cd5","title":"\u6700\u5c0f\u4f9d\u8d56\u96c6"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_52","text":"","title":"\u6a21\u5f0f\u5206\u89e3"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_53","text":"\u638c\u63e1\u5224\u65ad\u6a21\u5f0f\u5206\u89e3\u65e0\u635f\u8fde\u63a5\u6027\u7684\u7b97\u6cd5\uff0c\u7565","title":"\u65e0\u635f\u8fde\u63a5\u6027"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_54","text":"\u7565","title":"\u51fd\u6570\u4f9d\u8d56\u4fdd\u6301"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_55","text":"","title":"\u7b2c\u516d\u7ae0 \u6570\u636e\u5e93\u5e94\u7528\u5f00\u53d1"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#t-sql","text":"","title":"T-SQL"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_56","text":"declare @< \u5c40\u90e8\u53d8\u91cf\u540d > < \u6570\u636e\u7c7b\u578b > [, @< \u5c40\u90e8\u53d8\u91cf\u540d > < \u6570\u636e\u7c7b\u578b > ...] # \u58f0\u660e set @< \u5c40\u90e8\u53d8\u91cf\u540d > = < \u8868\u8fbe\u5f0f > # \u8d4b\u503c select @< \u5c40\u90e8\u53d8\u91cf\u540d > = < \u8868\u8fbe\u5f0f > [, @< \u5c40\u90e8\u53d8\u91cf\u540d > = < \u8868\u8fbe\u5f0f > ] # select \u53ef\u4ee5\u4e00\u6b21\u8d4b\u503c\u591a\u4e2a\u53d8\u91cf set @< \u5c40\u90e8\u53d8\u91cf\u540d > = ( select \u67e5\u8be2 ) # \u67e5\u8be2\u7ed3\u679c\u8d4b\u503c print \u5b57\u7b26\u4e32 | \u5c40\u90e8\u53d8\u91cf | \u5168\u5c40\u53d8\u91cf | \u51fd\u6570 # \u8f93\u51fa","title":"\u53d8\u91cf"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_57","text":"begin...end begin # \u4e00\u4e2a begin ... end \u662f\u4e00\u4e2a\u8bed\u53e5\u5757 SQL\u8bed\u53e51 SQL\u8bed\u53e52 ... end if...else if < \u6761\u4ef6\u8868\u8fbe\u5f0f > { \u8bed\u53e5 1 | \u8bed\u53e5\u5757 1 } # \u91cc\u9762\u6709 begin ... end [ else { \u8bed\u53e5 2 | \u8bed\u53e5\u5757 2 } ] while while < \u903b\u8f91\u8868\u8fbe\u5f0f > { \u8bed\u53e5 1 | \u8bed\u53e5\u5757 1 } # \u91cc\u9762\u6709 begin ... end break / continue / return \u7565","title":"\u6d41\u7a0b\u63a7\u5236\u8bed\u53e5"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_58","text":"","title":"\u51fd\u6570"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_59","text":"\u7565","title":"\u5185\u7f6e\u51fd\u6570"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_60","text":"\u6807\u91cf\u51fd\u6570 create function [ < \u6240\u6709\u8005 > .] < \u51fd\u6570\u540d > ([ { @< \u53c2\u6570\u540d > [ as ] < \u53c2\u6570\u7c7b\u578b > [ =< \u9ed8\u8ba4\u503c > ] } [,....] ]) returns < \u8fd4\u56de\u53c2\u6570\u7c7b\u578b > [ as ] begin < \u51fd\u6570\u4f53 > return < \u8fd4\u56de\u503c\u8868\u8fbe\u5f0f > end \u6807\u91cf\u51fd\u6570\u7684\u8c03\u7528 select @< \u53d8\u91cf\u540d > = dbo . < \u51fd\u6570\u540d > ( \u5b9e\u53c2 1 ,..., \u5b9e\u53c2 n ) # \u65b9\u5f0f 1 select exec @< \u53d8\u91cf\u540d > = dbo . < \u51fd\u6570\u540d > \u5b9e\u53c2 1 ,..., \u5b9e\u53c2 n # \u65b9\u5f0f 2 exec \u5185\u5d4c\u8868\u503c\u51fd\u6570 create function [ < \u6240\u6709\u8005 > .] < \u51fd\u6570\u540d > ([ { @< \u53c2\u6570\u540d > [ as ] < \u53c2\u6570\u7c7b\u578b > [ =< \u9ed8\u8ba4\u503c > ] } [,....] ]) returns table [ as ] begin return ( < select > \u8bed\u53e5 ) end \u5185\u5d4c\u8868\u503c\u51fd\u6570\u7684\u8c03\u7528 # \u53ea\u80fd\u901a\u8fc7 select select * from < \u51fd\u6570\u540d > ( \u53c2\u6570\u8868 ) \u591a\u8bed\u53e5\u8868\u503c\u51fd\u6570 create function [ < \u6240\u6709\u8005 > .] < \u51fd\u6570\u540d > ([ { @< \u53c2\u6570\u540d > [ as ] < \u53c2\u6570\u7c7b\u578b > [ =< \u9ed8\u8ba4\u503c > ] } [,....] ]) returns @ reuturn_variable table < \u8868\u7684\u5b9a\u4e49 > [ as ] begin < \u51fd\u6570\u4f53 > return end \u591a\u8bed\u53e5\u8868\u503c\u51fd\u6570 # \u53ea\u80fd\u901a\u8fc7 select select * from < \u51fd\u6570\u540d > ( \u53c2\u6570\u8868 ) \u5220\u9664\u51fd\u6570 drop function { [ < \u6240\u6709\u8005 > .] < \u51fd\u6570\u540d > } [,... n ]","title":"\u7528\u6237\u81ea\u5b9a\u4e49\u51fd\u6570"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_61","text":"","title":"\u6e38\u6807"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_62","text":"\u9759\u6001\u6e38\u6807 \u53ea\u8bfb \u52a8\u6001\u6e38\u6807 \u80fd\u591f\u53cd\u6620\u5bf9\u7ed3\u679c\u96c6\u4e2d\u6240\u505a\u7684\u66f4\u6539 \u53ea\u8fdb\u6e38\u6807 \u53ea\u652f\u6301\u4ece\u5934\u5230\u5c3e\u63d0\u53d6\u6570\u636e \u952e\u96c6\u9a71\u52a8\u6e38\u6807 \u53ef\u4ee5\u4fee\u6539\u57fa\u672c\u8868\u4e2d\u975e\u5173\u952e\u5b57\u5217\u7684\u503c\uff0c\u4f46\u4e0d\u53ef\u4ee5\u63d2\u5165\u6570\u636e","title":"\u6e38\u6807\u7c7b\u578b"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_63","text":"declare < \u6e38\u6807\u540d > cursor [ local | global ] -- \u6e38\u6807\u4f5c\u7528\u57df [ forword_only | scroll ] -- \u6e38\u6807\u79fb\u52a8\u65b9\u5411 [ static | keyset | dynamic | fast_forward ] -- \u6e38\u6807\u7c7b\u578b [ read_only | scroll_locks | optimistic ] -- \u8bbf\u95ee\u5c5e\u6027 [ type_warning ] -- \u7c7b\u578b\u8f6c\u6362\u8b66\u544a for < select\u8bed\u53e5 > [ for update [ of < \u5217\u540d > [,... n ]] -- \u53ef\u4fee\u6539\u7684\u5217","title":"\u58f0\u660e\u6e38\u6807"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_64","text":"open { { [ global ] < \u6e38\u6807\u540d > } | @< \u6e38\u6807\u53d8\u91cf\u540d > } -- eg select '\u6e38\u6807 KH_cur \u6570\u636e\u884c\u6570' = @@ CURSOR_ROWS","title":"\u6253\u5f00\u6e38\u6807"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_65","text":"fetch [ [ next | prior | first | last | absolute { n |@ nvar } | relative { n |@ nvar } ] from ] { { [ global ] < \u6e38\u6807\u540d > } | @< \u6e38\u6807\u53d8\u91cf\u540d > } [ into @ variable_name [,... n ]]","title":"\u8bfb\u53d6\u6e38\u6807"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_66","text":"close { { [ global ] < \u6e38\u6807\u540d > } |@< \u6e38\u6807\u53d8\u91cf\u540d > }","title":"\u5173\u95ed\u6e38\u6807"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_67","text":"deallocate { { [ global ] < \u6e38\u6807\u540d > } |@< \u6e38\u6807\u53d8\u91cf\u540d > }","title":"\u91ca\u653e\u6e38\u6807"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_68","text":"\u7565","title":"\u6e38\u6807\u53d8\u91cf"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_69","text":"CURSOR_STATUS ( 'loacl' | 'global' | 'variable' , '\u6e38\u6807\u540d' | '\u6e38\u6807\u53d8\u91cf\u540d' ) -- eg set @ statusVar = CURSOR_STATUS ( 'local' , 'CUR' )","title":"\u6e38\u6807\u51fd\u6570"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_70","text":"\u5b58\u50a8\u8fc7\u7a0b\u7f16\u8bd1\u548c\u4f18\u5316\u540e\u5b58\u653e\u5728\u6570\u636e\u5e93\u670d\u52a1\u5668\u4e0a\uff0c\u6267\u884c\u4e00\u6b21\u540e\u5b58\u653e\u5728 \u9ad8\u7f13 \u4e2d \u4f18\u70b9\uff1a \u63d0\u9ad8\u7cfb\u7edf\u6027\u80fd \u4ee3\u7801\u590d\u7528\uff0c\u6267\u884c\u6548\u7387\u9ad8","title":"\u5b58\u50a8\u8fc7\u7a0b"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_71","text":"create proc [ edure ] < \u5b58\u50a8\u8fc7\u7a0b\u540d > [ { @< \u53c2\u6570 >< \u6570\u636e\u7c7b\u578b > } [ = default ][ output ]] [,... n1 ] as < SQL\u8bed\u53e5 > [... n2 ]","title":"\u5b58\u50a8\u8fc7\u7a0b\u7684\u5b9a\u4e49"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_72","text":"[ exec [ ute ]] < \u5b58\u50a8\u8fc7\u7a0b\u540d > [[ @< \u53c2\u6570\u540d >= ] { < \u503c >|@< \u53d8\u91cf > [ output ] | [ default ] } [,... n ]] -- deaflut \u8868\u793a\u7528\u9ed8\u8ba4\u503c","title":"\u5b58\u50a8\u8fc7\u7a0b\u7684\u6267\u884c"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_73","text":"if exists ( select name from sysobjects where name = 'eg' and type = 'P' ) drop procedure eg -- \u5220\u9664\u51fd\u6570\u7b49\u540c\u7406","title":"\u5220\u9664\u540c\u540d\u5b58\u50a8\u8fc7\u7a0b"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_74","text":"alter proc [ edure ] < \u5b58\u50a8\u8fc7\u7a0b\u540d > [ { @< \u53c2\u6570 >< \u6570\u636e\u7c7b\u578b > } [ = default ][ output ]] [,... n1 ] as < SQL\u8bed\u53e5 > [... n2 ]","title":"\u4fee\u6539\u5b58\u50a8\u8fc7\u7a0b"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_75","text":"drop proc [ edure ] { < \u5b58\u50a8\u8fc7\u7a0b\u540d > } [,... n ]","title":"\u5220\u9664\u5b58\u50a8\u8fc7\u7a0b"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_76","text":"","title":"\u89e6\u53d1\u5668"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_77","text":"\u89e6\u53d1\u7c7b\u578b\uff1ainsert / update / delete \u89e6\u53d1\u65b9\u5f0f\uff1aafter / instead of","title":"\u89e6\u53d1\u5668\u7684\u5206\u7c7b"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_78","text":"create trigger < \u89e6\u53d1\u5668\u540d > on { < \u57fa\u672c\u8868 >|< \u89c6\u56fe > } -- \u6307\u5b9a\u89e6\u53d1\u5668\u540d\u53ca\u64cd\u4f5c\u5bf9\u8c61 { for | after | instead of } { [ delete ][,][ insert ][,][ update ] } -- \u5b9a\u4e49\u89e6\u53d1\u5668\u7684\u7c7b\u578b\uff0c\u9ed8\u8ba4\u662f after as [ if update ( < \u5217\u540d > )[ { and | or } update ( < \u5217\u540d > )] [,... n ] ] < SQL\u8bed\u53e5 > [,... n ] -- \u53ef\u5305\u542b\u4e00\u6761\u6216\u591a\u6761SQL\u8bed\u53e5","title":"\u521b\u5efa\u89e6\u53d1\u5668"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_79","text":"alter table { enable | disable } < \u89e6\u53d1\u5668\u540d >","title":"\u89e6\u53d1\u5668\u7684\u7981\u6b62\u4e0e\u542f\u7528"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_80","text":"alter trigger < \u89e6\u53d1\u5668\u540d > on { < \u57fa\u672c\u8868 >|< \u89c6\u56fe > } -- \u6307\u5b9a\u89e6\u53d1\u5668\u540d\u53ca\u64cd\u4f5c\u5bf9\u8c61 { for | after | instead of } { [ delete ][,][ insert ][,][ update ] } -- \u5b9a\u4e49\u89e6\u53d1\u5668\u7684\u7c7b\u578b\uff0c\u9ed8\u8ba4\u662f after as [ if update ( < \u5217\u540d > )[ { and | or } update ( < \u5217\u540d > )] [,... n ] ] < SQL\u8bed\u53e5 > [,... n ] -- \u53ef\u5305\u542b\u4e00\u6761\u6216\u591a\u6761SQL\u8bed\u53e5","title":"\u4fee\u6539\u89e6\u53d1\u5668"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_81","text":"drop trigger { < \u89e6\u53d1\u5668\u540d > } [,... n ]","title":"\u5220\u9664\u89e6\u53d1\u5668"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_82","text":"","title":"\u6570\u636e\u5e93\u8bbf\u95ee\u63a5\u53e3"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#odbc","text":"\u7ec4\u6210\uff1aODBC\u6570\u636e\u5e93\u5e94\u7528\u7a0b\u5e8f\uff0c\u9a71\u52a8\u7a0b\u5e8f\u7ba1\u7406\u5668\uff0c\u9a71\u52a8\u7a0b\u5e8f\uff0c\u6570\u636e\u6e90 5\u9636\u6bb5\uff1a\u914d\u7f6e\u6570\u636e\u6e90\uff0c\u8fde\u63a5\u6570\u636e\u6e90\uff0c\u521d\u59cb\u5316\u5e94\u7528\u7a0b\u5e8f\uff0cSQL\u5904\u7406\uff0c\u5904\u7406\u7ed3\u675f \u4f18\u70b9\uff1a\u4ee5\u7edf\u4e00\u7684\u65b9\u5f0f\u5904\u7406\u6240\u6709\u6570\u636e\u5e93","title":"\u5f00\u653e\u6570\u636e\u5e93\u8fde\u63a5(ODBC)"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#jdbc","text":"\u7ec4\u6210\uff1aJava\u5e94\u7528\u7a0b\u5e8f\uff0cJDBC\u9a71\u52a8\u7a0b\u5e8f\u7ba1\u7406\u5668\uff0cJDBC\u9a71\u52a8\u7a0b\u5e8f\uff0c\u6570\u636e\u5e93","title":"JDBC"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#adonet","text":"","title":"ADO.NET"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_83","text":"\u4f53\u7cfb\u7ed3\u6784\uff1a\u5355\u7528\u6237\u6a21\u5f0f\uff0c\u4e3b\u4ece\u5f0f\u591a\u7528\u6237\u6a21\u5f0f\uff0cC/S\u6a21\u5f0f\uff0cB/S\u6a21\u5f0f","title":"\u6570\u636e\u5e93\u5e94\u7528\u7cfb\u7edf\u4f53\u7cfb\u7ed3\u6784"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_84","text":"","title":"\u7b2c\u4e03\u7ae0 \u6570\u636e\u5e93\u4fdd\u62a4"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_85","text":"\u975e\u6cd5\u7528\u6237 \u975e\u6cd5\u6570\u636e \u5404\u79cd\u6545\u969c \u591a\u7528\u6237\u7684\u5e76\u53d1\u8bbf\u95ee","title":"\u5bf9\u6570\u636e\u5e93\u7684\u7834\u574f"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_86","text":"\u6570\u636e\u5e93\u7684\u5b89\u5168\u63a7\u5236 \u7528\u6237\u8bc6\u522b\u4e0e\u9274\u522b -- \u521b\u5efa\u767b\u5f55\u540d create login < \u767b\u5f55\u540d > with password = '<\u5bc6\u7801>' , default_database = < \u5173\u8054\u7684\u6570\u636e\u5e93 > -- \u521b\u5efa\u7528\u6237\u540d create user < \u7528\u6237\u540d > for login < \u767b\u5f55\u540d > # \u767b\u5f55\u540d\u4e0e\u7528\u6237\u540d\u5173\u8054 \u8bbf\u95ee\u63a7\u5236 -- \u6388\u6743 grant < \u6743\u9650 > [, < \u6743\u9650 > ...] # all privileges on < \u5bf9\u8c61\u7c7b\u578b > < \u5bf9\u8c61\u540d > [, < \u5bf9\u8c61\u7c7b\u578b > < \u5bf9\u8c61\u540d > ...] to < \u7528\u6237 > [, < \u7528\u6237 > ...] [ with grant option ] # \u5141\u8bb8\u8f6c\u6388 -- \u6536\u56de\u6743\u9650 revoke < \u6743\u9650 > [, < \u6743\u9650 > ...] on < \u5bf9\u8c61\u7c7b\u578b > < \u5bf9\u8c61\u540d > [, < \u5bf9\u8c61\u7c7b\u578b > < \u5bf9\u8c61\u540d > ...] from < \u7528\u6237 > [, < \u7528\u6237 > ...] [ cascade ] # cascade \u8868\u793a\u7ea7\u8054\u56de\u6536 \u89c6\u56fe\u673a\u5236 \u5b89\u5168\u5ba1\u8ba1\u673a\u5236 SQL Server\u7684\u5b89\u5168\u673a\u5236 \u8eab\u4efd\u9a8c\u8bc1\u6a21\u5f0f \u767b\u5f55\u548c\u7528\u6237 \u6743\u9650\u7ba1\u7406 \u89d2\u8272\u7ba1\u7406","title":"\u6570\u636e\u5e93\u5b89\u5168"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_87","text":"\u51c6\u786e\u6027\uff0c\u6709\u6548\u6027\uff0c\u76f8\u5bb9\u6027","title":"\u6570\u636e\u5e93\u5b8c\u6574\u6027"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_88","text":"\u5b9e\u4f53\u5b8c\u6574\u6027 \u53c2\u7167\u5b8c\u6574\u6027 \u7528\u6237\u81ea\u5b9a\u4e49\u5b8c\u6574\u6027","title":"\u6570\u636e\u5e93\u5b8c\u6574\u6027\u63a7\u5236"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#sql-server","text":"","title":"SQL Server \u7684\u5b8c\u6574\u6027\u673a\u5236"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#constraint","text":"not null primary key check foreign key default unique check \u7ea6\u675f \u7ea6\u675f\u5b57\u6bb5\u6240\u5141\u8bb8\u7684\u8303\u56f4 [ constraint < \u7ea6\u675f\u540d > ] check ( < \u6761\u4ef6 > ) unique \u7ea6\u675f [ constraint < \u7ea6\u675f\u540d > ] unique","title":"\u7ea6\u675f Constraint"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#rule","text":"\u521b\u5efa\u89c4\u5219 create rule < \u89c4\u5219\u540d > as < \u6761\u4ef6\u8868\u8fbe\u5f0f > \u7ed1\u5b9a\u89c4\u5219 [ exec [ ute ]] sp_bindrule [ @ rulename = ] '<\u89c4\u5219\u540d>' ,[ @ objanme ] '<\u7ed1\u5b9a\u5bf9\u8c61\u540d>' \u89e3\u7ed1\u89c4\u5219 [ exec [ ute ]] sp_unbindrule [ @ objanme ] '<\u7ed1\u5b9a\u5bf9\u8c61\u540d>' \u5220\u9664\u89c4\u5219 drop rule < \u89c4\u5219\u540d > [,...]","title":"\u89c4\u5219 Rule"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#default","text":"\u7565","title":"\u9ed8\u8ba4 Default"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_89","text":"\u4e8b\u52a1\uff1a\u662f\u7528\u6237\u5b9a\u4e49\u7684\u4e00\u4e2a\u6570\u636e\u5e93\u64cd\u4f5c\u5e8f\u5217\uff0c\u8981\u4e48\u5168\u505a\uff0c\u8981\u4e48\u90fd\u4e0d\u505a\uff0c\u662f\u4e00\u4e2a\u4e0d\u53ef\u5206\u5272\u7684\u5de5\u4f5c\u5355\u4f4d\uff0c\u662fDBMS\u7684\u57fa\u672c\u5355\u4f4d","title":"\u5e76\u53d1\u63a7\u5236"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#acid","text":"\u539f\u5b50\u6027 \u4e00\u81f4\u6027 \u9694\u79bb\u6027 \u6301\u4e45\u6027","title":"\u4e8b\u52a1\u7684 ACID \u6027\u8d28"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_90","text":"4 \u4e2a\u72b6\u6001 \u4e8b\u52a1\u5f00\u59cb \u4e8b\u52a1\u8bfb / \u5199 \u4e8b\u52a1\u63d0\u4ea4 (COMMIT) \u4e8b\u52a1\u56de\u6eda (ROLLBACK)","title":"\u4e8b\u52a1\u7684\u6d3b\u52a8\u8fc7\u7a0b"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_91","text":"\u4e22\u5931\u66f4\u65b0 \u8bfb \u201c\u810f\u201d \u6570\u636e \u4e0d\u53ef\u91cd\u590d\u8bfb","title":"\u4e8b\u52a1\u7684\u5e76\u53d1\u6267\u884c"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_92","text":"\u4e8b\u52a1\u7684\u5e76\u53d1\u8c03\u5ea6\u662f\u6b63\u786e\u7684\u5f53\u4e14\u4ec5\u5f53\u5176\u7ed3\u679c\u4e0e\u4e32\u884c\u8c03\u5ea6\u6267\u884c\u7684\u7ed3\u679c\u76f8\u540c\uff0c\u53ef\u4e32\u884c\u5316\u662f\u5e76\u53d1\u63a7\u5236\u7684\u6b63\u786e\u6027\u7684\u51c6\u5219","title":"\u5e76\u53d1\u8c03\u5ea6\u7684\u53ef\u4e32\u884c\u6027"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_93","text":"\u5c01\u9501\u7c7b\u578b\uff1a \u6392\u4ed6\u9501\uff1a\u5199\u9501\u6216 X \u9501\uff0c\u81ea\u5df1\u53ef\u8bfb\u53ef\u5199\uff0c\u5176\u4ed6\u4e8b\u52a1\u65e0\u6cd5\u5bf9\u6570\u636e\u8fdb\u884c\u52a0\u9501\u6216\u64cd\u4f5c \u5171\u4eab\u9501\uff1a\u8bfb\u9501\u6216 S \u9501\uff0c\u81ea\u5df1\u53ea\u53ef\u8bfb\uff0c\u5176\u4ed6\u4e8b\u52a1\u53ea\u80fd\u52a0 S \u9501 \u5c01\u9501\u534f\u8bae\uff1a \u4e00\u7ea7\u5c01\u9501\u534f\u8bae\uff1a\u5bf9\u6570\u636e\u8fdb\u884c\u5199\u64cd\u4f5c\u65f6\u5fc5\u987b\u52a0X\u9501\uff0c\u4e8b\u52a1\u7ed3\u675f\u91ca\u653e\uff0c\u89e3\u51b3\u2018\u4e22\u5931\u66f4\u65b0\u2019 \u4e8c\u7ea7\u5c01\u9501\u534f\u8bae\uff1a\u4e00\u7ea7\u5c01\u9501\u534f\u8bae\u518d\u52a0\u4e0a\u5728\u8bfb\u6570\u636e\u524d\u52a0\u4e0a S \u9501\uff0c\u8bfb\u5b8c\u5373\u91ca\u653e\uff0c\u8fdb\u4e00\u6b65\u89e3\u51b3\u2018\u8bfb\u810f\u6570\u636e\u2019 \u4e09\u7ea7\u5c01\u9501\u534f\u8bae\uff1a\u4e00\u7ea7\u5c01\u9501\u534f\u8bae\u518d\u52a0\u4e0a\u5728\u8bfb\u6570\u636e\u524d\u52a0\u4e0a S \u9501\uff0c\u4e8b\u52a1\u7ed3\u675f\u91ca\u653e\uff0c\u8fdb\u4e00\u6b65\u89e3\u51b3\u2018\u4e0d\u53ef\u91cd\u590d\u5ea6\u2019 \u4e24\u6bb5\u9501\u534f\u8bae\uff1a\u6240\u6709\u4e8b\u52a1\u5fc5\u987b\u5206\u4e24\u4e2a\u9636\u6bb5\u5bf9\u6570\u636e\u52a0\u9501\u548c\u89e3\u9501\uff0c\u5373\u540c\u610f\u4e0a\u9501\uff0c\u7136\u540e\u518d\u7edf\u4e00\u89e3\u9501 \u6d3b\u9501 & \u6b7b\u9501\uff1a \u6d3b\u9501\uff1a\u5728\u5c01\u9501\u8fc7\u7a0b\u4e2d\u67d0\u4e2a\u4e8b\u52a1\u6c38\u8fdc\u5904\u4e8e\u7b49\u5f85\u7684\u72b6\u6001\u800c\u5f97\u4e0d\u5230\u5c01\u9501\u673a\u4f1a \u89e3\u51b3\u65b9\u6cd5\uff1a\u5148\u6765\u5148\u670d\u52a1 \u6b7b\u9501\uff1a\u82e5\u5e72\u4e8b\u52a1\u90fd\u5904\u4e8e\u7b49\u5f85\u72b6\u6001\uff0c\u76f8\u4e92\u7b49\u5f85\u5bf9\u65b9\u91ca\u653e\u9501 \u89e3\u51b3\u65b9\u6cd5\uff1a\u9884\u9632\u6cd5\uff1a\u987a\u5e8f\u7533\u8bf7\u6cd5\uff0c\u4e00\u6b21\u7533\u8bf7\u6cd5 \u200b \u89e3\u9664\u6cd5\uff1a\u5b9a\u65f6\u6cd5\uff0c\u6b7b\u9501\u68c0\u6d4b\u6cd5","title":"\u5c01\u9501"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_94","text":"","title":"\u6570\u636e\u5e93\u6062\u590d"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_95","text":"\u7cfb\u7edf\u6545\u969c \u4e8b\u52a1\u6545\u969c \u4ecb\u8d28\u6545\u969c \u8ba1\u7b97\u673a\u75c5\u6bd2 \u8bef\u64cd\u4f5c \u81ea\u7136\u707e\u5bb3 \u76d7\u7a83","title":"\u6545\u969c\u79cd\u7c7b"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_96","text":"\u628a\u6570\u636e\u5e93\u4ece\u9519\u8bef\u72b6\u6001\u6062\u590d\u5230\u67d0\u4e2a\u6b63\u786e\u7684\u72b6\u6001 \u6570\u636e\u5e93\u6062\u590d\u673a\u5236\u7684\u4e24\u4e2a\u65b9\u9762\uff1a\u4e00\u662f\u5efa\u7acb\u5197\u4f59\u6570\u636e\uff0c\u4e8c\u662f\u7cfb\u7edf\u51fa\u73b0\u6545\u969c\u540e\u5229\u7528\u5197\u4f59\u6570\u636e\u5c06\u6570\u636e\u5e93\u6062\u590d\u5230\u67d0\u4e2a\u6b63\u5e38\u7684\u72b6\u6001 \u5907\u4efd\uff1a\u6570\u636e\u8f6c\u5b58\uff0c\u767b\u5f55\u65e5\u5fd7\u6587\u4ef6","title":"\u6570\u636e\u5e93\u6062\u590d\u6280\u672f"},{"location":"%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/#_97","text":"\u6570\u636e\u5e93\u57fa\u7840\u6559\u7a0b\uff08\u7b2c\u4e09\u7248\uff09 \u987e\u97f5\u534e \u7535\u5b50\u5de5\u4e1a\u51fa\u7248\u793e","title":"\u53c2\u8003"}]}